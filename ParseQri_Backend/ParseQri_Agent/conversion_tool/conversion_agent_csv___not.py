"""
json_to_csv_agent.py

A robust script that reads `preprocessed_data.json` generated by
preprocessing_agent.py and creates CSV files for each PDF entry.
"""

import json
import logging
import pandas as pd
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Any, Union, Optional

@dataclass
class CSVConversionResult:
    """
    Data class to store the results of a JSON -> CSV conversion
    for a single PDF's data.
    """
    pdf_file: str
    info_csv_path: Optional[str] = None
    tables_csv_paths: List[str] = None
    error_message: Optional[str] = None

class JsonToCSVAgent:
    """
    Agent responsible for converting the preprocessed JSON output
    into one or more CSV files per PDF.

    The JSON input is expected to be a list of dictionaries, where each
    dictionary represents one PDF's preprocessed data:

    [
      {
        "original_file": "path/to/file1.pdf",
        "cleaned_text": "...",
        "structured_text": {
          "sentences": [...],
          "word_count": 123,
          "sections": {...}
        },
        "tables": [
          {
            "columns": [...],
            "data": [...]
          },
          ...
        ],
        "metadata": { ... },
        "error_message": null
      },
      ...
    ]
    """

    def __init__(
        self,
        output_dir: Union[str, Path] = "csv_output"
    ):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        self.logger = self._setup_logger()

    def _setup_logger(self) -> logging.Logger:
        """Set up a logger for the agent."""
        logger = logging.getLogger("JsonToCSVAgent")
        logger.setLevel(logging.INFO)

        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        return logger

    def convert_file(self, json_item: Dict[str, Any]) -> CSVConversionResult:
        """
        Convert a single PDF's preprocessed JSON dictionary into CSVs.
        
        - Creates an "info" CSV with fields like original_file, word_count, etc.
        - Creates a single CSV containing all tables with proper alignment
        - Returns a CSVConversionResult object with file paths or errors.
        """
        try:
            pdf_path = json_item.get("original_file", "unknown_file")
            base_name = Path(pdf_path).stem or "pdf_data"
            
            # Extract tables from the JSON
            tables = json_item.get("tables", [])
            if tables:
                # Initialize a dictionary to store all columns and their values
                all_columns = {}
                
                # Process each table
                for table in tables:
                    columns = table.get("columns", [])
                    data = table.get("data", [])
                    
                    # Process each column in the table
                    for col_idx, col_name in enumerate(columns):
                        # Clean and standardize column name
                        clean_col = col_name.strip().title().replace(" ", "_")
                        
                        # Get all values for this column
                        col_values = []
                        for row in data:
                            if col_idx < len(row):
                                val = row[col_idx]
                                if val is not None and str(val).strip():
                                    col_values.append(str(val).strip())
                        
                        # If column already exists, combine values with separator
                        if clean_col in all_columns:
                            # Combine existing and new values, removing duplicates
                            combined_values = list(set(all_columns[clean_col] + col_values))
                            all_columns[clean_col] = [' | '.join(combined_values)]
                        else:
                            all_columns[clean_col] = [' | '.join(col_values)]
                
                # Convert to DataFrame (no need for padding since each column has one row)
                combined_df = pd.DataFrame(all_columns)
                
                # Clean the data
                combined_df = combined_df.fillna('')
                combined_df = combined_df.apply(lambda col: col.str.strip())
                
                # Save to CSV
                tables_csv_path = self.output_dir / f"{base_name}_all_tables.csv"
                combined_df.to_csv(tables_csv_path, index=False)
                
                return CSVConversionResult(
                    pdf_file=pdf_path,
                    info_csv_path=None,
                    tables_csv_paths=[str(tables_csv_path)]
                )
            else:
                return CSVConversionResult(
                    pdf_file=pdf_path,
                    info_csv_path=None,
                    tables_csv_paths=[]
                )

        except Exception as e:
            self.logger.error(f"Error converting {json_item}: {str(e)}")
            return CSVConversionResult(
                pdf_file=json_item.get("original_file", "unknown_file"),
                error_message=str(e)
            )

    def convert_json_file(
        self,
        input_json_path: Union[str, Path]
    ) -> List[CSVConversionResult]:
        """
        Read the entire `preprocessed_data.json` file and combine all PDF data
        into a single CSV file with one row per PDF.
        
        Returns a list of CSVConversionResult objects.
        """
        results = []
        input_json_path = Path(input_json_path)
        all_pdf_data = {}  # Dictionary to store combined data from all PDFs

        self.logger.info(f"Loading preprocessed JSON from: {input_json_path}")
        with open(input_json_path, "r", encoding="utf-8") as f:
            data_list = json.load(f)

        if not isinstance(data_list, list):
            self.logger.error("The input JSON is not a list of PDF objects.")
            return []

        self.logger.info(f"Found {len(data_list)} PDF objects in the JSON.")
        
        # Process each PDF and collect data
        for item in data_list:
            try:
                pdf_path = item.get("original_file", "unknown_file")
                tables = item.get("tables", [])
                
                # Initialize row data with PDF filename
                pdf_data = {"PDF_Filename": Path(pdf_path).name}
                
                # Process tables for this PDF
                for table in tables:
                    columns = table.get("columns", [])
                    data = table.get("data", [])
                    
                    # Process each column in the table
                    for col_idx, col_name in enumerate(columns):
                        clean_col = col_name.strip().title().replace(" ", "_")
                        
                        # Get all values for this column
                        col_values = []
                        for row in data:
                            if col_idx < len(row):
                                val = row[col_idx]
                                if val is not None and str(val).strip():
                                    col_values.append(str(val).strip())
                        
                        # Add or update column values
                        if clean_col in pdf_data:
                            existing_values = pdf_data[clean_col].split(" | ")
                            combined_values = list(set(existing_values + col_values))
                            pdf_data[clean_col] = " | ".join(combined_values)
                        else:
                            pdf_data[clean_col] = " | ".join(col_values)
                
                # Add this PDF's data to the combined dictionary
                pdf_key = Path(pdf_path).name
                all_pdf_data[pdf_key] = pdf_data
                
                results.append(CSVConversionResult(
                    pdf_file=pdf_path,
                    tables_csv_paths=[]  # Will be updated after saving combined CSV
                ))
                
            except Exception as e:
                self.logger.error(f"Error processing {item}: {str(e)}")
                results.append(CSVConversionResult(
                    pdf_file=item.get("original_file", "unknown_file"),
                    error_message=str(e)
                ))

        # Convert combined data to DataFrame and save
        if all_pdf_data:
            combined_df = pd.DataFrame.from_dict(all_pdf_data, orient='index')
            combined_df = combined_df.fillna('')
            combined_df = combined_df.apply(lambda col: col.str.strip())
            
            # Save combined CSV
            combined_csv_path = self.output_dir / "combined_tables.csv"
            combined_df.to_csv(combined_csv_path, index=False)
            
            # Update all successful results with the combined CSV path
            for result in results:
                if not result.error_message:
                    result.tables_csv_paths = [str(combined_csv_path)]

        # Summarize
        success_count = sum(1 for r in results if not r.error_message)
        self.logger.info(
            f"Conversion complete. {success_count}/{len(results)} processed without errors."
        )
        self.logger.info(f"Combined data saved to: {combined_csv_path}")
        return results

# ---------------
# Example Usage
# ---------------
if __name__ == "__main__":
    converter = JsonToCSVAgent(output_dir="csv_output")

    input_json = "preprocessed_data.json"  # generated by your PreprocessingAgent
    results = converter.convert_json_file(input_json)

    print("\nConversion Summary:")
    for r in results:
        if r.error_message:
            print(f"❌ {r.pdf_file} => ERROR: {r.error_message}")
        else:
            print(f"✓ {r.pdf_file}")
            print(f"   Info CSV: {r.info_csv_path}")
            if r.tables_csv_paths:
                print("   Table CSVs:")
                for p in r.tables_csv_paths:
                    print(f"     - {p}")
