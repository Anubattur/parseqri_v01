[
  {
    "original_file": ".",
    "cleaned_text": "JOURNAL OF AMRAN UNIVERSITY J. Amr. Uni. 03 2023 p.259 Crowd Detection, Monitoring and Management A literature Review Hisham Haider Yusef Saad1,2,, Yahya Al-Ashmoery2,3, Adnan Haider3, Al-Marhabi Zaid3, Kaleed Alwasbi2 , Ruqaih Hussein Salman2 1Department of Computer Science, Amran University, Amran, Yemen 2Department of Information Technology, Al-Razi University 3Department of Mathematics  Computer, Faculty of Science, Sanaa University, Yemen 3Department of Cybersecurity and networking, Al-Razi University, Yemen Abstract The rapid increase in the global population has led to the emergence of large crowds during public events across various domains such as sports, music festivals, religious gatherings, and political campaigns. If these events are not properly organized and controlled, they have the potential to result in disasters. Tragically, stampedes occur every year, causing fatalities, disappearances, and injuries for many individuals. Therefore, crowd identification, monitoring, and control are problems that will be addressed and discussed in this paper in order to lessen casualties and prevent such catastrophes. The objective of this study is to present a thorough review of technologies and methods relevant to crowd management, planning, behaviour analysis, and counting. Furthermore, it aids researchers future progress by examining recent technology developments in the field of crowd planning and monitoring. Keywords Crowd Detection, Crowd Monitoring, Crowd Management, Crowd behaviour, Crowd simulation, Crowd density estimation. ةماعلا ثادحلأا للاخ سانلا نم ةريبك دوشح ترهظ كلذل ةجيتنو .بكوكلا ناكس ددع يف عيرسلا ديزا تلا ببسب صخلملا ىلإ امو ةيسايسلا تلامحلاو ةينيدلا تاعمجتلاو ةيقيسوملا تاناجرهملاو ةضايرلا كلذ يف امب ةايحلا تلااجم نم ديدعلا يف تايفولا نم صاخشلأا نم ديدعلا يناعي .حيحص لكشب اهتبقرامو اهميظنت متي مل اذإ ثراوك ىلإ يدؤت دق يتلاو كلذ يف اهيلع ةرطيسلاو اهتبقرامو دوشحلا ديدحت ةلكشم ةشقانم متيس كلذل .ماع لك عفادتلا ثداوحل ةجيتن تاباصلإاو ءافتخلااو بيلاسلأاو تاينقتلل ةلماش ةعجرام ميدقت وه ةسرادلا هذه نم فدهلا .ثراوكلا هذه لثم عنمو رئاسخلا ليلقت فدهب ثحبلا اذه يف نيثحابلا مدقت ىلع ثحبلا اذه دعاسي كلذ ىلع ةولاع .درافلأا دعو اهكولس ليلحتو اهطيطختو دوشحلا ةرادإب ةقلعتملا .دوشحلا ةبقرامو طيطخت لاجم يف ةثيدحلا ةيجولونكتلا تراوطتلا ةسراد للاخ نم لبقتسملا 1. Introduction During the Hajj period in 2015, over 2,000 individuals perished and over 850 sustained injuries 1. Additionally, a range of applications can benefit greatly from the knowledge of crowd counting and density estimation 2 such as the psychological impacts of individuals congregating in groups 3, animal migration 4, and bacterial activity 5. In general, crowd counting is applicable to a wide range of situations where it is essential to comprehend crowd behaviour such as Safety monitoring 6-8, Design of public spaces 9, 10, Evidencebased decisionmaking 9, 11, Disaster management 12, 13, and Virtual environments 14, 15. Three recent techniques have been developed for gathering crowd data wireless/radio frequency RF, vision, and web/social media data extraction. Mobile phones, wireless sensor networks WSN, radio frequency identification RFID, and near-field communication NFC-based systems for gathering crowd data have also been taken into consideration. Two methods have been proposed by researchers to gather data on crowds. These strategies are both device-based everyone carrying an RF-based device and device-free no participants carrying any RF devices. The size of the crowd population that is in need of tracking has a direct impact on the monitoring system accuracy and the difficulties encountered. Table I and Fig. 1 illustrate the crowd scale depending on the number of people in each frame. The population density can be divided into three crowd levels identified with the crowd monitoring system low-scale, normal-scale, and large- scale, depending on the number of people in each frame. _________________________________________________ Corresponding author E-mail hesham_haideryahoo.com Amran University Publishing J. Amr. Uni. 03 2023 p.259 Hisham H. Y. Saad et al. The rest of the paper is formatted as follows The crowd detection models are revised in Section 2. In sections 3 and 4, the monitoring and management of crowd are examined, while one case study is discussed in section 5. Section 6 presents the conclusion of this article. Table 1 Crowd scale levels Crowd scale level Count Low Scale 150 Normal Scale 150-550 Large Scale 550 a Low scale b Normal Scale 260 J. Amr. Uni. 03 2023 p.259 Hisham H. Y. Saad et al. c Large scale Fig 1 Crowd Scale Level a low-scale, b normal-scale, and c large-scale 16 2. Related Works In this paper, we will divide the related works to three types which are crowd detection, crowd monitoring and crowd management as presented in the coming three sections. 3. Crowd Detection There are several ways to locate a crowd in the past, a person would typically report a congestion on the other hand, several types of crowd detection systems, including Laser-based, Radio-based wifi, Radio-based RFID, Radio-based Bluetooth, video-based, and thermal-based are recently presented. In order to manage a crowd similar to the crowd in Fig. 2, you must first predict when it will form. This requires some accurate crowd detection techniques. Two examples of crowds are illustrated in Fig 2. The first one is a crowd of Black Lives Matter protest in Australia and the second demonstrates the pilgrims path to the Jamaraat Bridge in Mecca, Saudi Arabia. a Black Lives Matter protest in Australia. b Muslim pilgrims during Hajj Fig 2. Examples of crowds The authors of 17 present a system that makes advantage of smartphone users to scan nearby Bluetooth devices and assess population aspects in urban settings. The proposed system does more than just add devices up to more sophisticated capabilities. It examines flow direction and population density. 261 J. Amr. Uni. 03 2023 p.259 Hisham H. Y. Saad et al. To examine the system described, a dataset of 200000 findings from 1000 scanning devices was compiled over the course of three days. The outcome demonstrates the effectiveness of Bluetooth devices as a reliable technique for crowd detection and monitoring. Utilizing Bluetooth technology that was readily available and installed on the bus ceiling, a wireless system with innovative and affordable features was created 18 . The Bluetooth device in the bus then does a periodic scan for discoverable devices nearby. In order to identify an origin/destination relationship, the system postprocesses the data and compares it to bus position and ticket information. Wi-Fi-based systems for counting crowds face some difficulties. The capacity to distinguish between those outside the bus and true passengers is one of these difficulties. Numerous articles have researched and debated this issue, including 19 and 20, which find a solution by filtering the probes with a sliding window in order to eliminate the MAC addresses that have not been detected for an extended period of time. In 21, 22, and 23, people counters based on thermal cameras are introduced. Thermal camera- based systems, in contrast to optical cameras like those in Fig. 3, are less susceptible to background colour contrasts or ambient lighting levels, albeit the performance of the systems can be impacted by weather and heat sources. Real-time image processing models require a lot of computer power. Utilizing picture compression is one technique to cut down on the expensive computation 24. For the detectionbased methods, like Figure 1, researchers use a sliding window to detect the people in an image and then use this information to count the number of people 33, 34. However, in the case of extremely crowded scenes, which are difficult to detect e.g., dense density, severe occlusion for classical methods, the regressionbased method comes in handy. a b Fig 3. Crowd detection a The density estimation based on crowd counting b The detection based on crowd counting 2537 4. Crowd Monitoring Crowd monitoring has drawn greater attention recently. The number of research publications has significantly expanded, as seen in Fig 4 below 26. The figure shows an increasing especially from 2010 due to the increasing in the number of the casualties during the huge gathering in all over the world. 262 J. Amr. Uni. 03 2023 p.259 Hisham H. Y. Saad et al. Fig 4 Documents published per year on crowd monitoring. in Scopus Monitoring the crowd is a crucial step in determining the crowd dynamics that will improve event management and public safety. As a result, event organizers are advised to keep a watch on the crowd in order to see any dangers early on and take the required precautions 27 . The primary objective of crowd surveillance equipment is to gather important data, such as crowd size and density. The volume of crowd assembling at a monitored site can be calculated by calculating the population for precise and effective managing and planning 28. Closed-circuit television CCTV surveillance is the most common method of crowd monitoring in traditional crowd monitoring systems CMSs 29. A system of video cameras that are used to relay signals from certain locations to a specific set of monitors or displays, typically for surveillance or security purposes, is known as a CCTV system 30. Typically, CCTV systems have recording hardware that stores video signal for later use. Therefore, CCTV systems can be utilized in a variety of settings to keep an eye on and protect people, deter crime, and promote public safety. When there are obstacles or poor weather conditions at the monitored site, the CCTV camera cannot effectively distinguish strange actions or crowd situations. For a number of abnormal scenarios, such as crowding, hail, conflicts, fire, violence attacks, and trampling, a high-efficiency crowd management and evacuation model utilizing communication technologies and artificial intelligence AI is required. Consequently, a multitude of sensors, quick decision transmission, and in-depth data analysis make up the fundamental parts of CMS 31. The proposed system in 32 was constructed using two key parts. The information management component also contains a fuzzy logic module and a thermal video analyzer. Recent fuzzy models 33 and 34 can be used to improve performance. 5. Crowd Management Crowd management is the examination of people who determine an areas capacity prior to its utilization. The systematic planning, coordination, and supervision of the orderly gathering and movement of people is known as crowd management 35. Crowd management is the supportive, organized direction provided for the orderly movement of people. As a crucial component of crowd management, actions are done to limit or regulate crowd behaviour. Securing crowd safety may be a part of crowd control. Additionally, a set of acts and preparations that are made to use, facilitate, and move crowds can be referred to as crowd management. Its crucial to clear up a common misunderstanding about the difference between crowd control and crowd management. Although these two terms are frequently used synonymously, it is important to understand their differences in order to behave more correctly throughout an event. Crowd management encompasses facilitating crowd activities and movement in addition to maintaining crowd safety. On the other hand, crowd control is primarily concerned with the problems that develop once a crowd starts behaving disorderly or gets out of control 36. 263 J. Amr. Uni. 03 2023 p.259 Hisham H. Y. Saad et al. 6. Conclusion Globally, congested conditions are getting worse due to population expansion, global urbanization, high-speed transportation, and the spread of effective information. The paper discusses a number of technology developments for seeing, estimating, keeping an eye on, and controlling huge crowds. Furthermore, in integrated crowd control frameworks for varied crowd sizes, technologies, including RF, RFID, WIFI, Bluetooth, optical imaging, and CCTV cameras have been examined under specific conditions. Numerous uses of crowd modelling in the actual world for well-known disasters have been discussed for analysing of crowded situations and in anticipating crowd anomalies in real time crowd management systems. References 1 Hoseinpourfard M., et al.. The emergence of Hajj stampedes lessons for Hajj trauma centers. Trauma Monthly, 2017, 224. 2 Chen, Y., et al., Large group activity security risk assessment and risk early warning based on random forest algorithm. Pattern Recognition Letters, 2021. 144 p. 1-5. 3 Aveni, A.F., The not-so-lonely crowd Friendship groups in collective behavior. Sociometry, 1977 p. 96-99. 4 Parrish, J.K. and L. Edelstein-Keshet, Complexity, pattern, and evolutionary trade-offs in animal aggregation. Science, 1999. 2845411 p. 99-101. 5 Zhang, H.-P., et al., Collective motion and density fluctuations in bacterial colonies. Proceedings of the National Academy of Sciences, 2010. 10731 p. 13626-13630. 6 Yi, S., H. Li, and X. Wang, Pedestrian behavior modeling from stationary crowds with applications to intelligent surveillance. IEEE transactions on image processing, 2016. 259 p. 4354-4368. 7 Chaker, R., Z. Al Aghbari, and I.N. Junejo, Social network model for crowd anomaly detection and localization. Pattern Recognition, 2017. 61 p. 266-281. 8 Lee, S., H.G. Kim, and Y.M. Ro. STAN Spatio-temporal adversarial networks for abnormal event detection. in 2018 IEEE international conference on acoustics, speech and signal processing ICASSP. 2018. IEEE. 9 Deng, L., et al., Hospital crowdedness evaluation and in-hospital resource allocation based on image recognition technology. Scientific Reports, 2023. 131 p. 299. 10 Lu, L., et al., A study of pedestrian group behaviors in crowd evacuation based on an extended floor field cellular automaton model. Transportation research part C emerging technologies, 2017. 81 p. 317-329. 11 Liu, Z., et al., Decision-Making Framework for GI Layout Considering Site Suitability and Weighted Multi-Function Effectiveness A Case Study in Beijing Sub-Center. Water, 2022. 1411 p. 1765. 12 Koswatte, S., K. McDougall, and X. Liu, Crowd-Assisted Flood Disaster Management, in Application of Remote Sensing and GIS in Natural Resources and Built Infrastructure Management. 2023, Springer. p. 39-55. 13 Liu, J., Y. Chen, and Y. Chen, Emergency and disaster management-crowd evacuation research. Journal of Industrial Information Integration, 2021. 21 p. 100191. 14 Hu, R., et al., RDC-SAL Refine distance compensating with quantum scale-aware learning for crowd counting and localization. Applied Intelligence, 2022. 5212 p. 14336-14348. 15 Perez, H., et al., Task-based crowd simulation for heterogeneous architectures, in Innovative Research and Applications in Next-Generation High Performance Computing. 2016, IGI Global. p. 194-219. 264 J. Amr. Uni. 03 2023 p.259 Hisham H. Y. Saad et al. 16 Jiang, Y., et al., Ultra large-scale crowd monitoring system architecture and design issues. IEEE Internet of Things Journal, 2021. 813 p. 10356-10366. 17 Weppner, J., et al., Participatory bluetooth scans serving as urban crowd probes. IEEE Sensors Journal, 2014. 1412 p. 4196-4206. 18 Kostakos, V., T. Camacho, and C. Mantero. Wireless detection of end-to-end passenger trips on public transport buses. in 13th International IEEE Conference on Intelligent Transportation Systems. 2010. IEEE. 19 Handte, M., et al. Crowd Density Estimation for Public Transport Vehicles. in EDBT/ICDT Workshops. 2014. Citeseer. 20 Handte, M., et al., An internet-of-things enabled connected navigation system for urban bus riders. IEEE internet of things journal, 2016. 35 p. 735-744. 21 Lin, W.-C., W.K. Seah, and W. Li. Exploiting radio irregularity in the Internet of Things for automated people counting. in 2011 IEEE 22nd International Symposium on Personal, Indoor and Mobile Radio Communications. 2011. IEEE. 22 Tikkanen, T., People detection and tracking using a network of low-cost depth cameras. Aalto University, 2014. 23 Tyndall, A., R. Cardell-Oliver, and A. Keating, Occupancy estimation using a low-pixel count thermal imager. IEEE Sensors Journal, 2016. 1610 p. 3784-3791. 24 Saad, A.-M.H., et al., Impact of spatial dynamic search with matching threshold strategy on fractal image compression algorithm performance study. IEEE Access, 2020. 8 p. 52687-52699. 25 Li, M., et al. Estimating the number of people in crowded scenes by mid based foreground segmentation and head-shoulder detection. in 2008 19th international conference on pattern recognition. 2008. IEEE. 26 Singh, U., et al., Crowd monitoring State-of-the-art and future directions. IETE Technical Review, 2021. 386 p. 578-594. 27 Li, X., et al., Data fusion for intelligent crowd monitoring and management systems A survey. IEEE Access, 2021. 9 p. 47069-47083. 28 Ding, X., et al., Crowd density estimation using fusion of multi-layer features. IEEE Transactions on Intelligent Transportation Systems, 2020. 228 p. 4776-4787. 29 Mallah, J.E., et al. Crowd Monitoring Critical Situations Prevention Using Smartphones and Group Detection. in Distributed, Ambient, and Pervasive Interactions Third International Conference, DAPI 2015, Held as Part of HCI International 2015, Los Angeles, CA, USA, August 2- 7, 2015, Proceedings 3. 2015. Springer. 30 Davies, A.C., J.H. Yin, and S.A. Velastin, Crowd monitoring using image processing. Electronics  Communication Engineering Journal, 1995. 71 p. 37-47. 31 Sirmacek, B. and P. Reinartz. Automatic crowd density and motion analysis in airborne image sequences based on a probabilistic framework. in 2011 IEEE International Conference on Computer Vision Workshops ICCV Workshops. 2011. IEEE. 32 Khozium, M.O., A.G. Abuarafah, and E. AbdRabou, A proposed computer-based system architecture for crowd management of pilgrims using thermography. Life Science Journal, 2012. 92 p. 377-383. 33 Saad, H.H.Y., et al., A robust structure identification method for evolving fuzzy system. Expert Systems with Applications, 2018. 93 p. 267-282. 34 Saad, H.H.Y., N.A.M. Isa, and M.M. Ahmed, A structural evolving approach for fuzzy systems. IEEE Transactions on Fuzzy Systems, 2019. 282 p. 273-287. 265 J. Amr. Uni. 03 2023 p.259 Hisham H. Y. Saad et al. 35 Al-Shaery, A. and M. Khozium, Crowd management challenges Tackling approach for real time crowd monitoring. Int. J. Sci. Eng. Res., 2019. 36 Saleh, S.A.M., S.A. Suandi, and H. Ibrahim, Recent survey on crowd density estimation and counting for visual surveillance. Engineering Applications of Artificial Intelligence, 2015. 41 p. 103-114. 37 Deng, Lijia,Zhou, QinghuaWang, ShuihuaGórriz, Juan Manuel Zhang, Yudong Deep learning in crowd counting A survey. 2023 266",
    "structured_text": {
      "sentences": [
        "JOURNAL OF AMRAN UNIVERSITY J.",
        "Amr.",
        "Uni.",
        "03 2023 p.259 Crowd Detection, Monitoring and Management A literature Review Hisham Haider Yusef Saad1,2,, Yahya Al-Ashmoery2,3, Adnan Haider3, Al-Marhabi Zaid3, Kaleed Alwasbi2 , Ruqaih Hussein Salman2 1Department of Computer Science, Amran University, Amran, Yemen 2Department of Information Technology, Al-Razi University 3Department of Mathematics  Computer, Faculty of Science, Sanaa University, Yemen 3Department of Cybersecurity and networking, Al-Razi University, Yemen Abstract The rapid increase in the global population has led to the emergence of large crowds during public events across various domains such as sports, music festivals, religious gatherings, and political campaigns.",
        "If these events are not properly organized and controlled, they have the potential to result in disasters.",
        "Tragically, stampedes occur every year, causing fatalities, disappearances, and injuries for many individuals.",
        "Therefore, crowd identification, monitoring, and control are problems that will be addressed and discussed in this paper in order to lessen casualties and prevent such catastrophes.",
        "The objective of this study is to present a thorough review of technologies and methods relevant to crowd management, planning, behaviour analysis, and counting.",
        "Furthermore, it aids researchers future progress by examining recent technology developments in the field of crowd planning and monitoring.",
        "Keywords Crowd Detection, Crowd Monitoring, Crowd Management, Crowd behaviour, Crowd simulation, Crowd density estimation.",
        "ةماعلا ثادحلأا للاخ سانلا نم ةريبك دوشح ترهظ كلذل ةجيتنو .بكوكلا ناكس ددع يف عيرسلا ديزا تلا ببسب صخلملا ىلإ امو ةيسايسلا تلامحلاو ةينيدلا تاعمجتلاو ةيقيسوملا تاناجرهملاو ةضايرلا كلذ يف امب ةايحلا تلااجم نم ديدعلا يف تايفولا نم صاخشلأا نم ديدعلا يناعي .حيحص لكشب اهتبقرامو اهميظنت متي مل اذإ ثراوك ىلإ يدؤت دق يتلاو كلذ يف اهيلع ةرطيسلاو اهتبقرامو دوشحلا ديدحت ةلكشم ةشقانم متيس كلذل .ماع لك عفادتلا ثداوحل ةجيتن تاباصلإاو ءافتخلااو بيلاسلأاو تاينقتلل ةلماش ةعجرام ميدقت وه ةسرادلا هذه نم فدهلا .ثراوكلا هذه لثم عنمو رئاسخلا ليلقت فدهب ثحبلا اذه يف نيثحابلا مدقت ىلع ثحبلا اذه دعاسي كلذ ىلع ةولاع .درافلأا دعو اهكولس ليلحتو اهطيطختو دوشحلا ةرادإب ةقلعتملا .دوشحلا ةبقرامو طيطخت لاجم يف ةثيدحلا ةيجولونكتلا تراوطتلا ةسراد للاخ نم لبقتسملا 1.",
        "Introduction During the Hajj period in 2015, over 2,000 individuals perished and over 850 sustained injuries 1.",
        "Additionally, a range of applications can benefit greatly from the knowledge of crowd counting and density estimation 2 such as the psychological impacts of individuals congregating in groups 3, animal migration 4, and bacterial activity 5.",
        "In general, crowd counting is applicable to a wide range of situations where it is essential to comprehend crowd behaviour such as Safety monitoring 6-8, Design of public spaces 9, 10, Evidencebased decisionmaking 9, 11, Disaster management 12, 13, and Virtual environments 14, 15.",
        "Three recent techniques have been developed for gathering crowd data wireless/radio frequency RF, vision, and web/social media data extraction.",
        "Mobile phones, wireless sensor networks WSN, radio frequency identification RFID, and near-field communication NFC-based systems for gathering crowd data have also been taken into consideration.",
        "Two methods have been proposed by researchers to gather data on crowds.",
        "These strategies are both device-based everyone carrying an RF-based device and device-free no participants carrying any RF devices.",
        "The size of the crowd population that is in need of tracking has a direct impact on the monitoring system accuracy and the difficulties encountered.",
        "Table I and Fig.",
        "1 illustrate the crowd scale depending on the number of people in each frame.",
        "The population density can be divided into three crowd levels identified with the crowd monitoring system low-scale, normal-scale, and large- scale, depending on the number of people in each frame.",
        "_________________________________________________ Corresponding author E-mail hesham_haideryahoo.com Amran University Publishing J.",
        "Amr.",
        "Uni.",
        "03 2023 p.259 Hisham H.",
        "Y.",
        "Saad et al.",
        "The rest of the paper is formatted as follows The crowd detection models are revised in Section 2.",
        "In sections 3 and 4, the monitoring and management of crowd are examined, while one case study is discussed in section 5.",
        "Section 6 presents the conclusion of this article.",
        "Table 1 Crowd scale levels Crowd scale level Count Low Scale 150 Normal Scale 150-550 Large Scale 550 a Low scale b Normal Scale 260 J.",
        "Amr.",
        "Uni.",
        "03 2023 p.259 Hisham H.",
        "Y.",
        "Saad et al.",
        "c Large scale Fig 1 Crowd Scale Level a low-scale, b normal-scale, and c large-scale 16 2.",
        "Related Works In this paper, we will divide the related works to three types which are crowd detection, crowd monitoring and crowd management as presented in the coming three sections.",
        "3.",
        "Crowd Detection There are several ways to locate a crowd in the past, a person would typically report a congestion on the other hand, several types of crowd detection systems, including Laser-based, Radio-based wifi, Radio-based RFID, Radio-based Bluetooth, video-based, and thermal-based are recently presented.",
        "In order to manage a crowd similar to the crowd in Fig.",
        "2, you must first predict when it will form.",
        "This requires some accurate crowd detection techniques.",
        "Two examples of crowds are illustrated in Fig 2.",
        "The first one is a crowd of Black Lives Matter protest in Australia and the second demonstrates the pilgrims path to the Jamaraat Bridge in Mecca, Saudi Arabia.",
        "a Black Lives Matter protest in Australia.",
        "b Muslim pilgrims during Hajj Fig 2.",
        "Examples of crowds The authors of 17 present a system that makes advantage of smartphone users to scan nearby Bluetooth devices and assess population aspects in urban settings.",
        "The proposed system does more than just add devices up to more sophisticated capabilities.",
        "It examines flow direction and population density.",
        "261 J.",
        "Amr.",
        "Uni.",
        "03 2023 p.259 Hisham H.",
        "Y.",
        "Saad et al.",
        "To examine the system described, a dataset of 200000 findings from 1000 scanning devices was compiled over the course of three days.",
        "The outcome demonstrates the effectiveness of Bluetooth devices as a reliable technique for crowd detection and monitoring.",
        "Utilizing Bluetooth technology that was readily available and installed on the bus ceiling, a wireless system with innovative and affordable features was created 18 .",
        "The Bluetooth device in the bus then does a periodic scan for discoverable devices nearby.",
        "In order to identify an origin/destination relationship, the system postprocesses the data and compares it to bus position and ticket information.",
        "Wi-Fi-based systems for counting crowds face some difficulties.",
        "The capacity to distinguish between those outside the bus and true passengers is one of these difficulties.",
        "Numerous articles have researched and debated this issue, including 19 and 20, which find a solution by filtering the probes with a sliding window in order to eliminate the MAC addresses that have not been detected for an extended period of time.",
        "In 21, 22, and 23, people counters based on thermal cameras are introduced.",
        "Thermal camera- based systems, in contrast to optical cameras like those in Fig.",
        "3, are less susceptible to background colour contrasts or ambient lighting levels, albeit the performance of the systems can be impacted by weather and heat sources.",
        "Real-time image processing models require a lot of computer power.",
        "Utilizing picture compression is one technique to cut down on the expensive computation 24.",
        "For the detectionbased methods, like Figure 1, researchers use a sliding window to detect the people in an image and then use this information to count the number of people 33, 34.",
        "However, in the case of extremely crowded scenes, which are difficult to detect e.g., dense density, severe occlusion for classical methods, the regressionbased method comes in handy.",
        "a b Fig 3.",
        "Crowd detection a The density estimation based on crowd counting b The detection based on crowd counting 2537 4.",
        "Crowd Monitoring Crowd monitoring has drawn greater attention recently.",
        "The number of research publications has significantly expanded, as seen in Fig 4 below 26.",
        "The figure shows an increasing especially from 2010 due to the increasing in the number of the casualties during the huge gathering in all over the world.",
        "262 J.",
        "Amr.",
        "Uni.",
        "03 2023 p.259 Hisham H.",
        "Y.",
        "Saad et al.",
        "Fig 4 Documents published per year on crowd monitoring.",
        "in Scopus Monitoring the crowd is a crucial step in determining the crowd dynamics that will improve event management and public safety.",
        "As a result, event organizers are advised to keep a watch on the crowd in order to see any dangers early on and take the required precautions 27 .",
        "The primary objective of crowd surveillance equipment is to gather important data, such as crowd size and density.",
        "The volume of crowd assembling at a monitored site can be calculated by calculating the population for precise and effective managing and planning 28.",
        "Closed-circuit television CCTV surveillance is the most common method of crowd monitoring in traditional crowd monitoring systems CMSs 29.",
        "A system of video cameras that are used to relay signals from certain locations to a specific set of monitors or displays, typically for surveillance or security purposes, is known as a CCTV system 30.",
        "Typically, CCTV systems have recording hardware that stores video signal for later use.",
        "Therefore, CCTV systems can be utilized in a variety of settings to keep an eye on and protect people, deter crime, and promote public safety.",
        "When there are obstacles or poor weather conditions at the monitored site, the CCTV camera cannot effectively distinguish strange actions or crowd situations.",
        "For a number of abnormal scenarios, such as crowding, hail, conflicts, fire, violence attacks, and trampling, a high-efficiency crowd management and evacuation model utilizing communication technologies and artificial intelligence AI is required.",
        "Consequently, a multitude of sensors, quick decision transmission, and in-depth data analysis make up the fundamental parts of CMS 31.",
        "The proposed system in 32 was constructed using two key parts.",
        "The information management component also contains a fuzzy logic module and a thermal video analyzer.",
        "Recent fuzzy models 33 and 34 can be used to improve performance.",
        "5.",
        "Crowd Management Crowd management is the examination of people who determine an areas capacity prior to its utilization.",
        "The systematic planning, coordination, and supervision of the orderly gathering and movement of people is known as crowd management 35.",
        "Crowd management is the supportive, organized direction provided for the orderly movement of people.",
        "As a crucial component of crowd management, actions are done to limit or regulate crowd behaviour.",
        "Securing crowd safety may be a part of crowd control.",
        "Additionally, a set of acts and preparations that are made to use, facilitate, and move crowds can be referred to as crowd management.",
        "Its crucial to clear up a common misunderstanding about the difference between crowd control and crowd management.",
        "Although these two terms are frequently used synonymously, it is important to understand their differences in order to behave more correctly throughout an event.",
        "Crowd management encompasses facilitating crowd activities and movement in addition to maintaining crowd safety.",
        "On the other hand, crowd control is primarily concerned with the problems that develop once a crowd starts behaving disorderly or gets out of control 36.",
        "263 J.",
        "Amr.",
        "Uni.",
        "03 2023 p.259 Hisham H.",
        "Y.",
        "Saad et al.",
        "6.",
        "Conclusion Globally, congested conditions are getting worse due to population expansion, global urbanization, high-speed transportation, and the spread of effective information.",
        "The paper discusses a number of technology developments for seeing, estimating, keeping an eye on, and controlling huge crowds.",
        "Furthermore, in integrated crowd control frameworks for varied crowd sizes, technologies, including RF, RFID, WIFI, Bluetooth, optical imaging, and CCTV cameras have been examined under specific conditions.",
        "Numerous uses of crowd modelling in the actual world for well-known disasters have been discussed for analysing of crowded situations and in anticipating crowd anomalies in real time crowd management systems.",
        "References 1 Hoseinpourfard M., et al..",
        "The emergence of Hajj stampedes lessons for Hajj trauma centers.",
        "Trauma Monthly, 2017, 224.",
        "2 Chen, Y., et al., Large group activity security risk assessment and risk early warning based on random forest algorithm.",
        "Pattern Recognition Letters, 2021.",
        "144 p.",
        "1-5.",
        "3 Aveni, A.F., The not-so-lonely crowd Friendship groups in collective behavior.",
        "Sociometry, 1977 p.",
        "96-99.",
        "4 Parrish, J.K.",
        "and L.",
        "Edelstein-Keshet, Complexity, pattern, and evolutionary trade-offs in animal aggregation.",
        "Science, 1999.",
        "2845411 p.",
        "99-101.",
        "5 Zhang, H.-P., et al., Collective motion and density fluctuations in bacterial colonies.",
        "Proceedings of the National Academy of Sciences, 2010.",
        "10731 p.",
        "13626-13630.",
        "6 Yi, S., H.",
        "Li, and X.",
        "Wang, Pedestrian behavior modeling from stationary crowds with applications to intelligent surveillance.",
        "IEEE transactions on image processing, 2016.",
        "259 p.",
        "4354-4368.",
        "7 Chaker, R., Z.",
        "Al Aghbari, and I.N.",
        "Junejo, Social network model for crowd anomaly detection and localization.",
        "Pattern Recognition, 2017.",
        "61 p.",
        "266-281.",
        "8 Lee, S., H.G.",
        "Kim, and Y.M.",
        "Ro.",
        "STAN Spatio-temporal adversarial networks for abnormal event detection.",
        "in 2018 IEEE international conference on acoustics, speech and signal processing ICASSP.",
        "2018.",
        "IEEE.",
        "9 Deng, L., et al., Hospital crowdedness evaluation and in-hospital resource allocation based on image recognition technology.",
        "Scientific Reports, 2023.",
        "131 p.",
        "299.",
        "10 Lu, L., et al., A study of pedestrian group behaviors in crowd evacuation based on an extended floor field cellular automaton model.",
        "Transportation research part C emerging technologies, 2017.",
        "81 p.",
        "317-329.",
        "11 Liu, Z., et al., Decision-Making Framework for GI Layout Considering Site Suitability and Weighted Multi-Function Effectiveness A Case Study in Beijing Sub-Center.",
        "Water, 2022.",
        "1411 p.",
        "1765.",
        "12 Koswatte, S., K.",
        "McDougall, and X.",
        "Liu, Crowd-Assisted Flood Disaster Management, in Application of Remote Sensing and GIS in Natural Resources and Built Infrastructure Management.",
        "2023, Springer.",
        "p.",
        "39-55.",
        "13 Liu, J., Y.",
        "Chen, and Y.",
        "Chen, Emergency and disaster management-crowd evacuation research.",
        "Journal of Industrial Information Integration, 2021.",
        "21 p.",
        "100191.",
        "14 Hu, R., et al., RDC-SAL Refine distance compensating with quantum scale-aware learning for crowd counting and localization.",
        "Applied Intelligence, 2022.",
        "5212 p.",
        "14336-14348.",
        "15 Perez, H., et al., Task-based crowd simulation for heterogeneous architectures, in Innovative Research and Applications in Next-Generation High Performance Computing.",
        "2016, IGI Global.",
        "p.",
        "194-219.",
        "264 J.",
        "Amr.",
        "Uni.",
        "03 2023 p.259 Hisham H.",
        "Y.",
        "Saad et al.",
        "16 Jiang, Y., et al., Ultra large-scale crowd monitoring system architecture and design issues.",
        "IEEE Internet of Things Journal, 2021.",
        "813 p.",
        "10356-10366.",
        "17 Weppner, J., et al., Participatory bluetooth scans serving as urban crowd probes.",
        "IEEE Sensors Journal, 2014.",
        "1412 p.",
        "4196-4206.",
        "18 Kostakos, V., T.",
        "Camacho, and C.",
        "Mantero.",
        "Wireless detection of end-to-end passenger trips on public transport buses.",
        "in 13th International IEEE Conference on Intelligent Transportation Systems.",
        "2010.",
        "IEEE.",
        "19 Handte, M., et al.",
        "Crowd Density Estimation for Public Transport Vehicles.",
        "in EDBT/ICDT Workshops.",
        "2014.",
        "Citeseer.",
        "20 Handte, M., et al., An internet-of-things enabled connected navigation system for urban bus riders.",
        "IEEE internet of things journal, 2016.",
        "35 p.",
        "735-744.",
        "21 Lin, W.-C., W.K.",
        "Seah, and W.",
        "Li.",
        "Exploiting radio irregularity in the Internet of Things for automated people counting.",
        "in 2011 IEEE 22nd International Symposium on Personal, Indoor and Mobile Radio Communications.",
        "2011.",
        "IEEE.",
        "22 Tikkanen, T., People detection and tracking using a network of low-cost depth cameras.",
        "Aalto University, 2014.",
        "23 Tyndall, A., R.",
        "Cardell-Oliver, and A.",
        "Keating, Occupancy estimation using a low-pixel count thermal imager.",
        "IEEE Sensors Journal, 2016.",
        "1610 p.",
        "3784-3791.",
        "24 Saad, A.-M.H., et al., Impact of spatial dynamic search with matching threshold strategy on fractal image compression algorithm performance study.",
        "IEEE Access, 2020.",
        "8 p.",
        "52687-52699.",
        "25 Li, M., et al.",
        "Estimating the number of people in crowded scenes by mid based foreground segmentation and head-shoulder detection.",
        "in 2008 19th international conference on pattern recognition.",
        "2008.",
        "IEEE.",
        "26 Singh, U., et al., Crowd monitoring State-of-the-art and future directions.",
        "IETE Technical Review, 2021.",
        "386 p.",
        "578-594.",
        "27 Li, X., et al., Data fusion for intelligent crowd monitoring and management systems A survey.",
        "IEEE Access, 2021.",
        "9 p.",
        "47069-47083.",
        "28 Ding, X., et al., Crowd density estimation using fusion of multi-layer features.",
        "IEEE Transactions on Intelligent Transportation Systems, 2020.",
        "228 p.",
        "4776-4787.",
        "29 Mallah, J.E., et al.",
        "Crowd Monitoring Critical Situations Prevention Using Smartphones and Group Detection.",
        "in Distributed, Ambient, and Pervasive Interactions Third International Conference, DAPI 2015, Held as Part of HCI International 2015, Los Angeles, CA, USA, August 2- 7, 2015, Proceedings 3.",
        "2015.",
        "Springer.",
        "30 Davies, A.C., J.H.",
        "Yin, and S.A.",
        "Velastin, Crowd monitoring using image processing.",
        "Electronics  Communication Engineering Journal, 1995.",
        "71 p.",
        "37-47.",
        "31 Sirmacek, B.",
        "and P.",
        "Reinartz.",
        "Automatic crowd density and motion analysis in airborne image sequences based on a probabilistic framework.",
        "in 2011 IEEE International Conference on Computer Vision Workshops ICCV Workshops.",
        "2011.",
        "IEEE.",
        "32 Khozium, M.O., A.G.",
        "Abuarafah, and E.",
        "AbdRabou, A proposed computer-based system architecture for crowd management of pilgrims using thermography.",
        "Life Science Journal, 2012.",
        "92 p.",
        "377-383.",
        "33 Saad, H.H.Y., et al., A robust structure identification method for evolving fuzzy system.",
        "Expert Systems with Applications, 2018.",
        "93 p.",
        "267-282.",
        "34 Saad, H.H.Y., N.A.M.",
        "Isa, and M.M.",
        "Ahmed, A structural evolving approach for fuzzy systems.",
        "IEEE Transactions on Fuzzy Systems, 2019.",
        "282 p.",
        "273-287.",
        "265 J.",
        "Amr.",
        "Uni.",
        "03 2023 p.259 Hisham H.",
        "Y.",
        "Saad et al.",
        "35 Al-Shaery, A.",
        "and M.",
        "Khozium, Crowd management challenges Tackling approach for real time crowd monitoring.",
        "Int.",
        "J.",
        "Sci.",
        "Eng.",
        "Res., 2019.",
        "36 Saleh, S.A.M., S.A.",
        "Suandi, and H.",
        "Ibrahim, Recent survey on crowd density estimation and counting for visual surveillance.",
        "Engineering Applications of Artificial Intelligence, 2015.",
        "41 p.",
        "103-114.",
        "37 Deng, Lijia,Zhou, QinghuaWang, ShuihuaGórriz, Juan Manuel Zhang, Yudong Deep learning in crowd counting A survey.",
        "2023 266"
      ],
      "word_count": 2856,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "crowd_scale_level",
          "",
          "",
          "count",
          "",
          ""
        ],
        "data": [
          [
            "",
            "Low Scale",
            "",
            "",
            "<150",
            ""
          ],
          [
            "Normal Scale",
            "",
            "",
            "150-550",
            "",
            ""
          ],
          [
            "",
            "Large Scale",
            "",
            "",
            ">550",
            ""
          ]
        ]
      }
    ],
    "metadata": {
      "Title": "A Reflective Approach to Improve Learning and Teaching of Software Engineering in Large Groups",
      "Author": "eyad",
      "Creator": "Microsoft® Word 2013",
      "CreationDate": "D:20231026200338+03'00'",
      "ModDate": "D:20231026200338+03'00'",
      "Producer": "Microsoft® Word 2013"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "Crowd Management and Monitoring using Deep Convolutinal Neural Network Pratiksha Singh DepartmentofComputerScience Engineering,MadanMohanMalviyaUniver- sityofTechnology,Gorakhpur,India A K Daniel DepartmentofComputerScience Engineering,MadanMohanMalviyaUniver- sityofTechnology,Gorakhpur,India CorrespondingauthorPratikshaSingh,Emailpratikshasingh1212gmail.com India is counted as one of the most populated countries in the world. A lot of crime is also increasing due to the increasing population, as criminal activities are more frequent in a crowded place. Being crowded is also facing a lot of dis- eases. Therefore, crowd management and monitoring are very important there- fore viewed from the security, crowd management, and monitoring plays a very importantroleinidentifyinggroup/individualsbehaviorinacrowdusingvideo and image sequence for counting the person and detection of such misbehavior elements, This paper proposed a model for crowd management and monitoring personcountingasobjectdetectiontechniques.ThispaperproposedDeepConvo- lutionalNeuralNetwork,andSupportVectorMachine.Thedatasetaretakenfrom Mall,KumbhMela,andUCFD.Theperformanceofthemodelusingtrainingand testingofdataisimproved. Keywords Crowd management, Crowd monitoring, Crowd detection, Radio fre- quencyidentification,Supportvectormachine,Deepconvolutionalneuralnetwork. 2021.InRajuPalPraveenK.Shuklaeds.,SCRSConferenceProceedingson Intelligent Systems, 171179. Computing  Intelligent Systems, SCRS, India. https//doi.org/10.52458/978-93-91842-08-6-15 PratikshaSingh AKDaniel 1 Introduction India is second in the world in increasing population rate of humans. And the rate of human popu- lation has been increasing very rapidly in the last few times and years, that is why crime has also increased due to increasing congestion in the field of development 1, 8. Basically, the crowd is a group of organized or different people in a group and is inspired by common goals. Several methods of technology are used to count congestion. There are mainly two types of crowd displays, structure crowds and unstructured crowds 7. In many areas such as markets, towns, college campuses, hos- pitals, airports, stadiums, shopping malls and cultural and religious places 1, crowds are moni- tored by video cameras. Computer vision congestion events have been the subject of a core re- search. This paper decodes both profitability and cutting-edge methods. It is very essential to un- derstand the behavior of the crowd from the research point of view, because based on this we use different methods and technologies. It is only through the behavior of the crowd that activities in the social space are shown such as crime activities, Terrorist attack etc. Several methods of algo- rithm have been used in computer visions such as crowd monitoring, crowd behavior, detect on the person in the crowd, and find out the crowd 10. Today many wireless devices and sensors are available such as radio frequency identification is one of them and it has been used for efficient crowd management, Deep Convolutional Neural Network and Support Vector Machine in efficient crowd management and monitoring both. Monitoring the crowded area and place monitoring the crowd is a task full of challenges and diffi- culties, explaining a wide variety of activities. Identify the behavior of a crowd becomes unpredicta- ble for some time. The crowd may be involved under the same act or for the same event and due to non-restructuring of this behavior of the crowd, crowd management takes some time apart 17. Because human behavior is different even if it is related to the same purpose or does not recognize that the main objective is dangerous 9. Humans and traffic cause jams and risks. Corona, swine flu, bird flu etc. viruses are also likely to spread as these viruses are caused by skin-to-skin contact status 5. It is very important to understand their behavior even to tell riots and terrorist attacks in a public place due to the mob. Several methods and techniques have been described to secure the individual and the environment and the developed environment. Several computer vision algo- rithms exist to describe congestion behavior by tracking, but sometimes this algorithm also fails for some reason 18, 19. 2 Crowd Model The crowd model has been classified into three categories crowd management, crowd monitoring behaviour, localisation, and counting, and crowd detection. Fig. 1. Defined crowd Models A Crowd Management Crowd management is a collected and proven plan and a direction towards the gradual progress of events where a lot of people gather. Also, the field of crowd management has improved a lot throughout the year. Real-time has been used to manage and monitor 9. A large amount of people gathers while going to Hajj, and the round robin algorithm has been structured to control the crowds in Hajj. Crowd management is not just for the event but including shopping malls, plazas, airports, etc all locations. Practical groups of people can be used as a part of crowd management 172 2 SCRSConferenceProceedingsonIntelligentSystems2021 with the aim of making them direct and limited, this is called controlling congestion and is essential for social security. B Crowd Monitoring CCTV cameras are used to monitor congestion, but CCTV cameras are also unable to cover certain areas such as side of the wall. This is the biggest loss of CCTV cameras. Many techniques are used to monitor congestion such as crowd counting, crowd localization, crowd density and crowd behavior etc.  Crowd counting entails counting a person present in an area and informing him of the number of individuals present in that area using a variety of technological approaches. 1.  The term crowd location refers to where a person exists and how many persons are in that area, And to indicate which person has a specific place.  The density of congestion means how many people arepresent in a person and an area and what the distance between them is and how much more or less 8.  Behavior of crowd tells the activities of the crowd what the reason for the gathering of the crowd is and what the main objective is. For example, if a person goes to the airport, it means that the activity there are a traveling and place, and if a person going to cultural place is mean that cultural events are happening in that place and crowd behavior tech- nologies have been used support vector machine and deep learning techniques 1112. C Crowd Detection Determines a number by identifying individuals located at a location. The model that detects this function is called the identification model. Some researchers have described detecting crowd at- tendees by vision-based and wavelet template techniques in which we call HWD head wavelet de- tection 8. This technology has been used for the main function of HWD technology, to tell the head size a specific description of the attribute, and SVM was used primarily to classify the presence of the head 21. And some technology and algorithms have also been analyzed that identify the area of the human shoulder and head. The size of a humans shoulder and head area is like an ome- ga Ω. And to identify humans in the crowd, the ROI is the filter and then the effect is based on different approaches in less congestion and successful and more density congestion 8. 3 Methodology There are various methodologies by which the object can be identified in a group set and the group using various techniques. A Radio Frequency Identification RFID Radio Frequency Identification has been used to identify crowded individual. It has been used in every area for indoor and outdoor. It has been used to count the ruse of real-time. RFID perform the people identify through of radio frequency and radio frequency provide unique tag chip identification card and a card is identified through the wireless sensor and identified to detect via of GPS tracking device 131815. RFID chip are available in various sizes, sensor network for read- ing and sensing chip would have some serious economic considerations in case of irregular event like Kumbha 5. RFID technology has even been successfully utilized for identifying purposes. B Support Vector Machine Support vector machine SVM algorithm for popular supervised machine learning algorithm, the crowd density management introduced a support vector machine technique using higher-order singular value decomposition HOSVD. 16. it is also classifying the regression problem for crowd control is SVM algorithm the data set display a range for training and testing dataset through su- pervised learning. 173 3 PratikshaSingh AKDaniel C Deep Convolutional Neural Network Many methods of model work inside of deep learning such as Recurrent Neural Network RNN, Auto encoders AE and Artificial Neural Networks ANN but Convolutional Neural Networks CNN very special model. This model is useful for computer vision and image analysis 8. CNN is an assortment for Deep neural network and classifies by identifying of special feature of the image. It provides a comprehensive look for visual objective and in this application the validation of image and video such as Computer Vision, Medical Image analysis MIA, image classification and natural language processing NLP are composite. CNN display the mathematical function and his calculate congestion. In a process known as Feature Extraction, a convolution tool isolates and identifies the different characteristics of a picture for analysis. There are three-layer Pooling layer, Convolutional layer, and Full connected layer 20, and com- prised of two additional parameters like dropout and active function and with this help to show its result. 4 Proposed Model This proposed model consists of data set as input and counting and localization as the techniques used for analyses and given objective. A Counting However, a description of the person present in a video and image and its status cannot be fully communicated. Nevertheless, we have used a variety of applications to crowd have tried to identify size and person. It breaks the technical and image into a small image and calculates the distance and average density between the person present in each image and the detector while many places are such where image calculation is a very challenging task 27. The area that can be captured cleanly by image and video. The exact average density of the areas of that is possible. Additionally, person counting, and density is also possible through serial images. This work is displayed by map, so and map is used all over the world to calculate ground areas. Calculating the people present in the crowd is also a complex task MAE and MSE try to make it comfortable. Average absolute error MAE determines the absolute average distance between real and approxi- mate data, although this high prediction does not punish mistakes. The average distance squared between actual data and estimated data is measured by the mean square error MSE. Major mis- takes are highlighted in this section. 𝑀𝐴𝐸 1𝑁 𝑉𝑗𝑉𝑗  1 𝑁 𝑗1 𝑀𝑆𝐸 1𝑁 𝑉𝑗𝑉𝑗2.. 2 𝑁 𝑗1 The total number of data points N, prediction value from Vjand then and jth truth value from Vj and MAE is mean absolute error and MSE is mean squared error value. B Localization This training does not fully claim the crowds location will give accurately. Because there is a very challenging task in localizing the crowd. It has been tried as an image and video. If viewed realisti- cally, the same head can match in multiple heads. The person present at one place is checked with every angle to localize the person, and then try to demonstrate a distance estimate. And the effort made has led to confirmation localization 28. 𝐹𝑀𝑒𝑎𝑠𝑢𝑟𝑒 2 𝑋 𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 𝑋 𝑅𝑒𝑐𝑎𝑙𝑙 3 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛𝑅𝑒𝑐𝑎𝑙𝑙 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 𝑇𝑟𝑢𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒 .... 4 𝑃𝑟𝑒𝑑𝑖𝑐𝑡𝑒𝑑 𝑣𝑎𝑙𝑢𝑒 174 4 SCRSConferenceProceedingsonIntelligentSystems2021 𝑃𝑟𝑒𝑑𝑖𝑐𝑡𝑒𝑑𝑇𝑟𝑢𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝐹𝑎𝑙𝑠𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒 5 𝑅𝑒𝑐𝑎𝑙𝑙 𝑇𝑟𝑢𝑒 𝑝𝑜𝑠𝑖𝑡𝑖𝑣𝑒. 6 𝐴𝑐𝑡𝑢𝑎𝑙 𝑉𝑎𝑙𝑢𝑒 𝐴𝑐𝑡𝑢𝑎𝑙 𝑣𝑎𝑙𝑢𝑒𝑇𝑟𝑢𝑒 𝑝𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝐹𝑎𝑙𝑠𝑒 𝑁𝑒𝑔𝑖𝑡𝑖𝑣𝑒 7 where True Positive, False Positive and False Negative. Normally, box level Precision, Recall, and F- measure are utilized for crowd localization tasks. C Dataset For the result we need some real-world data sets such as crowd videos and crowd pictures. For this we have some data set on the publicly such as the data set of the mall, fair, Kumbh Mela, class- rooms, events. Malls data are highly used, and they are capture with the help of CCTV camera all around area or have publicly data set This includes 2000 maximum videos and image and the person counted in this 2000 image and video is more the about 62325 more people. But due to the ongoing disease in current time the crowd count is reduced 23. Fig. 2. Mall dataset-based count person The UCSD dataset is the first dataset to counting person and this data set is used by installing the camera and the ends of the person in the camera present in it are made by highly resolution video and image in frame or at least 50 frames have been used and it has an overall population of 49885 people. It has mostly been used in place like mall, political areas, and stadium 22. Table 2. Defined by mean squared error and mean absolute error value UCSD Data set Method MAS MSE Gaussian process regression 2.23 7.95 Ridge regression 2.24 7.80 Density map  MESA 1.71 --- Count forest 1.61 4.41 Multi-column CNN 1.08 1.34 The Hindu festival Kumbh Mela to be held in India, which is a crowd data set in Allahabad, Nashik, Ujjain, and Haridwar is collected by drones and is a mass pilgrimage held every 12 years and a huge amount of crowd would gather. Whose management and monitoring are very im- portant. According to Allahabad Kumbh mela Data, the mela held in 2013 collects more than 120 million people and then has more than 600 frames in 6 hours and it sets a very large amount of data 25. Fig. 3. Kumbh Mela based every 6 hours Millen are person count 175 5 PratikshaSingh AKDaniel NWPU data set is a publicly collected data set. It works in deep CNN methods based on small scales. NWPU dataset has a dense congestion limit. NWPU crowd data set has about 2133375 head count based on 5120 images did has gone 26. Fig. 4. NWPU dataset Fig. 5. NWPU person evolution and person count Shanghai Technology is a very large data set and uses at least 1198 crowd image to count people and it divided into two parts of the data set which is first on his 482 image and the second which is in part there are 716 images, and the first part is divide two-way as testing and training dataset and second images also divide two-way training and testing dataset and it states the best result 24. Fig. 6. ShanghaiTech Part A, Part B Based person count The World Expo10 data set was first displayed by Sam at el. In this data set, 108 consecutive cameras were installed for surveillance at the World Expo in Shanghai City in 2010. This camera captured 1,132 annotated videos and 3,980 frames. The frame had annotation of the cantor of individuals running continuously on 1, 99, 923 2728. Fig. 7. Would expo 10 dataset to count person with help people head 176 6 SCRSConferenceProceedingsonIntelligentSystems2021 Table 3. Defined person counting based on MSE and MAS Would Expo10 data set Method MA MS S E Gaussian process regres- 2.23 7.95 sion Ridge regression 2.24 7.80 Density map  MESA 1.71 --- Count forest 1.61 4.41 Multi-column CNN 1.08 1.34 Table 4. Comparison of varies nine real-world public datasets based of frames Data Areas Purpose No of Person head From Use Device Image counting Mecca madina Counting and --- ---- Images, videos CCTV Surveillance behavior Mall Counting and 2000 62325 Images, videos CCTV Surveillance detection Shanghai tech Counting 1198 482,716 Images, videos CCTV Surveillance part A, B CUHK Counting 1535 ---- Images, videos CCTV and inter- net UCSD Counting 2000 49885 Images, videos CCTV Surveillance NWPU Counting 5120 21,33,345 Image Camera Kumbh mela Counting and 6144 120 mil- Images, videos CCTV Surveil- localization lion lance and Drone UCF_CC_50 Crowd man- 50 1279 Images, videos CCTV agement Would expo10 Person count- 1132 1199,9233 Image videos CCTV ing 5 Performance Analysis of Model and Result A Counting The ground truth image is called a sample image. It states the exact position of the person. Support vector machines have been used to make this image accurate. In this study we have used the data set of the mall. From the point of training, we have selected mall data sets and video sequential images, and the conclusion is displayed in the picture. Fig. 8. Target Image Mall Data set Fig. 9. Support vector machine base crowd counting 177 7 PratikshaSingh AKDaniel SVM Actual 60 40 45 50 39 34 37 40 33 30 25 30 30 1 2 0 0 3 4 6 9 6 7 5 8 4 0 Img 35 Img30 Img 25 Img 40 Img 30 Img 50 Img 40 Img 35 Img 40 Fig. 10. Actual value and SVM method Comparison based person counting Table 5. Define same image different-different area count person SVM techniques with image range Range Image SVM Actual value Img1 35 3 33 Img2 30 4 30 Img3 25 6 25 Img4 40 9 40 Img5 30 6 30 Img6 50 7 45 Img7 40 5 39 Img8 35 8 34 Img9 40 4 37 B Localization In many applications, as such the technology of high-density crowd tracking has been used. While ground veracity has been used 11 to indicate the error of permanent taxation. F-Measure in col- laboration with a Greedy Association, have tried local calculations from Recall and Precision. The area of the recall, precision curve is also known as L-AUC. It has been used to display overall per- formance 27. Table 6. Localization Accuracy on using different date set Method Recall Precision F-measure M-CNN 64 60 62 LSC-CNN 73.55 75 74 CL-CNN 60 76 67 D-CNN 79 82 81 6 Conclusion Crowd management, monitoring and counting analysis has gained popularity in recent years for identifying individuals behavior and misbehavior in video and image sequence The analysis of multiple crowd management and monitoring approach had been discussed. Crowd management and monitoring are complicated attributed to reason such as lighting variations in each picture scene. The paper including the finding using the Deep convolution neural network and SVM based crowd management and monitoring technique had been applied for more detailed infor- mation. The model is implemented for evaluation of Mall, Kumbh Mela, using would expo10, Shanghai Tech, NWPU and UCFD dataset. 178 8 SCRSConferenceProceedingsonIntelligentSystems2021 References 1 S. Jeevitha and R. Rajeswari, A Review of crowd counting techniques, Int. J. Res. Analytical Reviews, vol. 5, no. 3, pp. 1343-1348, 2018. 2 K. Khan, W. Albattah, R. U. Khan, A. M. Qamar and D. Nayab, Advances and trends in real time visual crowd analysis , Sensors, vol. 20, no. 18, pp. 1-12, 2020. 3 A. Rani, The soft crowd management-Special reference to Kumbh-Haridwar, IOSR J. Computer Eng., vol.19, no. 1, pp 99-102, 2017. 4 C. Martella, J. Li, C. Conrado and A. Vermeeren, On current crowd management practices and the need for increased situation awareness, predication, and intervention, Safety Sci., vol. 91, pp. 381-393, 2017. 5 M. Yamin and Y. Ades, Crowd management with RFID and Wireless Technologies in First Int. Conf. on Networks  Communications, pp. 439-442, 2009. 6 Wafaa M. Shalash, Aliaa Al. Hazimi, Basme Al Zahrani, A mobile based crowd management system, Int. J. Adv. Res. Comput. Commu. Eng., vol. 6, pp. 205-215, 2017. 7 A. Khan, J. A. Shah, K. Kadir, W. Albattah and F. Khan, Crowd monitoring and Localization using Deep Convolutional neural network the review, Appl. Sci., vol. 10, no. 14, pp. 1-17, 2020. 8 M. D. Chaudhari and A. S. Ghotkar, A study on crowd detection and density analysis for safety control, Int. J. Comput. Sci. Eng., vol. 6, pp. 424-428, 2018. 9 A. Mohammed, A. Shaery and M. O. Khozium, Crowd management challenges Tackling Approach for real time crowd monitoring, Int. J. Sci. Eng. Res., vol. 7, no. 1, pp. 84-88, 2019. 10 S. Lamba and N. Nain, Crowd monitoring and classification A survey, in Advances in Computer and Computational Sciences, S. K. Bhatia et al. Eds. Springer Nature Singapore, 2017, pp 21-31. 11 D. Yimin, C. Fudong, L. Jinping and C. Wei, Abnormal Behavior Detection Based on Optical Flow Trajec- tory of Human Joint Points, in Chinese Control and Decision Conference, 2019, pp. 653658. 12 T. Wang, M. Qiao, A. Zhu, G. Shan and H. Snoussi, Abnormal event detection via the analysis of multi- frame optical flow Information, Front. Comput. Sci., vol. 14, pp. 304313, 2020. 13M. Addlesee, R. Curwen, S. Hodges, J. Newman, P. Steggles, A. Ward and A. Hopper, Implementing a sentient computing system, in Computer, vol. 34, no. 8, pp. 5056, 2001. 14 I. Bokun and K. Zielinski, Active Badgesthe Next Generation Industrial Enterprises, 2009. 15 S. Granneman, RFID Chips Are Here, Available http//www.theregister.co.uk/2003-06-27/rfid_chips_are_here Want, R., Hopper, A., Falco, V. and Gib bons, J. 1992, The active badge location system, ACM Transactions on Information Systems 101. 16 B. Zhou, F. Zhang and L. Peng, Higher-order SVD analysis for crowd density estimation, Comput. Vision and Image Understanding, vol. 116, no. 9, pp. 10141021, 2012. 17 V. A. Sindagi and V. M. Patel, A Survey of Recent Advances in CNN-based Single Image Crowd Counting and Density Estimation, Pattern Recognition Letters, 2017. 18 H. Weiming, et al. A survey on visual surveillance of object motion and behaviors, IEEE Transactions on Systems, Man, and Cybernetics, Part C Applications and Reviews, vol. 34, no. 3, pp. 334-352, 2004. 19 B. Tapas, et al. An Adaptive Codebook Model for Change Detection with Dynamic Background, in 11th Int. Conf. on Signal-Image Technology  Internet-Based Systems, 2015, pp. 110-116. 20 C. Wang, H. Zhang, L. Yang, S. Liu and X. Cao, Deep People Counting in Extremely Dense Crowds, in 23rd ACM Int. Conf. on Multimedia, 2015, pp. 1299-1302. 21 S. F. Lin, J. Y. Chen and H. X. Chao, Estimation of number of people in crowded scenes using perspective transformation, IEEE Transactions on Systems, Man, and Cybernetics - Part A Systems and Humans, vol. 31, no. 6, pp. 645-654, 2001. 22 A. B. Chan, Z. S. J. Liang, N. Vasconcelos, Privacy preserving crowd monitoring Counting people with- out people models or tracking, in IEEE Conf. on Computer Vision and Pattern Recognition, 2008, pp. 1-7. 23 K. Chen, S. Gong, T. Xiang and C. C. Loy, Cumulative attribute space for age and crowd density estima- tion, in IEEE Conf. on Computer Vision and Pattern Recognition, 2013, pp. 2467-2474. 24 Y. Zhang, D. Zhou, S. Chen, S. Gao and Y. Ma, Single-image crowd counting via multi-column convolu- tional neural network, in IEEE Conf. on Computer Vision and Pattern Recognition, 2016, pp. 589-597. 25 A. Pandey, M. Pandey, N. Singh and A. Trivedi, KUMBH MELA A case study for dense crowd counting and modeling, Multimed. Tools Appl., vol. 79, pp. 1783717858, 2020. 26 Q. Wang, J. Gao, W. Lin and X. Li, NWPU-crowd A large-scale benchmark for crowd counting, IEEE Transac. Pattern Analy. Machine Intell., 2020. 27 C. Zhang, K. Kang, H. Li, X. Wang, R. Xie and X. Yang, Data-driven crowd understanding A baseline for a largescale crowd dataset, IEEE Transac. Multimed., vol . 8, no. 6, pp. 10481061, 2016. 28 C. Zhang, H. Li, X. Wang and X. Yang, Cross-scene crowd counting via deep convolutional neural net- works, in IEEE Conf. Comput. Vision and Pattern Recog., 2015, pp. 833-84. 179",
    "structured_text": {
      "sentences": [
        "Crowd Management and Monitoring using Deep Convolutinal Neural Network Pratiksha Singh DepartmentofComputerScience Engineering,MadanMohanMalviyaUniver- sityofTechnology,Gorakhpur,India A K Daniel DepartmentofComputerScience Engineering,MadanMohanMalviyaUniver- sityofTechnology,Gorakhpur,India CorrespondingauthorPratikshaSingh,Emailpratikshasingh1212gmail.com India is counted as one of the most populated countries in the world.",
        "A lot of crime is also increasing due to the increasing population, as criminal activities are more frequent in a crowded place.",
        "Being crowded is also facing a lot of dis- eases.",
        "Therefore, crowd management and monitoring are very important there- fore viewed from the security, crowd management, and monitoring plays a very importantroleinidentifyinggroup/individualsbehaviorinacrowdusingvideo and image sequence for counting the person and detection of such misbehavior elements, This paper proposed a model for crowd management and monitoring personcountingasobjectdetectiontechniques.ThispaperproposedDeepConvo- lutionalNeuralNetwork,andSupportVectorMachine.Thedatasetaretakenfrom Mall,KumbhMela,andUCFD.Theperformanceofthemodelusingtrainingand testingofdataisimproved.",
        "Keywords Crowd management, Crowd monitoring, Crowd detection, Radio fre- quencyidentification,Supportvectormachine,Deepconvolutionalneuralnetwork.",
        "2021.InRajuPalPraveenK.Shuklaeds.,SCRSConferenceProceedingson Intelligent Systems, 171179.",
        "Computing  Intelligent Systems, SCRS, India.",
        "https//doi.org/10.52458/978-93-91842-08-6-15 PratikshaSingh AKDaniel 1 Introduction India is second in the world in increasing population rate of humans.",
        "And the rate of human popu- lation has been increasing very rapidly in the last few times and years, that is why crime has also increased due to increasing congestion in the field of development 1, 8.",
        "Basically, the crowd is a group of organized or different people in a group and is inspired by common goals.",
        "Several methods of technology are used to count congestion.",
        "There are mainly two types of crowd displays, structure crowds and unstructured crowds 7.",
        "In many areas such as markets, towns, college campuses, hos- pitals, airports, stadiums, shopping malls and cultural and religious places 1, crowds are moni- tored by video cameras.",
        "Computer vision congestion events have been the subject of a core re- search.",
        "This paper decodes both profitability and cutting-edge methods.",
        "It is very essential to un- derstand the behavior of the crowd from the research point of view, because based on this we use different methods and technologies.",
        "It is only through the behavior of the crowd that activities in the social space are shown such as crime activities, Terrorist attack etc.",
        "Several methods of algo- rithm have been used in computer visions such as crowd monitoring, crowd behavior, detect on the person in the crowd, and find out the crowd 10.",
        "Today many wireless devices and sensors are available such as radio frequency identification is one of them and it has been used for efficient crowd management, Deep Convolutional Neural Network and Support Vector Machine in efficient crowd management and monitoring both.",
        "Monitoring the crowded area and place monitoring the crowd is a task full of challenges and diffi- culties, explaining a wide variety of activities.",
        "Identify the behavior of a crowd becomes unpredicta- ble for some time.",
        "The crowd may be involved under the same act or for the same event and due to non-restructuring of this behavior of the crowd, crowd management takes some time apart 17.",
        "Because human behavior is different even if it is related to the same purpose or does not recognize that the main objective is dangerous 9.",
        "Humans and traffic cause jams and risks.",
        "Corona, swine flu, bird flu etc.",
        "viruses are also likely to spread as these viruses are caused by skin-to-skin contact status 5.",
        "It is very important to understand their behavior even to tell riots and terrorist attacks in a public place due to the mob.",
        "Several methods and techniques have been described to secure the individual and the environment and the developed environment.",
        "Several computer vision algo- rithms exist to describe congestion behavior by tracking, but sometimes this algorithm also fails for some reason 18, 19.",
        "2 Crowd Model The crowd model has been classified into three categories crowd management, crowd monitoring behaviour, localisation, and counting, and crowd detection.",
        "Fig.",
        "1.",
        "Defined crowd Models A Crowd Management Crowd management is a collected and proven plan and a direction towards the gradual progress of events where a lot of people gather.",
        "Also, the field of crowd management has improved a lot throughout the year.",
        "Real-time has been used to manage and monitor 9.",
        "A large amount of people gathers while going to Hajj, and the round robin algorithm has been structured to control the crowds in Hajj.",
        "Crowd management is not just for the event but including shopping malls, plazas, airports, etc all locations.",
        "Practical groups of people can be used as a part of crowd management 172 2 SCRSConferenceProceedingsonIntelligentSystems2021 with the aim of making them direct and limited, this is called controlling congestion and is essential for social security.",
        "B Crowd Monitoring CCTV cameras are used to monitor congestion, but CCTV cameras are also unable to cover certain areas such as side of the wall.",
        "This is the biggest loss of CCTV cameras.",
        "Many techniques are used to monitor congestion such as crowd counting, crowd localization, crowd density and crowd behavior etc.",
        "Crowd counting entails counting a person present in an area and informing him of the number of individuals present in that area using a variety of technological approaches.",
        "1.",
        "The term crowd location refers to where a person exists and how many persons are in that area, And to indicate which person has a specific place.",
        "The density of congestion means how many people arepresent in a person and an area and what the distance between them is and how much more or less 8.",
        "Behavior of crowd tells the activities of the crowd what the reason for the gathering of the crowd is and what the main objective is.",
        "For example, if a person goes to the airport, it means that the activity there are a traveling and place, and if a person going to cultural place is mean that cultural events are happening in that place and crowd behavior tech- nologies have been used support vector machine and deep learning techniques 1112.",
        "C Crowd Detection Determines a number by identifying individuals located at a location.",
        "The model that detects this function is called the identification model.",
        "Some researchers have described detecting crowd at- tendees by vision-based and wavelet template techniques in which we call HWD head wavelet de- tection 8.",
        "This technology has been used for the main function of HWD technology, to tell the head size a specific description of the attribute, and SVM was used primarily to classify the presence of the head 21.",
        "And some technology and algorithms have also been analyzed that identify the area of the human shoulder and head.",
        "The size of a humans shoulder and head area is like an ome- ga Ω.",
        "And to identify humans in the crowd, the ROI is the filter and then the effect is based on different approaches in less congestion and successful and more density congestion 8.",
        "3 Methodology There are various methodologies by which the object can be identified in a group set and the group using various techniques.",
        "A Radio Frequency Identification RFID Radio Frequency Identification has been used to identify crowded individual.",
        "It has been used in every area for indoor and outdoor.",
        "It has been used to count the ruse of real-time.",
        "RFID perform the people identify through of radio frequency and radio frequency provide unique tag chip identification card and a card is identified through the wireless sensor and identified to detect via of GPS tracking device 131815.",
        "RFID chip are available in various sizes, sensor network for read- ing and sensing chip would have some serious economic considerations in case of irregular event like Kumbha 5.",
        "RFID technology has even been successfully utilized for identifying purposes.",
        "B Support Vector Machine Support vector machine SVM algorithm for popular supervised machine learning algorithm, the crowd density management introduced a support vector machine technique using higher-order singular value decomposition HOSVD.",
        "16.",
        "it is also classifying the regression problem for crowd control is SVM algorithm the data set display a range for training and testing dataset through su- pervised learning.",
        "173 3 PratikshaSingh AKDaniel C Deep Convolutional Neural Network Many methods of model work inside of deep learning such as Recurrent Neural Network RNN, Auto encoders AE and Artificial Neural Networks ANN but Convolutional Neural Networks CNN very special model.",
        "This model is useful for computer vision and image analysis 8.",
        "CNN is an assortment for Deep neural network and classifies by identifying of special feature of the image.",
        "It provides a comprehensive look for visual objective and in this application the validation of image and video such as Computer Vision, Medical Image analysis MIA, image classification and natural language processing NLP are composite.",
        "CNN display the mathematical function and his calculate congestion.",
        "In a process known as Feature Extraction, a convolution tool isolates and identifies the different characteristics of a picture for analysis.",
        "There are three-layer Pooling layer, Convolutional layer, and Full connected layer 20, and com- prised of two additional parameters like dropout and active function and with this help to show its result.",
        "4 Proposed Model This proposed model consists of data set as input and counting and localization as the techniques used for analyses and given objective.",
        "A Counting However, a description of the person present in a video and image and its status cannot be fully communicated.",
        "Nevertheless, we have used a variety of applications to crowd have tried to identify size and person.",
        "It breaks the technical and image into a small image and calculates the distance and average density between the person present in each image and the detector while many places are such where image calculation is a very challenging task 27.",
        "The area that can be captured cleanly by image and video.",
        "The exact average density of the areas of that is possible.",
        "Additionally, person counting, and density is also possible through serial images.",
        "This work is displayed by map, so and map is used all over the world to calculate ground areas.",
        "Calculating the people present in the crowd is also a complex task MAE and MSE try to make it comfortable.",
        "Average absolute error MAE determines the absolute average distance between real and approxi- mate data, although this high prediction does not punish mistakes.",
        "The average distance squared between actual data and estimated data is measured by the mean square error MSE.",
        "Major mis- takes are highlighted in this section.",
        "𝑀𝐴𝐸 1𝑁 𝑉𝑗𝑉𝑗  1 𝑁 𝑗1 𝑀𝑆𝐸 1𝑁 𝑉𝑗𝑉𝑗2..",
        "2 𝑁 𝑗1 The total number of data points N, prediction value from Vjand then and jth truth value from Vj and MAE is mean absolute error and MSE is mean squared error value.",
        "B Localization This training does not fully claim the crowds location will give accurately.",
        "Because there is a very challenging task in localizing the crowd.",
        "It has been tried as an image and video.",
        "If viewed realisti- cally, the same head can match in multiple heads.",
        "The person present at one place is checked with every angle to localize the person, and then try to demonstrate a distance estimate.",
        "And the effort made has led to confirmation localization 28.",
        "𝐹𝑀𝑒𝑎𝑠𝑢𝑟𝑒 2 𝑋 𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 𝑋 𝑅𝑒𝑐𝑎𝑙𝑙 3 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛𝑅𝑒𝑐𝑎𝑙𝑙 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 𝑇𝑟𝑢𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒 ....",
        "4 𝑃𝑟𝑒𝑑𝑖𝑐𝑡𝑒𝑑 𝑣𝑎𝑙𝑢𝑒 174 4 SCRSConferenceProceedingsonIntelligentSystems2021 𝑃𝑟𝑒𝑑𝑖𝑐𝑡𝑒𝑑𝑇𝑟𝑢𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝐹𝑎𝑙𝑠𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑒 5 𝑅𝑒𝑐𝑎𝑙𝑙 𝑇𝑟𝑢𝑒 𝑝𝑜𝑠𝑖𝑡𝑖𝑣𝑒.",
        "6 𝐴𝑐𝑡𝑢𝑎𝑙 𝑉𝑎𝑙𝑢𝑒 𝐴𝑐𝑡𝑢𝑎𝑙 𝑣𝑎𝑙𝑢𝑒𝑇𝑟𝑢𝑒 𝑝𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝐹𝑎𝑙𝑠𝑒 𝑁𝑒𝑔𝑖𝑡𝑖𝑣𝑒 7 where True Positive, False Positive and False Negative.",
        "Normally, box level Precision, Recall, and F- measure are utilized for crowd localization tasks.",
        "C Dataset For the result we need some real-world data sets such as crowd videos and crowd pictures.",
        "For this we have some data set on the publicly such as the data set of the mall, fair, Kumbh Mela, class- rooms, events.",
        "Malls data are highly used, and they are capture with the help of CCTV camera all around area or have publicly data set This includes 2000 maximum videos and image and the person counted in this 2000 image and video is more the about 62325 more people.",
        "But due to the ongoing disease in current time the crowd count is reduced 23.",
        "Fig.",
        "2.",
        "Mall dataset-based count person The UCSD dataset is the first dataset to counting person and this data set is used by installing the camera and the ends of the person in the camera present in it are made by highly resolution video and image in frame or at least 50 frames have been used and it has an overall population of 49885 people.",
        "It has mostly been used in place like mall, political areas, and stadium 22.",
        "Table 2.",
        "Defined by mean squared error and mean absolute error value UCSD Data set Method MAS MSE Gaussian process regression 2.23 7.95 Ridge regression 2.24 7.80 Density map  MESA 1.71 --- Count forest 1.61 4.41 Multi-column CNN 1.08 1.34 The Hindu festival Kumbh Mela to be held in India, which is a crowd data set in Allahabad, Nashik, Ujjain, and Haridwar is collected by drones and is a mass pilgrimage held every 12 years and a huge amount of crowd would gather.",
        "Whose management and monitoring are very im- portant.",
        "According to Allahabad Kumbh mela Data, the mela held in 2013 collects more than 120 million people and then has more than 600 frames in 6 hours and it sets a very large amount of data 25.",
        "Fig.",
        "3.",
        "Kumbh Mela based every 6 hours Millen are person count 175 5 PratikshaSingh AKDaniel NWPU data set is a publicly collected data set.",
        "It works in deep CNN methods based on small scales.",
        "NWPU dataset has a dense congestion limit.",
        "NWPU crowd data set has about 2133375 head count based on 5120 images did has gone 26.",
        "Fig.",
        "4.",
        "NWPU dataset Fig.",
        "5.",
        "NWPU person evolution and person count Shanghai Technology is a very large data set and uses at least 1198 crowd image to count people and it divided into two parts of the data set which is first on his 482 image and the second which is in part there are 716 images, and the first part is divide two-way as testing and training dataset and second images also divide two-way training and testing dataset and it states the best result 24.",
        "Fig.",
        "6.",
        "ShanghaiTech Part A, Part B Based person count The World Expo10 data set was first displayed by Sam at el.",
        "In this data set, 108 consecutive cameras were installed for surveillance at the World Expo in Shanghai City in 2010.",
        "This camera captured 1,132 annotated videos and 3,980 frames.",
        "The frame had annotation of the cantor of individuals running continuously on 1, 99, 923 2728.",
        "Fig.",
        "7.",
        "Would expo 10 dataset to count person with help people head 176 6 SCRSConferenceProceedingsonIntelligentSystems2021 Table 3.",
        "Defined person counting based on MSE and MAS Would Expo10 data set Method MA MS S E Gaussian process regres- 2.23 7.95 sion Ridge regression 2.24 7.80 Density map  MESA 1.71 --- Count forest 1.61 4.41 Multi-column CNN 1.08 1.34 Table 4.",
        "Comparison of varies nine real-world public datasets based of frames Data Areas Purpose No of Person head From Use Device Image counting Mecca madina Counting and --- ---- Images, videos CCTV Surveillance behavior Mall Counting and 2000 62325 Images, videos CCTV Surveillance detection Shanghai tech Counting 1198 482,716 Images, videos CCTV Surveillance part A, B CUHK Counting 1535 ---- Images, videos CCTV and inter- net UCSD Counting 2000 49885 Images, videos CCTV Surveillance NWPU Counting 5120 21,33,345 Image Camera Kumbh mela Counting and 6144 120 mil- Images, videos CCTV Surveil- localization lion lance and Drone UCF_CC_50 Crowd man- 50 1279 Images, videos CCTV agement Would expo10 Person count- 1132 1199,9233 Image videos CCTV ing 5 Performance Analysis of Model and Result A Counting The ground truth image is called a sample image.",
        "It states the exact position of the person.",
        "Support vector machines have been used to make this image accurate.",
        "In this study we have used the data set of the mall.",
        "From the point of training, we have selected mall data sets and video sequential images, and the conclusion is displayed in the picture.",
        "Fig.",
        "8.",
        "Target Image Mall Data set Fig.",
        "9.",
        "Support vector machine base crowd counting 177 7 PratikshaSingh AKDaniel SVM Actual 60 40 45 50 39 34 37 40 33 30 25 30 30 1 2 0 0 3 4 6 9 6 7 5 8 4 0 Img 35 Img30 Img 25 Img 40 Img 30 Img 50 Img 40 Img 35 Img 40 Fig.",
        "10.",
        "Actual value and SVM method Comparison based person counting Table 5.",
        "Define same image different-different area count person SVM techniques with image range Range Image SVM Actual value Img1 35 3 33 Img2 30 4 30 Img3 25 6 25 Img4 40 9 40 Img5 30 6 30 Img6 50 7 45 Img7 40 5 39 Img8 35 8 34 Img9 40 4 37 B Localization In many applications, as such the technology of high-density crowd tracking has been used.",
        "While ground veracity has been used 11 to indicate the error of permanent taxation.",
        "F-Measure in col- laboration with a Greedy Association, have tried local calculations from Recall and Precision.",
        "The area of the recall, precision curve is also known as L-AUC.",
        "It has been used to display overall per- formance 27.",
        "Table 6.",
        "Localization Accuracy on using different date set Method Recall Precision F-measure M-CNN 64 60 62 LSC-CNN 73.55 75 74 CL-CNN 60 76 67 D-CNN 79 82 81 6 Conclusion Crowd management, monitoring and counting analysis has gained popularity in recent years for identifying individuals behavior and misbehavior in video and image sequence The analysis of multiple crowd management and monitoring approach had been discussed.",
        "Crowd management and monitoring are complicated attributed to reason such as lighting variations in each picture scene.",
        "The paper including the finding using the Deep convolution neural network and SVM based crowd management and monitoring technique had been applied for more detailed infor- mation.",
        "The model is implemented for evaluation of Mall, Kumbh Mela, using would expo10, Shanghai Tech, NWPU and UCFD dataset.",
        "178 8 SCRSConferenceProceedingsonIntelligentSystems2021 References 1 S.",
        "Jeevitha and R.",
        "Rajeswari, A Review of crowd counting techniques, Int.",
        "J.",
        "Res.",
        "Analytical Reviews, vol.",
        "5, no.",
        "3, pp.",
        "1343-1348, 2018.",
        "2 K.",
        "Khan, W.",
        "Albattah, R.",
        "U.",
        "Khan, A.",
        "M.",
        "Qamar and D.",
        "Nayab, Advances and trends in real time visual crowd analysis , Sensors, vol.",
        "20, no.",
        "18, pp.",
        "1-12, 2020.",
        "3 A.",
        "Rani, The soft crowd management-Special reference to Kumbh-Haridwar, IOSR J.",
        "Computer Eng., vol.19, no.",
        "1, pp 99-102, 2017.",
        "4 C.",
        "Martella, J.",
        "Li, C.",
        "Conrado and A.",
        "Vermeeren, On current crowd management practices and the need for increased situation awareness, predication, and intervention, Safety Sci., vol.",
        "91, pp.",
        "381-393, 2017.",
        "5 M.",
        "Yamin and Y.",
        "Ades, Crowd management with RFID and Wireless Technologies in First Int.",
        "Conf.",
        "on Networks  Communications, pp.",
        "439-442, 2009.",
        "6 Wafaa M.",
        "Shalash, Aliaa Al.",
        "Hazimi, Basme Al Zahrani, A mobile based crowd management system, Int.",
        "J.",
        "Adv.",
        "Res.",
        "Comput.",
        "Commu.",
        "Eng., vol.",
        "6, pp.",
        "205-215, 2017.",
        "7 A.",
        "Khan, J.",
        "A.",
        "Shah, K.",
        "Kadir, W.",
        "Albattah and F.",
        "Khan, Crowd monitoring and Localization using Deep Convolutional neural network the review, Appl.",
        "Sci., vol.",
        "10, no.",
        "14, pp.",
        "1-17, 2020.",
        "8 M.",
        "D.",
        "Chaudhari and A.",
        "S.",
        "Ghotkar, A study on crowd detection and density analysis for safety control, Int.",
        "J.",
        "Comput.",
        "Sci.",
        "Eng., vol.",
        "6, pp.",
        "424-428, 2018.",
        "9 A.",
        "Mohammed, A.",
        "Shaery and M.",
        "O.",
        "Khozium, Crowd management challenges Tackling Approach for real time crowd monitoring, Int.",
        "J.",
        "Sci.",
        "Eng.",
        "Res., vol.",
        "7, no.",
        "1, pp.",
        "84-88, 2019.",
        "10 S.",
        "Lamba and N.",
        "Nain, Crowd monitoring and classification A survey, in Advances in Computer and Computational Sciences, S.",
        "K.",
        "Bhatia et al.",
        "Eds.",
        "Springer Nature Singapore, 2017, pp 21-31.",
        "11 D.",
        "Yimin, C.",
        "Fudong, L.",
        "Jinping and C.",
        "Wei, Abnormal Behavior Detection Based on Optical Flow Trajec- tory of Human Joint Points, in Chinese Control and Decision Conference, 2019, pp.",
        "653658.",
        "12 T.",
        "Wang, M.",
        "Qiao, A.",
        "Zhu, G.",
        "Shan and H.",
        "Snoussi, Abnormal event detection via the analysis of multi- frame optical flow Information, Front.",
        "Comput.",
        "Sci., vol.",
        "14, pp.",
        "304313, 2020.",
        "13M.",
        "Addlesee, R.",
        "Curwen, S.",
        "Hodges, J.",
        "Newman, P.",
        "Steggles, A.",
        "Ward and A.",
        "Hopper, Implementing a sentient computing system, in Computer, vol.",
        "34, no.",
        "8, pp.",
        "5056, 2001.",
        "14 I.",
        "Bokun and K.",
        "Zielinski, Active Badgesthe Next Generation Industrial Enterprises, 2009.",
        "15 S.",
        "Granneman, RFID Chips Are Here, Available http//www.theregister.co.uk/2003-06-27/rfid_chips_are_here Want, R., Hopper, A., Falco, V.",
        "and Gib bons, J.",
        "1992, The active badge location system, ACM Transactions on Information Systems 101.",
        "16 B.",
        "Zhou, F.",
        "Zhang and L.",
        "Peng, Higher-order SVD analysis for crowd density estimation, Comput.",
        "Vision and Image Understanding, vol.",
        "116, no.",
        "9, pp.",
        "10141021, 2012.",
        "17 V.",
        "A.",
        "Sindagi and V.",
        "M.",
        "Patel, A Survey of Recent Advances in CNN-based Single Image Crowd Counting and Density Estimation, Pattern Recognition Letters, 2017.",
        "18 H.",
        "Weiming, et al.",
        "A survey on visual surveillance of object motion and behaviors, IEEE Transactions on Systems, Man, and Cybernetics, Part C Applications and Reviews, vol.",
        "34, no.",
        "3, pp.",
        "334-352, 2004.",
        "19 B.",
        "Tapas, et al.",
        "An Adaptive Codebook Model for Change Detection with Dynamic Background, in 11th Int.",
        "Conf.",
        "on Signal-Image Technology  Internet-Based Systems, 2015, pp.",
        "110-116.",
        "20 C.",
        "Wang, H.",
        "Zhang, L.",
        "Yang, S.",
        "Liu and X.",
        "Cao, Deep People Counting in Extremely Dense Crowds, in 23rd ACM Int.",
        "Conf.",
        "on Multimedia, 2015, pp.",
        "1299-1302.",
        "21 S.",
        "F.",
        "Lin, J.",
        "Y.",
        "Chen and H.",
        "X.",
        "Chao, Estimation of number of people in crowded scenes using perspective transformation, IEEE Transactions on Systems, Man, and Cybernetics - Part A Systems and Humans, vol.",
        "31, no.",
        "6, pp.",
        "645-654, 2001.",
        "22 A.",
        "B.",
        "Chan, Z.",
        "S.",
        "J.",
        "Liang, N.",
        "Vasconcelos, Privacy preserving crowd monitoring Counting people with- out people models or tracking, in IEEE Conf.",
        "on Computer Vision and Pattern Recognition, 2008, pp.",
        "1-7.",
        "23 K.",
        "Chen, S.",
        "Gong, T.",
        "Xiang and C.",
        "C.",
        "Loy, Cumulative attribute space for age and crowd density estima- tion, in IEEE Conf.",
        "on Computer Vision and Pattern Recognition, 2013, pp.",
        "2467-2474.",
        "24 Y.",
        "Zhang, D.",
        "Zhou, S.",
        "Chen, S.",
        "Gao and Y.",
        "Ma, Single-image crowd counting via multi-column convolu- tional neural network, in IEEE Conf.",
        "on Computer Vision and Pattern Recognition, 2016, pp.",
        "589-597.",
        "25 A.",
        "Pandey, M.",
        "Pandey, N.",
        "Singh and A.",
        "Trivedi, KUMBH MELA A case study for dense crowd counting and modeling, Multimed.",
        "Tools Appl., vol.",
        "79, pp.",
        "1783717858, 2020.",
        "26 Q.",
        "Wang, J.",
        "Gao, W.",
        "Lin and X.",
        "Li, NWPU-crowd A large-scale benchmark for crowd counting, IEEE Transac.",
        "Pattern Analy.",
        "Machine Intell., 2020.",
        "27 C.",
        "Zhang, K.",
        "Kang, H.",
        "Li, X.",
        "Wang, R.",
        "Xie and X.",
        "Yang, Data-driven crowd understanding A baseline for a largescale crowd dataset, IEEE Transac.",
        "Multimed., vol .",
        "8, no.",
        "6, pp.",
        "10481061, 2016.",
        "28 C.",
        "Zhang, H.",
        "Li, X.",
        "Wang and X.",
        "Yang, Cross-scene crowd counting via deep convolutional neural net- works, in IEEE Conf.",
        "Comput.",
        "Vision and Pattern Recog., 2015, pp.",
        "833-84.",
        "179"
      ],
      "word_count": 3796,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "method",
          "mas",
          "mse"
        ],
        "data": [
          [
            "Gaussian process regression",
            "2.23",
            "7.95"
          ],
          [
            "Ridge regression",
            "2.24",
            "7.80"
          ],
          [
            "Density map + MESA",
            "1.71",
            "---"
          ],
          [
            "Count forest",
            "1.61",
            "4.41"
          ],
          [
            "Multi-column CNN",
            "1.08",
            "1.34"
          ]
        ]
      },
      {
        "columns": [
          "method",
          "ma\ns",
          "ms\ne"
        ],
        "data": [
          [
            "Gaussian process regres-\nsion",
            "2.23",
            "7.95"
          ],
          [
            "Ridge regression",
            "2.24",
            "7.80"
          ],
          [
            "Density map + MESA",
            "1.71",
            "---"
          ],
          [
            "Count forest",
            "1.61",
            "4.41"
          ],
          [
            "Multi-column CNN",
            "1.08",
            "1.34"
          ]
        ]
      },
      {
        "columns": [
          "data_areas",
          "purpose",
          "no_of\nimage",
          "person_head\ncounting",
          "from_use",
          "device"
        ],
        "data": [
          [
            "Mecca madina",
            "Counting and\nbehavior",
            "---",
            "----",
            "Images, videos",
            "CCTV Surveillance"
          ],
          [
            "Mall",
            "Counting and\ndetection",
            "2000",
            "62325",
            "Images, videos",
            "CCTV Surveillance"
          ],
          [
            "Shanghai tech\npart A, B",
            "Counting",
            "1198",
            "482,716",
            "Images, videos",
            "CCTV Surveillance"
          ],
          [
            "CUHK",
            "Counting",
            "1535",
            "----",
            "Images, videos",
            "CCTV and inter-\nnet"
          ],
          [
            "UCSD",
            "Counting",
            "2000",
            "49885",
            "Images, videos",
            "CCTV Surveillance"
          ],
          [
            "NWPU",
            "Counting",
            "5120",
            "21,33,345",
            "Image",
            "Camera"
          ],
          [
            "Kumbh mela",
            "Counting and\nlocalization",
            "6144",
            "120 mil-\nlion",
            "Images, videos",
            "CCTV Surveil-\nlance and Drone"
          ],
          [
            "UCF_CC_50",
            "Crowd man-\nagement",
            "50",
            "1279",
            "Images, videos",
            "CCTV"
          ],
          [
            "Would expo’10",
            "Person count-\ning",
            "1132",
            "1199,9233",
            "Image videos",
            "CCTV"
          ]
        ]
      },
      {
        "columns": [
          "33",
          "",
          "",
          "30",
          "",
          "",
          "",
          "",
          "",
          "40",
          "",
          "",
          "30",
          "",
          "",
          "",
          "",
          "",
          "39",
          "",
          "",
          "34",
          "",
          "37",
          "",
          ""
        ],
        "data": [
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "25",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "3",
            "",
            "",
            "4",
            "",
            "",
            "6",
            "",
            "9",
            "",
            "",
            "",
            "6",
            "",
            "",
            "7",
            "",
            "",
            "5",
            "",
            "8",
            "",
            "",
            "4",
            ""
          ]
        ]
      },
      {
        "columns": [
          "range_(image)",
          "svm",
          "actual_value"
        ],
        "data": [
          [
            "Img1 (35)",
            "3",
            "33"
          ],
          [
            "Img2 (30)",
            "4",
            "30"
          ],
          [
            "Img3 (25)",
            "6",
            "25"
          ],
          [
            "Img4 (40)",
            "9",
            "40"
          ],
          [
            "Img5 (30)",
            "6",
            "30"
          ],
          [
            "Img6 (50)",
            "7",
            "45"
          ],
          [
            "Img7 (40)",
            "5",
            "39"
          ],
          [
            "Img8 (35)",
            "8",
            "34"
          ],
          [
            "Img9 (40)",
            "4",
            "37"
          ]
        ]
      },
      {
        "columns": [
          "method",
          "recall",
          "precision",
          "f-measure"
        ],
        "data": [
          [
            "M-CNN",
            "64%",
            "60%",
            "62%"
          ],
          [
            "LSC-CNN",
            "73.55%",
            "75%",
            "74%"
          ],
          [
            "CL-CNN",
            "60%",
            "76%",
            "67%"
          ],
          [
            "D-CNN",
            "79%",
            "82%",
            "81%"
          ]
        ]
      }
    ],
    "metadata": {
      "CreationDate": "D:20220215184930",
      "Creator": "PDFium",
      "Producer": "PDFium"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "Availableonlineatwww.sciencedirect.com Availableonlineatwww.sciencedirect.com Availableonlineatwww.sciencedirect.com Available online at www.sciencedirect.com 2 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 Proc S edi c aC ie om n pu c ter e Sc D ien i c r e e 00 c 2 t 019000000 in the society. Currently, video cameras are used for such kind of surveillance and they can be deployed in several ProcediaComputerScience002019000000 www.elsevier.com/locate/procedia placeseasilysuchascompanies,railwaystations,shoppingcenters,bankofficesandATMmachinesetc. ProcPerdoicae dCioamCpoumtepru StecrieSncciee n1c7e10 02022001 9350000350900 www.elsevier.com/locate/procedia Somedecadesago,videosurveillancesystemwerenotsomuchprevalentasoftoday.Variouschangesinthisperiod www.elsevier.com/locate/procedia haveresultedindeploymentandgrowthofvideosurveillancesystem.Humansocialdysfunctionischangingandtheir ThirdInternationalConferenceonComputingandNetworkCommunicationsCoCoNet19 ThirdInternationalConferenceonComputingandNetworkCommunicationsCoCoNet19 approach to security is becoming more sensible. In present time, everyone is getting familiar with technological ThirdInteHrnuatmionaanlCConrfoewrendceDoneCteocmtpiuotningfoanrdCNeittwyoWrkCidomemSuunricvaetioilnlsanCcoCeoNet19 platformtohandledifferentsecuritytasks.CCTVusageisgettingmorepopularwiththepriceaffordabilityandless Human Crowd Detection for City Wide Surveillance effortfortheirsetup.Thesesurveillancesystemarefruitlesstoprovidesecurity,untilinadequatecapacityoftrained Human Crowd Detection for City Wide Surveillance peoplewiththeirhighattentioncompetencearefulfilledforwatchingtheflicks12.AccordingtoH.Keval3and Dushyant Kumar Singha, , Sumit Paroothib, Mayank Kumar Rusiac, Mohd. Aquib Ansarid Dushyant Kumar Singha,  , Sumit Paroothib, Mayank Kumar Rusiac, Mohd. Aquib Ansarid N.Petrovic4,Monitoringsystemconsistsoflargenumberofcamerasthathelpstomonitordifferentsites.Itisused Dushyant KumaarDSepianrtgmehn a t , o  f,CSomupmuteirtScPieanrceootEhngii b n,eeMringa,yMaNnNIkTAKllauhmabaadr,PRrauyasgiraaj, c U,.MP.INoDhIdA. Aquib Ansarid todetectanynoticeableandunwantedorillegalactivity,soastoimmediatelyrespondtothesituationwithveryshort aDepartmentofCompubteMroSrcgieanncSetanlEeny,gBineenegrliunrgu,,MKNaNrnIaTtaAklala,hINabDaIdA,Prayagraj,U.P.INDIA delay.Sometimes,searchingspecificactivityfromthelargeamountofrecordedvideosfilesseemsverydifficultand acDDeeppaarrttmmeennttooffCCoommppuubtteeMrroSSrccgiieeannnccSeetanlEEenny,ggBiinneeeneegrrliiunnrggu,,,MMKNNaNNrnIIaTTtaAAkllallaa,hhINaabbDaaIddA,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA timeconsumingprocessforexaminingtheoccurredevent.Hence,itrequirescomputervisionsystem. dcDDeeppaarrttmmeennttooffCCoommppuu b tteeMrroSSrccgiieeannnccSeetanlEEenny,ggBiinneeeneegrrliiunnrggu,,,MMKNNaNNrnIIaTTtaAAkllallaa,hhINaabbDaaIddA,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA dcDDeeppaarrttmmeennttooffCCoommppuutteerrSScciieenncceeEEnnggiinneeeerriinngg,,MMNNNNIITTAAllllaahhaabbaadd,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA Thesystemproposedhereaimstoovercomelimitationsoftraditionalsurveillancetechniques.Thissystemworks dDepartmentofComputerScienceEngineering,MNNITAllahabad,Prayagraj,U.P.INDIA inrealtimetodetecttheunusualbehaviourofpeoplesinpublic,forexampleviolentcrowdbehaviour,andpedestrian detection in restricted areas. In this paper, object detection approaches are utilized to detect human pedestrians and Abstract crowd behavior analysis is modeled using violent flow descriptor with SVM classification. Next part of the system Abstract isrealtimeinformationdisseminationtopoliceauthoritiesatdifferentlevels,i.e.localpolicestationpolicehead- SAubrsvteriallcatnce systems are most commonly used for monitoring/surveillance of almost all public and private places. Real time bSeuhrvaveiiloluanrcoefstyhsetseemssysatreemmsoasdtdcoexmtrmaocnalpyaucisteydtofotrhmeosunritvoeriilnlagn/scuervaecitlilvaintyc.eIonfsaulcmhocsatsaelsl,paunbyliscusapnidciporuisvaoter upnlaecveesn. aRcetaivlittyimies quarter.Thiscomponenthelpsearlyresolutionofanysevereimpactofcrowdviolenceinpublic.Systemasawhole dbS eeu thr e vacve t iie lod lua b nry coe afn sta yhl sey tss eei m nsg sytsa htree emr m esa o las tdt idm c e oexm vtirm dae o ocnas lpy trae ucais mteyd otof fo thtrhe mec o asun mrit evo rer aii slnlat g hn / r sco ueu rv gae hcitl tilvh aie ntsyc e.e sIy ons f tse aum lcmh. o Acs tatsm ael asl,x p iam unbyu l m iscupsa lpn aic dceis po, rut isv h a eot s eruup rvnla eec ivl eel s an. ncaR eceta aivc litti t vyim itiy es contributestotheintelligent/smartpolicingforeffectivelawenforcement10. idb seeth meaco vtr iee odu mbrya o naf una tah ll, eys is. eien. sgr y etsha t l eem triem saelatd vidmidee e x ovtir fda oeooc t a asp gtra eecao imt f y CotofCtThth Veecias s umm rev orean isl i l t atohn rrc eoe duga bhc y tti s vhe iec tsy ue. rsi I tyn ysts peu emc rs h.oAn cta a smls eas i ,xniams n o yumms e upc slo pan icc tei rso o,u ltshroeo osr muur.vn Iee tivli elsanndci affiectac ivcu itl titvy fiotiys r This paper is outlined in five sections. Despite introduction in first section, the related works corresponding to aidsn e y tmec hot ureem dma b n yanb aun eai a nll,y gis.t ieo n.grmethaole nitr tie oma rel C tvi C midT eeVovifd coo eoo nttas ingtr uee o aou mfsCl o y fCa tTh nVe d c tia isr m eml e eor s ans s liyttoh wrreo idt u h gbo hyu t tshea ecn suy ersirty eys s t tp. eem Trsh .oe Anre taf mlosr aie xn, imsroou bmm ues p tcn loa enc sstersoa ,ln th droe eosffmu e r.c vIt e itv ilie lsa n nde cisffis eaco cuf tls itv ufi cot h yr differentmonitoringsystemaredelineatedinsection2.Section3consistsofproposedmethodologyinwhichactivity sais unrym veho iur l e lma m nacna e nbu dea einl p ,ge i n .te do. s rme o aon lntit etiom crh e nCv oCi l d oTe gVo ic f aco loons t tta ring enue goo tuf hsCloyC faT sne Vdcutiir sriet m yleo psnseli ryt s o owr n eia dtlhs bo, yuti s . e eac .nuyh r u irt meysatp.n eTr b she oei nrnea gfl os ,ri aen n,d sroo hbm eue nstc cne oen psst o r s oae lndr t o heo effm ne. ece Itit dvieo snf dem is ffi so cor u eflst mufca ohn r detection and communication sub system are briefly described. Section four comprises the comparative analysis of psaun ory wveeh riullm faona rcn reo b ude nein dpgetnh tdo esm colo onc n ktietocs r uhrnC voC elioT llgV ainccac elo . nsTttrin henu isgo ptuha sl poy efr asn ded icsuc tiru rie stys le eps s sea lryscow onm iatlh pso l,e ut tie.ea a.n u yhtour nme o sat m .nT obu hes eirns ego fl o u,r tae ion, ndro thb heu ans t tcn wee ips ll sonsaeo n t dtho een ff lny eec ret e idv d e uon cfe ems t s hoo eref e smffu o car hnt experimentalresults.Conclusionwithanyfuturescopearedeliberatedinofsection5. opsu forwi v nee dril iv lfaoi n drc ure aolud sne bdp u ett nhw des icl ollon aclkt s e o csuh inrnvc oer l eiolalgas i encca tel h.e sTtr eheffnise g cpt t haivpo eef nre sde sis csuco ruf isty tshee pse lar a s wcoonme a n lps fl, oer tc ie. e eam .uh etou nnm toa amu n toh buo esr i i nsty golui , ntaion pnd attr hho eal n lti c nwe gipltlo hns e eoptt u hob enlli nyc ere ped ldauo cce fes mtoho fere aemffciot a yrnt. Topfo h w iisneds r yivf s oitdr eum raolu iss nbd pur t oth pwe oic sle llo daclt ksoos u uisnr e vcertei h lae laseen x cti ehs .eti T neh gffiseCcp CtaiTvpeV enrei d nsisf s r coa u sfs trtshu eec s tulaarwc e o o mefnp tfh loe ertce cei amty ue. tonV nta oar m iuoto uhu sosrcio styo m luipnt u io tpe narttrv hoi alslt iionw ngil ttl ehc neh o npt iuo qbn ull eiycs r ape rld eauce cem esp toh lfo e yae e ff cdiottyr o t. dTo e fhtii esn c dstyi t v hsite deums a u l sisspi bpc uriot opu wos isl ael cda ti l vtsoi o tyuisn fer c o rtehm aes ree exa til hse ttiimneg ff e eCv cCi t d iTv e e oVn s eiens q sfuroaesf ntcrthue e sc.tul A arwenoi e nfn ttr fhi o cer a cct e eimtyc e.o nVm tam ariu uot nuh iso c r aci tot i ymon ipn suytpes art t e rvm oilslii ios nng alts teh ocehdnp eis uqi b gul neic esdaprl tea o ced eme s cpo rle foaya see cdi t t htyoe . 2. RelatedWorks rdT eeh sti pes ocstn ytshs e tee ti msmuse ispoipcf ris ooy pus oste sae mcdtifvt o oirtyu th sfe erop thmo e lire cex eaila stu tii tmn h g oer Cvit Ciide Teso. V Tsi henqi f sura sey snt scr t ueesc m.tuAi r s enc oianf pta trhibce lae ctet i o tycg .oe Vmn ame r r iua ont u eiscaac ntoia molna p rsu mytess rtieg vmn is a iil osi naflt tse hoc e h rde neisf qiogu une nes dda s rta eon edy mescu prs leo pay isc eei d othu toes frd eee lst lpe ooc w tntso her etuismn u u ses pou icfa i lsoya usc sttei a vmc i t t i yfvoi irt n ytht f her e opm roelsirct e rea ic lat tue itd mhsoe irt vieti .ideI est o.aTl s she o qisu gse eyn nsc ete rea sm. te Aissn tch iae npt car o ibc mlaet p etloe c tgo eem dnm eesruac ntrei i p cat ani t o iao nlnarre sml y a s tst eie dgmntoails tih afe ltshe oevrd eee n sfts ioguh nna edp dsp t eao nnd iyn esg cus rse ipa niscf eioot r hum es ofree flslt poe o xwn tu soe arl tui w mnaue rsn oui fanls g yam sctte eivs m sitayf g o eirns t . htheeproelsictreicatuetdhsoirtiet.ieIst.aTlshoisgseynsetreamteisstchaepcaobmleptloetgeedneesractreipatnioanlarremlatseidgntoaltihfetheevreenftsouhnadpspeanniynsgussipnicfioorums Thisreviewconcentrateonmethodologiesfordetectingdifferentobjectsofinterestlikehuman,vehicleortanketc. ofeflltoexwtuoarluwnaursnuianlgamcteivssitaygeins.therestrictedsite.Italsogeneratesthecompletedescriptionrelatedtotheeventshappeningsinform 5.Surveillanceisaverydemandingtopicnowadaysbecauseithelpstheobjectthatcanbetrackedoverlongperiods o c ft 2 e 0 x 2 tu 0 a T l h w e a A rn u in th g o m rs e . s P s u a b g l e i s s . hedbyElsevierB.V. of time under different circumstances. There are many difficulties to detect and track the object within surveillance  Tcid30 cid30 T P cid30 Tc c e h hh e 2i i2 2 i s ssr 0 0 0 - 2i iir 2 2s sse 0 0 0 v a aa T i T Tn nne h h h w o oo e e ep pp A u e ee A An nnn u u u d ta aa t t h e h hc cc o r o oc cc re er r er s s s e s ss . . . s sss P P P p a aa u o u ur rr b n t tb b t i ii l s l lc cc i i i i sl ll s s b e ee h h h i e l u ue e ui d d dn ntny d dd b b be ee y o y yr rr f E E Et tt h hth l l l h se es s ee e e e C C v C v v s i i iC CCc e e e i r r r e B B B B n B BY YYt . . . i V- -V V -fi N NN . . . c C CCc - --o N NNm D DDm l lli i iit c cct e eee n nen s sso e eef   h hhth t tt t tte p pp  T / / / / / /h c cci r rrr e eed a aa t ttI i ii v vnv e etee c ccr o oon m mmat m mimo o ono n nan s sls . .. o oCo r rro g ggn / / / l lfl i iie c ccr e eee n nnn s ssc e eee s ss / / /o b bbn y yy - -- n nCn c coc - --m n nn d dpd / /u/ 4 44t . .i. 0 0n0 / /g/  and Network v S i o d , e t o he d s u e e m to o d d i e ff ls er a e r n e t m ill o u s m tly in u at s i e o d n i c n on th d a i t ti p o l n a , c a e c s ro w s h s e a re sc c a l t e t a e r re d d et a e n c d tio ch n a o n f gi e n n g un b c a i c a k t g e r h o u u m nd a , n ex b i o s d te y n o c r e a o n f y ob o s th cu er rit o y bj e e t c c t . P T CPeeh oeei m s rr--m i rrs eeuvva niin eeicwwo a p tuu e io nnnndda seec rr c C erreoe ssssCpp a ooor Nnnti ssc eiil tbbe i1illu 9iit ntyy. d e oor ff thtthh e eeC ss Ccciiee Bnn Yttii- fifiN ccC cc -oo Nmm Dmm l iii ttc tte een ee soo eff  htthh ttee p TT // hh cir irr edd a tIi I vnn ettee crr onn maatt miioo onn n aas ll .oCC roo gnn /lff iee c rre een nns cce ees / ob ony n -nCC coo -mm ndpp / uu 4tt .ii 0nn / gg aanndd NNeettwwoorrkk canbedoneonthebasisoflength,widthandheight6.Heterogeneoustechniqueshavebeendefendedfortracking, C PCe ooe mmr- mmre uuv nnie iiccw aatti uioon nnd sse  rCCr o eoC sCp ooo NNn e set it b11i 9 l9i  t. y. of the scientific committee of the Third International Conference on Computing and Network detectionandidentificationofobjectsinvideos922. CKeoymwmorudnsicaItnitoenrnsetCoofCThoiNngest1C9om.puterVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge Anautomatedsurveillancesystem,knownasknight1,isasystemthatisusedforvideosurveillanceandmonitor- Kcoemywpuotrindgs. InternetofThingsComputerVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge Kcoemywpuotrindgs. InternetofThingsComputerVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge ingthroughdifferentCCTV,whichconsistsself-operativemode.Itcandetectaswellasclassifythetargetsefficiently computing. bycoherentlytrackingtheobjectthroughdifferentcamerasusingstate-of-artcomputervisiontechniques.Itproduce detailedtextualdescriptivesummaryinformationintheorbitformwithgooglemaptrackingsitelocation.Thissum- mary will gives direction to police officer in analysis and quick response decision. The limitations of surveillance 1. Introduction systemincludetheinabilitytodetectobjectwhichismasked,identifyingobjectsamongcrowd,managingcrowdand 1. Introduction workinginunfavorableweatherconditionamongtheearlierautomatedmonitoringsystem.Backgroundsubtraction 1. Introduction Videosurveillanceisthefacilitytoobserveandanalyzeanyparticularsiteforidentifyingsuspiciousactivitywith 716canalsobeoneofthesolutionfordifferentproblemsasliketrafficcontrolling,visualinspectionandinter- respVeicdteotossuarfveetiyllaanndceseiscuthrietyfapcuilriptyosteos.obVsiedrevoesaunrdveainllaalnyczeesaynsytepmarctiacmulearinstioteefxoirstiednecnetiffoyrinsgecsuursiptyicaionudscaricmtiveictyonwtritohl actionbetweencomputerandhumanbymovingobjectdetection19.Intheseapplicationswehavesomeobjectof Videosurveillanceisthefacilitytoobserveandanalyzeanyparticularsiteforidentifyingsuspiciousactivitywith respecttosafetyandsecuritypurposes.Videosurveillancesystemcameintoexistenceforsecurityandcrimecontrol interestfordetectionandthatcanbetrackedfortheiractivity. respecttosafetyandsecuritypurposes.Videosurveillancesystemcameintoexistenceforsecurityandcrimecontrol Opticalflowtechniqueisusefultoidentifythevelocitiesofmovingpointsinanimage.Opticalflowworkswhen  Correspondingauthor.Tel.91-7905514182fax0-000-000-0000. background is static and foreground object is in motion. Therefore, optical flow delivers important information of  CE-omrraeislpaodnddriensgsaduuthsohry.aTnetl.m9n1n-i7t.9ac0.5in514182fax0-000-000-0000. objectmomentumw.r.t.time17.Hassneretal.2hasproposedawellknownalgorithmforviolencecrowddetec-  CE-omrraeislpaodnddriensgsaduuthsohry.aTnetl.m9n1n-i7t.9ac0.5in514182fax0-000-000-0000. tion.Here,individualandstraightfullpostureofthebodyarecoveredinthescene.Unimodalbackgroundmodelis 1877E--0m5a0i9lacdd2r0e2ss0TdhueshAyuanthtorsm.nPnuibt.laisch.iendbyElsevierB.V. cid30 responsibletotrackmovingpersoninthescene. T PT 1 1 1 T 8 8 8 e h hhe 7 7 7i ii s sr 7 7 7 s- - - -i iri s s 0 0 0 es 5 5v 5a a a 0 0i 0n nen 9 9 9 w o o cid30 cid30 p p  o c cu e ep n n n 2 2 2 ed 0 0 0 n a ae 2 2 2 c cra 0 0 0 c ccr e e T T T ec s sse s s h h h ps e e e a aos r r A A An t ta i is u c c u u ri l l t t t tb e e h h h iic o o ol u uil r r rte n n s s sy d d . . . u e eo P P P n r rf u u u d t t b b bt h hhe l l l e er i i ie s s s C C h h h tshc e e e C Ci d d d ee B Bn b b b Ct Y Y y y yiC fi - - E E E N N cB l l l s C C s sc e e e Yo - - v v v N Nm- i i i N e e e D Dm r r r C B B B i l lt- i it c c . . N . e V V V e eeD . . n n . s so e elfic  t h hhe t tne t t p psTe   / /h / / c cihr r rd e et a atIp t tn i i v vt/e e e/r c cnc o oar m mteiao m mtn o oiav n nle s sCc . . o ooo r rmn g gf / /m l le i ir c coe e enn n ncs s s.e e eo s sro / /gn b b/ y yCl - -i n nco c cem - -n n nps d due / /st 4 4i/n . .b 0 0g / /y  a-nndc-Nnde/tw4o.0r/kCommunications J.Rehgetal.13proposedatechniquetodetectandtrackofmovingpersonwhoiswalkinginprohibitedareaof PT PCeh eoei e srCr-- iros reNeva vieneitewo1w p9ue nn u.dn aec drc ere res ss rpe aor snt p isc oilbn eisluiitn byd il eoi r tfy tth he oef Cs cC thiee Bn tY sifi- c Ncie Ccno- t Nmifi Dmc ilti ctc oeeem nsom ef ith tht tee tp eT /ho /cifrr de t a hItne ivt ee Trcnh oam itridom no Ian nls tCe .o ror nng af/let i irc oee nnn acsel e soC /nb o yCn -n foe cmr -n epn du/ ct4ien.0 go /ann dCNometwpuotrikngC oamnmd uNniectawtioonrks kioskbyusingfacedetection,skincolorandstereo.StaufferandGrimson14proposedaBackgroundSubtraction P CCe ooe m rC-rom eNv u ien etwi1ca9u tn i.o de n r s r  e C sp o o C n o si N bi e li t t  y 19 o  f . thescientificcommitteeoftheThirdInternationalConferenceonComputingandNetworkCommunications modelthathascapabilitytoprovidegoodresultswhilechangeshappensduetoillumination,repeateddisorderfrom 1C0o.1C0o1N6/ejt.p19ro.cs.2020.04.036 10.1016/j.procs.2020.04.036 1877-0509 Availableonlineatwww.sciencedirect.com Availableonlineatwww.sciencedirect.com Availableonlineatwww.sciencedirect.com Dushyant Kumar Singh et al. / Procedia Computer Science 171 2020 350359 351 2 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 ProcediaComputerScience002019000000 in the society. Currently, video cameras are used for such kind of surveillance and they can be deployed in several ProcediaComputerScience002019000000 www.elsevier.com/locate/procedia placeseasilysuchascompanies,railwaystations,shoppingcenters,bankofficesandATMmachinesetc. ProcediaComputerScience002019000000 www.elsevier.com/locate/procedia Somedecadesago,videosurveillancesystemwerenotsomuchprevalentasoftoday.Variouschangesinthisperiod www.elsevier.com/locate/procedia haveresultedindeploymentandgrowthofvideosurveillancesystem.Humansocialdysfunctionischangingandtheir ThirdInternationalConferenceonComputingandNetworkCommunicationsCoCoNet19 ThirdInternationalConferenceonComputingandNetworkCommunicationsCoCoNet19 approach to security is becoming more sensible. In present time, everyone is getting familiar with technological ThirdInteHrnuatmionaanlCConrfoewrendceDoneCteocmtpiuotningfoanrdCNeittwyoWrkCidomemSuunricvaetioilnlsanCcoCeoNet19 platformtohandledifferentsecuritytasks.CCTVusageisgettingmorepopularwiththepriceaffordabilityandless Human Crowd Detection for City Wide Surveillance effortfortheirsetup.Thesesurveillancesystemarefruitlesstoprovidesecurity,untilinadequatecapacityoftrained Human Crowd Detection for City Wide Surveillance peoplewiththeirhighattentioncompetencearefulfilledforwatchingtheflicks12.AccordingtoH.Keval3and Dushyant Kumar Singha, , Sumit Paroothib, Mayank Kumar Rusiac, Mohd. Aquib Ansarid Dushyant Kumar Singha,  , Sumit Paroothib, Mayank Kumar Rusiac, Mohd. Aquib Ansarid N.Petrovic4,Monitoringsystemconsistsoflargenumberofcamerasthathelpstomonitordifferentsites.Itisused Dushyant KumaarDSepianrtgmehn a t , o  f,CSomupmuteirtScPieanrceootEhngii b n,eeMringa,yMaNnNIkTAKllauhmabaadr,PRrauyasgiraaj, c U,.MP.INoDhIdA. Aquib Ansarid todetectanynoticeableandunwantedorillegalactivity,soastoimmediatelyrespondtothesituationwithveryshort aDepartmentofCompubteMroSrcgieanncSetanlEeny,gBineenegrliunrgu,,MKNaNrnIaTtaAklala,hINabDaIdA,Prayagraj,U.P.INDIA delay.Sometimes,searchingspecificactivityfromthelargeamountofrecordedvideosfilesseemsverydifficultand acDDeeppaarrttmmeennttooffCCoommppuubtteeMrroSSrccgiieeannnccSeetanlEEenny,ggBiinneeeneegrrliiunnrggu,,,MMKNNaNNrnIIaTTtaAAkllallaa,hhINaabbDaaIddA,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA timeconsumingprocessforexaminingtheoccurredevent.Hence,itrequirescomputervisionsystem. dcDDeeppaarrttmmeennttooffCCoommppuu b tteeMrroSSrccgiieeannnccSeetanlEEenny,ggBiinneeeneegrrliiunnrggu,,,MMKNNaNNrnIIaTTtaAAkllallaa,hhINaabbDaaIddA,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA dcDDeeppaarrttmmeennttooffCCoommppuutteerrSScciieenncceeEEnnggiinneeeerriinngg,,MMNNNNIITTAAllllaahhaabbaadd,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA Thesystemproposedhereaimstoovercomelimitationsoftraditionalsurveillancetechniques.Thissystemworks dDepartmentofComputerScienceEngineering,MNNITAllahabad,Prayagraj,U.P.INDIA inrealtimetodetecttheunusualbehaviourofpeoplesinpublic,forexampleviolentcrowdbehaviour,andpedestrian detection in restricted areas. In this paper, object detection approaches are utilized to detect human pedestrians and Abstract crowd behavior analysis is modeled using violent flow descriptor with SVM classification. Next part of the system Abstract isrealtimeinformationdisseminationtopoliceauthoritiesatdifferentlevels,i.e.localpolicestationpolicehead- SAubrsvteriallcatnce systems are most commonly used for monitoring/surveillance of almost all public and private places. Real time bSeuhrvaveiiloluanrcoefstyhsetseemssysatreemmsoasdtdcoexmtrmaocnalpyaucisteydtofotrhmeosunritvoeriilnlagn/scuervaecitlilvaintyc.eIonfsaulcmhocsatsaelsl,paunbyliscusapnidciporuisvaoter upnlaecveesn. aRcetaivlittyimies quarter.Thiscomponenthelpsearlyresolutionofanysevereimpactofcrowdviolenceinpublic.Systemasawhole dbS eeu thr e vacve t iie lod lua b nry coe afn sta yhl sey tss eei m nsg sytsa htree emr m esa o las tdt idm c e oexm vtirm dae o ocnas lpy trae ucais mteyd otof fo thtrhe mec o asun mrit evo rer aii slnlat g hn / r sco ueu rv gae hcitl tilvh aie ntsyc e.e sIy ons f tse aum lcmh. o Acs tatsm ael asl,x p iam unbyu l m iscupsa lpn aic dceis po, rut isv h a eot s eruup rvnla eec ivl eel s an. ncaR eceta aivc litti t vyim itiy es contributestotheintelligent/smartpolicingforeffectivelawenforcement10. idb seeth meaco vtr iee odu mbrya o naf una tah ll, eys is. eien. sgr y etsha t l eem triem saelatd vidmidee e x ovtir fda oeooc t a asp gtra eecao imt f y CotofCtThth Veecias s umm rev orean isl i l t atohn rrc eoe duga bhc y tti s vhe iec tsy ue. rsi I tyn ysts peu emc rs h.oAn cta a smls eas i ,xniams n o yumms e upc slo pan icc tei rso o,u ltshroeo osr muur.vn Iee tivli elsanndci affiectac ivcu itl titvy fiotiys r This paper is outlined in five sections. Despite introduction in first section, the related works corresponding to aidsn e y tmec hot ureem dma b n yanb aun eai a nll,y gis.t ieo n.grmethaole nitr tie oma rel C tvi C midT eeVovifd coo eoo nttas ingtr uee o aou mfsCl o y fCa tTh nVe d c tia isr m eml e eor s ans s liyttoh wrreo idt u h gbo hyu t tshea ecn suy ersirty eys s t tp. eem Trsh .oe Anre taf mlosr aie xn, imsroou bmm ues p tcn loa enc sstersoa ,ln th droe eosffmu e r.c vIt e itv ilie lsa n nde cisffis eaco cuf tls itv ufi cot h yr differentmonitoringsystemaredelineatedinsection2.Section3consistsofproposedmethodologyinwhichactivity sais unrym veho iur l e lma m nacna e nbu dea einl p ,ge i n .te do. s rme o aon lntit etiom crh e nCv oCi l d oTe gVo ic f aco loons t tta ring enue goo tuf hsCloyC faT sne Vdcutiir sriet m yleo psnseli ryt s o owr n eia dtlhs bo, yuti s . e eac .nuyh r u irt meysatp.n eTr b she oei nrnea gfl os ,ri aen n,d sroo hbm eue nstc cne oen psst o r s oae lndr t o heo effm ne. ece Itit dvieo snf dem is ffi so cor u eflst mufca ohn r detection and communication sub system are briefly described. Section four comprises the comparative analysis of psaun ory wveeh riullm faona rcn reo b ude nein dpgetnh tdo esm colo onc n ktietocs r uhrnC voC elioT llgV ainccac elo . nsTttrin henu isgo ptuha sl poy efr asn ded icsuc tiru rie stys le eps s sea lryscow onm iatlh pso l,e ut tie.ea a.n u yhtour nme o sat m .nT obu hes eirns ego fl o u,r tae ion, ndro thb heu ans t tcn wee ips ll sonsaeo n t dtho een ff lny eec ret e idv d e uon cfe ems t s hoo eref e smffu o car hnt experimentalresults.Conclusionwithanyfuturescopearedeliberatedinofsection5. opsu forwi v nee dril iv lfaoi n drc ure aolud sne bdp u ett nhw des icl ollon aclkt s e o csuh inrnvc oer l eiolalgas i encca tel h.e sTtr eheffnise g cpt t haivpo eef nre sde sis csuco ruf isty tshee pse lar a s wcoonme a n lps fl, oer tc ie. e eam .uh etou nnm toa amu n toh buo esr i i nsty golui , ntaion pnd attr hho eal n lti c nwe gipltlo hns e eoptt u hob enlli nyc ere ped ldauo cce fes mtoho fere aemffciot a yrnt. Topfo h w iisneds r yivf s oitdr eum raolu iss nbd pur t oth pwe oic sle llo daclt ksoos u uisnr e vcertei h lae laseen x cti ehs .eti T neh gffiseCcp CtaiTvpeV enrei d nsisf s r coa u sfs trtshu eec s tulaarwc e o o mefnp tfh loe ertce cei amty ue. tonV nta oar m iuoto uhu sosrcio styo m luipnt u io tpe narttrv hoi alslt iionw ngil ttl ehc neh o npt iuo qbn ull eiycs r ape rld eauce cem esp toh lfo e yae e ff cdiottyr o t. dTo e fhtii esn c dstyi t v hsite deums a u l sisspi bpc uriot opu wos isl ael cda ti l vtsoi o tyuisn fer c o rtehm aes ree exa til hse ttiimneg ff e eCv cCi t d iTv e e oVn s eiens q sfuroaesf ntcrthue e sc.tul A arwenoi e nfn ttr fhi o cer a cct e eimtyc e.o nVm tam ariu uot nuh iso c r aci tot i ymon ipn suytpes art t e rvm oilslii ios nng alts teh ocehdnp eis uqi b gul neic esdaprl tea o ced eme s cpo rle foaya see cdi t t htyoe . 2. RelatedWorks rdT eeh sti pes ocstn ytshs e tee ti msmuse ispoipcf ris ooy pus oste sae mcdtifvt o oirtyu th sfe erop thmo e lire cex eaila stu tii tmn h g oer Cvit Ciide Teso. V Tsi henqi f sura sey snt scr t ueesc m.tuAi r s enc oianf pta trhibce lae ctet i o tycg .oe Vmn ame r r iua ont u eiscaac ntoia molna p rsu mytess rtieg vmn is a iil osi naflt tse hoc e h rde neisf qiogu une nes dda s rta eon edy mescu prs leo pay isc eei d othu toes frd eee lst lpe ooc w tntso her etuismn u u ses pou icfa i lsoya usc sttei a vmc i t t i yfvoi irt n ytht f her e opm roelsirct e rea ic lat tue itd mhsoe irt vieti .ideI est o.aTl s she o qisu gse eyn nsc ete rea sm. te Aissn tch iae npt car o ibc mlaet p etloe c tgo eem dnm eesruac ntrei i p cat ani t o iao nlnarre sml y a s tst eie dgmntoails tih afe ltshe oevrd eee n sfts ioguh nna edp dsp t eao nnd iyn esg cus rse ipa niscf eioot r hum es ofree flslt poe o xwn tu soe arl tui w mnaue rsn oui fanls g yam sctte eivs m sitayf g o eirns t . htheeproelsictreicatuetdhsoirtiet.ieIst.aTlshoisgseynsetreamteisstchaepcaobmleptloetgeedneesractreipatnioanlarremlatseidgntoaltihfetheevreenftsouhnadpspeanniynsgussipnicfioorums Thisreviewconcentrateonmethodologiesfordetectingdifferentobjectsofinterestlikehuman,vehicleortanketc. ofeflltoexwtuoarluwnaursnuianlgamcteivssitaygeins.therestrictedsite.Italsogeneratesthecompletedescriptionrelatedtotheeventshappeningsinform 5.Surveillanceisaverydemandingtopicnowadaysbecauseithelpstheobjectthatcanbetrackedoverlongperiods o c ft 2 e 0 x 2 tu 0 a T l h w e a A rn u in th g o m rs e . s P s u a b g l e i s s . hedbyElsevierB.V. of time under different circumstances. There are many difficulties to detect and track the object within surveillance cid30 Tchi2s0i2s0aTnhoepeAnuathcocerss.sPaurtbilcilsehuedndbeyrEthleseCviCerBBY.-VN.C-NDlicensehttp//creativecommons.org/licenses/by-nc-nd/4.0/ videoduetodifferentilluminationcondition,acrossascatteredandchangingbackground,existenceofobscurityetc. P cid30 T cid30 c ehei2sr 0 -ir 2se 0 vai Tne h woepueAnn u dat e hcr ocer r s es.ss P pao urntbis lci ils beh ilue i dntydbeo yrf Etht l hes e eCv s iCc e i r eBn BYt . i-V fiN. cCc-oNmDmliitcteenesoefhthttepT//hcirredatIivnetecronmatmioonnasl.oCrogn/lfiecreennscees/obny-nCco-mndp/u4t.i0n/g and Network So, these models are mostly used in that places where clear detection of enunciate human body or any other object CPTeh oei m sr-m irseuva nineicwo a p tue io nnnda secr c C ereo sssCpa oor Nntisc eil tbe 1ilu 9inty. deorfththeeCsCcieBnYti-fiNcCc-oNmDmliitcteenesoefhthttepT // hcirredatIivnetecronmatmioonnasl.oCrogn /lfiecreennscees/ obny-nCco-mndp / u4t.i0n / g and Network canbedoneonthebasisoflength,widthandheight6.Heterogeneoustechniqueshavebeendefendedfortracking, CPeoemr-mreuvnieicwatuionndserCreosCpooNnseitb1il9ity. of the scientific committee of the Third International Conference on Computing and Network detectionandidentificationofobjectsinvideos922. KCeoymwmorudnsicaItnitoenrnsetCoofCThoiNngest1C9om.puterVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge Anautomatedsurveillancesystem,knownasknight1,isasystemthatisusedforvideosurveillanceandmonitor- Kcoemywpuotrindgs. InternetofThingsComputerVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge Kcoemywpuotrindgs. InternetofThingsComputerVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge ingthroughdifferentCCTV,whichconsistsself-operativemode.Itcandetectaswellasclassifythetargetsefficiently computing. bycoherentlytrackingtheobjectthroughdifferentcamerasusingstate-of-artcomputervisiontechniques.Itproduce detailedtextualdescriptivesummaryinformationintheorbitformwithgooglemaptrackingsitelocation.Thissum- mary will gives direction to police officer in analysis and quick response decision. The limitations of surveillance 1. Introduction systemincludetheinabilitytodetectobjectwhichismasked,identifyingobjectsamongcrowd,managingcrowdand 1. Introduction workinginunfavorableweatherconditionamongtheearlierautomatedmonitoringsystem.Backgroundsubtraction 1. Introduction Videosurveillanceisthefacilitytoobserveandanalyzeanyparticularsiteforidentifyingsuspiciousactivitywith 716canalsobeoneofthesolutionfordifferentproblemsasliketrafficcontrolling,visualinspectionandinter- respVeicdteotossuarfveetiyllaanndceseiscuthrietyfapcuilriptyosteos.obVsiedrevoesaunrdveainllaalnyczeesaynsytepmarctiacmulearinstioteefxoirstiednecnetiffoyrinsgecsuursiptyicaionudscaricmtiveictyonwtriothl actionbetweencomputerandhumanbymovingobjectdetection19.Intheseapplicationswehavesomeobjectof Videosurveillanceisthefacilitytoobserveandanalyzeanyparticularsiteforidentifyingsuspiciousactivitywith respecttosafetyandsecuritypurposes.Videosurveillancesystemcameintoexistenceforsecurityandcrimecontrol interestfordetectionandthatcanbetrackedfortheiractivity. respecttosafetyandsecuritypurposes.Videosurveillancesystemcameintoexistenceforsecurityandcrimecontrol Opticalflowtechniqueisusefultoidentifythevelocitiesofmovingpointsinanimage.Opticalflowworkswhen  Correspondingauthor.Tel.91-7905514182fax0-000-000-0000. background is static and foreground object is in motion. Therefore, optical flow delivers important information of  EC-omrraeislpaodnddriensgsaduuthsohry.aTnetl.m9n1n-i7t.9ac0.5in514182fax0-000-000-0000. objectmomentumw.r.t.time17.Hassneretal.2hasproposedawellknownalgorithmforviolencecrowddetec-  EC-omrraeislpaodnddriensgsaduuthsohry.aTnetl.m9n1n-i7t.9ac0.5in514182fax0-000-000-0000. tion.Here,individualandstraightfullpostureofthebodyarecoveredinthescene.Unimodalbackgroundmodelis 1877E--0m5a0i9lacdd2r0e2ss0TdhueshAyuanthtorsm.nPnuibt.laisch.iendbyElsevierB.V. cid30 responsibletotrackmovingpersoninthescene. T18h7is7-is05a0n9opcen20a2c0ceTsshearAticultehournsd.ePrutbhleisCheCdBbYy-ENlCse-vNieDrBlic.Ve.nsehttp//creativecommons.org/licenses/by-nc-nd/4.0/ PT18ehe7isr7--irs0e5va0ine9wo cid30 pcuenn2d0ae2cr0creTessshpeaorAntiscuiltbehioluirtnsyd.eoPrfutbthhleiesChsceCideBnbtYyifi-ENclCsceo-vNmieDmrBiltitc.eVee.nsoefthhtetpT/h/cirrdeaItnivteercnoamtiomnoanlsC.oorngf/leirceenncseeso/nbyC-nocm-npdu/t4in.0g/andNetworkCommunications J.Rehgetal.13proposedatechniquetodetectandtrackofmovingpersonwhoiswalkinginprohibitedareaof cid30 PTCehoeisrC-iroseNvaienetwo1p9uenn.daecrcreessspaorntiscilbeiluitnydeorftthheeCscCieBntYifi-NcCco-NmDmiltitceeensoefthhtetpT/h/cirrdeaItnivteercnoamtiomnoanlsC.oorngf/leirceenncseeso/nbyC-nocm-npdu/t4in.0g/andNetworkCommunications kioskbyusingfacedetection,skincolorandstereo.StaufferandGrimson14proposedaBackgroundSubtraction PCeoerC-roeNvieetw19un.derresponsibilityofthescientificcommitteeoftheThirdInternationalConferenceonComputingandNetworkCommunications modelthathascapabilitytoprovidegoodresultswhilechangeshappensduetoillumination,repeateddisorderfrom CoCoNet19. 352 Dushyant Kumar Singh et al. / Procedia Computer Science 171 2020 350359 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 3 4 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 backgroundmotion,andlongscenechangingstatus.Theyobservedundesiredorsuspiciousactivitiesthroughanalysis Background Subtraction Technique 7 17 is mostly used in real time scenario, as HOG could not work in of statistics rules and specified amount of time learning mechanism of common patterns of activities. Ricquebourg realtimeefficientllyduetoitshighrequirementofprocessingspeed.Therefore,insteadofprocessingeachframewe andBouthemy15usesspatiotemporalmechanismtotrackanddetectthepersonbyfindingthetemporaldifferences processtheframesinwhichthemotionisdetected.Formotiondetection,backgroundsubtractionalgorithmisused, amongthreesuccessiveframesandafterthatcomparisonistakeplacebetweencurrentframetobackgroundreference inwhichthepixelpositionbetweentwoimagescanshowthetruedifferenceinintensitywithrespecttodisplacement. framewithconsideringintensitychange. If,weremovethebackgroundthenthisisassumedthatbackgroundpixelsarestaticandforegroundimagepixelsare Abdelkaderetal.18suggestedaframeworkfordetectingthegestureandactionrecognitionbasedonsilhouette in motion. When movement is detected by background subtraction algorithm, HOG  SVM Classifier is triggered mechanism.ThisrecognitionwasdoneviamodellingtrajectoriesonRiemannianshapemanifoldsmethodology.Kel- for human detection. Now, any threshold value can be taken accordingly to improve the accuracy of approach. If, lokumpuetal.20usedthedynamictexturebasedmethodstorecognizethehumanactivitiesinspatiotemporalway. movementinimageisfastthenhighervalueofthresholdisneeded. The LBP-TOP is used for extracting the features in spatiotemporal space to identify human volumes as well as its HistogramofGradientHOG1121isawell-knowntechniqueofthecomputervision.Itisbasicallyaglobal movements.Asper8and9,CCTVtechnologyhasraisedthedemandofCCTVdeploymentincommercialaswell imagedescriptorusedforobjectdetectionandfeatureextractionwithveryhighsuccessrate.Themainobjectiveof aspublicandprivatesectorstofulfiltheneedofsecuritytask.NowadaysnumerousCCTVusershavingversatile HOGdescriptoristocounttheexistenceofgradientsorientationswithintheimagelocally.TheHOGusesnumberof skills,managementandtroubleshootingexperience.Forexample,USgovernmentallowswebuserstoseeliveCCTV stepsforextractingthefeaturesfromtheimage.Firststepistosplittheimageintotheblocks.Further,theseblocks videofootagethroughinternettomonitorillegalcrossingandconveysuchtypeofactivitytorespectiveauthorities. areechelonedintothecells.Then,thehorizontalandverticalgradientsareevaluatedforeachpixelwithinthecell. ResidentsofUKuseslivedigitalCCTVimagestorecognizeanysuspiciousorunpredictableactivitybysubscribing TheSobeloperatorcanbeusedforevaluatingthesegradientsasshowninequation1and2. communitysafetychannelsandrespondimmediatelytopoliceifsomethingfoundillegal. S y,xYy,x1 Yy,x 1 1 x   S y,xYy1,x Yy 1,x 2 3. Methodology y   Where the pixel intensity with co-ordinates value x, y is represented by Yy, x. The horizontal and vertical ThesystemwouldmakeuseoftheexistingCCTVinfrastructureinpublicplaceslikeparks,railwaystation,roads, gradientsarerepresentedbyS y,xandS y,xrespectively.ThegradientsmagnitudeSanditsorientationθcan shoppingcomplexesetc.anddetectsuspiciousactivitiesusingsophisticatedcomputervisiontechniques.Thesystem x y bedrawnbyequation3andequation4. would alert the main police control room or Headquarter and the nearest police station with relevant information in case any suspicious/unwanted activity is detected. The system consists of two distinct components i.e. activity S  S2S2 3 detectionmoduleandcommunicationmodule. x y cid31 S y 3.1. ActivityDetectionModule θarctan  4 S x Thiscomponentdetectsthesuspicious/unwantedactivity121315inrealtimefromthevideofeedandinforms Theninenumberofhistogrambinsareusedforstoringeachorientationofgradients.Later,thisprocessisrepeated to communication component. This system aims to detect pedestrian in the prohibited area and to identify violent foreachcell.Thecellhistogramsarecombinedforeachblock.Innextstep,blocknormalizationprocessisperformed behaviorofcrowdforcitywidesurveillance. fornormalizingtheeachvalueofbins.Theblocknormalizationplaysanimportantroletomakethisdescriptorfree fromlightningvariations.Atlast,allthehistogramvectorsareconcatenatedintoonevector.Thisresultantvectorcan alsobereferencedasfeaturevectorwhichcanbeusedforobjectdetection.Further,thesefeaturevectorsareusedto 3.1.1. PedestriandetectioninProhibitedArea buildtheSVMclassifierwhichhelpstodecidewhethertheresultingobjectishumanornot. Pedestrian detection in prohibited area is aimed to detect presence of people in a prohibited area and capture a Support Vector Machine SVM is very effective and useful machine learning technique to classify different pictureasevidence.Theobjectiveisachievedbytakingadvantageofbackgroundsubtractiontechniqueandhistogram classes. SVM classifier technique basically used to maximize the marginal difference between two distinct classes. oforientedgradientsHOG.Theworkflowofpedestriandetectionframeworkisillustratedinfigure1. PerformanceofSVMisbestinhighdimensionalspaceespeciallywhenavailabledatasetisless.SVMworkswellfor linearhyperplaneaswellasmultidimensionalhyperplanebutitcanalsobegoodifdataisnotinlinearform.Sofor non-linearclassificationSVMusesdifferentkernelfunctionforvariousdecisionfunction.Thisiscalledapproximation function.Twomostcommonlyusedfunctionsarelossfunctionandobjectivefunction.LossFunctiondescribeswhat to minimize to achieve best results. Hinge Loss is used for training classifier and maximize margin classification is usedforsupportvectormachine. Cx,y, fx1 y fx 5    Here, C, x, y and fx are loss, sample value, true level and predicted level respectively. If y fx 1 then   Cx,y, fx0otherwiseCx,y, fx1 y fx.   ObjectivefunctionofSVMconcernwithregularizerandloss.Wewanttofindthedecisionsurfacethatismaximum farawayfromanydatapoints.Regularizercontrolsthetradeoff,sothattrainingandtestingerrorscanbeminimizedto improvetheperformanceofclassifierforunseendata.Ifsamplesareclassifiedcorrectlythenweightwcanbeupdated bythegradientusingequation6. Fig.1.WorkFlowofPedestrianDetectionFramework wwn 2νw 6  Dushyant Kumar Singh et al. / Procedia Computer Science 171 2020 350359 353 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 3 4 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 backgroundmotion,andlongscenechangingstatus.Theyobservedundesiredorsuspiciousactivitiesthroughanalysis Background Subtraction Technique 7 17 is mostly used in real time scenario, as HOG could not work in of statistics rules and specified amount of time learning mechanism of common patterns of activities. Ricquebourg realtimeefficientllyduetoitshighrequirementofprocessingspeed.Therefore,insteadofprocessingeachframewe andBouthemy15usesspatiotemporalmechanismtotrackanddetectthepersonbyfindingthetemporaldifferences processtheframesinwhichthemotionisdetected.Formotiondetection,backgroundsubtractionalgorithmisused, amongthreesuccessiveframesandafterthatcomparisonistakeplacebetweencurrentframetobackgroundreference inwhichthepixelpositionbetweentwoimagescanshowthetruedifferenceinintensitywithrespecttodisplacement. framewithconsideringintensitychange. If,weremovethebackgroundthenthisisassumedthatbackgroundpixelsarestaticandforegroundimagepixelsare Abdelkaderetal.18suggestedaframeworkfordetectingthegestureandactionrecognitionbasedonsilhouette in motion. When movement is detected by background subtraction algorithm, HOG  SVM Classifier is triggered mechanism.ThisrecognitionwasdoneviamodellingtrajectoriesonRiemannianshapemanifoldsmethodology.Kel- for human detection. Now, any threshold value can be taken accordingly to improve the accuracy of approach. If, lokumpuetal.20usedthedynamictexturebasedmethodstorecognizethehumanactivitiesinspatiotemporalway. movementinimageisfastthenhighervalueofthresholdisneeded. The LBP-TOP is used for extracting the features in spatiotemporal space to identify human volumes as well as its HistogramofGradientHOG1121isawell-knowntechniqueofthecomputervision.Itisbasicallyaglobal movements.Asper8and9,CCTVtechnologyhasraisedthedemandofCCTVdeploymentincommercialaswell imagedescriptorusedforobjectdetectionandfeatureextractionwithveryhighsuccessrate.Themainobjectiveof aspublicandprivatesectorstofulfiltheneedofsecuritytask.NowadaysnumerousCCTVusershavingversatile HOGdescriptoristocounttheexistenceofgradientsorientationswithintheimagelocally.TheHOGusesnumberof skills,managementandtroubleshootingexperience.Forexample,USgovernmentallowswebuserstoseeliveCCTV stepsforextractingthefeaturesfromtheimage.Firststepistosplittheimageintotheblocks.Further,theseblocks videofootagethroughinternettomonitorillegalcrossingandconveysuchtypeofactivitytorespectiveauthorities. areechelonedintothecells.Then,thehorizontalandverticalgradientsareevaluatedforeachpixelwithinthecell. ResidentsofUKuseslivedigitalCCTVimagestorecognizeanysuspiciousorunpredictableactivitybysubscribing TheSobeloperatorcanbeusedforevaluatingthesegradientsasshowninequation1and2. communitysafetychannelsandrespondimmediatelytopoliceifsomethingfoundillegal. S y,xYy,x1 Yy,x 1 1 x   S y,xYy1,x Yy 1,x 2 3. Methodology y   Where the pixel intensity with co-ordinates value x, y is represented by Yy, x. The horizontal and vertical ThesystemwouldmakeuseoftheexistingCCTVinfrastructureinpublicplaceslikeparks,railwaystation,roads, gradientsarerepresentedbyS y,xandS y,xrespectively.ThegradientsmagnitudeSanditsorientationθcan shoppingcomplexesetc.anddetectsuspiciousactivitiesusingsophisticatedcomputervisiontechniques.Thesystem x y bedrawnbyequation3andequation4. would alert the main police control room or Headquarter and the nearest police station with relevant information in case any suspicious/unwanted activity is detected. The system consists of two distinct components i.e. activity S  S2S2 3 detectionmoduleandcommunicationmodule. x y cid31 S y 3.1. ActivityDetectionModule θarctan  4 S x Thiscomponentdetectsthesuspicious/unwantedactivity121315inrealtimefromthevideofeedandinforms Theninenumberofhistogrambinsareusedforstoringeachorientationofgradients.Later,thisprocessisrepeated to communication component. This system aims to detect pedestrian in the prohibited area and to identify violent foreachcell.Thecellhistogramsarecombinedforeachblock.Innextstep,blocknormalizationprocessisperformed behaviorofcrowdforcitywidesurveillance. fornormalizingtheeachvalueofbins.Theblocknormalizationplaysanimportantroletomakethisdescriptorfree fromlightningvariations.Atlast,allthehistogramvectorsareconcatenatedintoonevector.Thisresultantvectorcan alsobereferencedasfeaturevectorwhichcanbeusedforobjectdetection.Further,thesefeaturevectorsareusedto 3.1.1. PedestriandetectioninProhibitedArea buildtheSVMclassifierwhichhelpstodecidewhethertheresultingobjectishumanornot. Pedestrian detection in prohibited area is aimed to detect presence of people in a prohibited area and capture a Support Vector Machine SVM is very effective and useful machine learning technique to classify different pictureasevidence.Theobjectiveisachievedbytakingadvantageofbackgroundsubtractiontechniqueandhistogram classes. SVM classifier technique basically used to maximize the marginal difference between two distinct classes. oforientedgradientsHOG.Theworkflowofpedestriandetectionframeworkisillustratedinfigure1. PerformanceofSVMisbestinhighdimensionalspaceespeciallywhenavailabledatasetisless.SVMworkswellfor linearhyperplaneaswellasmultidimensionalhyperplanebutitcanalsobegoodifdataisnotinlinearform.Sofor non-linearclassificationSVMusesdifferentkernelfunctionforvariousdecisionfunction.Thisiscalledapproximation function.Twomostcommonlyusedfunctionsarelossfunctionandobjectivefunction.LossFunctiondescribeswhat to minimize to achieve best results. Hinge Loss is used for training classifier and maximize margin classification is usedforsupportvectormachine. Cx,y, fx1 y fx 5    Here, C, x, y and fx are loss, sample value, true level and predicted level respectively. If y fx 1 then   Cx,y, fx0otherwiseCx,y, fx1 y fx.   ObjectivefunctionofSVMconcernwithregularizerandloss.Wewanttofindthedecisionsurfacethatismaximum farawayfromanydatapoints.Regularizercontrolsthetradeoff,sothattrainingandtestingerrorscanbeminimizedto improvetheperformanceofclassifierforunseendata.Ifsamplesareclassifiedcorrectlythenweightwcanbeupdated bythegradientusingequation6. Fig.1.WorkFlowofPedestrianDetectionFramework wwn 2νw 6  354 Dushyant Kumar Singh et al. / Procedia Computer Science 171 2020 350359 6 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 5 Fig.2.WorkFlowofViolentCrowdDetectionFramework Ifsamplesaremisclassifiedthangradientofbothtermscanbeupdatedwithrespecttoweightvectorasshownin eqation7. wwnyx 2νw 7 i i  Wherenisthelearningrateandνisregularizer.Asaregularizingparameterwehavetochoose1/epochsepoch Numberofiterationtotrainthemachine. 3.1.2. ViolentCrowdBehavior Fig.3.FlowofCommunicationModule ViolentCrowdBehaviorfocusesonmonitoringthecrowdedeventsforoutbreaksofviolence.Efficientanalysisin realtimeoperatingenvironmentcanbeachievedbyobservingdensityonaspecificpointandmotionofthecrowdin specificdirection.Movementofthecrowdtowardscertainplacecanbeoneofthecausetoviolence.Forthepurpose, 3.1.3. CommunicationModule we have to find out high shape and intensive processing without compromising processing speed with respect to This component is responsible for transferring of information from the site under surveillance to the pertinent changes observed in vector magnitudes through time. The Violent Flows ViF descriptor is used here to extract police control room. There are 3 types of nodes in communication module architecture i.e. main server, client A, the motion information for sequence of frames. Further, these vectors are used svm classifier 18 22 is used for clientB.ThebriefarchitectureofcommunicationmoduleforproposedsystemisshowninFigure3. classifying the violent or non-violent behaviour. The complete process for violent crowd detection is presented in Mainserverisresponsibleforallkindsofcommunicationsinthesystem.Asimplewebserverhasbeenutilized Figure2. forthispurpose.ARESTfulwebserviceismadetorunontheserverwhichrespondstotherequestofallotherclients. ViF representation framework 23 24 is used to notice the violence in the real time video sequences. It is Currentlythebuilt-inserverofflaskhasbeenutilized.Italsomaintainsadatabasewhichstores calculated into various steps. First step is to evaluate the optical flow vectors between the couples of successive videosequences.Theflowvectorsareprovidedforeachframepixels.ThepixelisrepresentedbyP andtheflow x,y,t Configurationsettingsforeachsurveillancesitediscussedindetaillater. vectorsaredenotedbyu x,y,t andv x,y,t .Where,tisrepresentedbyindexofframe.Themagnitudeofthevectorscanbe  IDs for each surveillance site, police control room along with description address, contact and other relevant representedbyequation8.  info. M  u2 v2 8 Messagesreceivedfromsurveillancesites. x,y,t x,y,t x,y,t  cid31 Next,thebinaryindicator B x,y,t isevaluatedforeachframepixels.Itisevaluatedbyif  M x,y,t  M x,y,t  1  θ then TheparticularsofthedatabaseschemacanbeprocuredfromFigure4. B  1otherwise B  0.Itshowstheimportanceofmagnitudesadjustmentamongvideoframes.Where,θ is x,y,t x,y,t thethresholdvaluethatisadaptivelyfixedtoaveragerateof M M .Here,theaveragemodificationchange  x,y,t  x,y,t  1 mapisevaluatedforindividualpixelsoverentiresequencesorframesbyaverageofthesebinaryvaluesasshownin equation9. 1 b  Σ b 9 x,y x,y x,y,t T Further,thereisneedtobeformedtheViF-descriptor.Itisformedbyapportioningthebintonon-overlappingcells ofsizeMxN.ItisalsobeneededtocollectthemagnitudeadjustmentfrequencythatisalsohelpfultobuildtheViF- descriptionforeachseparatedcell.Here,afixedsizeofhistogramisusedforrepresentingthechangeinmagnitude distributionofeachcell.Finally,theseevaluatedhistogramsarefusedintoadistinctvector.Thisevaluatedvectoris representedasViF-descriptorfeaturevector.Thenthesefeaturevectorcanbeusedtobuildanyoftheclassifier6. In this paper, the ViF-descriptor is used to extract the information from the video sequences. The information from Fig.4.DatabaseDesign featurevectorisusedbytheSVMclassifiertoclassifytheviolentandnon-violentscenes. Dushyant Kumar Singh et al. / Procedia Computer Science 171 2020 350359 355 6 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 5 Fig.2.WorkFlowofViolentCrowdDetectionFramework Ifsamplesaremisclassifiedthangradientofbothtermscanbeupdatedwithrespecttoweightvectorasshownin eqation7. wwnyx 2νw 7 i i  Wherenisthelearningrateandνisregularizer.Asaregularizingparameterwehavetochoose1/epochsepoch Numberofiterationtotrainthemachine. 3.1.2. ViolentCrowdBehavior Fig.3.FlowofCommunicationModule ViolentCrowdBehaviorfocusesonmonitoringthecrowdedeventsforoutbreaksofviolence.Efficientanalysisin realtimeoperatingenvironmentcanbeachievedbyobservingdensityonaspecificpointandmotionofthecrowdin specificdirection.Movementofthecrowdtowardscertainplacecanbeoneofthecausetoviolence.Forthepurpose, 3.1.3. CommunicationModule we have to find out high shape and intensive processing without compromising processing speed with respect to This component is responsible for transferring of information from the site under surveillance to the pertinent changes observed in vector magnitudes through time. The Violent Flows ViF descriptor is used here to extract police control room. There are 3 types of nodes in communication module architecture i.e. main server, client A, the motion information for sequence of frames. Further, these vectors are used svm classifier 18 22 is used for clientB.ThebriefarchitectureofcommunicationmoduleforproposedsystemisshowninFigure3. classifying the violent or non-violent behaviour. The complete process for violent crowd detection is presented in Mainserverisresponsibleforallkindsofcommunicationsinthesystem.Asimplewebserverhasbeenutilized Figure2. forthispurpose.ARESTfulwebserviceismadetorunontheserverwhichrespondstotherequestofallotherclients. ViF representation framework 23 24 is used to notice the violence in the real time video sequences. It is Currentlythebuilt-inserverofflaskhasbeenutilized.Italsomaintainsadatabasewhichstores calculated into various steps. First step is to evaluate the optical flow vectors between the couples of successive videosequences.Theflowvectorsareprovidedforeachframepixels.ThepixelisrepresentedbyP andtheflow x,y,t Configurationsettingsforeachsurveillancesitediscussedindetaillater. vectorsaredenotedbyu x,y,t andv x,y,t .Where,tisrepresentedbyindexofframe.Themagnitudeofthevectorscanbe  IDs for each surveillance site, police control room along with description address, contact and other relevant representedbyequation8.  info. M  u2 v2 8 Messagesreceivedfromsurveillancesites. x,y,t x,y,t x,y,t  cid31 Next,thebinaryindicator B x,y,t isevaluatedforeachframepixels.Itisevaluatedbyif  M x,y,t  M x,y,t  1  θ then TheparticularsofthedatabaseschemacanbeprocuredfromFigure4. B  1otherwise B  0.Itshowstheimportanceofmagnitudesadjustmentamongvideoframes.Where,θ is x,y,t x,y,t thethresholdvaluethatisadaptivelyfixedtoaveragerateof M M .Here,theaveragemodificationchange  x,y,t  x,y,t  1 mapisevaluatedforindividualpixelsoverentiresequencesorframesbyaverageofthesebinaryvaluesasshownin equation9. 1 b  Σ b 9 x,y x,y x,y,t T Further,thereisneedtobeformedtheViF-descriptor.Itisformedbyapportioningthebintonon-overlappingcells ofsizeMxN.ItisalsobeneededtocollectthemagnitudeadjustmentfrequencythatisalsohelpfultobuildtheViF- descriptionforeachseparatedcell.Here,afixedsizeofhistogramisusedforrepresentingthechangeinmagnitude distributionofeachcell.Finally,theseevaluatedhistogramsarefusedintoadistinctvector.Thisevaluatedvectoris representedasViF-descriptorfeaturevector.Thenthesefeaturevectorcanbeusedtobuildanyoftheclassifier6. In this paper, the ViF-descriptor is used to extract the information from the video sequences. The information from Fig.4.DatabaseDesign featurevectorisusedbytheSVMclassifiertoclassifytheviolentandnon-violentscenes. 356 Dushyant Kumar Singh et al. / Procedia Computer Science 171 2020 350359 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 7 8 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 Client A is placed in each site under surveillance as a node. It will receive video feed from all CCTVs on this site. It will process the feed and send a thorough account of any activity to the main server. Each site will have its ownconfigurationsettings.Itwillretrievethesesettingsperiodicallyfromthemainserver.Themessagesenttomain serverwillcontainthesefieldsSiteID,CCTVID,ActivityRecognized,TimeStampandImageSequence. Configurationsettingsgovernthefunctioningofthisnodeandalsokeepdetailsaboutthenode.Thesesettingswill bestoredonthelocalfilesystemitself.EachclientAnodeperiodically15secondsrequeststhemainserverforits configurationsettingsandworksaccordingly. Client B is situated in each police control room as a node. It will periodically request the main server at small intervalof1-2secondstocheckifithasanynewmessagewhichisdestinedforthiscontrolRoom.ClientB2receives alerts from all surveillance sites. While, other control rooms as client B1 receive only if they are the nearest site. It is provided with a GUI which shows which site has reported an alert. The GUI makes it easier and intuitive to get Fig.6.DetectionResults information about any site. Configuration Settings enable the server to have fine control over each surveillance site withrespecttoitsfunctioningandself-information. ConfigurationSettingsincludethesefieldsSiteID,NearestPoliceControlRoomID,MainPoliceControlRoom 4.1. ActivityDetectionModule ID,DescriptionAddress,Contactetc.andisAreaProhibitedTrue/False. Graphicaluserinterface-googlemapsGUIenablesthepersonnelatpoliceheadquarterstomonitorthecomplete Currentlythesystemsupportsdetectionoftwoactivities.Eachactivitywastestedunderdifferentbenchmarksas city.Allthesurveillancesitesaremarkedonthemap.TheCCTVcamerasareusedheretomonitortheactivitiesof applicable. people.Ifanysuspiciousactivityisrecorded,thesystemsalertsthepolicepersonnelandalsohighlightsthelocation HumandetectioninprohibitedareaisdonewithHOGdescriptor152324.Thresholdingareaparameterused oftheactivity.Thepersonnelcanalsoseekinformationofanysurveillancesitegooglemapsjavascript.APIisused inbackgroundsubtractionalsoimpactsprocessingtime.Iffalsepositiveincreasesthanprocessingtimeincreasesand to embed map in the GUI. google maps geocoding API is used for conversion between addresses and Geolocation. viceversa.TheresultscanbeseeninFigure6. HTMLandCSShavebeenusedtocustomizealertwindowsinmap.QWebViewisaWebKitwidgetfromthePyQt Theperformanceintermofprocessingtimeoftheproposedalgorithmundervariousparametersareillustratedin library. It enables us to use java script code from within a python Qt application. A button is also displayed on the Table1andTable2.BothtablesshowtheparametertuninginHOGdescriptoraccordingtoWinStrideandScaleFactor. customized info window on google maps. The person can view the video or image evidence as applicable to the Where, WinStride is the stepsize in x and y directions of sliding window and the ScaleFactor is used to control the activityshowninfigure5. imagepyramid. Table1.ParameterResultstuninginHOGdescriptorasperWinStride. 4. EXPERIMENTALRESULTS S.No. WinStridex,y ProcessingTime WeusedRaspberrypi3modelBrunningonraspbianstretchatsurveillancesite.Theanalysisofvideofeedhappens 1 4,4 0.47sec ontheedgeitselfaswithedgecomputing.Theexperimentalresultsandanalysisforeachofthecomponentisshown 2 8,8 0.10sec 3 16,16 0.071sec infollowingsections Table2.ParameterResultstuninginHOGdescriptorasperScaleFactor. S.No. ScaleFactor ProcessingTime 1 1.01 0.50sec 2 1.06 0.10sec 3 1.3 0.03sec 4 1.5 0.029sec Violentcrowdbehaviordetectionalgorithmisimplementedinpython.Here,1inevery3framesareprocessedto achieverealtimeperformanceforaccuratetemporaldetection.Eachsequenceof15framesaftersamplingisclassi- fiedasviolentbehaviorornon-violentbehaviorusingSVM.Violentflowsdatabase25isanexpansionbenchmark forcrowdviolencedetection.Weusedtotal246videosastrainingoutofwhich123areforviolenceandremaining 123non-violencebehavioridentification.Videosthatwehaveusedaredownloadedfromthewebwithaverage3.60 seconds and are under uncontrolled, in-the-wild conditions. We adopted five-fold cross validation method which is mostcommonformanyproblems.The246videosarealmostequallydistributedin5parts,eachpartcontainingequal numberofviolentbehaviorandnon-violentbehaviorvideowhicharerandomlyselected.Thefirstfourpartsofvideo aretakenfortrainingandfifthpartistakenfortestingpurposes.Thetrainingsetcontains46videosofwhich23depict Fig.5.ACityView,BSuspiciousActivityDetected,CSafeSiteInfo,DSuspiciousActivityInfo violenceand23depictnon-violence. Dushyant Kumar Singh et al. / Procedia Computer Science 171 2020 350359 357 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 7 8 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 Client A is placed in each site under surveillance as a node. It will receive video feed from all CCTVs on this site. It will process the feed and send a thorough account of any activity to the main server. Each site will have its ownconfigurationsettings.Itwillretrievethesesettingsperiodicallyfromthemainserver.Themessagesenttomain serverwillcontainthesefieldsSiteID,CCTVID,ActivityRecognized,TimeStampandImageSequence. Configurationsettingsgovernthefunctioningofthisnodeandalsokeepdetailsaboutthenode.Thesesettingswill bestoredonthelocalfilesystemitself.EachclientAnodeperiodically15secondsrequeststhemainserverforits configurationsettingsandworksaccordingly. Client B is situated in each police control room as a node. It will periodically request the main server at small intervalof1-2secondstocheckifithasanynewmessagewhichisdestinedforthiscontrolRoom.ClientB2receives alerts from all surveillance sites. While, other control rooms as client B1 receive only if they are the nearest site. It is provided with a GUI which shows which site has reported an alert. The GUI makes it easier and intuitive to get Fig.6.DetectionResults information about any site. Configuration Settings enable the server to have fine control over each surveillance site withrespecttoitsfunctioningandself-information. ConfigurationSettingsincludethesefieldsSiteID,NearestPoliceControlRoomID,MainPoliceControlRoom 4.1. ActivityDetectionModule ID,DescriptionAddress,Contactetc.andisAreaProhibitedTrue/False. Graphicaluserinterface-googlemapsGUIenablesthepersonnelatpoliceheadquarterstomonitorthecomplete Currentlythesystemsupportsdetectionoftwoactivities.Eachactivitywastestedunderdifferentbenchmarksas city.Allthesurveillancesitesaremarkedonthemap.TheCCTVcamerasareusedheretomonitortheactivitiesof applicable. people.Ifanysuspiciousactivityisrecorded,thesystemsalertsthepolicepersonnelandalsohighlightsthelocation HumandetectioninprohibitedareaisdonewithHOGdescriptor152324.Thresholdingareaparameterused oftheactivity.Thepersonnelcanalsoseekinformationofanysurveillancesitegooglemapsjavascript.APIisused inbackgroundsubtractionalsoimpactsprocessingtime.Iffalsepositiveincreasesthanprocessingtimeincreasesand to embed map in the GUI. google maps geocoding API is used for conversion between addresses and Geolocation. viceversa.TheresultscanbeseeninFigure6. HTMLandCSShavebeenusedtocustomizealertwindowsinmap.QWebViewisaWebKitwidgetfromthePyQt Theperformanceintermofprocessingtimeoftheproposedalgorithmundervariousparametersareillustratedin library. It enables us to use java script code from within a python Qt application. A button is also displayed on the Table1andTable2.BothtablesshowtheparametertuninginHOGdescriptoraccordingtoWinStrideandScaleFactor. customized info window on google maps. The person can view the video or image evidence as applicable to the Where, WinStride is the stepsize in x and y directions of sliding window and the ScaleFactor is used to control the activityshowninfigure5. imagepyramid. Table1.ParameterResultstuninginHOGdescriptorasperWinStride. 4. EXPERIMENTALRESULTS S.No. WinStridex,y ProcessingTime WeusedRaspberrypi3modelBrunningonraspbianstretchatsurveillancesite.Theanalysisofvideofeedhappens 1 4,4 0.47sec ontheedgeitselfaswithedgecomputing.Theexperimentalresultsandanalysisforeachofthecomponentisshown 2 8,8 0.10sec 3 16,16 0.071sec infollowingsections Table2.ParameterResultstuninginHOGdescriptorasperScaleFactor. S.No. ScaleFactor ProcessingTime 1 1.01 0.50sec 2 1.06 0.10sec 3 1.3 0.03sec 4 1.5 0.029sec Violentcrowdbehaviordetectionalgorithmisimplementedinpython.Here,1inevery3framesareprocessedto achieverealtimeperformanceforaccuratetemporaldetection.Eachsequenceof15framesaftersamplingisclassi- fiedasviolentbehaviorornon-violentbehaviorusingSVM.Violentflowsdatabase25isanexpansionbenchmark forcrowdviolencedetection.Weusedtotal246videosastrainingoutofwhich123areforviolenceandremaining 123non-violencebehavioridentification.Videosthatwehaveusedaredownloadedfromthewebwithaverage3.60 seconds and are under uncontrolled, in-the-wild conditions. We adopted five-fold cross validation method which is mostcommonformanyproblems.The246videosarealmostequallydistributedin5parts,eachpartcontainingequal numberofviolentbehaviorandnon-violentbehaviorvideowhicharerandomlyselected.Thefirstfourpartsofvideo aretakenfortrainingandfifthpartistakenfortestingpurposes.Thetrainingsetcontains46videosofwhich23depict Fig.5.ACityView,BSuspiciousActivityDetected,CSafeSiteInfo,DSuspiciousActivityInfo violenceand23depictnon-violence. 358 Dushyant Kumar Singh et al. / Procedia Computer Science 171 2020 350359 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 9 10 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 comparedforpedestriandetectionandviolencecrowddetection.Formeasurementofprocessingtime,theRaspberry Pi device and personal computer PC are used as processing unit. The system offers a host of bright prospects for extending the work to make it even more effective. It can be used in other various applications or detecting other unwantedactivitieslikeabnormalcrowddensity,multiplepeoplerunningtheftetc.,personfallingetc.fromCCTV footageinrealtime. References Fig.7.ConfusionMatrixforCrowdViolencedetectionmodel 1 PoliceDepartmentInformationSystemsTechnologyEnhancementProjectISTEP.ReportontheReviewoftheQueenslandPoliceService, Brisbane.DepartmentofJustice,OfficeofCommunityOrientedPolicingServices,Washington,DC.Bingham,M.,2014 2 T.Hassner,Y.Itcher,andO.Kliper-Gross.ViolentFlowsReal-TimeDetectionofViolentCrowdBehavior.3rdIEEEInternationalWorkshop The results can be visualized from the confusion matrix 24 26 in Figure 7. We process selective short time onSociallyIntelligentSurveillanceandMonitoringSISMattheIEEEConf.onComputerVisionandPatternRecognitionCVPR,Rhode of delay in frame sequences separately, classifying them by labelling as either violent or nonviolent, if violent sub- Island,June2012. sequence of frames are detected then action take place. Acceptable results were obtained when we used PC for 3 H.Keval.Effective,design,configuration,anduseofdigitalCCTV.PhDthesis,UniversityCollegeLondon,2009 4 N.Petrovic,N.Jojic,andT.Huang.Adaptivevideofastforward.MultimediaToolsandApplications,263327344,2005. processing. Extraction of feature vector ViF descriptor for a sequence of 15 frames took on an average 5 seconds 5 Y.Pritch,S.Ratovitch,A.Hendel,andS.Peleg.Clusteredsynopsisofsurveillancevideo.InAdvancedVideoandSignalBasedSurveillance, tobeprocessed.Hence,appropriatesamplinghadtobedonewithoutcompromisingondelayinalerts.Experiments pages195200,2009 showedthatnotmorethan15continuousframesarerequiredforclassification. 6 M.Shah,O.Javed,K.Shafique.AutomatedVisualSurveillanceinRealisticScenarios.IEEEMultiMedia,Vol.14,Issue1,2007 Where,TP,FP,FNandTNareTruePositive,FalsePositive,FalseNegativeandTrueNegativerespectively.The 7 O.Javed,K.Shafique,andM.Shah.AHierarchicalApproachtoRobustBackgroundSubtractionUsingColorandGradientInformation. mathematicalevaluationofaccuracyandsensitivityareshowninequation10and11. Proc.IEEEWorkshoponMotionandVideoComputing,IEEECSPress,2002,pp.22-27 8 O.Javed.TrackingacrossMultipleCameraswithDisjointViews.Proc.Proc.9thIEEEIntlConf.ComputerVision,pp.343-3572003 TPTN 9 R.Collins,A.Lipton,T.KanadeIntroductiontotheSpecialSectiononVideoSurveillance.IEEETrans.PatternAnalysisandMachine Accuracy 81.25 10 TPFPTNFN Intelligence,vol.22,no.8,pp.745,2000 10 ManoharKarki,SaikatBasu,RobertDiBiano,SupratikMukhopadhyay,JerryWeltman,MalcolmStagg.Asymbolicframeworkforrecogniz- TP ingactivitiesinfullmotionsurveillancevideos.ComputationalIntelligenceSSCI,pp.1-7,2016. Sensitivity 87.5 11 11 N.Dalal,B.Triggs.Histogramsoforientedgradientsforhumandetection.ComputerVisionandPatternRecognition,2005.CVPR2005. TPFN IEEE 12 Wrenetal.Pfinder,Real-TimeTrackingoftheHumanBody.IEEETrans.PatternAnalysisandMachineIntelligence,vol.19,no.7,pp. 4.2. CommunicationComponent 780-785,1997. 13 J.Rehg,M.Loughlin,andK.Waters.VisionforaSmartKiosk.ComputerVisionandPatternRecognition,IEEEPress,1997,pp.690-696 3clientAsystemsand3clientBsystemsweremadetorunsimultaneouslywithinputfromlocallystoredvideos.A 14 StaufferandW.E.L.Grimson.LearningPatternsofActivityUsingReal-TimeTracking.IEEETrans.PatternAnalysisandMachineIntelli- privatenetworkwasneededforcommunication.Thesystemwastestedusingbothmobilehotspotandcollegenetwork. gence,vol.22,no.8,2000,pp.747-757 15 Y.RicquebourgandP.Bouthemy.Real-TimeTrackingofMovingPersonsbyExploitingSpatiotemporalImageSlices.IEEETrans.Pattern Nofaults/datalossincommunicationsystemwereobservedduringtesting.Therewerenoerrorsoratypicalbehavior AnalysisandMachineIntelligence,vol.22,no.8,2000,pp.797-808 detected in the communication component. The table 3 illustrates the average delay between time of occurence of 16 PushkarP.Goswami,DiwakarPaswan,DushyantKumarSingh.Detectingmovingobjectsintrafficsurveillancevideo.InternationalJournal activity and raising of alert at client B. There was a maximum lag of 3 seconds between detection of activity at ofControlTheoryandapplications,Vol9.17,pp8423-84302016 surveillancesiteandmessagealertatcontrolroom. 17 PushkarProtikGoswami,DushyantKumarSingh.Ahybridapproachforreal-timeobjectdetectionandtrackingtocoverbackgroundturbu- lenceproblem.IndianJournalofScienceandTechnology,Vol9.452016 18 Abdelkaderetal.Silhouette-basedgestureandactionrecognitionviamodelingtrajectoriesonRiemannianshapemanifolds.ComputerVision Table3.Averagedelayinseconds andImageUnderstanding,115.32011439-455 19 O.Kliper-Gross,T.Hassner,andL.Wolf.Pfinder,Real-TimeTrackingoftheHumanBody.IEEETrans.PatternAnalysisandMachine Detection RaspberryPi PC Intelligence,pages3145,2011 PedestrianDetection 4.1sec 2.6sec 20 V.Kellokumpu,G.Zhao,andM.Pietikainen.Humanactivityrecognitionusingadynamictexturebasedmethod.InBMVC,pages110, ViolentCrowdDetection 5.1sec 4.3sec 2008 21 O.Kliper-Gross,T.Hassner,andLiu.Beyond.PixelsExploringNewRepresentationsandApplicationsforMotionAnalysis.PhDthesis, MassachusettsInstituteofTechnology,May2009 22 NikhilSingh,ShambhuShankarBharti,RupalSingh,DushyantKumarSingh.Remotelycontrolledhomeautomationsystem.International ConferenceonAdvancesinEngineeringTechnologyResearchICAETR-2014,IEEE2014 23 Agarwal,Anshuman,ShivamGupta,andDushyantKumarSingh.Reviewofopticalflowtechniqueformovingobjectdetection.2ndInter- 5. CONCLUSIONANDFUTUREVISION nationalConferenceonContemporaryComputingandInformaticsIC3I,pages110,2016 24 KaelonLloydetal.DetectingViolentandAbnormalCrowdactivityusingTemporalAnalysisofGreyLevelCo-occurrenceMatrixGLCM Despiterecentadvancementintechnologyofcomputervisionandrelatedareas,therearestillsomemajorissues BasedTextureMeasures.ComputerVisionandPatternRecognition,2017 thatneedstobeovercomeformakingcompleterealtimeoperatingandreliableautomatedsurveillancesystem.These 25 Violent-Flows-CrowdViolence Non-violenceDatabaseandbenchmark-2017,www.cslab.openu.ac.il/download issuesincludetechnicalaspectasphysicalplacementtofullcoverage,installation,maintenanceofcamera,network 26 M.A.AnsariandM.Dixit.AnenhancedCBIRusingHSVquantization,discretewavelettransformandedgehistogramdescriptor.2017 InternationalConferenceonComputing,CommunicationandAutomationICCCA,GreaterNoida,2017,pp.1136-1141. bandwidthrequiredtosupportcameraandingeneralaspectasrobustnessofcameraintypicalweatherandlightening conditions,installationcost,privacyconcernetc.However,demandofautomatedsurveillancesystemisbeingmade more frequently specially in public safety and home security with respect to quality control parameters. Military intelligencecanalsobeoneoftheapplicationareaastechnologicalgrowthisalsoreachingtoheights.Thispaperis providingagoodresultforcrowdviolencedetectionintermsofaccuracyandsensitivity.Theprocessingtimeisalso Dushyant Kumar Singh et al. / Procedia Computer Science 171 2020 350359 359 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 9 10 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 comparedforpedestriandetectionandviolencecrowddetection.Formeasurementofprocessingtime,theRaspberry Pi device and personal computer PC are used as processing unit. The system offers a host of bright prospects for extending the work to make it even more effective. It can be used in other various applications or detecting other unwantedactivitieslikeabnormalcrowddensity,multiplepeoplerunningtheftetc.,personfallingetc.fromCCTV footageinrealtime. References Fig.7.ConfusionMatrixforCrowdViolencedetectionmodel 1 PoliceDepartmentInformationSystemsTechnologyEnhancementProjectISTEP.ReportontheReviewoftheQueenslandPoliceService, Brisbane.DepartmentofJustice,OfficeofCommunityOrientedPolicingServices,Washington,DC.Bingham,M.,2014 2 T.Hassner,Y.Itcher,andO.Kliper-Gross.ViolentFlowsReal-TimeDetectionofViolentCrowdBehavior.3rdIEEEInternationalWorkshop The results can be visualized from the confusion matrix 24 26 in Figure 7. We process selective short time onSociallyIntelligentSurveillanceandMonitoringSISMattheIEEEConf.onComputerVisionandPatternRecognitionCVPR,Rhode of delay in frame sequences separately, classifying them by labelling as either violent or nonviolent, if violent sub- Island,June2012. sequence of frames are detected then action take place. Acceptable results were obtained when we used PC for 3 H.Keval.Effective,design,configuration,anduseofdigitalCCTV.PhDthesis,UniversityCollegeLondon,2009 4 N.Petrovic,N.Jojic,andT.Huang.Adaptivevideofastforward.MultimediaToolsandApplications,263327344,2005. processing. Extraction of feature vector ViF descriptor for a sequence of 15 frames took on an average 5 seconds 5 Y.Pritch,S.Ratovitch,A.Hendel,andS.Peleg.Clusteredsynopsisofsurveillancevideo.InAdvancedVideoandSignalBasedSurveillance, tobeprocessed.Hence,appropriatesamplinghadtobedonewithoutcompromisingondelayinalerts.Experiments pages195200,2009 showedthatnotmorethan15continuousframesarerequiredforclassification. 6 M.Shah,O.Javed,K.Shafique.AutomatedVisualSurveillanceinRealisticScenarios.IEEEMultiMedia,Vol.14,Issue1,2007 Where,TP,FP,FNandTNareTruePositive,FalsePositive,FalseNegativeandTrueNegativerespectively.The 7 O.Javed,K.Shafique,andM.Shah.AHierarchicalApproachtoRobustBackgroundSubtractionUsingColorandGradientInformation. mathematicalevaluationofaccuracyandsensitivityareshowninequation10and11. Proc.IEEEWorkshoponMotionandVideoComputing,IEEECSPress,2002,pp.22-27 8 O.Javed.TrackingacrossMultipleCameraswithDisjointViews.Proc.Proc.9thIEEEIntlConf.ComputerVision,pp.343-3572003 TPTN 9 R.Collins,A.Lipton,T.KanadeIntroductiontotheSpecialSectiononVideoSurveillance.IEEETrans.PatternAnalysisandMachine Accuracy 81.25 10 TPFPTNFN Intelligence,vol.22,no.8,pp.745,2000 10 ManoharKarki,SaikatBasu,RobertDiBiano,SupratikMukhopadhyay,JerryWeltman,MalcolmStagg.Asymbolicframeworkforrecogniz- TP ingactivitiesinfullmotionsurveillancevideos.ComputationalIntelligenceSSCI,pp.1-7,2016. Sensitivity 87.5 11 11 N.Dalal,B.Triggs.Histogramsoforientedgradientsforhumandetection.ComputerVisionandPatternRecognition,2005.CVPR2005. TPFN IEEE 12 Wrenetal.Pfinder,Real-TimeTrackingoftheHumanBody.IEEETrans.PatternAnalysisandMachineIntelligence,vol.19,no.7,pp. 4.2. CommunicationComponent 780-785,1997. 13 J.Rehg,M.Loughlin,andK.Waters.VisionforaSmartKiosk.ComputerVisionandPatternRecognition,IEEEPress,1997,pp.690-696 3clientAsystemsand3clientBsystemsweremadetorunsimultaneouslywithinputfromlocallystoredvideos.A 14 StaufferandW.E.L.Grimson.LearningPatternsofActivityUsingReal-TimeTracking.IEEETrans.PatternAnalysisandMachineIntelli- privatenetworkwasneededforcommunication.Thesystemwastestedusingbothmobilehotspotandcollegenetwork. gence,vol.22,no.8,2000,pp.747-757 15 Y.RicquebourgandP.Bouthemy.Real-TimeTrackingofMovingPersonsbyExploitingSpatiotemporalImageSlices.IEEETrans.Pattern Nofaults/datalossincommunicationsystemwereobservedduringtesting.Therewerenoerrorsoratypicalbehavior AnalysisandMachineIntelligence,vol.22,no.8,2000,pp.797-808 detected in the communication component. The table 3 illustrates the average delay between time of occurence of 16 PushkarP.Goswami,DiwakarPaswan,DushyantKumarSingh.Detectingmovingobjectsintrafficsurveillancevideo.InternationalJournal activity and raising of alert at client B. There was a maximum lag of 3 seconds between detection of activity at ofControlTheoryandapplications,Vol9.17,pp8423-84302016 surveillancesiteandmessagealertatcontrolroom. 17 PushkarProtikGoswami,DushyantKumarSingh.Ahybridapproachforreal-timeobjectdetectionandtrackingtocoverbackgroundturbu- lenceproblem.IndianJournalofScienceandTechnology,Vol9.452016 18 Abdelkaderetal.Silhouette-basedgestureandactionrecognitionviamodelingtrajectoriesonRiemannianshapemanifolds.ComputerVision Table3.Averagedelayinseconds andImageUnderstanding,115.32011439-455 19 O.Kliper-Gross,T.Hassner,andL.Wolf.Pfinder,Real-TimeTrackingoftheHumanBody.IEEETrans.PatternAnalysisandMachine Detection RaspberryPi PC Intelligence,pages3145,2011 PedestrianDetection 4.1sec 2.6sec 20 V.Kellokumpu,G.Zhao,andM.Pietikainen.Humanactivityrecognitionusingadynamictexturebasedmethod.InBMVC,pages110, ViolentCrowdDetection 5.1sec 4.3sec 2008 21 O.Kliper-Gross,T.Hassner,andLiu.Beyond.PixelsExploringNewRepresentationsandApplicationsforMotionAnalysis.PhDthesis, MassachusettsInstituteofTechnology,May2009 22 NikhilSingh,ShambhuShankarBharti,RupalSingh,DushyantKumarSingh.Remotelycontrolledhomeautomationsystem.International ConferenceonAdvancesinEngineeringTechnologyResearchICAETR-2014,IEEE2014 23 Agarwal,Anshuman,ShivamGupta,andDushyantKumarSingh.Reviewofopticalflowtechniqueformovingobjectdetection.2ndInter- 5. CONCLUSIONANDFUTUREVISION nationalConferenceonContemporaryComputingandInformaticsIC3I,pages110,2016 24 KaelonLloydetal.DetectingViolentandAbnormalCrowdactivityusingTemporalAnalysisofGreyLevelCo-occurrenceMatrixGLCM Despiterecentadvancementintechnologyofcomputervisionandrelatedareas,therearestillsomemajorissues BasedTextureMeasures.ComputerVisionandPatternRecognition,2017 thatneedstobeovercomeformakingcompleterealtimeoperatingandreliableautomatedsurveillancesystem.These 25 Violent-Flows-CrowdViolence Non-violenceDatabaseandbenchmark-2017,www.cslab.openu.ac.il/download issuesincludetechnicalaspectasphysicalplacementtofullcoverage,installation,maintenanceofcamera,network 26 M.A.AnsariandM.Dixit.AnenhancedCBIRusingHSVquantization,discretewavelettransformandedgehistogramdescriptor.2017 InternationalConferenceonComputing,CommunicationandAutomationICCCA,GreaterNoida,2017,pp.1136-1141. bandwidthrequiredtosupportcameraandingeneralaspectasrobustnessofcameraintypicalweatherandlightening conditions,installationcost,privacyconcernetc.However,demandofautomatedsurveillancesystemisbeingmade more frequently specially in public safety and home security with respect to quality control parameters. Military intelligencecanalsobeoneoftheapplicationareaastechnologicalgrowthisalsoreachingtoheights.Thispaperis providingagoodresultforcrowdviolencedetectionintermsofaccuracyandsensitivity.Theprocessingtimeisalso",
    "structured_text": {
      "sentences": [
        "Availableonlineatwww.sciencedirect.com Availableonlineatwww.sciencedirect.com Availableonlineatwww.sciencedirect.com Available online at www.sciencedirect.com 2 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 Proc S edi c aC ie om n pu c ter e Sc D ien i c r e e 00 c 2 t 019000000 in the society.",
        "Currently, video cameras are used for such kind of surveillance and they can be deployed in several ProcediaComputerScience002019000000 www.elsevier.com/locate/procedia placeseasilysuchascompanies,railwaystations,shoppingcenters,bankofficesandATMmachinesetc.",
        "ProcPerdoicae dCioamCpoumtepru StecrieSncciee n1c7e10 02022001 9350000350900 www.elsevier.com/locate/procedia Somedecadesago,videosurveillancesystemwerenotsomuchprevalentasoftoday.Variouschangesinthisperiod www.elsevier.com/locate/procedia haveresultedindeploymentandgrowthofvideosurveillancesystem.Humansocialdysfunctionischangingandtheir ThirdInternationalConferenceonComputingandNetworkCommunicationsCoCoNet19 ThirdInternationalConferenceonComputingandNetworkCommunicationsCoCoNet19 approach to security is becoming more sensible.",
        "In present time, everyone is getting familiar with technological ThirdInteHrnuatmionaanlCConrfoewrendceDoneCteocmtpiuotningfoanrdCNeittwyoWrkCidomemSuunricvaetioilnlsanCcoCeoNet19 platformtohandledifferentsecuritytasks.CCTVusageisgettingmorepopularwiththepriceaffordabilityandless Human Crowd Detection for City Wide Surveillance effortfortheirsetup.Thesesurveillancesystemarefruitlesstoprovidesecurity,untilinadequatecapacityoftrained Human Crowd Detection for City Wide Surveillance peoplewiththeirhighattentioncompetencearefulfilledforwatchingtheflicks12.AccordingtoH.Keval3and Dushyant Kumar Singha, , Sumit Paroothib, Mayank Kumar Rusiac, Mohd.",
        "Aquib Ansarid Dushyant Kumar Singha,  , Sumit Paroothib, Mayank Kumar Rusiac, Mohd.",
        "Aquib Ansarid N.Petrovic4,Monitoringsystemconsistsoflargenumberofcamerasthathelpstomonitordifferentsites.Itisused Dushyant KumaarDSepianrtgmehn a t , o  f,CSomupmuteirtScPieanrceootEhngii b n,eeMringa,yMaNnNIkTAKllauhmabaadr,PRrauyasgiraaj, c U,.MP.INoDhIdA.",
        "Aquib Ansarid todetectanynoticeableandunwantedorillegalactivity,soastoimmediatelyrespondtothesituationwithveryshort aDepartmentofCompubteMroSrcgieanncSetanlEeny,gBineenegrliunrgu,,MKNaNrnIaTtaAklala,hINabDaIdA,Prayagraj,U.P.INDIA delay.Sometimes,searchingspecificactivityfromthelargeamountofrecordedvideosfilesseemsverydifficultand acDDeeppaarrttmmeennttooffCCoommppuubtteeMrroSSrccgiieeannnccSeetanlEEenny,ggBiinneeeneegrrliiunnrggu,,,MMKNNaNNrnIIaTTtaAAkllallaa,hhINaabbDaaIddA,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA timeconsumingprocessforexaminingtheoccurredevent.Hence,itrequirescomputervisionsystem.",
        "dcDDeeppaarrttmmeennttooffCCoommppuu b tteeMrroSSrccgiieeannnccSeetanlEEenny,ggBiinneeeneegrrliiunnrggu,,,MMKNNaNNrnIIaTTtaAAkllallaa,hhINaabbDaaIddA,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA dcDDeeppaarrttmmeennttooffCCoommppuutteerrSScciieenncceeEEnnggiinneeeerriinngg,,MMNNNNIITTAAllllaahhaabbaadd,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA Thesystemproposedhereaimstoovercomelimitationsoftraditionalsurveillancetechniques.Thissystemworks dDepartmentofComputerScienceEngineering,MNNITAllahabad,Prayagraj,U.P.INDIA inrealtimetodetecttheunusualbehaviourofpeoplesinpublic,forexampleviolentcrowdbehaviour,andpedestrian detection in restricted areas.",
        "In this paper, object detection approaches are utilized to detect human pedestrians and Abstract crowd behavior analysis is modeled using violent flow descriptor with SVM classification.",
        "Next part of the system Abstract isrealtimeinformationdisseminationtopoliceauthoritiesatdifferentlevels,i.e.localpolicestationpolicehead- SAubrsvteriallcatnce systems are most commonly used for monitoring/surveillance of almost all public and private places.",
        "Real time bSeuhrvaveiiloluanrcoefstyhsetseemssysatreemmsoasdtdcoexmtrmaocnalpyaucisteydtofotrhmeosunritvoeriilnlagn/scuervaecitlilvaintyc.eIonfsaulcmhocsatsaelsl,paunbyliscusapnidciporuisvaoter upnlaecveesn.",
        "aRcetaivlittyimies quarter.Thiscomponenthelpsearlyresolutionofanysevereimpactofcrowdviolenceinpublic.Systemasawhole dbS eeu thr e vacve t iie lod lua b nry coe afn sta yhl sey tss eei m nsg sytsa htree emr m esa o las tdt idm c e oexm vtirm dae o ocnas lpy trae ucais mteyd otof fo thtrhe mec o asun mrit evo rer aii slnlat g hn / r sco ueu rv gae hcitl tilvh aie ntsyc e.e sIy ons f tse aum lcmh.",
        "o Acs tatsm ael asl,x p iam unbyu l m iscupsa lpn aic dceis po, rut isv h a eot s eruup rvnla eec ivl eel s an.",
        "ncaR eceta aivc litti t vyim itiy es contributestotheintelligent/smartpolicingforeffectivelawenforcement10.",
        "idb seeth meaco vtr iee odu mbrya o naf una tah ll, eys is.",
        "eien.",
        "sgr y etsha t l eem triem saelatd vidmidee e x ovtir fda oeooc t a asp gtra eecao imt f y CotofCtThth Veecias s umm rev orean isl i l t atohn rrc eoe duga bhc y tti s vhe iec tsy ue.",
        "rsi I tyn ysts peu emc rs h.oAn cta a smls eas i ,xniams n o yumms e upc slo pan icc tei rso o,u ltshroeo osr muur.vn Iee tivli elsanndci affiectac ivcu itl titvy fiotiys r This paper is outlined in five sections.",
        "Despite introduction in first section, the related works corresponding to aidsn e y tmec hot ureem dma b n yanb aun eai a nll,y gis.t ieo n.grmethaole nitr tie oma rel C tvi C midT eeVovifd coo eoo nttas ingtr uee o aou mfsCl o y fCa tTh nVe d c tia isr m eml e eor s ans s liyttoh wrreo idt u h gbo hyu t tshea ecn suy ersirty eys s t tp.",
        "eem Trsh .oe Anre taf mlosr aie xn, imsroou bmm ues p tcn loa enc sstersoa ,ln th droe eosffmu e r.c vIt e itv ilie lsa n nde cisffis eaco cuf tls itv ufi cot h yr differentmonitoringsystemaredelineatedinsection2.Section3consistsofproposedmethodologyinwhichactivity sais unrym veho iur l e lma m nacna e nbu dea einl p ,ge i n .te do.",
        "s rme o aon lntit etiom crh e nCv oCi l d oTe gVo ic f aco loons t tta ring enue goo tuf hsCloyC faT sne Vdcutiir sriet m yleo psnseli ryt s o owr n eia dtlhs bo, yuti s .",
        "e eac .nuyh r u irt meysatp.n eTr b she oei nrnea gfl os ,ri aen n,d sroo hbm eue nstc cne oen psst o r s oae lndr t o heo effm ne.",
        "ece Itit dvieo snf dem is ffi so cor u eflst mufca ohn r detection and communication sub system are briefly described.",
        "Section four comprises the comparative analysis of psaun ory wveeh riullm faona rcn reo b ude nein dpgetnh tdo esm colo onc n ktietocs r uhrnC voC elioT llgV ainccac elo .",
        "nsTttrin henu isgo ptuha sl poy efr asn ded icsuc tiru rie stys le eps s sea lryscow onm iatlh pso l,e ut tie.ea a.n u yhtour nme o sat m .nT obu hes eirns ego fl o u,r tae ion, ndro thb heu ans t tcn wee ips ll sonsaeo n t dtho een ff lny eec ret e idv d e uon cfe ems t s hoo eref e smffu o car hnt experimentalresults.Conclusionwithanyfuturescopearedeliberatedinofsection5.",
        "opsu forwi v nee dril iv lfaoi n drc ure aolud sne bdp u ett nhw des icl ollon aclkt s e o csuh inrnvc oer l eiolalgas i encca tel h.e sTtr eheffnise g cpt t haivpo eef nre sde sis csuco ruf isty tshee pse lar a s wcoonme a n lps fl, oer tc ie.",
        "e eam .uh etou nnm toa amu n toh buo esr i i nsty golui , ntaion pnd attr hho eal n lti c nwe gipltlo hns e eoptt u hob enlli nyc ere ped ldauo cce fes mtoho fere aemffciot a yrnt.",
        "Topfo h w iisneds r yivf s oitdr eum raolu iss nbd pur t oth pwe oic sle llo daclt ksoos u uisnr e vcertei h lae laseen x cti ehs .eti T neh gffiseCcp CtaiTvpeV enrei d nsisf s r coa u sfs trtshu eec s tulaarwc e o o mefnp tfh loe ertce cei amty ue.",
        "tonV nta oar m iuoto uhu sosrcio styo m luipnt u io tpe narttrv hoi alslt iionw ngil ttl ehc neh o npt iuo qbn ull eiycs r ape rld eauce cem esp toh lfo e yae e ff cdiottyr o t.",
        "dTo e fhtii esn c dstyi t v hsite deums a u l sisspi bpc uriot opu wos isl ael cda ti l vtsoi o tyuisn fer c o rtehm aes ree exa til hse ttiimneg ff e eCv cCi t d iTv e e oVn s eiens q sfuroaesf ntcrthue e sc.tul A arwenoi e nfn ttr fhi o cer a cct e eimtyc e.o nVm tam ariu uot nuh iso c r aci tot i ymon ipn suytpes art t e rvm oilslii ios nng alts teh ocehdnp eis uqi b gul neic esdaprl tea o ced eme s cpo rle foaya see cdi t t htyoe .",
        "2.",
        "RelatedWorks rdT eeh sti pes ocstn ytshs e tee ti msmuse ispoipcf ris ooy pus oste sae mcdtifvt o oirtyu th sfe erop thmo e lire cex eaila stu tii tmn h g oer Cvit Ciide Teso.",
        "V Tsi henqi f sura sey snt scr t ueesc m.tuAi r s enc oianf pta trhibce lae ctet i o tycg .oe Vmn ame r r iua ont u eiscaac ntoia molna p rsu mytess rtieg vmn is a iil osi naflt tse hoc e h rde neisf qiogu une nes dda s rta eon edy mescu prs leo pay isc eei d othu toes frd eee lst lpe ooc w tntso her etuismn u u ses pou icfa i lsoya usc sttei a vmc i t t i yfvoi irt n ytht f her e opm roelsirct e rea ic lat tue itd mhsoe irt vieti .ideI est o.aTl s she o qisu gse eyn nsc ete rea sm.",
        "te Aissn tch iae npt car o ibc mlaet p etloe c tgo eem dnm eesruac ntrei i p cat ani t o iao nlnarre sml y a s tst eie dgmntoails tih afe ltshe oevrd eee n sfts ioguh nna edp dsp t eao nnd iyn esg cus rse ipa niscf eioot r hum es ofree flslt poe o xwn tu soe arl tui w mnaue rsn oui fanls g yam sctte eivs m sitayf g o eirns t .",
        "htheeproelsictreicatuetdhsoirtiet.ieIst.aTlshoisgseynsetreamteisstchaepcaobmleptloetgeedneesractreipatnioanlarremlatseidgntoaltihfetheevreenftsouhnadpspeanniynsgussipnicfioorums Thisreviewconcentrateonmethodologiesfordetectingdifferentobjectsofinterestlikehuman,vehicleortanketc.",
        "ofeflltoexwtuoarluwnaursnuianlgamcteivssitaygeins.therestrictedsite.Italsogeneratesthecompletedescriptionrelatedtotheeventshappeningsinform 5.Surveillanceisaverydemandingtopicnowadaysbecauseithelpstheobjectthatcanbetrackedoverlongperiods o c ft 2 e 0 x 2 tu 0 a T l h w e a A rn u in th g o m rs e .",
        "s P s u a b g l e i s s .",
        "hedbyElsevierB.V.",
        "of time under different circumstances.",
        "There are many difficulties to detect and track the object within surveillance  Tcid30 cid30 T P cid30 Tc c e h hh e 2i i2 2 i s ssr 0 0 0 - 2i iir 2 2s sse 0 0 0 v a aa T i T Tn nne h h h w o oo e e ep pp A u e ee A An nnn u u u d ta aa t t h e h hc cc o r o oc cc re er r er s s s e s ss .",
        ".",
        ".",
        "s sss P P P p a aa u o u ur rr b n t tb b t i ii l s l lc cc i i i i sl ll s s b e ee h h h i e l u ue e ui d d dn ntny d dd b b be ee y o y yr rr f E E Et tt h hth l l l h se es s ee e e e C C v C v v s i i iC CCc e e e i r r r e B B B B n B BY YYt .",
        ".",
        ".",
        "i V- -V V -fi N NN .",
        ".",
        ".",
        "c C CCc - --o N NNm D DDm l lli i iit c cct e eee n nen s sso e eef   h hhth t tt t tte p pp  T / / / / / /h c cci r rrr e eed a aa t ttI i ii v vnv e etee c ccr o oon m mmat m mimo o ono n nan s sls .",
        "..",
        "o oCo r rro g ggn / / / l lfl i iie c ccr e eee n nnn s ssc e eee s ss / / /o b bbn y yy - -- n nCn c coc - --m n nn d dpd / /u/ 4 44t .",
        ".i.",
        "0 0n0 / /g/  and Network v S i o d , e t o he d s u e e m to o d d i e ff ls er a e r n e t m ill o u s m tly in u at s i e o d n i c n on th d a i t ti p o l n a , c a e c s ro w s h s e a re sc c a l t e t a e r re d d et a e n c d tio ch n a o n f gi e n n g un b c a i c a k t g e r h o u u m nd a , n ex b i o s d te y n o c r e a o n f y ob o s th cu er rit o y bj e e t c c t .",
        "P T CPeeh oeei m s rr--m i rrs eeuvva niin eeicwwo a p tuu e io nnnndda seec rr c C erreoe ssssCpp a ooor Nnnti ssc eiil tbbe i1illu 9iit ntyy.",
        "d e oor ff thtthh e eeC ss Ccciiee Bnn Yttii- fifiN ccC cc -oo Nmm Dmm l iii ttc tte een ee soo eff  htthh ttee p TT // hh cir irr edd a tIi I vnn ettee crr onn maatt miioo onn n aas ll .oCC roo gnn /lff iee c rre een nns cce ees / ob ony n -nCC coo -mm ndpp / uu 4tt .ii 0nn / gg aanndd NNeettwwoorrkk canbedoneonthebasisoflength,widthandheight6.Heterogeneoustechniqueshavebeendefendedfortracking, C PCe ooe mmr- mmre uuv nnie iiccw aatti uioon nnd sse  rCCr o eoC sCp ooo NNn e set it b11i 9 l9i  t.",
        "y.",
        "of the scientific committee of the Third International Conference on Computing and Network detectionandidentificationofobjectsinvideos922.",
        "CKeoymwmorudnsicaItnitoenrnsetCoofCThoiNngest1C9om.puterVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge Anautomatedsurveillancesystem,knownasknight1,isasystemthatisusedforvideosurveillanceandmonitor- Kcoemywpuotrindgs.",
        "InternetofThingsComputerVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge Kcoemywpuotrindgs.",
        "InternetofThingsComputerVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge ingthroughdifferentCCTV,whichconsistsself-operativemode.Itcandetectaswellasclassifythetargetsefficiently computing.",
        "bycoherentlytrackingtheobjectthroughdifferentcamerasusingstate-of-artcomputervisiontechniques.Itproduce detailedtextualdescriptivesummaryinformationintheorbitformwithgooglemaptrackingsitelocation.Thissum- mary will gives direction to police officer in analysis and quick response decision.",
        "The limitations of surveillance 1.",
        "Introduction systemincludetheinabilitytodetectobjectwhichismasked,identifyingobjectsamongcrowd,managingcrowdand 1.",
        "Introduction workinginunfavorableweatherconditionamongtheearlierautomatedmonitoringsystem.Backgroundsubtraction 1.",
        "Introduction Videosurveillanceisthefacilitytoobserveandanalyzeanyparticularsiteforidentifyingsuspiciousactivitywith 716canalsobeoneofthesolutionfordifferentproblemsasliketrafficcontrolling,visualinspectionandinter- respVeicdteotossuarfveetiyllaanndceseiscuthrietyfapcuilriptyosteos.obVsiedrevoesaunrdveainllaalnyczeesaynsytepmarctiacmulearinstioteefxoirstiednecnetiffoyrinsgecsuursiptyicaionudscaricmtiveictyonwtritohl actionbetweencomputerandhumanbymovingobjectdetection19.Intheseapplicationswehavesomeobjectof Videosurveillanceisthefacilitytoobserveandanalyzeanyparticularsiteforidentifyingsuspiciousactivitywith respecttosafetyandsecuritypurposes.Videosurveillancesystemcameintoexistenceforsecurityandcrimecontrol interestfordetectionandthatcanbetrackedfortheiractivity.",
        "respecttosafetyandsecuritypurposes.Videosurveillancesystemcameintoexistenceforsecurityandcrimecontrol Opticalflowtechniqueisusefultoidentifythevelocitiesofmovingpointsinanimage.Opticalflowworkswhen  Correspondingauthor.Tel.91-7905514182fax0-000-000-0000.",
        "background is static and foreground object is in motion.",
        "Therefore, optical flow delivers important information of  CE-omrraeislpaodnddriensgsaduuthsohry.aTnetl.m9n1n-i7t.9ac0.5in514182fax0-000-000-0000.",
        "objectmomentumw.r.t.time17.Hassneretal.2hasproposedawellknownalgorithmforviolencecrowddetec-  CE-omrraeislpaodnddriensgsaduuthsohry.aTnetl.m9n1n-i7t.9ac0.5in514182fax0-000-000-0000.",
        "tion.Here,individualandstraightfullpostureofthebodyarecoveredinthescene.Unimodalbackgroundmodelis 1877E--0m5a0i9lacdd2r0e2ss0TdhueshAyuanthtorsm.nPnuibt.laisch.iendbyElsevierB.V.",
        "cid30 responsibletotrackmovingpersoninthescene.",
        "T PT 1 1 1 T 8 8 8 e h hhe 7 7 7i ii s sr 7 7 7 s- - - -i iri s s 0 0 0 es 5 5v 5a a a 0 0i 0n nen 9 9 9 w o o cid30 cid30 p p  o c cu e ep n n n 2 2 2 ed 0 0 0 n a ae 2 2 2 c cra 0 0 0 c ccr e e T T T ec s sse s s h h h ps e e e a aos r r A A An t ta i is u c c u u ri l l t t t tb e e h h h iic o o ol u uil r r rte n n s s sy d d .",
        ".",
        ".",
        "u e eo P P P n r rf u u u d t t b b bt h hhe l l l e er i i ie s s s C C h h h tshc e e e C Ci d d d ee B Bn b b b Ct Y Y y y yiC fi - - E E E N N cB l l l s C C s sc e e e Yo - - v v v N Nm- i i i N e e e D Dm r r r C B B B i l lt- i it c c .",
        ".",
        "N .",
        "e V V V e eeD .",
        ".",
        "n n .",
        "s so e elfic  t h hhe t tne t t p psTe   / /h / / c cihr r rd e et a atIp t tn i i v vt/e e e/r c cnc o oar m mteiao m mtn o oiav n nle s sCc .",
        ".",
        "o ooo r rmn g gf / /m l le i ir c coe e enn n ncs s s.e e eo s sro / /gn b b/ y yCl - -i n nco c cem - -n n nps d due / /st 4 4i/n .",
        ".b 0 0g / /y  a-nndc-Nnde/tw4o.0r/kCommunications J.Rehgetal.13proposedatechniquetodetectandtrackofmovingpersonwhoiswalkinginprohibitedareaof PT PCeh eoei e srCr-- iros reNeva vieneitewo1w p9ue nn u.dn aec drc ere res ss rpe aor snt p isc oilbn eisluiitn byd il eoi r tfy tth he oef Cs cC thiee Bn tY sifi- c Ncie Ccno- t Nmifi Dmc ilti ctc oeeem nsom ef ith tht tee tp eT /ho /cifrr de t a hItne ivt ee Trcnh oam itridom no Ian nls tCe .o ror nng af/let i irc oee nnn acsel e soC /nb o yCn -n foe cmr -n epn du/ ct4ien.0 go /ann dCNometwpuotrikngC oamnmd uNniectawtioonrks kioskbyusingfacedetection,skincolorandstereo.StaufferandGrimson14proposedaBackgroundSubtraction P CCe ooe m rC-rom eNv u ien etwi1ca9u tn i.o de n r s r  e C sp o o C n o si N bi e li t t  y 19 o  f .",
        "thescientificcommitteeoftheThirdInternationalConferenceonComputingandNetworkCommunications modelthathascapabilitytoprovidegoodresultswhilechangeshappensduetoillumination,repeateddisorderfrom 1C0o.1C0o1N6/ejt.p19ro.cs.2020.04.036 10.1016/j.procs.2020.04.036 1877-0509 Availableonlineatwww.sciencedirect.com Availableonlineatwww.sciencedirect.com Availableonlineatwww.sciencedirect.com Dushyant Kumar Singh et al.",
        "/ Procedia Computer Science 171 2020 350359 351 2 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 ProcediaComputerScience002019000000 in the society.",
        "Currently, video cameras are used for such kind of surveillance and they can be deployed in several ProcediaComputerScience002019000000 www.elsevier.com/locate/procedia placeseasilysuchascompanies,railwaystations,shoppingcenters,bankofficesandATMmachinesetc.",
        "ProcediaComputerScience002019000000 www.elsevier.com/locate/procedia Somedecadesago,videosurveillancesystemwerenotsomuchprevalentasoftoday.Variouschangesinthisperiod www.elsevier.com/locate/procedia haveresultedindeploymentandgrowthofvideosurveillancesystem.Humansocialdysfunctionischangingandtheir ThirdInternationalConferenceonComputingandNetworkCommunicationsCoCoNet19 ThirdInternationalConferenceonComputingandNetworkCommunicationsCoCoNet19 approach to security is becoming more sensible.",
        "In present time, everyone is getting familiar with technological ThirdInteHrnuatmionaanlCConrfoewrendceDoneCteocmtpiuotningfoanrdCNeittwyoWrkCidomemSuunricvaetioilnlsanCcoCeoNet19 platformtohandledifferentsecuritytasks.CCTVusageisgettingmorepopularwiththepriceaffordabilityandless Human Crowd Detection for City Wide Surveillance effortfortheirsetup.Thesesurveillancesystemarefruitlesstoprovidesecurity,untilinadequatecapacityoftrained Human Crowd Detection for City Wide Surveillance peoplewiththeirhighattentioncompetencearefulfilledforwatchingtheflicks12.AccordingtoH.Keval3and Dushyant Kumar Singha, , Sumit Paroothib, Mayank Kumar Rusiac, Mohd.",
        "Aquib Ansarid Dushyant Kumar Singha,  , Sumit Paroothib, Mayank Kumar Rusiac, Mohd.",
        "Aquib Ansarid N.Petrovic4,Monitoringsystemconsistsoflargenumberofcamerasthathelpstomonitordifferentsites.Itisused Dushyant KumaarDSepianrtgmehn a t , o  f,CSomupmuteirtScPieanrceootEhngii b n,eeMringa,yMaNnNIkTAKllauhmabaadr,PRrauyasgiraaj, c U,.MP.INoDhIdA.",
        "Aquib Ansarid todetectanynoticeableandunwantedorillegalactivity,soastoimmediatelyrespondtothesituationwithveryshort aDepartmentofCompubteMroSrcgieanncSetanlEeny,gBineenegrliunrgu,,MKNaNrnIaTtaAklala,hINabDaIdA,Prayagraj,U.P.INDIA delay.Sometimes,searchingspecificactivityfromthelargeamountofrecordedvideosfilesseemsverydifficultand acDDeeppaarrttmmeennttooffCCoommppuubtteeMrroSSrccgiieeannnccSeetanlEEenny,ggBiinneeeneegrrliiunnrggu,,,MMKNNaNNrnIIaTTtaAAkllallaa,hhINaabbDaaIddA,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA timeconsumingprocessforexaminingtheoccurredevent.Hence,itrequirescomputervisionsystem.",
        "dcDDeeppaarrttmmeennttooffCCoommppuu b tteeMrroSSrccgiieeannnccSeetanlEEenny,ggBiinneeeneegrrliiunnrggu,,,MMKNNaNNrnIIaTTtaAAkllallaa,hhINaabbDaaIddA,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA dcDDeeppaarrttmmeennttooffCCoommppuutteerrSScciieenncceeEEnnggiinneeeerriinngg,,MMNNNNIITTAAllllaahhaabbaadd,,PPrraayyaaggrraajj,,UU..PP..IINNDDIIAA Thesystemproposedhereaimstoovercomelimitationsoftraditionalsurveillancetechniques.Thissystemworks dDepartmentofComputerScienceEngineering,MNNITAllahabad,Prayagraj,U.P.INDIA inrealtimetodetecttheunusualbehaviourofpeoplesinpublic,forexampleviolentcrowdbehaviour,andpedestrian detection in restricted areas.",
        "In this paper, object detection approaches are utilized to detect human pedestrians and Abstract crowd behavior analysis is modeled using violent flow descriptor with SVM classification.",
        "Next part of the system Abstract isrealtimeinformationdisseminationtopoliceauthoritiesatdifferentlevels,i.e.localpolicestationpolicehead- SAubrsvteriallcatnce systems are most commonly used for monitoring/surveillance of almost all public and private places.",
        "Real time bSeuhrvaveiiloluanrcoefstyhsetseemssysatreemmsoasdtdcoexmtrmaocnalpyaucisteydtofotrhmeosunritvoeriilnlagn/scuervaecitlilvaintyc.eIonfsaulcmhocsatsaelsl,paunbyliscusapnidciporuisvaoter upnlaecveesn.",
        "aRcetaivlittyimies quarter.Thiscomponenthelpsearlyresolutionofanysevereimpactofcrowdviolenceinpublic.Systemasawhole dbS eeu thr e vacve t iie lod lua b nry coe afn sta yhl sey tss eei m nsg sytsa htree emr m esa o las tdt idm c e oexm vtirm dae o ocnas lpy trae ucais mteyd otof fo thtrhe mec o asun mrit evo rer aii slnlat g hn / r sco ueu rv gae hcitl tilvh aie ntsyc e.e sIy ons f tse aum lcmh.",
        "o Acs tatsm ael asl,x p iam unbyu l m iscupsa lpn aic dceis po, rut isv h a eot s eruup rvnla eec ivl eel s an.",
        "ncaR eceta aivc litti t vyim itiy es contributestotheintelligent/smartpolicingforeffectivelawenforcement10.",
        "idb seeth meaco vtr iee odu mbrya o naf una tah ll, eys is.",
        "eien.",
        "sgr y etsha t l eem triem saelatd vidmidee e x ovtir fda oeooc t a asp gtra eecao imt f y CotofCtThth Veecias s umm rev orean isl i l t atohn rrc eoe duga bhc y tti s vhe iec tsy ue.",
        "rsi I tyn ysts peu emc rs h.oAn cta a smls eas i ,xniams n o yumms e upc slo pan icc tei rso o,u ltshroeo osr muur.vn Iee tivli elsanndci affiectac ivcu itl titvy fiotiys r This paper is outlined in five sections.",
        "Despite introduction in first section, the related works corresponding to aidsn e y tmec hot ureem dma b n yanb aun eai a nll,y gis.t ieo n.grmethaole nitr tie oma rel C tvi C midT eeVovifd coo eoo nttas ingtr uee o aou mfsCl o y fCa tTh nVe d c tia isr m eml e eor s ans s liyttoh wrreo idt u h gbo hyu t tshea ecn suy ersirty eys s t tp.",
        "eem Trsh .oe Anre taf mlosr aie xn, imsroou bmm ues p tcn loa enc sstersoa ,ln th droe eosffmu e r.c vIt e itv ilie lsa n nde cisffis eaco cuf tls itv ufi cot h yr differentmonitoringsystemaredelineatedinsection2.Section3consistsofproposedmethodologyinwhichactivity sais unrym veho iur l e lma m nacna e nbu dea einl p ,ge i n .te do.",
        "s rme o aon lntit etiom crh e nCv oCi l d oTe gVo ic f aco loons t tta ring enue goo tuf hsCloyC faT sne Vdcutiir sriet m yleo psnseli ryt s o owr n eia dtlhs bo, yuti s .",
        "e eac .nuyh r u irt meysatp.n eTr b she oei nrnea gfl os ,ri aen n,d sroo hbm eue nstc cne oen psst o r s oae lndr t o heo effm ne.",
        "ece Itit dvieo snf dem is ffi so cor u eflst mufca ohn r detection and communication sub system are briefly described.",
        "Section four comprises the comparative analysis of psaun ory wveeh riullm faona rcn reo b ude nein dpgetnh tdo esm colo onc n ktietocs r uhrnC voC elioT llgV ainccac elo .",
        "nsTttrin henu isgo ptuha sl poy efr asn ded icsuc tiru rie stys le eps s sea lryscow onm iatlh pso l,e ut tie.ea a.n u yhtour nme o sat m .nT obu hes eirns ego fl o u,r tae ion, ndro thb heu ans t tcn wee ips ll sonsaeo n t dtho een ff lny eec ret e idv d e uon cfe ems t s hoo eref e smffu o car hnt experimentalresults.Conclusionwithanyfuturescopearedeliberatedinofsection5.",
        "opsu forwi v nee dril iv lfaoi n drc ure aolud sne bdp u ett nhw des icl ollon aclkt s e o csuh inrnvc oer l eiolalgas i encca tel h.e sTtr eheffnise g cpt t haivpo eef nre sde sis csuco ruf isty tshee pse lar a s wcoonme a n lps fl, oer tc ie.",
        "e eam .uh etou nnm toa amu n toh buo esr i i nsty golui , ntaion pnd attr hho eal n lti c nwe gipltlo hns e eoptt u hob enlli nyc ere ped ldauo cce fes mtoho fere aemffciot a yrnt.",
        "Topfo h w iisneds r yivf s oitdr eum raolu iss nbd pur t oth pwe oic sle llo daclt ksoos u uisnr e vcertei h lae laseen x cti ehs .eti T neh gffiseCcp CtaiTvpeV enrei d nsisf s r coa u sfs trtshu eec s tulaarwc e o o mefnp tfh loe ertce cei amty ue.",
        "tonV nta oar m iuoto uhu sosrcio styo m luipnt u io tpe narttrv hoi alslt iionw ngil ttl ehc neh o npt iuo qbn ull eiycs r ape rld eauce cem esp toh lfo e yae e ff cdiottyr o t.",
        "dTo e fhtii esn c dstyi t v hsite deums a u l sisspi bpc uriot opu wos isl ael cda ti l vtsoi o tyuisn fer c o rtehm aes ree exa til hse ttiimneg ff e eCv cCi t d iTv e e oVn s eiens q sfuroaesf ntcrthue e sc.tul A arwenoi e nfn ttr fhi o cer a cct e eimtyc e.o nVm tam ariu uot nuh iso c r aci tot i ymon ipn suytpes art t e rvm oilslii ios nng alts teh ocehdnp eis uqi b gul neic esdaprl tea o ced eme s cpo rle foaya see cdi t t htyoe .",
        "2.",
        "RelatedWorks rdT eeh sti pes ocstn ytshs e tee ti msmuse ispoipcf ris ooy pus oste sae mcdtifvt o oirtyu th sfe erop thmo e lire cex eaila stu tii tmn h g oer Cvit Ciide Teso.",
        "V Tsi henqi f sura sey snt scr t ueesc m.tuAi r s enc oianf pta trhibce lae ctet i o tycg .oe Vmn ame r r iua ont u eiscaac ntoia molna p rsu mytess rtieg vmn is a iil osi naflt tse hoc e h rde neisf qiogu une nes dda s rta eon edy mescu prs leo pay isc eei d othu toes frd eee lst lpe ooc w tntso her etuismn u u ses pou icfa i lsoya usc sttei a vmc i t t i yfvoi irt n ytht f her e opm roelsirct e rea ic lat tue itd mhsoe irt vieti .ideI est o.aTl s she o qisu gse eyn nsc ete rea sm.",
        "te Aissn tch iae npt car o ibc mlaet p etloe c tgo eem dnm eesruac ntrei i p cat ani t o iao nlnarre sml y a s tst eie dgmntoails tih afe ltshe oevrd eee n sfts ioguh nna edp dsp t eao nnd iyn esg cus rse ipa niscf eioot r hum es ofree flslt poe o xwn tu soe arl tui w mnaue rsn oui fanls g yam sctte eivs m sitayf g o eirns t .",
        "htheeproelsictreicatuetdhsoirtiet.ieIst.aTlshoisgseynsetreamteisstchaepcaobmleptloetgeedneesractreipatnioanlarremlatseidgntoaltihfetheevreenftsouhnadpspeanniynsgussipnicfioorums Thisreviewconcentrateonmethodologiesfordetectingdifferentobjectsofinterestlikehuman,vehicleortanketc.",
        "ofeflltoexwtuoarluwnaursnuianlgamcteivssitaygeins.therestrictedsite.Italsogeneratesthecompletedescriptionrelatedtotheeventshappeningsinform 5.Surveillanceisaverydemandingtopicnowadaysbecauseithelpstheobjectthatcanbetrackedoverlongperiods o c ft 2 e 0 x 2 tu 0 a T l h w e a A rn u in th g o m rs e .",
        "s P s u a b g l e i s s .",
        "hedbyElsevierB.V.",
        "of time under different circumstances.",
        "There are many difficulties to detect and track the object within surveillance cid30 Tchi2s0i2s0aTnhoepeAnuathcocerss.sPaurtbilcilsehuedndbeyrEthleseCviCerBBY.-VN.C-NDlicensehttp//creativecommons.org/licenses/by-nc-nd/4.0/ videoduetodifferentilluminationcondition,acrossascatteredandchangingbackground,existenceofobscurityetc.",
        "P cid30 T cid30 c ehei2sr 0 -ir 2se 0 vai Tne h woepueAnn u dat e hcr ocer r s es.ss P pao urntbis lci ils beh ilue i dntydbeo yrf Etht l hes e eCv s iCc e i r eBn BYt .",
        "i-V fiN.",
        "cCc-oNmDmliitcteenesoefhthttepT//hcirredatIivnetecronmatmioonnasl.oCrogn/lfiecreennscees/obny-nCco-mndp/u4t.i0n/g and Network So, these models are mostly used in that places where clear detection of enunciate human body or any other object CPTeh oei m sr-m irseuva nineicwo a p tue io nnnda secr c C ereo sssCpa oor Nntisc eil tbe 1ilu 9inty.",
        "deorfththeeCsCcieBnYti-fiNcCc-oNmDmliitcteenesoefhthttepT // hcirredatIivnetecronmatmioonnasl.oCrogn /lfiecreennscees/ obny-nCco-mndp / u4t.i0n / g and Network canbedoneonthebasisoflength,widthandheight6.Heterogeneoustechniqueshavebeendefendedfortracking, CPeoemr-mreuvnieicwatuionndserCreosCpooNnseitb1il9ity.",
        "of the scientific committee of the Third International Conference on Computing and Network detectionandidentificationofobjectsinvideos922.",
        "KCeoymwmorudnsicaItnitoenrnsetCoofCThoiNngest1C9om.puterVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge Anautomatedsurveillancesystem,knownasknight1,isasystemthatisusedforvideosurveillanceandmonitor- Kcoemywpuotrindgs.",
        "InternetofThingsComputerVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge Kcoemywpuotrindgs.",
        "InternetofThingsComputerVisionAutomatedVideoSurveillanceCCTVmonitoringActivitydetectionHumandetectionEdge ingthroughdifferentCCTV,whichconsistsself-operativemode.Itcandetectaswellasclassifythetargetsefficiently computing.",
        "bycoherentlytrackingtheobjectthroughdifferentcamerasusingstate-of-artcomputervisiontechniques.Itproduce detailedtextualdescriptivesummaryinformationintheorbitformwithgooglemaptrackingsitelocation.Thissum- mary will gives direction to police officer in analysis and quick response decision.",
        "The limitations of surveillance 1.",
        "Introduction systemincludetheinabilitytodetectobjectwhichismasked,identifyingobjectsamongcrowd,managingcrowdand 1.",
        "Introduction workinginunfavorableweatherconditionamongtheearlierautomatedmonitoringsystem.Backgroundsubtraction 1.",
        "Introduction Videosurveillanceisthefacilitytoobserveandanalyzeanyparticularsiteforidentifyingsuspiciousactivitywith 716canalsobeoneofthesolutionfordifferentproblemsasliketrafficcontrolling,visualinspectionandinter- respVeicdteotossuarfveetiyllaanndceseiscuthrietyfapcuilriptyosteos.obVsiedrevoesaunrdveainllaalnyczeesaynsytepmarctiacmulearinstioteefxoirstiednecnetiffoyrinsgecsuursiptyicaionudscaricmtiveictyonwtriothl actionbetweencomputerandhumanbymovingobjectdetection19.Intheseapplicationswehavesomeobjectof Videosurveillanceisthefacilitytoobserveandanalyzeanyparticularsiteforidentifyingsuspiciousactivitywith respecttosafetyandsecuritypurposes.Videosurveillancesystemcameintoexistenceforsecurityandcrimecontrol interestfordetectionandthatcanbetrackedfortheiractivity.",
        "respecttosafetyandsecuritypurposes.Videosurveillancesystemcameintoexistenceforsecurityandcrimecontrol Opticalflowtechniqueisusefultoidentifythevelocitiesofmovingpointsinanimage.Opticalflowworkswhen  Correspondingauthor.Tel.91-7905514182fax0-000-000-0000.",
        "background is static and foreground object is in motion.",
        "Therefore, optical flow delivers important information of  EC-omrraeislpaodnddriensgsaduuthsohry.aTnetl.m9n1n-i7t.9ac0.5in514182fax0-000-000-0000.",
        "objectmomentumw.r.t.time17.Hassneretal.2hasproposedawellknownalgorithmforviolencecrowddetec-  EC-omrraeislpaodnddriensgsaduuthsohry.aTnetl.m9n1n-i7t.9ac0.5in514182fax0-000-000-0000.",
        "tion.Here,individualandstraightfullpostureofthebodyarecoveredinthescene.Unimodalbackgroundmodelis 1877E--0m5a0i9lacdd2r0e2ss0TdhueshAyuanthtorsm.nPnuibt.laisch.iendbyElsevierB.V.",
        "cid30 responsibletotrackmovingpersoninthescene.",
        "T18h7is7-is05a0n9opcen20a2c0ceTsshearAticultehournsd.ePrutbhleisCheCdBbYy-ENlCse-vNieDrBlic.Ve.nsehttp//creativecommons.org/licenses/by-nc-nd/4.0/ PT18ehe7isr7--irs0e5va0ine9wo cid30 pcuenn2d0ae2cr0creTessshpeaorAntiscuiltbehioluirtnsyd.eoPrfutbthhleiesChsceCideBnbtYyifi-ENclCsceo-vNmieDmrBiltitc.eVee.nsoefthhtetpT/h/cirrdeaItnivteercnoamtiomnoanlsC.oorngf/leirceenncseeso/nbyC-nocm-npdu/t4in.0g/andNetworkCommunications J.Rehgetal.13proposedatechniquetodetectandtrackofmovingpersonwhoiswalkinginprohibitedareaof cid30 PTCehoeisrC-iroseNvaienetwo1p9uenn.daecrcreessspaorntiscilbeiluitnydeorftthheeCscCieBntYifi-NcCco-NmDmiltitceeensoefthhtetpT/h/cirrdeaItnivteercnoamtiomnoanlsC.oorngf/leirceenncseeso/nbyC-nocm-npdu/t4in.0g/andNetworkCommunications kioskbyusingfacedetection,skincolorandstereo.StaufferandGrimson14proposedaBackgroundSubtraction PCeoerC-roeNvieetw19un.derresponsibilityofthescientificcommitteeoftheThirdInternationalConferenceonComputingandNetworkCommunications modelthathascapabilitytoprovidegoodresultswhilechangeshappensduetoillumination,repeateddisorderfrom CoCoNet19.",
        "352 Dushyant Kumar Singh et al.",
        "/ Procedia Computer Science 171 2020 350359 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 3 4 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 backgroundmotion,andlongscenechangingstatus.Theyobservedundesiredorsuspiciousactivitiesthroughanalysis Background Subtraction Technique 7 17 is mostly used in real time scenario, as HOG could not work in of statistics rules and specified amount of time learning mechanism of common patterns of activities.",
        "Ricquebourg realtimeefficientllyduetoitshighrequirementofprocessingspeed.Therefore,insteadofprocessingeachframewe andBouthemy15usesspatiotemporalmechanismtotrackanddetectthepersonbyfindingthetemporaldifferences processtheframesinwhichthemotionisdetected.Formotiondetection,backgroundsubtractionalgorithmisused, amongthreesuccessiveframesandafterthatcomparisonistakeplacebetweencurrentframetobackgroundreference inwhichthepixelpositionbetweentwoimagescanshowthetruedifferenceinintensitywithrespecttodisplacement.",
        "framewithconsideringintensitychange.",
        "If,weremovethebackgroundthenthisisassumedthatbackgroundpixelsarestaticandforegroundimagepixelsare Abdelkaderetal.18suggestedaframeworkfordetectingthegestureandactionrecognitionbasedonsilhouette in motion.",
        "When movement is detected by background subtraction algorithm, HOG  SVM Classifier is triggered mechanism.ThisrecognitionwasdoneviamodellingtrajectoriesonRiemannianshapemanifoldsmethodology.Kel- for human detection.",
        "Now, any threshold value can be taken accordingly to improve the accuracy of approach.",
        "If, lokumpuetal.20usedthedynamictexturebasedmethodstorecognizethehumanactivitiesinspatiotemporalway.",
        "movementinimageisfastthenhighervalueofthresholdisneeded.",
        "The LBP-TOP is used for extracting the features in spatiotemporal space to identify human volumes as well as its HistogramofGradientHOG1121isawell-knowntechniqueofthecomputervision.Itisbasicallyaglobal movements.Asper8and9,CCTVtechnologyhasraisedthedemandofCCTVdeploymentincommercialaswell imagedescriptorusedforobjectdetectionandfeatureextractionwithveryhighsuccessrate.Themainobjectiveof aspublicandprivatesectorstofulfiltheneedofsecuritytask.NowadaysnumerousCCTVusershavingversatile HOGdescriptoristocounttheexistenceofgradientsorientationswithintheimagelocally.TheHOGusesnumberof skills,managementandtroubleshootingexperience.Forexample,USgovernmentallowswebuserstoseeliveCCTV stepsforextractingthefeaturesfromtheimage.Firststepistosplittheimageintotheblocks.Further,theseblocks videofootagethroughinternettomonitorillegalcrossingandconveysuchtypeofactivitytorespectiveauthorities.",
        "areechelonedintothecells.Then,thehorizontalandverticalgradientsareevaluatedforeachpixelwithinthecell.",
        "ResidentsofUKuseslivedigitalCCTVimagestorecognizeanysuspiciousorunpredictableactivitybysubscribing TheSobeloperatorcanbeusedforevaluatingthesegradientsasshowninequation1and2.",
        "communitysafetychannelsandrespondimmediatelytopoliceifsomethingfoundillegal.",
        "S y,xYy,x1 Yy,x 1 1 x   S y,xYy1,x Yy 1,x 2 3.",
        "Methodology y   Where the pixel intensity with co-ordinates value x, y is represented by Yy, x.",
        "The horizontal and vertical ThesystemwouldmakeuseoftheexistingCCTVinfrastructureinpublicplaceslikeparks,railwaystation,roads, gradientsarerepresentedbyS y,xandS y,xrespectively.ThegradientsmagnitudeSanditsorientationθcan shoppingcomplexesetc.anddetectsuspiciousactivitiesusingsophisticatedcomputervisiontechniques.Thesystem x y bedrawnbyequation3andequation4.",
        "would alert the main police control room or Headquarter and the nearest police station with relevant information in case any suspicious/unwanted activity is detected.",
        "The system consists of two distinct components i.e.",
        "activity S  S2S2 3 detectionmoduleandcommunicationmodule.",
        "x y cid31 S y 3.1.",
        "ActivityDetectionModule θarctan  4 S x Thiscomponentdetectsthesuspicious/unwantedactivity121315inrealtimefromthevideofeedandinforms Theninenumberofhistogrambinsareusedforstoringeachorientationofgradients.Later,thisprocessisrepeated to communication component.",
        "This system aims to detect pedestrian in the prohibited area and to identify violent foreachcell.Thecellhistogramsarecombinedforeachblock.Innextstep,blocknormalizationprocessisperformed behaviorofcrowdforcitywidesurveillance.",
        "fornormalizingtheeachvalueofbins.Theblocknormalizationplaysanimportantroletomakethisdescriptorfree fromlightningvariations.Atlast,allthehistogramvectorsareconcatenatedintoonevector.Thisresultantvectorcan alsobereferencedasfeaturevectorwhichcanbeusedforobjectdetection.Further,thesefeaturevectorsareusedto 3.1.1.",
        "PedestriandetectioninProhibitedArea buildtheSVMclassifierwhichhelpstodecidewhethertheresultingobjectishumanornot.",
        "Pedestrian detection in prohibited area is aimed to detect presence of people in a prohibited area and capture a Support Vector Machine SVM is very effective and useful machine learning technique to classify different pictureasevidence.Theobjectiveisachievedbytakingadvantageofbackgroundsubtractiontechniqueandhistogram classes.",
        "SVM classifier technique basically used to maximize the marginal difference between two distinct classes.",
        "oforientedgradientsHOG.Theworkflowofpedestriandetectionframeworkisillustratedinfigure1.",
        "PerformanceofSVMisbestinhighdimensionalspaceespeciallywhenavailabledatasetisless.SVMworkswellfor linearhyperplaneaswellasmultidimensionalhyperplanebutitcanalsobegoodifdataisnotinlinearform.Sofor non-linearclassificationSVMusesdifferentkernelfunctionforvariousdecisionfunction.Thisiscalledapproximation function.Twomostcommonlyusedfunctionsarelossfunctionandobjectivefunction.LossFunctiondescribeswhat to minimize to achieve best results.",
        "Hinge Loss is used for training classifier and maximize margin classification is usedforsupportvectormachine.",
        "Cx,y, fx1 y fx 5    Here, C, x, y and fx are loss, sample value, true level and predicted level respectively.",
        "If y fx 1 then   Cx,y, fx0otherwiseCx,y, fx1 y fx.",
        "ObjectivefunctionofSVMconcernwithregularizerandloss.Wewanttofindthedecisionsurfacethatismaximum farawayfromanydatapoints.Regularizercontrolsthetradeoff,sothattrainingandtestingerrorscanbeminimizedto improvetheperformanceofclassifierforunseendata.Ifsamplesareclassifiedcorrectlythenweightwcanbeupdated bythegradientusingequation6.",
        "Fig.1.WorkFlowofPedestrianDetectionFramework wwn 2νw 6  Dushyant Kumar Singh et al.",
        "/ Procedia Computer Science 171 2020 350359 353 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 3 4 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 backgroundmotion,andlongscenechangingstatus.Theyobservedundesiredorsuspiciousactivitiesthroughanalysis Background Subtraction Technique 7 17 is mostly used in real time scenario, as HOG could not work in of statistics rules and specified amount of time learning mechanism of common patterns of activities.",
        "Ricquebourg realtimeefficientllyduetoitshighrequirementofprocessingspeed.Therefore,insteadofprocessingeachframewe andBouthemy15usesspatiotemporalmechanismtotrackanddetectthepersonbyfindingthetemporaldifferences processtheframesinwhichthemotionisdetected.Formotiondetection,backgroundsubtractionalgorithmisused, amongthreesuccessiveframesandafterthatcomparisonistakeplacebetweencurrentframetobackgroundreference inwhichthepixelpositionbetweentwoimagescanshowthetruedifferenceinintensitywithrespecttodisplacement.",
        "framewithconsideringintensitychange.",
        "If,weremovethebackgroundthenthisisassumedthatbackgroundpixelsarestaticandforegroundimagepixelsare Abdelkaderetal.18suggestedaframeworkfordetectingthegestureandactionrecognitionbasedonsilhouette in motion.",
        "When movement is detected by background subtraction algorithm, HOG  SVM Classifier is triggered mechanism.ThisrecognitionwasdoneviamodellingtrajectoriesonRiemannianshapemanifoldsmethodology.Kel- for human detection.",
        "Now, any threshold value can be taken accordingly to improve the accuracy of approach.",
        "If, lokumpuetal.20usedthedynamictexturebasedmethodstorecognizethehumanactivitiesinspatiotemporalway.",
        "movementinimageisfastthenhighervalueofthresholdisneeded.",
        "The LBP-TOP is used for extracting the features in spatiotemporal space to identify human volumes as well as its HistogramofGradientHOG1121isawell-knowntechniqueofthecomputervision.Itisbasicallyaglobal movements.Asper8and9,CCTVtechnologyhasraisedthedemandofCCTVdeploymentincommercialaswell imagedescriptorusedforobjectdetectionandfeatureextractionwithveryhighsuccessrate.Themainobjectiveof aspublicandprivatesectorstofulfiltheneedofsecuritytask.NowadaysnumerousCCTVusershavingversatile HOGdescriptoristocounttheexistenceofgradientsorientationswithintheimagelocally.TheHOGusesnumberof skills,managementandtroubleshootingexperience.Forexample,USgovernmentallowswebuserstoseeliveCCTV stepsforextractingthefeaturesfromtheimage.Firststepistosplittheimageintotheblocks.Further,theseblocks videofootagethroughinternettomonitorillegalcrossingandconveysuchtypeofactivitytorespectiveauthorities.",
        "areechelonedintothecells.Then,thehorizontalandverticalgradientsareevaluatedforeachpixelwithinthecell.",
        "ResidentsofUKuseslivedigitalCCTVimagestorecognizeanysuspiciousorunpredictableactivitybysubscribing TheSobeloperatorcanbeusedforevaluatingthesegradientsasshowninequation1and2.",
        "communitysafetychannelsandrespondimmediatelytopoliceifsomethingfoundillegal.",
        "S y,xYy,x1 Yy,x 1 1 x   S y,xYy1,x Yy 1,x 2 3.",
        "Methodology y   Where the pixel intensity with co-ordinates value x, y is represented by Yy, x.",
        "The horizontal and vertical ThesystemwouldmakeuseoftheexistingCCTVinfrastructureinpublicplaceslikeparks,railwaystation,roads, gradientsarerepresentedbyS y,xandS y,xrespectively.ThegradientsmagnitudeSanditsorientationθcan shoppingcomplexesetc.anddetectsuspiciousactivitiesusingsophisticatedcomputervisiontechniques.Thesystem x y bedrawnbyequation3andequation4.",
        "would alert the main police control room or Headquarter and the nearest police station with relevant information in case any suspicious/unwanted activity is detected.",
        "The system consists of two distinct components i.e.",
        "activity S  S2S2 3 detectionmoduleandcommunicationmodule.",
        "x y cid31 S y 3.1.",
        "ActivityDetectionModule θarctan  4 S x Thiscomponentdetectsthesuspicious/unwantedactivity121315inrealtimefromthevideofeedandinforms Theninenumberofhistogrambinsareusedforstoringeachorientationofgradients.Later,thisprocessisrepeated to communication component.",
        "This system aims to detect pedestrian in the prohibited area and to identify violent foreachcell.Thecellhistogramsarecombinedforeachblock.Innextstep,blocknormalizationprocessisperformed behaviorofcrowdforcitywidesurveillance.",
        "fornormalizingtheeachvalueofbins.Theblocknormalizationplaysanimportantroletomakethisdescriptorfree fromlightningvariations.Atlast,allthehistogramvectorsareconcatenatedintoonevector.Thisresultantvectorcan alsobereferencedasfeaturevectorwhichcanbeusedforobjectdetection.Further,thesefeaturevectorsareusedto 3.1.1.",
        "PedestriandetectioninProhibitedArea buildtheSVMclassifierwhichhelpstodecidewhethertheresultingobjectishumanornot.",
        "Pedestrian detection in prohibited area is aimed to detect presence of people in a prohibited area and capture a Support Vector Machine SVM is very effective and useful machine learning technique to classify different pictureasevidence.Theobjectiveisachievedbytakingadvantageofbackgroundsubtractiontechniqueandhistogram classes.",
        "SVM classifier technique basically used to maximize the marginal difference between two distinct classes.",
        "oforientedgradientsHOG.Theworkflowofpedestriandetectionframeworkisillustratedinfigure1.",
        "PerformanceofSVMisbestinhighdimensionalspaceespeciallywhenavailabledatasetisless.SVMworkswellfor linearhyperplaneaswellasmultidimensionalhyperplanebutitcanalsobegoodifdataisnotinlinearform.Sofor non-linearclassificationSVMusesdifferentkernelfunctionforvariousdecisionfunction.Thisiscalledapproximation function.Twomostcommonlyusedfunctionsarelossfunctionandobjectivefunction.LossFunctiondescribeswhat to minimize to achieve best results.",
        "Hinge Loss is used for training classifier and maximize margin classification is usedforsupportvectormachine.",
        "Cx,y, fx1 y fx 5    Here, C, x, y and fx are loss, sample value, true level and predicted level respectively.",
        "If y fx 1 then   Cx,y, fx0otherwiseCx,y, fx1 y fx.",
        "ObjectivefunctionofSVMconcernwithregularizerandloss.Wewanttofindthedecisionsurfacethatismaximum farawayfromanydatapoints.Regularizercontrolsthetradeoff,sothattrainingandtestingerrorscanbeminimizedto improvetheperformanceofclassifierforunseendata.Ifsamplesareclassifiedcorrectlythenweightwcanbeupdated bythegradientusingequation6.",
        "Fig.1.WorkFlowofPedestrianDetectionFramework wwn 2νw 6  354 Dushyant Kumar Singh et al.",
        "/ Procedia Computer Science 171 2020 350359 6 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 5 Fig.2.WorkFlowofViolentCrowdDetectionFramework Ifsamplesaremisclassifiedthangradientofbothtermscanbeupdatedwithrespecttoweightvectorasshownin eqation7.",
        "wwnyx 2νw 7 i i  Wherenisthelearningrateandνisregularizer.Asaregularizingparameterwehavetochoose1/epochsepoch Numberofiterationtotrainthemachine.",
        "3.1.2.",
        "ViolentCrowdBehavior Fig.3.FlowofCommunicationModule ViolentCrowdBehaviorfocusesonmonitoringthecrowdedeventsforoutbreaksofviolence.Efficientanalysisin realtimeoperatingenvironmentcanbeachievedbyobservingdensityonaspecificpointandmotionofthecrowdin specificdirection.Movementofthecrowdtowardscertainplacecanbeoneofthecausetoviolence.Forthepurpose, 3.1.3.",
        "CommunicationModule we have to find out high shape and intensive processing without compromising processing speed with respect to This component is responsible for transferring of information from the site under surveillance to the pertinent changes observed in vector magnitudes through time.",
        "The Violent Flows ViF descriptor is used here to extract police control room.",
        "There are 3 types of nodes in communication module architecture i.e.",
        "main server, client A, the motion information for sequence of frames.",
        "Further, these vectors are used svm classifier 18 22 is used for clientB.ThebriefarchitectureofcommunicationmoduleforproposedsystemisshowninFigure3.",
        "classifying the violent or non-violent behaviour.",
        "The complete process for violent crowd detection is presented in Mainserverisresponsibleforallkindsofcommunicationsinthesystem.Asimplewebserverhasbeenutilized Figure2.",
        "forthispurpose.ARESTfulwebserviceismadetorunontheserverwhichrespondstotherequestofallotherclients.",
        "ViF representation framework 23 24 is used to notice the violence in the real time video sequences.",
        "It is Currentlythebuilt-inserverofflaskhasbeenutilized.Italsomaintainsadatabasewhichstores calculated into various steps.",
        "First step is to evaluate the optical flow vectors between the couples of successive videosequences.Theflowvectorsareprovidedforeachframepixels.ThepixelisrepresentedbyP andtheflow x,y,t Configurationsettingsforeachsurveillancesitediscussedindetaillater.",
        "vectorsaredenotedbyu x,y,t andv x,y,t .Where,tisrepresentedbyindexofframe.Themagnitudeofthevectorscanbe  IDs for each surveillance site, police control room along with description address, contact and other relevant representedbyequation8.",
        "info.",
        "M  u2 v2 8 Messagesreceivedfromsurveillancesites.",
        "x,y,t x,y,t x,y,t  cid31 Next,thebinaryindicator B x,y,t isevaluatedforeachframepixels.Itisevaluatedbyif  M x,y,t  M x,y,t  1  θ then TheparticularsofthedatabaseschemacanbeprocuredfromFigure4.",
        "B  1otherwise B  0.Itshowstheimportanceofmagnitudesadjustmentamongvideoframes.Where,θ is x,y,t x,y,t thethresholdvaluethatisadaptivelyfixedtoaveragerateof M M .Here,theaveragemodificationchange  x,y,t  x,y,t  1 mapisevaluatedforindividualpixelsoverentiresequencesorframesbyaverageofthesebinaryvaluesasshownin equation9.",
        "1 b  Σ b 9 x,y x,y x,y,t T Further,thereisneedtobeformedtheViF-descriptor.Itisformedbyapportioningthebintonon-overlappingcells ofsizeMxN.ItisalsobeneededtocollectthemagnitudeadjustmentfrequencythatisalsohelpfultobuildtheViF- descriptionforeachseparatedcell.Here,afixedsizeofhistogramisusedforrepresentingthechangeinmagnitude distributionofeachcell.Finally,theseevaluatedhistogramsarefusedintoadistinctvector.Thisevaluatedvectoris representedasViF-descriptorfeaturevector.Thenthesefeaturevectorcanbeusedtobuildanyoftheclassifier6.",
        "In this paper, the ViF-descriptor is used to extract the information from the video sequences.",
        "The information from Fig.4.DatabaseDesign featurevectorisusedbytheSVMclassifiertoclassifytheviolentandnon-violentscenes.",
        "Dushyant Kumar Singh et al.",
        "/ Procedia Computer Science 171 2020 350359 355 6 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 5 Fig.2.WorkFlowofViolentCrowdDetectionFramework Ifsamplesaremisclassifiedthangradientofbothtermscanbeupdatedwithrespecttoweightvectorasshownin eqation7.",
        "wwnyx 2νw 7 i i  Wherenisthelearningrateandνisregularizer.Asaregularizingparameterwehavetochoose1/epochsepoch Numberofiterationtotrainthemachine.",
        "3.1.2.",
        "ViolentCrowdBehavior Fig.3.FlowofCommunicationModule ViolentCrowdBehaviorfocusesonmonitoringthecrowdedeventsforoutbreaksofviolence.Efficientanalysisin realtimeoperatingenvironmentcanbeachievedbyobservingdensityonaspecificpointandmotionofthecrowdin specificdirection.Movementofthecrowdtowardscertainplacecanbeoneofthecausetoviolence.Forthepurpose, 3.1.3.",
        "CommunicationModule we have to find out high shape and intensive processing without compromising processing speed with respect to This component is responsible for transferring of information from the site under surveillance to the pertinent changes observed in vector magnitudes through time.",
        "The Violent Flows ViF descriptor is used here to extract police control room.",
        "There are 3 types of nodes in communication module architecture i.e.",
        "main server, client A, the motion information for sequence of frames.",
        "Further, these vectors are used svm classifier 18 22 is used for clientB.ThebriefarchitectureofcommunicationmoduleforproposedsystemisshowninFigure3.",
        "classifying the violent or non-violent behaviour.",
        "The complete process for violent crowd detection is presented in Mainserverisresponsibleforallkindsofcommunicationsinthesystem.Asimplewebserverhasbeenutilized Figure2.",
        "forthispurpose.ARESTfulwebserviceismadetorunontheserverwhichrespondstotherequestofallotherclients.",
        "ViF representation framework 23 24 is used to notice the violence in the real time video sequences.",
        "It is Currentlythebuilt-inserverofflaskhasbeenutilized.Italsomaintainsadatabasewhichstores calculated into various steps.",
        "First step is to evaluate the optical flow vectors between the couples of successive videosequences.Theflowvectorsareprovidedforeachframepixels.ThepixelisrepresentedbyP andtheflow x,y,t Configurationsettingsforeachsurveillancesitediscussedindetaillater.",
        "vectorsaredenotedbyu x,y,t andv x,y,t .Where,tisrepresentedbyindexofframe.Themagnitudeofthevectorscanbe  IDs for each surveillance site, police control room along with description address, contact and other relevant representedbyequation8.",
        "info.",
        "M  u2 v2 8 Messagesreceivedfromsurveillancesites.",
        "x,y,t x,y,t x,y,t  cid31 Next,thebinaryindicator B x,y,t isevaluatedforeachframepixels.Itisevaluatedbyif  M x,y,t  M x,y,t  1  θ then TheparticularsofthedatabaseschemacanbeprocuredfromFigure4.",
        "B  1otherwise B  0.Itshowstheimportanceofmagnitudesadjustmentamongvideoframes.Where,θ is x,y,t x,y,t thethresholdvaluethatisadaptivelyfixedtoaveragerateof M M .Here,theaveragemodificationchange  x,y,t  x,y,t  1 mapisevaluatedforindividualpixelsoverentiresequencesorframesbyaverageofthesebinaryvaluesasshownin equation9.",
        "1 b  Σ b 9 x,y x,y x,y,t T Further,thereisneedtobeformedtheViF-descriptor.Itisformedbyapportioningthebintonon-overlappingcells ofsizeMxN.ItisalsobeneededtocollectthemagnitudeadjustmentfrequencythatisalsohelpfultobuildtheViF- descriptionforeachseparatedcell.Here,afixedsizeofhistogramisusedforrepresentingthechangeinmagnitude distributionofeachcell.Finally,theseevaluatedhistogramsarefusedintoadistinctvector.Thisevaluatedvectoris representedasViF-descriptorfeaturevector.Thenthesefeaturevectorcanbeusedtobuildanyoftheclassifier6.",
        "In this paper, the ViF-descriptor is used to extract the information from the video sequences.",
        "The information from Fig.4.DatabaseDesign featurevectorisusedbytheSVMclassifiertoclassifytheviolentandnon-violentscenes.",
        "356 Dushyant Kumar Singh et al.",
        "/ Procedia Computer Science 171 2020 350359 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 7 8 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 Client A is placed in each site under surveillance as a node.",
        "It will receive video feed from all CCTVs on this site.",
        "It will process the feed and send a thorough account of any activity to the main server.",
        "Each site will have its ownconfigurationsettings.Itwillretrievethesesettingsperiodicallyfromthemainserver.Themessagesenttomain serverwillcontainthesefieldsSiteID,CCTVID,ActivityRecognized,TimeStampandImageSequence.",
        "Configurationsettingsgovernthefunctioningofthisnodeandalsokeepdetailsaboutthenode.Thesesettingswill bestoredonthelocalfilesystemitself.EachclientAnodeperiodically15secondsrequeststhemainserverforits configurationsettingsandworksaccordingly.",
        "Client B is situated in each police control room as a node.",
        "It will periodically request the main server at small intervalof1-2secondstocheckifithasanynewmessagewhichisdestinedforthiscontrolRoom.ClientB2receives alerts from all surveillance sites.",
        "While, other control rooms as client B1 receive only if they are the nearest site.",
        "It is provided with a GUI which shows which site has reported an alert.",
        "The GUI makes it easier and intuitive to get Fig.6.DetectionResults information about any site.",
        "Configuration Settings enable the server to have fine control over each surveillance site withrespecttoitsfunctioningandself-information.",
        "ConfigurationSettingsincludethesefieldsSiteID,NearestPoliceControlRoomID,MainPoliceControlRoom 4.1.",
        "ActivityDetectionModule ID,DescriptionAddress,Contactetc.andisAreaProhibitedTrue/False.",
        "Graphicaluserinterface-googlemapsGUIenablesthepersonnelatpoliceheadquarterstomonitorthecomplete Currentlythesystemsupportsdetectionoftwoactivities.Eachactivitywastestedunderdifferentbenchmarksas city.Allthesurveillancesitesaremarkedonthemap.TheCCTVcamerasareusedheretomonitortheactivitiesof applicable.",
        "people.Ifanysuspiciousactivityisrecorded,thesystemsalertsthepolicepersonnelandalsohighlightsthelocation HumandetectioninprohibitedareaisdonewithHOGdescriptor152324.Thresholdingareaparameterused oftheactivity.Thepersonnelcanalsoseekinformationofanysurveillancesitegooglemapsjavascript.APIisused inbackgroundsubtractionalsoimpactsprocessingtime.Iffalsepositiveincreasesthanprocessingtimeincreasesand to embed map in the GUI.",
        "google maps geocoding API is used for conversion between addresses and Geolocation.",
        "viceversa.TheresultscanbeseeninFigure6.",
        "HTMLandCSShavebeenusedtocustomizealertwindowsinmap.QWebViewisaWebKitwidgetfromthePyQt Theperformanceintermofprocessingtimeoftheproposedalgorithmundervariousparametersareillustratedin library.",
        "It enables us to use java script code from within a python Qt application.",
        "A button is also displayed on the Table1andTable2.BothtablesshowtheparametertuninginHOGdescriptoraccordingtoWinStrideandScaleFactor.",
        "customized info window on google maps.",
        "The person can view the video or image evidence as applicable to the Where, WinStride is the stepsize in x and y directions of sliding window and the ScaleFactor is used to control the activityshowninfigure5.",
        "imagepyramid.",
        "Table1.ParameterResultstuninginHOGdescriptorasperWinStride.",
        "4.",
        "EXPERIMENTALRESULTS S.No.",
        "WinStridex,y ProcessingTime WeusedRaspberrypi3modelBrunningonraspbianstretchatsurveillancesite.Theanalysisofvideofeedhappens 1 4,4 0.47sec ontheedgeitselfaswithedgecomputing.Theexperimentalresultsandanalysisforeachofthecomponentisshown 2 8,8 0.10sec 3 16,16 0.071sec infollowingsections Table2.ParameterResultstuninginHOGdescriptorasperScaleFactor.",
        "S.No.",
        "ScaleFactor ProcessingTime 1 1.01 0.50sec 2 1.06 0.10sec 3 1.3 0.03sec 4 1.5 0.029sec Violentcrowdbehaviordetectionalgorithmisimplementedinpython.Here,1inevery3framesareprocessedto achieverealtimeperformanceforaccuratetemporaldetection.Eachsequenceof15framesaftersamplingisclassi- fiedasviolentbehaviorornon-violentbehaviorusingSVM.Violentflowsdatabase25isanexpansionbenchmark forcrowdviolencedetection.Weusedtotal246videosastrainingoutofwhich123areforviolenceandremaining 123non-violencebehavioridentification.Videosthatwehaveusedaredownloadedfromthewebwithaverage3.60 seconds and are under uncontrolled, in-the-wild conditions.",
        "We adopted five-fold cross validation method which is mostcommonformanyproblems.The246videosarealmostequallydistributedin5parts,eachpartcontainingequal numberofviolentbehaviorandnon-violentbehaviorvideowhicharerandomlyselected.Thefirstfourpartsofvideo aretakenfortrainingandfifthpartistakenfortestingpurposes.Thetrainingsetcontains46videosofwhich23depict Fig.5.ACityView,BSuspiciousActivityDetected,CSafeSiteInfo,DSuspiciousActivityInfo violenceand23depictnon-violence.",
        "Dushyant Kumar Singh et al.",
        "/ Procedia Computer Science 171 2020 350359 357 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 7 8 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 Client A is placed in each site under surveillance as a node.",
        "It will receive video feed from all CCTVs on this site.",
        "It will process the feed and send a thorough account of any activity to the main server.",
        "Each site will have its ownconfigurationsettings.Itwillretrievethesesettingsperiodicallyfromthemainserver.Themessagesenttomain serverwillcontainthesefieldsSiteID,CCTVID,ActivityRecognized,TimeStampandImageSequence.",
        "Configurationsettingsgovernthefunctioningofthisnodeandalsokeepdetailsaboutthenode.Thesesettingswill bestoredonthelocalfilesystemitself.EachclientAnodeperiodically15secondsrequeststhemainserverforits configurationsettingsandworksaccordingly.",
        "Client B is situated in each police control room as a node.",
        "It will periodically request the main server at small intervalof1-2secondstocheckifithasanynewmessagewhichisdestinedforthiscontrolRoom.ClientB2receives alerts from all surveillance sites.",
        "While, other control rooms as client B1 receive only if they are the nearest site.",
        "It is provided with a GUI which shows which site has reported an alert.",
        "The GUI makes it easier and intuitive to get Fig.6.DetectionResults information about any site.",
        "Configuration Settings enable the server to have fine control over each surveillance site withrespecttoitsfunctioningandself-information.",
        "ConfigurationSettingsincludethesefieldsSiteID,NearestPoliceControlRoomID,MainPoliceControlRoom 4.1.",
        "ActivityDetectionModule ID,DescriptionAddress,Contactetc.andisAreaProhibitedTrue/False.",
        "Graphicaluserinterface-googlemapsGUIenablesthepersonnelatpoliceheadquarterstomonitorthecomplete Currentlythesystemsupportsdetectionoftwoactivities.Eachactivitywastestedunderdifferentbenchmarksas city.Allthesurveillancesitesaremarkedonthemap.TheCCTVcamerasareusedheretomonitortheactivitiesof applicable.",
        "people.Ifanysuspiciousactivityisrecorded,thesystemsalertsthepolicepersonnelandalsohighlightsthelocation HumandetectioninprohibitedareaisdonewithHOGdescriptor152324.Thresholdingareaparameterused oftheactivity.Thepersonnelcanalsoseekinformationofanysurveillancesitegooglemapsjavascript.APIisused inbackgroundsubtractionalsoimpactsprocessingtime.Iffalsepositiveincreasesthanprocessingtimeincreasesand to embed map in the GUI.",
        "google maps geocoding API is used for conversion between addresses and Geolocation.",
        "viceversa.TheresultscanbeseeninFigure6.",
        "HTMLandCSShavebeenusedtocustomizealertwindowsinmap.QWebViewisaWebKitwidgetfromthePyQt Theperformanceintermofprocessingtimeoftheproposedalgorithmundervariousparametersareillustratedin library.",
        "It enables us to use java script code from within a python Qt application.",
        "A button is also displayed on the Table1andTable2.BothtablesshowtheparametertuninginHOGdescriptoraccordingtoWinStrideandScaleFactor.",
        "customized info window on google maps.",
        "The person can view the video or image evidence as applicable to the Where, WinStride is the stepsize in x and y directions of sliding window and the ScaleFactor is used to control the activityshowninfigure5.",
        "imagepyramid.",
        "Table1.ParameterResultstuninginHOGdescriptorasperWinStride.",
        "4.",
        "EXPERIMENTALRESULTS S.No.",
        "WinStridex,y ProcessingTime WeusedRaspberrypi3modelBrunningonraspbianstretchatsurveillancesite.Theanalysisofvideofeedhappens 1 4,4 0.47sec ontheedgeitselfaswithedgecomputing.Theexperimentalresultsandanalysisforeachofthecomponentisshown 2 8,8 0.10sec 3 16,16 0.071sec infollowingsections Table2.ParameterResultstuninginHOGdescriptorasperScaleFactor.",
        "S.No.",
        "ScaleFactor ProcessingTime 1 1.01 0.50sec 2 1.06 0.10sec 3 1.3 0.03sec 4 1.5 0.029sec Violentcrowdbehaviordetectionalgorithmisimplementedinpython.Here,1inevery3framesareprocessedto achieverealtimeperformanceforaccuratetemporaldetection.Eachsequenceof15framesaftersamplingisclassi- fiedasviolentbehaviorornon-violentbehaviorusingSVM.Violentflowsdatabase25isanexpansionbenchmark forcrowdviolencedetection.Weusedtotal246videosastrainingoutofwhich123areforviolenceandremaining 123non-violencebehavioridentification.Videosthatwehaveusedaredownloadedfromthewebwithaverage3.60 seconds and are under uncontrolled, in-the-wild conditions.",
        "We adopted five-fold cross validation method which is mostcommonformanyproblems.The246videosarealmostequallydistributedin5parts,eachpartcontainingequal numberofviolentbehaviorandnon-violentbehaviorvideowhicharerandomlyselected.Thefirstfourpartsofvideo aretakenfortrainingandfifthpartistakenfortestingpurposes.Thetrainingsetcontains46videosofwhich23depict Fig.5.ACityView,BSuspiciousActivityDetected,CSafeSiteInfo,DSuspiciousActivityInfo violenceand23depictnon-violence.",
        "358 Dushyant Kumar Singh et al.",
        "/ Procedia Computer Science 171 2020 350359 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 9 10 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 comparedforpedestriandetectionandviolencecrowddetection.Formeasurementofprocessingtime,theRaspberry Pi device and personal computer PC are used as processing unit.",
        "The system offers a host of bright prospects for extending the work to make it even more effective.",
        "It can be used in other various applications or detecting other unwantedactivitieslikeabnormalcrowddensity,multiplepeoplerunningtheftetc.,personfallingetc.fromCCTV footageinrealtime.",
        "References Fig.7.ConfusionMatrixforCrowdViolencedetectionmodel 1 PoliceDepartmentInformationSystemsTechnologyEnhancementProjectISTEP.ReportontheReviewoftheQueenslandPoliceService, Brisbane.DepartmentofJustice,OfficeofCommunityOrientedPolicingServices,Washington,DC.Bingham,M.,2014 2 T.Hassner,Y.Itcher,andO.Kliper-Gross.ViolentFlowsReal-TimeDetectionofViolentCrowdBehavior.3rdIEEEInternationalWorkshop The results can be visualized from the confusion matrix 24 26 in Figure 7.",
        "We process selective short time onSociallyIntelligentSurveillanceandMonitoringSISMattheIEEEConf.onComputerVisionandPatternRecognitionCVPR,Rhode of delay in frame sequences separately, classifying them by labelling as either violent or nonviolent, if violent sub- Island,June2012.",
        "sequence of frames are detected then action take place.",
        "Acceptable results were obtained when we used PC for 3 H.Keval.Effective,design,configuration,anduseofdigitalCCTV.PhDthesis,UniversityCollegeLondon,2009 4 N.Petrovic,N.Jojic,andT.Huang.Adaptivevideofastforward.MultimediaToolsandApplications,263327344,2005.",
        "processing.",
        "Extraction of feature vector ViF descriptor for a sequence of 15 frames took on an average 5 seconds 5 Y.Pritch,S.Ratovitch,A.Hendel,andS.Peleg.Clusteredsynopsisofsurveillancevideo.InAdvancedVideoandSignalBasedSurveillance, tobeprocessed.Hence,appropriatesamplinghadtobedonewithoutcompromisingondelayinalerts.Experiments pages195200,2009 showedthatnotmorethan15continuousframesarerequiredforclassification.",
        "6 M.Shah,O.Javed,K.Shafique.AutomatedVisualSurveillanceinRealisticScenarios.IEEEMultiMedia,Vol.14,Issue1,2007 Where,TP,FP,FNandTNareTruePositive,FalsePositive,FalseNegativeandTrueNegativerespectively.The 7 O.Javed,K.Shafique,andM.Shah.AHierarchicalApproachtoRobustBackgroundSubtractionUsingColorandGradientInformation.",
        "mathematicalevaluationofaccuracyandsensitivityareshowninequation10and11.",
        "Proc.IEEEWorkshoponMotionandVideoComputing,IEEECSPress,2002,pp.22-27 8 O.Javed.TrackingacrossMultipleCameraswithDisjointViews.Proc.Proc.9thIEEEIntlConf.ComputerVision,pp.343-3572003 TPTN 9 R.Collins,A.Lipton,T.KanadeIntroductiontotheSpecialSectiononVideoSurveillance.IEEETrans.PatternAnalysisandMachine Accuracy 81.25 10 TPFPTNFN Intelligence,vol.22,no.8,pp.745,2000 10 ManoharKarki,SaikatBasu,RobertDiBiano,SupratikMukhopadhyay,JerryWeltman,MalcolmStagg.Asymbolicframeworkforrecogniz- TP ingactivitiesinfullmotionsurveillancevideos.ComputationalIntelligenceSSCI,pp.1-7,2016.",
        "Sensitivity 87.5 11 11 N.Dalal,B.Triggs.Histogramsoforientedgradientsforhumandetection.ComputerVisionandPatternRecognition,2005.CVPR2005.",
        "TPFN IEEE 12 Wrenetal.Pfinder,Real-TimeTrackingoftheHumanBody.IEEETrans.PatternAnalysisandMachineIntelligence,vol.19,no.7,pp.",
        "4.2.",
        "CommunicationComponent 780-785,1997.",
        "13 J.Rehg,M.Loughlin,andK.Waters.VisionforaSmartKiosk.ComputerVisionandPatternRecognition,IEEEPress,1997,pp.690-696 3clientAsystemsand3clientBsystemsweremadetorunsimultaneouslywithinputfromlocallystoredvideos.A 14 StaufferandW.E.L.Grimson.LearningPatternsofActivityUsingReal-TimeTracking.IEEETrans.PatternAnalysisandMachineIntelli- privatenetworkwasneededforcommunication.Thesystemwastestedusingbothmobilehotspotandcollegenetwork.",
        "gence,vol.22,no.8,2000,pp.747-757 15 Y.RicquebourgandP.Bouthemy.Real-TimeTrackingofMovingPersonsbyExploitingSpatiotemporalImageSlices.IEEETrans.Pattern Nofaults/datalossincommunicationsystemwereobservedduringtesting.Therewerenoerrorsoratypicalbehavior AnalysisandMachineIntelligence,vol.22,no.8,2000,pp.797-808 detected in the communication component.",
        "The table 3 illustrates the average delay between time of occurence of 16 PushkarP.Goswami,DiwakarPaswan,DushyantKumarSingh.Detectingmovingobjectsintrafficsurveillancevideo.InternationalJournal activity and raising of alert at client B.",
        "There was a maximum lag of 3 seconds between detection of activity at ofControlTheoryandapplications,Vol9.17,pp8423-84302016 surveillancesiteandmessagealertatcontrolroom.",
        "17 PushkarProtikGoswami,DushyantKumarSingh.Ahybridapproachforreal-timeobjectdetectionandtrackingtocoverbackgroundturbu- lenceproblem.IndianJournalofScienceandTechnology,Vol9.452016 18 Abdelkaderetal.Silhouette-basedgestureandactionrecognitionviamodelingtrajectoriesonRiemannianshapemanifolds.ComputerVision Table3.Averagedelayinseconds andImageUnderstanding,115.32011439-455 19 O.Kliper-Gross,T.Hassner,andL.Wolf.Pfinder,Real-TimeTrackingoftheHumanBody.IEEETrans.PatternAnalysisandMachine Detection RaspberryPi PC Intelligence,pages3145,2011 PedestrianDetection 4.1sec 2.6sec 20 V.Kellokumpu,G.Zhao,andM.Pietikainen.Humanactivityrecognitionusingadynamictexturebasedmethod.InBMVC,pages110, ViolentCrowdDetection 5.1sec 4.3sec 2008 21 O.Kliper-Gross,T.Hassner,andLiu.Beyond.PixelsExploringNewRepresentationsandApplicationsforMotionAnalysis.PhDthesis, MassachusettsInstituteofTechnology,May2009 22 NikhilSingh,ShambhuShankarBharti,RupalSingh,DushyantKumarSingh.Remotelycontrolledhomeautomationsystem.International ConferenceonAdvancesinEngineeringTechnologyResearchICAETR-2014,IEEE2014 23 Agarwal,Anshuman,ShivamGupta,andDushyantKumarSingh.Reviewofopticalflowtechniqueformovingobjectdetection.2ndInter- 5.",
        "CONCLUSIONANDFUTUREVISION nationalConferenceonContemporaryComputingandInformaticsIC3I,pages110,2016 24 KaelonLloydetal.DetectingViolentandAbnormalCrowdactivityusingTemporalAnalysisofGreyLevelCo-occurrenceMatrixGLCM Despiterecentadvancementintechnologyofcomputervisionandrelatedareas,therearestillsomemajorissues BasedTextureMeasures.ComputerVisionandPatternRecognition,2017 thatneedstobeovercomeformakingcompleterealtimeoperatingandreliableautomatedsurveillancesystem.These 25 Violent-Flows-CrowdViolence Non-violenceDatabaseandbenchmark-2017,www.cslab.openu.ac.il/download issuesincludetechnicalaspectasphysicalplacementtofullcoverage,installation,maintenanceofcamera,network 26 M.A.AnsariandM.Dixit.AnenhancedCBIRusingHSVquantization,discretewavelettransformandedgehistogramdescriptor.2017 InternationalConferenceonComputing,CommunicationandAutomationICCCA,GreaterNoida,2017,pp.1136-1141.",
        "bandwidthrequiredtosupportcameraandingeneralaspectasrobustnessofcameraintypicalweatherandlightening conditions,installationcost,privacyconcernetc.However,demandofautomatedsurveillancesystemisbeingmade more frequently specially in public safety and home security with respect to quality control parameters.",
        "Military intelligencecanalsobeoneoftheapplicationareaastechnologicalgrowthisalsoreachingtoheights.Thispaperis providingagoodresultforcrowdviolencedetectionintermsofaccuracyandsensitivity.Theprocessingtimeisalso Dushyant Kumar Singh et al.",
        "/ Procedia Computer Science 171 2020 350359 359 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 9 10 DushyantKumarSingh,SumitParoothi,MayankkumarRusiaetal./ProcediaComputerScience002019000000 comparedforpedestriandetectionandviolencecrowddetection.Formeasurementofprocessingtime,theRaspberry Pi device and personal computer PC are used as processing unit.",
        "The system offers a host of bright prospects for extending the work to make it even more effective.",
        "It can be used in other various applications or detecting other unwantedactivitieslikeabnormalcrowddensity,multiplepeoplerunningtheftetc.,personfallingetc.fromCCTV footageinrealtime.",
        "References Fig.7.ConfusionMatrixforCrowdViolencedetectionmodel 1 PoliceDepartmentInformationSystemsTechnologyEnhancementProjectISTEP.ReportontheReviewoftheQueenslandPoliceService, Brisbane.DepartmentofJustice,OfficeofCommunityOrientedPolicingServices,Washington,DC.Bingham,M.,2014 2 T.Hassner,Y.Itcher,andO.Kliper-Gross.ViolentFlowsReal-TimeDetectionofViolentCrowdBehavior.3rdIEEEInternationalWorkshop The results can be visualized from the confusion matrix 24 26 in Figure 7.",
        "We process selective short time onSociallyIntelligentSurveillanceandMonitoringSISMattheIEEEConf.onComputerVisionandPatternRecognitionCVPR,Rhode of delay in frame sequences separately, classifying them by labelling as either violent or nonviolent, if violent sub- Island,June2012.",
        "sequence of frames are detected then action take place.",
        "Acceptable results were obtained when we used PC for 3 H.Keval.Effective,design,configuration,anduseofdigitalCCTV.PhDthesis,UniversityCollegeLondon,2009 4 N.Petrovic,N.Jojic,andT.Huang.Adaptivevideofastforward.MultimediaToolsandApplications,263327344,2005.",
        "processing.",
        "Extraction of feature vector ViF descriptor for a sequence of 15 frames took on an average 5 seconds 5 Y.Pritch,S.Ratovitch,A.Hendel,andS.Peleg.Clusteredsynopsisofsurveillancevideo.InAdvancedVideoandSignalBasedSurveillance, tobeprocessed.Hence,appropriatesamplinghadtobedonewithoutcompromisingondelayinalerts.Experiments pages195200,2009 showedthatnotmorethan15continuousframesarerequiredforclassification.",
        "6 M.Shah,O.Javed,K.Shafique.AutomatedVisualSurveillanceinRealisticScenarios.IEEEMultiMedia,Vol.14,Issue1,2007 Where,TP,FP,FNandTNareTruePositive,FalsePositive,FalseNegativeandTrueNegativerespectively.The 7 O.Javed,K.Shafique,andM.Shah.AHierarchicalApproachtoRobustBackgroundSubtractionUsingColorandGradientInformation.",
        "mathematicalevaluationofaccuracyandsensitivityareshowninequation10and11.",
        "Proc.IEEEWorkshoponMotionandVideoComputing,IEEECSPress,2002,pp.22-27 8 O.Javed.TrackingacrossMultipleCameraswithDisjointViews.Proc.Proc.9thIEEEIntlConf.ComputerVision,pp.343-3572003 TPTN 9 R.Collins,A.Lipton,T.KanadeIntroductiontotheSpecialSectiononVideoSurveillance.IEEETrans.PatternAnalysisandMachine Accuracy 81.25 10 TPFPTNFN Intelligence,vol.22,no.8,pp.745,2000 10 ManoharKarki,SaikatBasu,RobertDiBiano,SupratikMukhopadhyay,JerryWeltman,MalcolmStagg.Asymbolicframeworkforrecogniz- TP ingactivitiesinfullmotionsurveillancevideos.ComputationalIntelligenceSSCI,pp.1-7,2016.",
        "Sensitivity 87.5 11 11 N.Dalal,B.Triggs.Histogramsoforientedgradientsforhumandetection.ComputerVisionandPatternRecognition,2005.CVPR2005.",
        "TPFN IEEE 12 Wrenetal.Pfinder,Real-TimeTrackingoftheHumanBody.IEEETrans.PatternAnalysisandMachineIntelligence,vol.19,no.7,pp.",
        "4.2.",
        "CommunicationComponent 780-785,1997.",
        "13 J.Rehg,M.Loughlin,andK.Waters.VisionforaSmartKiosk.ComputerVisionandPatternRecognition,IEEEPress,1997,pp.690-696 3clientAsystemsand3clientBsystemsweremadetorunsimultaneouslywithinputfromlocallystoredvideos.A 14 StaufferandW.E.L.Grimson.LearningPatternsofActivityUsingReal-TimeTracking.IEEETrans.PatternAnalysisandMachineIntelli- privatenetworkwasneededforcommunication.Thesystemwastestedusingbothmobilehotspotandcollegenetwork.",
        "gence,vol.22,no.8,2000,pp.747-757 15 Y.RicquebourgandP.Bouthemy.Real-TimeTrackingofMovingPersonsbyExploitingSpatiotemporalImageSlices.IEEETrans.Pattern Nofaults/datalossincommunicationsystemwereobservedduringtesting.Therewerenoerrorsoratypicalbehavior AnalysisandMachineIntelligence,vol.22,no.8,2000,pp.797-808 detected in the communication component.",
        "The table 3 illustrates the average delay between time of occurence of 16 PushkarP.Goswami,DiwakarPaswan,DushyantKumarSingh.Detectingmovingobjectsintrafficsurveillancevideo.InternationalJournal activity and raising of alert at client B.",
        "There was a maximum lag of 3 seconds between detection of activity at ofControlTheoryandapplications,Vol9.17,pp8423-84302016 surveillancesiteandmessagealertatcontrolroom.",
        "17 PushkarProtikGoswami,DushyantKumarSingh.Ahybridapproachforreal-timeobjectdetectionandtrackingtocoverbackgroundturbu- lenceproblem.IndianJournalofScienceandTechnology,Vol9.452016 18 Abdelkaderetal.Silhouette-basedgestureandactionrecognitionviamodelingtrajectoriesonRiemannianshapemanifolds.ComputerVision Table3.Averagedelayinseconds andImageUnderstanding,115.32011439-455 19 O.Kliper-Gross,T.Hassner,andL.Wolf.Pfinder,Real-TimeTrackingoftheHumanBody.IEEETrans.PatternAnalysisandMachine Detection RaspberryPi PC Intelligence,pages3145,2011 PedestrianDetection 4.1sec 2.6sec 20 V.Kellokumpu,G.Zhao,andM.Pietikainen.Humanactivityrecognitionusingadynamictexturebasedmethod.InBMVC,pages110, ViolentCrowdDetection 5.1sec 4.3sec 2008 21 O.Kliper-Gross,T.Hassner,andLiu.Beyond.PixelsExploringNewRepresentationsandApplicationsforMotionAnalysis.PhDthesis, MassachusettsInstituteofTechnology,May2009 22 NikhilSingh,ShambhuShankarBharti,RupalSingh,DushyantKumarSingh.Remotelycontrolledhomeautomationsystem.International ConferenceonAdvancesinEngineeringTechnologyResearchICAETR-2014,IEEE2014 23 Agarwal,Anshuman,ShivamGupta,andDushyantKumarSingh.Reviewofopticalflowtechniqueformovingobjectdetection.2ndInter- 5.",
        "CONCLUSIONANDFUTUREVISION nationalConferenceonContemporaryComputingandInformaticsIC3I,pages110,2016 24 KaelonLloydetal.DetectingViolentandAbnormalCrowdactivityusingTemporalAnalysisofGreyLevelCo-occurrenceMatrixGLCM Despiterecentadvancementintechnologyofcomputervisionandrelatedareas,therearestillsomemajorissues BasedTextureMeasures.ComputerVisionandPatternRecognition,2017 thatneedstobeovercomeformakingcompleterealtimeoperatingandreliableautomatedsurveillancesystem.These 25 Violent-Flows-CrowdViolence Non-violenceDatabaseandbenchmark-2017,www.cslab.openu.ac.il/download issuesincludetechnicalaspectasphysicalplacementtofullcoverage,installation,maintenanceofcamera,network 26 M.A.AnsariandM.Dixit.AnenhancedCBIRusingHSVquantization,discretewavelettransformandedgehistogramdescriptor.2017 InternationalConferenceonComputing,CommunicationandAutomationICCCA,GreaterNoida,2017,pp.1136-1141.",
        "bandwidthrequiredtosupportcameraandingeneralaspectasrobustnessofcameraintypicalweatherandlightening conditions,installationcost,privacyconcernetc.However,demandofautomatedsurveillancesystemisbeingmade more frequently specially in public safety and home security with respect to quality control parameters.",
        "Military intelligencecanalsobeoneoftheapplicationareaastechnologicalgrowthisalsoreachingtoheights.Thispaperis providingagoodresultforcrowdviolencedetectionintermsofaccuracyandsensitivity.Theprocessingtimeisalso"
      ],
      "word_count": 6637,
      "sections": {}
    },
    "tables": [],
    "metadata": {
      "AuthoritativeDomain[1]": "sciencedirect.com",
      "AuthoritativeDomain[2]": "elsevier.com",
      "CreationDate": "D:20200525160524+05'30'",
      "CrossMarkDomains[1]": "sciencedirect.com",
      "CrossMarkDomains[2]": "elsevier.com",
      "CrossmarkDomainExclusive": "2010-04-23",
      "CrossmarkMajorVersionDate": "2010-04-23",
      "ElsevierWebPDFSpecifications": "6.5",
      "ModDate": "D:20200530100214+05'30'",
      "Producer": "Adobe PDF Library 15.0",
      "doi": "10.1016/j.procs.2020.04.036",
      "robots": "noindex"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "CROWD MANAGEMENT, CRIME DETECTION, WORK MONITORING USING AI/ML Manoj Kumar .R P.R.Adithya Assistant Professor, School of Computer Science and UG Scholar, School of Computer Science and Engineering Engineering Vellore Institute of Technology, Vellore Institute of Technology Chennai, India Chennai, India Manojkumar.rvit.ac.in Adithya.pr2022vitstudent.ac.in Akash UG Scholar, School of Computer Science and Dheepak Engineering UG Scholar, School of Computer Science and Vellore Institute of Technology Engineering Chennai, India Vellore Institute of Technology akash.b2022vitstudent.ac.in Chennai, India dheepak.s2022vitstudent.ac.in HARSHINI .V SAI LAKSHANA UG Scholar,School of computer science and ug scholar,school of computer science and engineering engineering vellore institute of technology vellore institute of technology chennai,india chennai,india harshini.v2022vitstudent.ac.in sailakshanavitstudent.ac.in Abstract I. Introduction This research endeavors to harness the potential of existing Closed-Circuit Television CCTV networks for a In our project, we leveraged the power of teachable comprehensive approach to crowd management, crime machines to revolutionize crime detection and crowd prevention, and workplace monitoring through the management. Harnessing the potential of artificial intelligence, particularly in computer vision, we integration of Artificial Intelligence AI and Machine employed advanced algorithms to analyze image Learning ML technologies. The primary objective is to inputs, including CCTV videos, with unprecedented develop and implement advanced algorithms capable of precision. These CCTV videos have been converted to images in .jpg format using an online tool, and real-time analysis of video feeds, enabling the these converted images were used to train the model. identification and assessment of crowd dynamics, early The model employs a Convolutional Neural Network detection of potential criminal activities, and continuous CNN to classify the input video as either normal or indicative of criminal activity. Furthermore, our monitoring of workplace environments. By leveraging application extends beyond crime prevention to AI/ML, the project aims to optimize surveillance crowd management, where the same technology facilitates real-time monitoring and analysis of capabilities, thereby enhancing public safety measures crowded spaces. The teachable machines not only and improving organizational productivity. This initiative enable us to identify potential security threats but underscores the transformative impact that intelligent also provide valuable insights for optimizing public safety strategies. This project represents a significant video analytics can have on existing infrastructure, step forward in the fusion of cutting-edge technology mitigating the need for extensive system overhauls while and public safety, showcasing the potential of significantly advancing security and operational artificial intelligence in creating safer and more secure environments for communities. efficiency. Now to know, how a convolution neural network works lets break it into parts. the 3 most important parts of this convolution neural networks are, 1. Convolution A. To enhance image recognition in a neural network, 2. Pooling its crucial to identify and focus on the most relevant 3. Flattening features while discarding unnecessary pixel information. Convolution, despite its reputation as a Convolution complex topic, is a fundamental technique that Consider a 28x28 image, like those in the MNIST simplifies this process. In essence, convolution dataset used for handwritten digit recognition. In a involves sliding a filter, or kernel, across an image to basic artificial neural network setup, each pixels detect various features. Kernels, represented as 2D value is treated as an individual feature input, matrices with distinct weights, traverse the image, resulting in 784 input nodes. While this approach replacing pixel values with the weighted average of may yield satisfactory results, it falls short in neighboring values. recognizing crucial features within the image. The model essentially processes each pixel independently, B. This method allows us to pinpoint significant potentially missing important patterns. features in an image, providing a more nuanced understanding. By applying multiple randomly Scaling this concept to a larger image, such as a generated kernels, we can extract diverse features, 1920x1080 Ultra HD image, poses significant enriching the models ability to recognize intricate challenges. Applying the same methodology would patterns. result in an impractical 2 million input nodes. Even C. Following the convolution layer, the next step with a relatively modest hidden layer of 64 nodes, involves pooling these features. Pooling is a which is insufficient for such a large input, the technique used to condense and emphasize essential network would involve a staggering 130 million information while reducing computational weights. This massive scale of parameters necessitates complexity. This ensures that the model retains an enormous computational load, overwhelming the crucial details while discarding redundant capabilities of most machines. The sheer volume of information, contributing to improved image calculations involved makes it unfeasible for effective recognition performance. image recognition, emphasizing the need for more sophisticated approaches in handling high-resolution D. Pooling images. After identifying crucial features through convolution, the challenge remains in handling the large number of inputs, a task addressed by pooling. Pooling serves to shrink the image dimensions while retaining the features uncovered during convolution. Take, for instance, the MaxPooling method, which operates on a matrix shape and outputs the maximum value within that region. This technique allows for image compression without sacrificing the essential features, facilitating a more manageable input size for the subsequent layers of the neural network. E. Flattening Flattening is the process of transforming a 3D or 2D matrix into a 1D format, serving as the final step in preparing the image for input into the model. This step involves converting the structured In the dynamic landscape of contemporary workplaces, representation of the image into a linear, one- the need for efficient and effective work monitoring has dimensional input. The flattened data can then be become paramount. Organizations strive to optimize seamlessly connected to a fully connected dense layer, productivity, ensure employee safety, and maintain a facilitating subsequent stages of classification in the secure work environment. The advent of machine learning neural network technologies has opened up new avenues for addressing these challenges. This project report delves into the . implementation of YOLO You Only Look Once, a state- of-the-art object detection algorithm, as a pioneering solution for work monitoring. YOLOYOU ONLY LOOK ONCE MODULE Unlike traditional object detection methods that involve multiple stages, YOLO streamlines the process, allowing for real-time detection with impressive speed and accuracy. Heres a step-by-step explanation of how the YOLO module works Libraries used in this project Input ProcessingThe input image undergoes grid-based  OpenCV Used to read the video input and division, forming the foundation for subsequent splitting videointo frames for analysing. predictions.  Keras Used to implement neural networks. It is a high-level neural network library that runs on top of tensorflow Bounding Box Prediction YOLO predicts multiple  Numpy Used to process images as the image bounding boxes within each grid cell, each associated pixel is in the form of matrix with parameters x, y for the boxs center, width w,  Pushbullet It is an API used for sending SMS height h, confidence score, and class probabilities. to mobile phone after detecting crime. Sample images used in Dataset Class Prediction YOLO determines the probability of each class for all bounding boxes in a grid cell, enabling simultaneous detection of multiple object classes in a given image. Confidence Score A confidence score indicates the models certainty that a bounding box contains an object, with a range from 0 to 1. Non-Maximum Suppression Following predictions for all grid cells, a post-processing step, non-maximum suppression, removes redundant and low-confidence bounding boxes, retaining only the most confident and non-overlapping ones. Input Output The input is a video that is being monitored for potential criminal activities. The output indicates Output The YOLO module produces a final output of whether the video involves suspicious activities or not. bounding boxes, each linked to a class and a confidence In the event of criminal behaviour, a notification is score, representing the detected objects in the input image. sent to the relevant authorities. INTERSECTION OVER UNION II. OBJECT DETECTION A.EMPLOYEE MONITORING Intersection over Union IoU is a metric used to evaluate the accuracy of an object detection algorithm, particularly 3Uses Microsoft azure cognitive services and cloud in tasks such as image segmentation and bounding box system for implementation.Provides a comparative study prediction. IoU measures the overlap between the of traditional methodologies used such as Haar Cascade. predicted bounding box and the ground truth bounding Proposed System for Criminal Detection and Recognition box for a given object in an image.The IoU is calculated on CCTV Data Using Cloud and Machine Learning as the ratio of the area of intersection between the predicted and ground truth bounding boxes to the area of Samit Shirsat, Aakash Naik, Darshan Tamse their union. The formula for IoU is 4 Uses pre trained deep leaning model VGGNet-19 which detects gun and knife.Uses SMS sending module to send IOU Area of Intersection/Area of Union alert. Crime Intention Detection System Using Deep Learning Heres a breakdown of the terms Umadevi V Navalgund, Priyadharshini.K 1. Area of IntersectionThe region where the 5 Focuses on identifying patterns and trends in crime predicted bounding box and the ground truth bounding occurrences.Uses ML and DL algorithms to predict crime box overlap. related activities. Crime Prediction Using Machine Learning and Deep Learning A Systematic Review and Future Directions 2. Area of UnionThe combined region covered by both the predicted bounding box and the ground truth VarunMandalapu , Lavanya Elluri bounding box. The IoU value ranges from 0 to 1, where IV. Methodology IoU0 indicates no overlap between the predicted and ground truth bounding boxes. EMPLOYEE MONITORING In the dynamic landscape of contemporary workplaces, the need for efficient and effective work monitoring has IoU1 indicates a perfect overlap between the predicted become paramount. Organizations strive to optimize and ground truth bounding boxes. productivity, ensure employee safety, and maintain a secure work environment. The advent of machine learning technologies has opened up new avenues for addressing these challenges. This project report delves into the implementation of YOLO You Only Look Once, a state- of-the-art object detection algorithm, as a pioneering III. LITERATURE SURVEY solution for work monitoring. 1 Uses OpenCV for object detection in computer YOLOYOU ONLY LOOK ONCE MODULE Vision.LSTM Long Short-Term Memory is used to classify any event or behaviour as a crime or not. Autonomous Anomaly Detection System for Crime Unlike traditional object detection methods that involve Monitoring and Alert Generation multiple stages, YOLO streamlines the process, allowing for real-time detection with impressive speed and Jyoti Kukad, Swapnil Soner, Sagar Pandya accuracy. Heres a step-by-step explanation of how the YOLO module works 2 Uses state-of-the-art face identification system Uses deepneural networks DNN. Input ProcessingThe input image undergoes grid-based Face Detection and Recognition for Criminal division, forming the foundation for subsequent Identification System predictions. Sanika Tanmay, Aamani Tandasi, Shipra Saraswat Bounding Box Prediction YOLO predicts multiple Upon capturing an input image indicative of theft or bounding boxes within each grid cell, each associated criminal activity, the system triggers an alert mechanism. with parameters x, y for the boxs center, width w, This mechanism not only highlights the suspicious event height h, confidence score, and class probabilities. but also sends an immediate alert message to designated authorities. The integration of heatmap visualization enhances the alert system by providing a visual Class Prediction YOLO determines the probability of representation of the anomaly, allowing authorities to each class for all bounding boxes in a grid cell, enabling swiftly assess the situation and respond effectively. simultaneous detection of multiple object classes in a given image. One of the projects standout features is the seamless integration of heatmap visualization. This graphical representation method offers a clear and intuitive display of numerical data, indicating the intensity of activities Confidence Score A confidence score indicates the within the monitored space. In the context of work models certainty that a bounding box contains an object, monitoring and crime detection, the heatmap becomes a with a range from 0 to 1. powerful tool, showcasing the concentration and distribution of work hours and identifying anomalies that may indicate criminal behavior. Non-Maximum Suppression Following predictions for all grid cells, a post-processing step, non-maximum suppression, removes redundant and low-confidence bounding boxes, retaining only the most confident and non-overlapping ones. VI. Conclusion Output The YOLO module produces a final output of This project marks a significant advancement in the bounding boxes, each linked to a class and a confidence convergence of work monitoring and crime detection, score, representing the detected objects in the input image. offering a holistic solution that promotes both workplace efficiency and security. The synergy between advanced algorithms, specialized datasets, and heatmap visualization sets this system apart, exemplifying the potential of technology to revolutionize surveillance and safety measures in various domains. At the core of the V. RESULTS AND DISCUSSIONS system lies the utilization of sophisticated AI/ML algorithms, particularly the YOLO model, to simultaneously monitor work activities and detect In the realm of advanced surveillance systems, the criminal incidents. The YOLO model, renowned for its integration of work monitoring and crime detection has efficiency in object detection, ensures precise tracking of reached new heights, offering a comprehensive solution to individuals and objects within the monitored space. The enhance security measures. This innovative project projects specialized dataset focuses on capturing both leverages cutting-edge technologies, merging work work-related scenarios and criminal activities, enabling monitoring outputs with crime detection capabilities, the model to distinguish between routine work tasks and ultimately contributing to a safer and more efficient potential thefts. environment. 3 Proposed System for Criminal Detection and VII. Reference Recognition on CCTV Data Using Cloud and Machine Learning Samit Shirsat, Aakash Naik, Darshan Tamse 4 Crime Intention Detection System Using Deep 1 Autonomous Anomaly Detection System for Crime Learning Monitoring and Alert Generation Umadevi V Navalgund, Priyadharshini.K Jyoti Kukad, Swapnil Soner, Sagar Pandya 5 Crime Prediction Using Machine Learning and Deep 2 Face Detection and Recognition for Criminal Learning A Systematic Review and Future Directions Identification System Varun Mandalapu , Lavanya Elluri Sanika Tanmay, Aamani Tandasi, Shipra Saraswat",
    "structured_text": {
      "sentences": [
        "CROWD MANAGEMENT, CRIME DETECTION, WORK MONITORING USING AI/ML Manoj Kumar .R P.R.Adithya Assistant Professor, School of Computer Science and UG Scholar, School of Computer Science and Engineering Engineering Vellore Institute of Technology, Vellore Institute of Technology Chennai, India Chennai, India Manojkumar.rvit.ac.in Adithya.pr2022vitstudent.ac.in Akash UG Scholar, School of Computer Science and Dheepak Engineering UG Scholar, School of Computer Science and Vellore Institute of Technology Engineering Chennai, India Vellore Institute of Technology akash.b2022vitstudent.ac.in Chennai, India dheepak.s2022vitstudent.ac.in HARSHINI .V SAI LAKSHANA UG Scholar,School of computer science and ug scholar,school of computer science and engineering engineering vellore institute of technology vellore institute of technology chennai,india chennai,india harshini.v2022vitstudent.ac.in sailakshanavitstudent.ac.in Abstract I.",
        "Introduction This research endeavors to harness the potential of existing Closed-Circuit Television CCTV networks for a In our project, we leveraged the power of teachable comprehensive approach to crowd management, crime machines to revolutionize crime detection and crowd prevention, and workplace monitoring through the management.",
        "Harnessing the potential of artificial intelligence, particularly in computer vision, we integration of Artificial Intelligence AI and Machine employed advanced algorithms to analyze image Learning ML technologies.",
        "The primary objective is to inputs, including CCTV videos, with unprecedented develop and implement advanced algorithms capable of precision.",
        "These CCTV videos have been converted to images in .jpg format using an online tool, and real-time analysis of video feeds, enabling the these converted images were used to train the model.",
        "identification and assessment of crowd dynamics, early The model employs a Convolutional Neural Network detection of potential criminal activities, and continuous CNN to classify the input video as either normal or indicative of criminal activity.",
        "Furthermore, our monitoring of workplace environments.",
        "By leveraging application extends beyond crime prevention to AI/ML, the project aims to optimize surveillance crowd management, where the same technology facilitates real-time monitoring and analysis of capabilities, thereby enhancing public safety measures crowded spaces.",
        "The teachable machines not only and improving organizational productivity.",
        "This initiative enable us to identify potential security threats but underscores the transformative impact that intelligent also provide valuable insights for optimizing public safety strategies.",
        "This project represents a significant video analytics can have on existing infrastructure, step forward in the fusion of cutting-edge technology mitigating the need for extensive system overhauls while and public safety, showcasing the potential of significantly advancing security and operational artificial intelligence in creating safer and more secure environments for communities.",
        "efficiency.",
        "Now to know, how a convolution neural network works lets break it into parts.",
        "the 3 most important parts of this convolution neural networks are, 1.",
        "Convolution A.",
        "To enhance image recognition in a neural network, 2.",
        "Pooling its crucial to identify and focus on the most relevant 3.",
        "Flattening features while discarding unnecessary pixel information.",
        "Convolution, despite its reputation as a Convolution complex topic, is a fundamental technique that Consider a 28x28 image, like those in the MNIST simplifies this process.",
        "In essence, convolution dataset used for handwritten digit recognition.",
        "In a involves sliding a filter, or kernel, across an image to basic artificial neural network setup, each pixels detect various features.",
        "Kernels, represented as 2D value is treated as an individual feature input, matrices with distinct weights, traverse the image, resulting in 784 input nodes.",
        "While this approach replacing pixel values with the weighted average of may yield satisfactory results, it falls short in neighboring values.",
        "recognizing crucial features within the image.",
        "The model essentially processes each pixel independently, B.",
        "This method allows us to pinpoint significant potentially missing important patterns.",
        "features in an image, providing a more nuanced understanding.",
        "By applying multiple randomly Scaling this concept to a larger image, such as a generated kernels, we can extract diverse features, 1920x1080 Ultra HD image, poses significant enriching the models ability to recognize intricate challenges.",
        "Applying the same methodology would patterns.",
        "result in an impractical 2 million input nodes.",
        "Even C.",
        "Following the convolution layer, the next step with a relatively modest hidden layer of 64 nodes, involves pooling these features.",
        "Pooling is a which is insufficient for such a large input, the technique used to condense and emphasize essential network would involve a staggering 130 million information while reducing computational weights.",
        "This massive scale of parameters necessitates complexity.",
        "This ensures that the model retains an enormous computational load, overwhelming the crucial details while discarding redundant capabilities of most machines.",
        "The sheer volume of information, contributing to improved image calculations involved makes it unfeasible for effective recognition performance.",
        "image recognition, emphasizing the need for more sophisticated approaches in handling high-resolution D.",
        "Pooling images.",
        "After identifying crucial features through convolution, the challenge remains in handling the large number of inputs, a task addressed by pooling.",
        "Pooling serves to shrink the image dimensions while retaining the features uncovered during convolution.",
        "Take, for instance, the MaxPooling method, which operates on a matrix shape and outputs the maximum value within that region.",
        "This technique allows for image compression without sacrificing the essential features, facilitating a more manageable input size for the subsequent layers of the neural network.",
        "E.",
        "Flattening Flattening is the process of transforming a 3D or 2D matrix into a 1D format, serving as the final step in preparing the image for input into the model.",
        "This step involves converting the structured In the dynamic landscape of contemporary workplaces, representation of the image into a linear, one- the need for efficient and effective work monitoring has dimensional input.",
        "The flattened data can then be become paramount.",
        "Organizations strive to optimize seamlessly connected to a fully connected dense layer, productivity, ensure employee safety, and maintain a facilitating subsequent stages of classification in the secure work environment.",
        "The advent of machine learning neural network technologies has opened up new avenues for addressing these challenges.",
        "This project report delves into the .",
        "implementation of YOLO You Only Look Once, a state- of-the-art object detection algorithm, as a pioneering solution for work monitoring.",
        "YOLOYOU ONLY LOOK ONCE MODULE Unlike traditional object detection methods that involve multiple stages, YOLO streamlines the process, allowing for real-time detection with impressive speed and accuracy.",
        "Heres a step-by-step explanation of how the YOLO module works Libraries used in this project Input ProcessingThe input image undergoes grid-based  OpenCV Used to read the video input and division, forming the foundation for subsequent splitting videointo frames for analysing.",
        "predictions.",
        "Keras Used to implement neural networks.",
        "It is a high-level neural network library that runs on top of tensorflow Bounding Box Prediction YOLO predicts multiple  Numpy Used to process images as the image bounding boxes within each grid cell, each associated pixel is in the form of matrix with parameters x, y for the boxs center, width w,  Pushbullet It is an API used for sending SMS height h, confidence score, and class probabilities.",
        "to mobile phone after detecting crime.",
        "Sample images used in Dataset Class Prediction YOLO determines the probability of each class for all bounding boxes in a grid cell, enabling simultaneous detection of multiple object classes in a given image.",
        "Confidence Score A confidence score indicates the models certainty that a bounding box contains an object, with a range from 0 to 1.",
        "Non-Maximum Suppression Following predictions for all grid cells, a post-processing step, non-maximum suppression, removes redundant and low-confidence bounding boxes, retaining only the most confident and non-overlapping ones.",
        "Input Output The input is a video that is being monitored for potential criminal activities.",
        "The output indicates Output The YOLO module produces a final output of whether the video involves suspicious activities or not.",
        "bounding boxes, each linked to a class and a confidence In the event of criminal behaviour, a notification is score, representing the detected objects in the input image.",
        "sent to the relevant authorities.",
        "INTERSECTION OVER UNION II.",
        "OBJECT DETECTION A.EMPLOYEE MONITORING Intersection over Union IoU is a metric used to evaluate the accuracy of an object detection algorithm, particularly 3Uses Microsoft azure cognitive services and cloud in tasks such as image segmentation and bounding box system for implementation.Provides a comparative study prediction.",
        "IoU measures the overlap between the of traditional methodologies used such as Haar Cascade.",
        "predicted bounding box and the ground truth bounding Proposed System for Criminal Detection and Recognition box for a given object in an image.The IoU is calculated on CCTV Data Using Cloud and Machine Learning as the ratio of the area of intersection between the predicted and ground truth bounding boxes to the area of Samit Shirsat, Aakash Naik, Darshan Tamse their union.",
        "The formula for IoU is 4 Uses pre trained deep leaning model VGGNet-19 which detects gun and knife.Uses SMS sending module to send IOU Area of Intersection/Area of Union alert.",
        "Crime Intention Detection System Using Deep Learning Heres a breakdown of the terms Umadevi V Navalgund, Priyadharshini.K 1.",
        "Area of IntersectionThe region where the 5 Focuses on identifying patterns and trends in crime predicted bounding box and the ground truth bounding occurrences.Uses ML and DL algorithms to predict crime box overlap.",
        "related activities.",
        "Crime Prediction Using Machine Learning and Deep Learning A Systematic Review and Future Directions 2.",
        "Area of UnionThe combined region covered by both the predicted bounding box and the ground truth VarunMandalapu , Lavanya Elluri bounding box.",
        "The IoU value ranges from 0 to 1, where IV.",
        "Methodology IoU0 indicates no overlap between the predicted and ground truth bounding boxes.",
        "EMPLOYEE MONITORING In the dynamic landscape of contemporary workplaces, the need for efficient and effective work monitoring has IoU1 indicates a perfect overlap between the predicted become paramount.",
        "Organizations strive to optimize and ground truth bounding boxes.",
        "productivity, ensure employee safety, and maintain a secure work environment.",
        "The advent of machine learning technologies has opened up new avenues for addressing these challenges.",
        "This project report delves into the implementation of YOLO You Only Look Once, a state- of-the-art object detection algorithm, as a pioneering III.",
        "LITERATURE SURVEY solution for work monitoring.",
        "1 Uses OpenCV for object detection in computer YOLOYOU ONLY LOOK ONCE MODULE Vision.LSTM Long Short-Term Memory is used to classify any event or behaviour as a crime or not.",
        "Autonomous Anomaly Detection System for Crime Unlike traditional object detection methods that involve Monitoring and Alert Generation multiple stages, YOLO streamlines the process, allowing for real-time detection with impressive speed and Jyoti Kukad, Swapnil Soner, Sagar Pandya accuracy.",
        "Heres a step-by-step explanation of how the YOLO module works 2 Uses state-of-the-art face identification system Uses deepneural networks DNN.",
        "Input ProcessingThe input image undergoes grid-based Face Detection and Recognition for Criminal division, forming the foundation for subsequent Identification System predictions.",
        "Sanika Tanmay, Aamani Tandasi, Shipra Saraswat Bounding Box Prediction YOLO predicts multiple Upon capturing an input image indicative of theft or bounding boxes within each grid cell, each associated criminal activity, the system triggers an alert mechanism.",
        "with parameters x, y for the boxs center, width w, This mechanism not only highlights the suspicious event height h, confidence score, and class probabilities.",
        "but also sends an immediate alert message to designated authorities.",
        "The integration of heatmap visualization enhances the alert system by providing a visual Class Prediction YOLO determines the probability of representation of the anomaly, allowing authorities to each class for all bounding boxes in a grid cell, enabling swiftly assess the situation and respond effectively.",
        "simultaneous detection of multiple object classes in a given image.",
        "One of the projects standout features is the seamless integration of heatmap visualization.",
        "This graphical representation method offers a clear and intuitive display of numerical data, indicating the intensity of activities Confidence Score A confidence score indicates the within the monitored space.",
        "In the context of work models certainty that a bounding box contains an object, monitoring and crime detection, the heatmap becomes a with a range from 0 to 1.",
        "powerful tool, showcasing the concentration and distribution of work hours and identifying anomalies that may indicate criminal behavior.",
        "Non-Maximum Suppression Following predictions for all grid cells, a post-processing step, non-maximum suppression, removes redundant and low-confidence bounding boxes, retaining only the most confident and non-overlapping ones.",
        "VI.",
        "Conclusion Output The YOLO module produces a final output of This project marks a significant advancement in the bounding boxes, each linked to a class and a confidence convergence of work monitoring and crime detection, score, representing the detected objects in the input image.",
        "offering a holistic solution that promotes both workplace efficiency and security.",
        "The synergy between advanced algorithms, specialized datasets, and heatmap visualization sets this system apart, exemplifying the potential of technology to revolutionize surveillance and safety measures in various domains.",
        "At the core of the V.",
        "RESULTS AND DISCUSSIONS system lies the utilization of sophisticated AI/ML algorithms, particularly the YOLO model, to simultaneously monitor work activities and detect In the realm of advanced surveillance systems, the criminal incidents.",
        "The YOLO model, renowned for its integration of work monitoring and crime detection has efficiency in object detection, ensures precise tracking of reached new heights, offering a comprehensive solution to individuals and objects within the monitored space.",
        "The enhance security measures.",
        "This innovative project projects specialized dataset focuses on capturing both leverages cutting-edge technologies, merging work work-related scenarios and criminal activities, enabling monitoring outputs with crime detection capabilities, the model to distinguish between routine work tasks and ultimately contributing to a safer and more efficient potential thefts.",
        "environment.",
        "3 Proposed System for Criminal Detection and VII.",
        "Reference Recognition on CCTV Data Using Cloud and Machine Learning Samit Shirsat, Aakash Naik, Darshan Tamse 4 Crime Intention Detection System Using Deep 1 Autonomous Anomaly Detection System for Crime Learning Monitoring and Alert Generation Umadevi V Navalgund, Priyadharshini.K Jyoti Kukad, Swapnil Soner, Sagar Pandya 5 Crime Prediction Using Machine Learning and Deep 2 Face Detection and Recognition for Criminal Learning A Systematic Review and Future Directions Identification System Varun Mandalapu , Lavanya Elluri Sanika Tanmay, Aamani Tandasi, Shipra Saraswat"
      ],
      "word_count": 2278,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "in_our_project,_we_leveraged_the_power_of_teachable"
        ],
        "data": [
          [
            "machines to revolutionize crime detection and crowd"
          ],
          [
            "management. Harnessing the potential of artificial"
          ],
          [
            "intelligence, particularly in computer vision, we"
          ],
          [
            "employed advanced algorithms to analyze image"
          ],
          [
            "inputs, including CCTV videos, with unprecedented"
          ],
          [
            "precision. These CCTV videos have been converted"
          ],
          [
            "to images in .jpg format using an online tool, and"
          ],
          [
            "these converted images were used to train the model."
          ],
          [
            "The model employs a Convolutional Neural Network"
          ],
          [
            "(CNN) to classify the input video as either normal or"
          ],
          [
            "indicative of criminal activity. Furthermore, our"
          ],
          [
            "application extends beyond crime prevention to"
          ],
          [
            "crowd management, where the same technology"
          ],
          [
            "facilitates real-time monitoring and analysis of"
          ],
          [
            "crowded spaces. The teachable machines not only"
          ],
          [
            "enable us to identify potential security threats but"
          ],
          [
            "also provide valuable insights for optimizing public"
          ],
          [
            "safety strategies. This project represents a significant"
          ],
          [
            "step forward in the fusion of cutting-edge technology"
          ],
          [
            "and public safety, showcasing the potential of"
          ],
          [
            "artificial intelligence in creating safer and more"
          ],
          [
            "secure environments for communities."
          ]
        ]
      },
      {
        "columns": [
          "now_to_know,_how_a_convolution_neural"
        ],
        "data": [
          [
            "network works lets break it into parts. the 3"
          ],
          [
            "most important parts of this convolution neural"
          ],
          [
            "networks are,"
          ]
        ]
      },
      {
        "columns": [
          "a._to_enhance_image_recognition_in_a_neural_network,"
        ],
        "data": [
          [
            "it's crucial to identify and focus on the most relevant"
          ],
          [
            "features while discarding unnecessary pixel"
          ],
          [
            "information. Convolution, despite its reputation as a"
          ],
          [
            "complex topic, is a fundamental technique that"
          ],
          [
            "simplifies this process. In essence, convolution"
          ],
          [
            "involves sliding a filter, or kernel, across an image to"
          ],
          [
            "detect various features. Kernels, represented as 2D"
          ],
          [
            "matrices with distinct weights, traverse the image,"
          ],
          [
            "replacing pixel values with the weighted average of"
          ],
          [
            "neighboring values."
          ],
          [
            "B. This method allows us to pinpoint significant"
          ],
          [
            "features in an image, providing a more nuanced"
          ],
          [
            "understanding. By applying multiple randomly"
          ],
          [
            "generated kernels, we can extract diverse features,"
          ],
          [
            "enriching the model's ability to recognize intricate"
          ],
          [
            "patterns."
          ],
          [
            "C. Following the convolution layer, the next step"
          ],
          [
            "involves pooling these features. Pooling is a"
          ],
          [
            "technique used to condense and emphasize essential"
          ],
          [
            "information while reducing computational"
          ],
          [
            "complexity. This ensures that the model retains"
          ],
          [
            "crucial details while discarding redundant"
          ],
          [
            "information, contributing to improved image"
          ],
          [
            "recognition performance."
          ]
        ]
      },
      {
        "columns": [
          "",
          "1._convolution",
          ""
        ],
        "data": [
          [
            "",
            "2. Pooling",
            ""
          ],
          [
            "",
            "3. Flattening",
            ""
          ],
          [
            "",
            "",
            ""
          ],
          [
            "Convolution",
            "",
            ""
          ],
          [
            "Consider a 28x28 image, like those in the MNIST",
            "",
            ""
          ],
          [
            "dataset used for handwritten digit recognition. In a",
            "",
            ""
          ],
          [
            "basic artificial neural network setup, each pixel's",
            "",
            ""
          ],
          [
            "value is treated as an individual feature input,",
            "",
            ""
          ],
          [
            "resulting in 784 input nodes. While this approach",
            "",
            ""
          ],
          [
            "may yield satisfactory results, it falls short in",
            "",
            ""
          ],
          [
            "recognizing crucial features within the image. The",
            "",
            ""
          ],
          [
            "model essentially processes each pixel independently,",
            "",
            ""
          ],
          [
            "potentially missing important patterns.",
            "",
            ""
          ],
          [
            "",
            "",
            ""
          ],
          [
            "Scaling this concept to a larger image, such as a",
            "",
            ""
          ],
          [
            "1920x1080 Ultra HD image, poses significant",
            "",
            ""
          ],
          [
            "challenges. Applying the same methodology would",
            "",
            ""
          ],
          [
            "result in an impractical 2 million input nodes. Even",
            "",
            ""
          ],
          [
            "with a relatively modest hidden layer of 64 nodes,",
            "",
            ""
          ],
          [
            "which is insufficient for such a large input, the",
            "",
            ""
          ],
          [
            "network would involve a staggering 130 million",
            "",
            ""
          ],
          [
            "weights. This massive scale of parameters necessitates",
            "",
            ""
          ],
          [
            "an enormous computational load, overwhelming the",
            "",
            ""
          ],
          [
            "capabilities of most machines. The sheer volume of",
            "",
            ""
          ],
          [
            "calculations involved makes it unfeasible for effective",
            "",
            ""
          ],
          [
            "image recognition, emphasizing the need for more",
            "",
            ""
          ],
          [
            "sophisticated approaches in handling high-resolution",
            "",
            ""
          ],
          [
            "images.",
            "",
            ""
          ],
          [
            "",
            "",
            ""
          ],
          [
            "",
            "",
            ""
          ]
        ]
      },
      {
        "columns": [
          "",
          ""
        ],
        "data": [
          [
            "D. Pooling",
            ""
          ],
          [
            "After identifying crucial features through",
            ""
          ],
          [
            "convolution, the challenge remains in handling the",
            ""
          ],
          [
            "large number of inputs, a task addressed by pooling.",
            ""
          ],
          [
            "Pooling serves to shrink the image dimensions while",
            ""
          ],
          [
            "retaining the features uncovered during convolution.",
            ""
          ],
          [
            "Take, for instance, the MaxPooling method, which",
            ""
          ],
          [
            "operates on a matrix shape and outputs the",
            ""
          ],
          [
            "maximum value within that region. This technique",
            ""
          ],
          [
            "allows for image compression without sacrificing the",
            ""
          ],
          [
            "essential features, facilitating a more manageable",
            ""
          ],
          [
            "input size for the subsequent layers of the neural",
            ""
          ],
          [
            "network.",
            ""
          ],
          [
            "",
            ""
          ],
          [
            "E. Flattening",
            ""
          ],
          [
            "Flattening is the process of transforming a 3D or 2D",
            ""
          ],
          [
            "matrix into a 1D format, serving as the final step in",
            ""
          ],
          [
            "preparing the image for input into the model. This",
            ""
          ]
        ]
      },
      {
        "columns": [
          "step_involves_converting_the_structured"
        ],
        "data": [
          [
            "representation of the image into a linear, one-"
          ],
          [
            "dimensional input. The flattened data can then be"
          ],
          [
            "seamlessly connected to a fully connected dense layer,"
          ],
          [
            "facilitating subsequent stages of classification in the"
          ],
          [
            "neural network"
          ],
          [
            "."
          ],
          [
            ""
          ]
        ]
      },
      {
        "columns": [
          "in_the_dynamic_landscape_of_contemporary_workplaces,"
        ],
        "data": [
          [
            "the need for efficient and effective work monitoring has"
          ],
          [
            "become paramount. Organizations strive to optimize"
          ],
          [
            "productivity, ensure employee safety, and maintain a"
          ],
          [
            "secure work environment. The advent of machine learning"
          ],
          [
            "technologies has opened up new avenues for addressing"
          ],
          [
            "these challenges. This project report delves into the"
          ],
          [
            "implementation of YOLO (You Only Look Once), a state-"
          ],
          [
            "of-the-art object detection algorithm, as a pioneering"
          ],
          [
            "solution for work monitoring."
          ],
          [
            "YOLO(YOU ONLY LOOK ONCE) MODULE"
          ],
          [
            "Unlike traditional object detection methods that involve"
          ],
          [
            "multiple stages, YOLO streamlines the process, allowing"
          ],
          [
            "for real-time detection with impressive speed and"
          ],
          [
            "accuracy. Here's a step-by-step explanation of how the"
          ],
          [
            "YOLO module works:"
          ],
          [
            "Input Processing:The input image undergoes grid-based"
          ],
          [
            "division, forming the foundation for subsequent"
          ],
          [
            "predictions."
          ],
          [
            "Bounding Box Prediction: YOLO predicts multiple"
          ],
          [
            "bounding boxes within each grid cell, each associated"
          ],
          [
            "with parameters (x, y) for the box's center, width (w),"
          ],
          [
            "height (h), confidence score, and class probabilities."
          ],
          [
            "Class Prediction: YOLO determines the probability of"
          ],
          [
            "each class for all bounding boxes in a grid cell, enabling"
          ],
          [
            "simultaneous detection of multiple object classes in a"
          ],
          [
            "given image."
          ],
          [
            "Confidence Score: A confidence score indicates the"
          ],
          [
            "model's certainty that a bounding box contains an object,"
          ],
          [
            "with a range from 0 to 1."
          ],
          [
            "Non-Maximum Suppression: Following predictions for"
          ],
          [
            "all grid cells, a post-processing step, non-maximum"
          ],
          [
            "suppression, removes redundant and low-confidence"
          ],
          [
            "bounding boxes, retaining only the most confident and"
          ],
          [
            "non-overlapping ones."
          ],
          [
            "Output: The YOLO module produces a final output of"
          ],
          [
            "bounding boxes, each linked to a class and a confidence"
          ],
          [
            "score, representing the detected objects in the input image."
          ],
          [
            "INTERSECTION OVER UNION"
          ]
        ]
      },
      {
        "columns": [
          "intersection_over_union_(iou)_is_a_metric_used_to_evaluate"
        ],
        "data": [
          [
            "the accuracy of an object detection algorithm, particularly"
          ],
          [
            "in tasks such as image segmentation and bounding box"
          ],
          [
            "prediction. IoU measures the overlap between the"
          ],
          [
            "predicted bounding box and the ground truth bounding"
          ],
          [
            "box for a given object in an image.The IoU is calculated"
          ],
          [
            "as the ratio of the area of intersection between the"
          ],
          [
            "predicted and ground truth bounding boxes to the area of"
          ],
          [
            "their union. The formula for IoU is:"
          ],
          [
            "IOU= Area of Intersection/Area of Union"
          ],
          [
            "Here's a breakdown of the terms:"
          ],
          [
            "1. Area of Intersection:The region where the"
          ],
          [
            "predicted bounding box and the ground truth bounding"
          ],
          [
            "box overlap."
          ],
          [
            "2. Area of Union:The combined region covered by"
          ],
          [
            "both the predicted bounding box and the ground truth"
          ],
          [
            "bounding box."
          ],
          [
            "The IoU value ranges from 0 to 1, where:"
          ],
          [
            "IoU=0 indicates no overlap between the predicted and"
          ],
          [
            "ground truth bounding boxes."
          ],
          [
            "IoU=1 indicates a perfect overlap between the predicted"
          ],
          [
            "and ground truth bounding boxes."
          ]
        ]
      },
      {
        "columns": [
          "in_the_dynamic_landscape_of_contemporary_workplaces,"
        ],
        "data": [
          [
            "the need for efficient and effective work monitoring has"
          ],
          [
            "become paramount. Organizations strive to optimize"
          ],
          [
            "productivity, ensure employee safety, and maintain a"
          ],
          [
            "secure work environment. The advent of machine learning"
          ],
          [
            "technologies has opened up new avenues for addressing"
          ],
          [
            "these challenges. This project report delves into the"
          ],
          [
            "implementation of YOLO (You Only Look Once), a state-"
          ],
          [
            "of-the-art object detection algorithm, as a pioneering"
          ],
          [
            "solution for work monitoring."
          ],
          [
            "YOLO(YOU ONLY LOOK ONCE) MODULE"
          ],
          [
            "Unlike traditional object detection methods that involve"
          ],
          [
            "multiple stages, YOLO streamlines the process, allowing"
          ],
          [
            "for real-time detection with impressive speed and"
          ],
          [
            "accuracy. Here's a step-by-step explanation of how the"
          ],
          [
            "YOLO module works:"
          ],
          [
            "Input Processing:The input image undergoes grid-based"
          ],
          [
            "division, forming the foundation for subsequent"
          ],
          [
            "predictions."
          ]
        ]
      },
      {
        "columns": [
          "bounding_box_prediction:_yolo_predicts_multiple"
        ],
        "data": [
          [
            "bounding boxes within each grid cell, each associated"
          ],
          [
            "with parameters (x, y) for the box's center, width (w),"
          ],
          [
            "height (h), confidence score, and class probabilities."
          ],
          [
            "Class Prediction: YOLO determines the probability of"
          ],
          [
            "each class for all bounding boxes in a grid cell, enabling"
          ],
          [
            "simultaneous detection of multiple object classes in a"
          ],
          [
            "given image."
          ],
          [
            "Confidence Score: A confidence score indicates the"
          ],
          [
            "model's certainty that a bounding box contains an object,"
          ],
          [
            "with a range from 0 to 1."
          ],
          [
            "Non-Maximum Suppression: Following predictions for"
          ],
          [
            "all grid cells, a post-processing step, non-maximum"
          ],
          [
            "suppression, removes redundant and low-confidence"
          ],
          [
            "bounding boxes, retaining only the most confident and"
          ],
          [
            "non-overlapping ones."
          ],
          [
            "Output: The YOLO module produces a final output of"
          ],
          [
            "bounding boxes, each linked to a class and a confidence"
          ],
          [
            "score, representing the detected objects in the input image."
          ]
        ]
      }
    ],
    "metadata": {
      "Title": "Paper Title (use style: paper title)",
      "Author": "TVL Bharathwaj",
      "Creator": "Microsoft® Word 2019",
      "CreationDate": "D:20231121153053+05'30'",
      "ModDate": "D:20231121153053+05'30'",
      "Producer": "Microsoft® Word 2019"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "495 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 CRIMINAL ACTIVITY MONITORING AND PREVENTION USING CCTV SURVEILLANCE Sumaira Hedaoo, Riddhi Shanbhag, Sakshi Sonalkar , Sayam Tukra, Prof. Shailesh Hule Abstract In this paper, we describe a surveillance program which is to be designed that can automatically detect the gestures or signs of aggression and brutality on real time. A single CCTV human operator can handle very limited set of operations, so as the number of CCTV camera increases the need of the human intervention also increases which can also cause human errors so automation for certain detection operations is necessary. Basically, our proposed system consists of 2 main modules which are capable of detecting the actions of objectional objects and humans in the frame for example gun and knife. Here in this project, we propose algorithms which are able to make the people attentive about 1 Presence of a any hazardous act, the danger is detected when the objectional object appears in the frame with the presence of human. 2 An abnormal activity of human when they be handling the weapons or acts of assaults, In this project, we focus to allow the real time application, we completely focus on reducing the number of negative alarms. Index Terms Objectional Objects, CCTV Surveillance, Gun, knife, alarm, abnormal activities.    1.INTRODUCTION Crime and theft are the social irritation for the society. It has major contribution to the crime rate in the world. To overcome So, in the continuation it responses to the trigger with an alert or such situations of crimes recently CCTVS are being used. Lately buzzer noise which helps in scenarios to escalate further. So, this here has been a sustainable growth in the use of CCTV system can be validated for ensuring the security privacy and IJSER surveillance cameras in order to prevent criminal activities. In confidentiality. There is no human intervention. The CCTV between the public expansion, as well the concerns for stabbing camera is inactive when there is no human presence. Basically, the and getting robbed, there is an alarming need for a proof -based human presence is checked by the motion detection algorithms. approach with the CCTV Services. Cases of harassment in public When there is any criminal activity, there is an alarm or buzzer places are also becoming very significant. With the growing that will ring that is connected to the main system. insertion of CCTV Cameras surveillances, almost now every area can be monitored, so through this if any crimes are committed the vital evidences can be presented from the crime scene. It is 2.EXISTING SYSTEM very essential to expect an alert or buzzer system for the ongoing The existing system of the CCTV surveillance is done by the /to be happen accidents and criminal activities, where certain human operator and also the automated system of CCTV actions should be taken on time as it can be question of life and surveillance is not that accurate for making decision and give death situation. Such structure is to be identified and monitored responses as per the bizarre situation. by live footages. But as the number of CCTVS per unit are rising, Normally monitoring in dynamic situations is mainly to the personnel viewing experience by a human operator is not recognize, detect and locate the certain thing or object from the possible. So, we require a particular surveillance unit which are provided image and moreover to understand the object behavior. capable of flourishing these situations with minimum human So, our main objective is to develop an intelligent Monitoring intervention. Model system and can take over the existing passive CCTV We shall define a scenario of need or vital scenario as any surveillance system which proves to be inefficient and ineffective sensitive scenario that can lead to any of mishaps in the public as, the number of CCTV increase the number of human operator places. We consider the idea of smart supervision which is or human intervention to observe the system also increases. activated only when there is the movement in room. Furthermore, if we are placing the cameras as human eyes in So this means ,at all other times the surveillance is not active so certain organization then the main aim of the surveillance is to that it helps in keeping the privacy of the person and also hide accomplish the task to be as automated as possible. certain confidentiality of work. But, the traditional surveillance Visual Monitoring the dynamic scenarios has a huge range of technically can be more risky as it does not hide any private potential applications such as a for the Guards, traffic, building in information and does not follow any privacy concerns. city expressways Detection of objects and human activities in So, the video feed would be recorded only when there is a Mall, Airways etc. need of hour in case there need to be any evidence for crime In this paper we focus on monitoring of people and objects in the committed. full range in the frame. We also focus on detecting the knives and pistols these objectional objects which are mainly overseen in the existing passive CCTV IJSER  2021 http//www .ijser.org 496 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 system. Monitoring applications which involve people include the following - a Access control in special areas People with certain specific identity or authorized person are allowed to enter in private or security centered locations such as certain government office and military camps. Certain security system has biometric features which helps in deciding the difference between authorized and non-authorized person which basically gets recorded in biometric database. When someone is about to enter the biometric centered place then the system automatically records the persons features, it compares the captured biometric with the saved ones and decide whether or not the person is allowed to enter the place. b Person-specific identification in certain scenes The security guards /police can catch criminals or suspects with the assistance of personal identification at a distance by a smart surveillance system. The police database may contain or store new suspect biometric and this can be obtained using visual CCTV system from the places where the suspect is usually seen as casinos and subway stations etc. So, after this the system is automatically enable to recognize whether or not the person in view are suspects. If yes, then the alarms will be given immediately. Even though such systems with faIce recoJgnition havSe already been ER used at public sites, their reliability is too low for police requirements. c Crowd flux statistics and congestion analysis The flux of people at important public areas such as stores, can be Drawbacks automatically computed by the surveillance systems, using  The passive system is used only in the military bases but techniques for human detection. It can then provide congestion not metro stations, airports and mall etc. analysis to assist in the management of the people. Similarly,  It is a complex architecture. In passive system there is expressways and junctions of the roads can be monitored not individual safety level considered. through visual surveillance systems, and further analyze the  Basically, the video in passive system is captured status of road congestion and traffic. continuously which can lead to privacy issue.  Also, the system does not have efficient alarm system d Ambiguity detection and alarming At sometimes, it is very that responses in return of any act of abuse or bullying. vital to analyze the behavior or characteristics of people and to  There is nor blurring out of the sensitive information in check whether they are normal or abnormal. For example, present system. abnormal behaviors indicative of theft, can be analyzed using the visual surveillance systems, which can be placed in supermarkets and parking lots. Basically, there are so many ways of giving alert such as by ringing the buzzer. One way is to make recorded declaration automatically whether certain abnormal behavior is detected. e Face detection and Object Detection Convolutional neural networks are widely used in addressing image-based problems, such as object/character detection and face recognition. In this paper we will be Using Faster-RCNN Because its Faster Than the traditional CNN and also saves time as it detects the things region-wise and searches only the region that is needed rather than searching for all the regions marked in the image as the CNN does. IJSER  2021 http//www .ijser.org 497 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 3.PROPOSED SYSTEM respective authorities about the criminal activity taking place The main aim of our project is to detect the criminal activities and they take instant action. with the utmost accuracy that take place in the public areas through the CCTV that take place in the public areas. Our current model consists of 2 detection functions, one for detecting crimes which are done when there are little movements detected e.g., Robbery or people armed with weapons and another one for detecting crimes that committed with the heavy or large movements e.g., stabbing. To avoid the negative/false alarms detection, we have executed a system where the already stored detections are all cleared and only the recently detected. Other crime prediction system software perform certain citizen trustworthiness analyzes which is basically based on data that is provided or obtained from organization such as police, hospital, school, banks and from social media. But this solution we believe that such a system can potentially be prone to certain discriminations against certain discrimination against certain situation that may involve in any crime. In our particular solution, there is no such social credit system that keeps permanent log of all the activity, So in this there is no need of continuous monitoring and assessment. Instead of this Machine Learning is used to detect the crime or criminal activity and react to the scenario by responding or alerting user or relevant authority. IJSER The flowchart here explains the flow of our system Whenever there is any action in the room the CCTV surveillance gets active. 4. METHODOLOGY 1If there is any situation of concern then the CCTV cam is In this paper we will be using certain algorithms to determine directed towards it and the frame is captured. the human and object detection in the surveillance. For Detection system we are using faster R-CNN deep learning 2Now the algorithms detect if the frame has a knife or a pistol. If algorithm. As in traditional CNN we take the image then we the frame detects the knife then optical flow algorithm calculates divide into regions. we will then consider each as separate image the velocity at which the knife is being moved from one frame to then pass all these regions to CNN as classify them into various the other. It then calculates the probability of stabbing by which classes. Once every region is divided into its certain classes, then intensity the process is taking place. we combine all the regions to get original image with the detected objects. We pass an object to the network and it then goes through 3If the probability taken is greater than the threshold value that various loops and pooling layers and then we get the output from is being set by us. The threshold needs to be set reasonably low the object class. We basically use R-CNN as it implements to ensure that the tip of knife is detected as a corner, even at the selective search to extract a bunch of regions in the image rather expense of more corners being detected. Basically, the range is than the massive number of regions to check if any of these boxes from 0 to 255. Here the threshold set is 204 as low as possible, contain any object that we require for our process. Process for R- when we set 204 as threshold it detects the knife in the frame with CNN is as follows - the utmost accuracy. 1It takes the images 2It generates initial sub segmentation so that multiple images 4Then when the knife is detected with much accuracy then the from the original image there is an alert that is the buzzer goes on. After which the 3The technique then combines certain same and relatable regions respective authorities are informed about the criminal activity to form a layer region which is based on color, similarity, texture taking place and they can take instant action. similarity, size similarity and shape compatibility. But this algorithm has certain drawback that are overcome by 5If the knife is not detected then the surveillance is continued. Faster-RCNN. The slowest part in R-CNN in selective search or Now, secondly if the pistol is detected in the given frame with a Edge boxes. Faster RCNN replaces selective search with a very human handling the object then the buzzer goes on and alert the small convolution network called Region Proposal network to IJSER  2021 http//www .ijser.org 498 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 generate regions of Interest. Faster R-CNN introduces idea of anchor. Secondly, for Motion Estimation we earlier used Open Pose library it created problems when the knife detector is integrated it hardly distinguished between human in the frame and who is holding the knife. Looking for alternative we found Motion estimation using Optical Flow to determine average speed of human Optical flow is basically a motion of object between consecutive frame of sequences, caused by the relative movement between object and camera. It is basically 2D vector field where each vector is a displacement vector showing movement of points from first frame to second. So Basically, for our project it is necessary as we have a knife and a person if person makes certain movement with the knife it should be captured instantly. Fig 4 Events Center It works on several assumptions 1The intensities of pixel for the item do not change between the frame that are one after the other 2The pixels that are present nearby have similar motion. Lastly, for very low levels of lightning can render the knife undetectable by our algorithm, hence we are using gamma correction to try and increase the brightness of frame gamma correction also blurs the picture so we need to find a good level of gamma correction such that our object is not blurred. IJSER 5.RESULTS AND DISCUSSION In this paper, the result is the final design of the project on topic Fig 5 Camera Feed for Gun Detection Criminal Activity Monitoring and Prevention Using CCTV Surveillance. Since there it has intuitive GUI which displays the feeds and a event manager tab to store the images of the detected events. Whenever there is a situation of need then the CCTV is active and captures the situation and responses accordingly. Here, algorithms are designed such that it can alert the respective authorities when there is a presence of any dangerous act, or an abnormal behavior of a person is detected. This can assure security to the public in the public places as well as in other locations such as offices, cinema halls etc. The major advantage of the project includes efficiency, fast to access and uniqueness. The behavioral analysis algorithm also makes it easier to monitor and prevent the crimes. Fig 5 Event Center 6.CONCLUSION Surveillance by using the CCTV system has reached its great heights. Also, whenever we will be sending the information or data through the networks to any server the transmission process is a very crucial work. CCTV surveillance systems are mostly managed by governments professional. As CCTV Information are very sensitive and confidential and also very difficult to handle. In this project, we have proposed certain algorithms that are able to alert the Fig 3 Camera feed for knife detection respective authorities if any abnormal behavior of a person is detected. We have limited the number of negative alarms in order to allow for a real-time working of the system to process well. This IJSER  2021 http//www .ijser.org 499 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 proposed system we will implement first implement it at low T.A.P., 2013, Smart Attendance using Real Time Face Recognation scale then further we can escalate things to higher Smart-FR, SAITM Research Symposium on Engineering implementation. In the future, we will enhance the proposed Advancement, Sri Lanka. system by implementing the night vision surveillance using the Infrared image enhancement. So that our project progress well and also gives us more coverage to handle the situation at night. 7.REFERENCES 1 Choi Woo Chul and Na Joon Yeop, Relative Importance for Crime Prevention Technologies as Part of Smart City based on Spatial Information, IEEE Journal, Smart Cities Symposium Prague, 13 July 2017 2 Robin Singh Sidhu and Mrigank Sharad, Smart Surveillance System for Detecting Interpersonal Crime, presented in International Conference on Communication and Signal Processing, April 6-8, 2016, published in IEEE Journal, 24 November 2016 3 Huang J, Rathod V, Sun C, Zhu M, Korattikara A, Fathi A, Fischer I, Wojna Z, Song Y, Guadarrama S, Murphy K, Speed/accuracy trade-offs for modern convolutional object detectors, CVPR 2017 IJSE R 4 Klima M., Pazderak J., Bernas M., Pata J., Hozman J., Roubik K., Objective and Subjective Image Quality Evaluation for Security Purposes, 35th IEEE International Carnahan Conference on Security Technology, London, U.K. 5 Padaruth, S., Indiwarsingh, F.  Bhugun, N., 2013, A Unified Intrusion Alert System using Motion Detection and Faces Recognition, 2nd International Conference on Mechine Learning and Computer Science IMLCS, Kuala Lumpur. 6 Namrata, Pradeep  Sagar, R., 2013. Cognitive Security System Based on Image Comparison and Motion Detection with Able Memory Usage. International Journal of Advances in Engineering  Technology, VI2, pp.850-61. 7 Putro, M.D., Adji, T.B.  Winduratna, B., 2012, Sistem Deteksi Wajah dengan Menggunakan Metode Viola-Jones, Proseding Seminar Nasional Science, Engineering and Technology. Malang. 8 Santoso, H.  Harjoko, A., 2013. Haar Cascade Classifier dan Algoritma Adaboost untuk Deteksi Banyak Wajah dalam Ruang Kelas. Jurnal Teknologi, VI2, pp.108-15 9 Febrianto, A.J., 2012, Pengenalan Wajah Dengan Metode Principle Component Analysis PCA Pada sistem Absensi Real Time, Tesis, Magister Teknik Elektro, Universitas Gadjah Mada, Yogyakarta. 10 Tharanga, J.G.R., Samarakoon, S.M.C.  Karunarathne, IJSER  2021 http//www .ijser.org 500 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 IJSER IJSER  2021 http//www .ijser.org",
    "structured_text": {
      "sentences": [
        "495 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 CRIMINAL ACTIVITY MONITORING AND PREVENTION USING CCTV SURVEILLANCE Sumaira Hedaoo, Riddhi Shanbhag, Sakshi Sonalkar , Sayam Tukra, Prof.",
        "Shailesh Hule Abstract In this paper, we describe a surveillance program which is to be designed that can automatically detect the gestures or signs of aggression and brutality on real time.",
        "A single CCTV human operator can handle very limited set of operations, so as the number of CCTV camera increases the need of the human intervention also increases which can also cause human errors so automation for certain detection operations is necessary.",
        "Basically, our proposed system consists of 2 main modules which are capable of detecting the actions of objectional objects and humans in the frame for example gun and knife.",
        "Here in this project, we propose algorithms which are able to make the people attentive about 1 Presence of a any hazardous act, the danger is detected when the objectional object appears in the frame with the presence of human.",
        "2 An abnormal activity of human when they be handling the weapons or acts of assaults, In this project, we focus to allow the real time application, we completely focus on reducing the number of negative alarms.",
        "Index Terms Objectional Objects, CCTV Surveillance, Gun, knife, alarm, abnormal activities.",
        "1.INTRODUCTION Crime and theft are the social irritation for the society.",
        "It has major contribution to the crime rate in the world.",
        "To overcome So, in the continuation it responses to the trigger with an alert or such situations of crimes recently CCTVS are being used.",
        "Lately buzzer noise which helps in scenarios to escalate further.",
        "So, this here has been a sustainable growth in the use of CCTV system can be validated for ensuring the security privacy and IJSER surveillance cameras in order to prevent criminal activities.",
        "In confidentiality.",
        "There is no human intervention.",
        "The CCTV between the public expansion, as well the concerns for stabbing camera is inactive when there is no human presence.",
        "Basically, the and getting robbed, there is an alarming need for a proof -based human presence is checked by the motion detection algorithms.",
        "approach with the CCTV Services.",
        "Cases of harassment in public When there is any criminal activity, there is an alarm or buzzer places are also becoming very significant.",
        "With the growing that will ring that is connected to the main system.",
        "insertion of CCTV Cameras surveillances, almost now every area can be monitored, so through this if any crimes are committed the vital evidences can be presented from the crime scene.",
        "It is 2.EXISTING SYSTEM very essential to expect an alert or buzzer system for the ongoing The existing system of the CCTV surveillance is done by the /to be happen accidents and criminal activities, where certain human operator and also the automated system of CCTV actions should be taken on time as it can be question of life and surveillance is not that accurate for making decision and give death situation.",
        "Such structure is to be identified and monitored responses as per the bizarre situation.",
        "by live footages.",
        "But as the number of CCTVS per unit are rising, Normally monitoring in dynamic situations is mainly to the personnel viewing experience by a human operator is not recognize, detect and locate the certain thing or object from the possible.",
        "So, we require a particular surveillance unit which are provided image and moreover to understand the object behavior.",
        "capable of flourishing these situations with minimum human So, our main objective is to develop an intelligent Monitoring intervention.",
        "Model system and can take over the existing passive CCTV We shall define a scenario of need or vital scenario as any surveillance system which proves to be inefficient and ineffective sensitive scenario that can lead to any of mishaps in the public as, the number of CCTV increase the number of human operator places.",
        "We consider the idea of smart supervision which is or human intervention to observe the system also increases.",
        "activated only when there is the movement in room.",
        "Furthermore, if we are placing the cameras as human eyes in So this means ,at all other times the surveillance is not active so certain organization then the main aim of the surveillance is to that it helps in keeping the privacy of the person and also hide accomplish the task to be as automated as possible.",
        "certain confidentiality of work.",
        "But, the traditional surveillance Visual Monitoring the dynamic scenarios has a huge range of technically can be more risky as it does not hide any private potential applications such as a for the Guards, traffic, building in information and does not follow any privacy concerns.",
        "city expressways Detection of objects and human activities in So, the video feed would be recorded only when there is a Mall, Airways etc.",
        "need of hour in case there need to be any evidence for crime In this paper we focus on monitoring of people and objects in the committed.",
        "full range in the frame.",
        "We also focus on detecting the knives and pistols these objectional objects which are mainly overseen in the existing passive CCTV IJSER  2021 http//www .ijser.org 496 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 system.",
        "Monitoring applications which involve people include the following - a Access control in special areas People with certain specific identity or authorized person are allowed to enter in private or security centered locations such as certain government office and military camps.",
        "Certain security system has biometric features which helps in deciding the difference between authorized and non-authorized person which basically gets recorded in biometric database.",
        "When someone is about to enter the biometric centered place then the system automatically records the persons features, it compares the captured biometric with the saved ones and decide whether or not the person is allowed to enter the place.",
        "b Person-specific identification in certain scenes The security guards /police can catch criminals or suspects with the assistance of personal identification at a distance by a smart surveillance system.",
        "The police database may contain or store new suspect biometric and this can be obtained using visual CCTV system from the places where the suspect is usually seen as casinos and subway stations etc.",
        "So, after this the system is automatically enable to recognize whether or not the person in view are suspects.",
        "If yes, then the alarms will be given immediately.",
        "Even though such systems with faIce recoJgnition havSe already been ER used at public sites, their reliability is too low for police requirements.",
        "c Crowd flux statistics and congestion analysis The flux of people at important public areas such as stores, can be Drawbacks automatically computed by the surveillance systems, using  The passive system is used only in the military bases but techniques for human detection.",
        "It can then provide congestion not metro stations, airports and mall etc.",
        "analysis to assist in the management of the people.",
        "Similarly,  It is a complex architecture.",
        "In passive system there is expressways and junctions of the roads can be monitored not individual safety level considered.",
        "through visual surveillance systems, and further analyze the  Basically, the video in passive system is captured status of road congestion and traffic.",
        "continuously which can lead to privacy issue.",
        "Also, the system does not have efficient alarm system d Ambiguity detection and alarming At sometimes, it is very that responses in return of any act of abuse or bullying.",
        "vital to analyze the behavior or characteristics of people and to  There is nor blurring out of the sensitive information in check whether they are normal or abnormal.",
        "For example, present system.",
        "abnormal behaviors indicative of theft, can be analyzed using the visual surveillance systems, which can be placed in supermarkets and parking lots.",
        "Basically, there are so many ways of giving alert such as by ringing the buzzer.",
        "One way is to make recorded declaration automatically whether certain abnormal behavior is detected.",
        "e Face detection and Object Detection Convolutional neural networks are widely used in addressing image-based problems, such as object/character detection and face recognition.",
        "In this paper we will be Using Faster-RCNN Because its Faster Than the traditional CNN and also saves time as it detects the things region-wise and searches only the region that is needed rather than searching for all the regions marked in the image as the CNN does.",
        "IJSER  2021 http//www .ijser.org 497 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 3.PROPOSED SYSTEM respective authorities about the criminal activity taking place The main aim of our project is to detect the criminal activities and they take instant action.",
        "with the utmost accuracy that take place in the public areas through the CCTV that take place in the public areas.",
        "Our current model consists of 2 detection functions, one for detecting crimes which are done when there are little movements detected e.g., Robbery or people armed with weapons and another one for detecting crimes that committed with the heavy or large movements e.g., stabbing.",
        "To avoid the negative/false alarms detection, we have executed a system where the already stored detections are all cleared and only the recently detected.",
        "Other crime prediction system software perform certain citizen trustworthiness analyzes which is basically based on data that is provided or obtained from organization such as police, hospital, school, banks and from social media.",
        "But this solution we believe that such a system can potentially be prone to certain discriminations against certain discrimination against certain situation that may involve in any crime.",
        "In our particular solution, there is no such social credit system that keeps permanent log of all the activity, So in this there is no need of continuous monitoring and assessment.",
        "Instead of this Machine Learning is used to detect the crime or criminal activity and react to the scenario by responding or alerting user or relevant authority.",
        "IJSER The flowchart here explains the flow of our system Whenever there is any action in the room the CCTV surveillance gets active.",
        "4.",
        "METHODOLOGY 1If there is any situation of concern then the CCTV cam is In this paper we will be using certain algorithms to determine directed towards it and the frame is captured.",
        "the human and object detection in the surveillance.",
        "For Detection system we are using faster R-CNN deep learning 2Now the algorithms detect if the frame has a knife or a pistol.",
        "If algorithm.",
        "As in traditional CNN we take the image then we the frame detects the knife then optical flow algorithm calculates divide into regions.",
        "we will then consider each as separate image the velocity at which the knife is being moved from one frame to then pass all these regions to CNN as classify them into various the other.",
        "It then calculates the probability of stabbing by which classes.",
        "Once every region is divided into its certain classes, then intensity the process is taking place.",
        "we combine all the regions to get original image with the detected objects.",
        "We pass an object to the network and it then goes through 3If the probability taken is greater than the threshold value that various loops and pooling layers and then we get the output from is being set by us.",
        "The threshold needs to be set reasonably low the object class.",
        "We basically use R-CNN as it implements to ensure that the tip of knife is detected as a corner, even at the selective search to extract a bunch of regions in the image rather expense of more corners being detected.",
        "Basically, the range is than the massive number of regions to check if any of these boxes from 0 to 255.",
        "Here the threshold set is 204 as low as possible, contain any object that we require for our process.",
        "Process for R- when we set 204 as threshold it detects the knife in the frame with CNN is as follows - the utmost accuracy.",
        "1It takes the images 2It generates initial sub segmentation so that multiple images 4Then when the knife is detected with much accuracy then the from the original image there is an alert that is the buzzer goes on.",
        "After which the 3The technique then combines certain same and relatable regions respective authorities are informed about the criminal activity to form a layer region which is based on color, similarity, texture taking place and they can take instant action.",
        "similarity, size similarity and shape compatibility.",
        "But this algorithm has certain drawback that are overcome by 5If the knife is not detected then the surveillance is continued.",
        "Faster-RCNN.",
        "The slowest part in R-CNN in selective search or Now, secondly if the pistol is detected in the given frame with a Edge boxes.",
        "Faster RCNN replaces selective search with a very human handling the object then the buzzer goes on and alert the small convolution network called Region Proposal network to IJSER  2021 http//www .ijser.org 498 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 generate regions of Interest.",
        "Faster R-CNN introduces idea of anchor.",
        "Secondly, for Motion Estimation we earlier used Open Pose library it created problems when the knife detector is integrated it hardly distinguished between human in the frame and who is holding the knife.",
        "Looking for alternative we found Motion estimation using Optical Flow to determine average speed of human Optical flow is basically a motion of object between consecutive frame of sequences, caused by the relative movement between object and camera.",
        "It is basically 2D vector field where each vector is a displacement vector showing movement of points from first frame to second.",
        "So Basically, for our project it is necessary as we have a knife and a person if person makes certain movement with the knife it should be captured instantly.",
        "Fig 4 Events Center It works on several assumptions 1The intensities of pixel for the item do not change between the frame that are one after the other 2The pixels that are present nearby have similar motion.",
        "Lastly, for very low levels of lightning can render the knife undetectable by our algorithm, hence we are using gamma correction to try and increase the brightness of frame gamma correction also blurs the picture so we need to find a good level of gamma correction such that our object is not blurred.",
        "IJSER 5.RESULTS AND DISCUSSION In this paper, the result is the final design of the project on topic Fig 5 Camera Feed for Gun Detection Criminal Activity Monitoring and Prevention Using CCTV Surveillance.",
        "Since there it has intuitive GUI which displays the feeds and a event manager tab to store the images of the detected events.",
        "Whenever there is a situation of need then the CCTV is active and captures the situation and responses accordingly.",
        "Here, algorithms are designed such that it can alert the respective authorities when there is a presence of any dangerous act, or an abnormal behavior of a person is detected.",
        "This can assure security to the public in the public places as well as in other locations such as offices, cinema halls etc.",
        "The major advantage of the project includes efficiency, fast to access and uniqueness.",
        "The behavioral analysis algorithm also makes it easier to monitor and prevent the crimes.",
        "Fig 5 Event Center 6.CONCLUSION Surveillance by using the CCTV system has reached its great heights.",
        "Also, whenever we will be sending the information or data through the networks to any server the transmission process is a very crucial work.",
        "CCTV surveillance systems are mostly managed by governments professional.",
        "As CCTV Information are very sensitive and confidential and also very difficult to handle.",
        "In this project, we have proposed certain algorithms that are able to alert the Fig 3 Camera feed for knife detection respective authorities if any abnormal behavior of a person is detected.",
        "We have limited the number of negative alarms in order to allow for a real-time working of the system to process well.",
        "This IJSER  2021 http//www .ijser.org 499 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 proposed system we will implement first implement it at low T.A.P., 2013, Smart Attendance using Real Time Face Recognation scale then further we can escalate things to higher Smart-FR, SAITM Research Symposium on Engineering implementation.",
        "In the future, we will enhance the proposed Advancement, Sri Lanka.",
        "system by implementing the night vision surveillance using the Infrared image enhancement.",
        "So that our project progress well and also gives us more coverage to handle the situation at night.",
        "7.REFERENCES 1 Choi Woo Chul and Na Joon Yeop, Relative Importance for Crime Prevention Technologies as Part of Smart City based on Spatial Information, IEEE Journal, Smart Cities Symposium Prague, 13 July 2017 2 Robin Singh Sidhu and Mrigank Sharad, Smart Surveillance System for Detecting Interpersonal Crime, presented in International Conference on Communication and Signal Processing, April 6-8, 2016, published in IEEE Journal, 24 November 2016 3 Huang J, Rathod V, Sun C, Zhu M, Korattikara A, Fathi A, Fischer I, Wojna Z, Song Y, Guadarrama S, Murphy K, Speed/accuracy trade-offs for modern convolutional object detectors, CVPR 2017 IJSE R 4 Klima M., Pazderak J., Bernas M., Pata J., Hozman J., Roubik K., Objective and Subjective Image Quality Evaluation for Security Purposes, 35th IEEE International Carnahan Conference on Security Technology, London, U.K.",
        "5 Padaruth, S., Indiwarsingh, F.",
        "Bhugun, N., 2013, A Unified Intrusion Alert System using Motion Detection and Faces Recognition, 2nd International Conference on Mechine Learning and Computer Science IMLCS, Kuala Lumpur.",
        "6 Namrata, Pradeep  Sagar, R., 2013.",
        "Cognitive Security System Based on Image Comparison and Motion Detection with Able Memory Usage.",
        "International Journal of Advances in Engineering  Technology, VI2, pp.850-61.",
        "7 Putro, M.D., Adji, T.B.",
        "Winduratna, B., 2012, Sistem Deteksi Wajah dengan Menggunakan Metode Viola-Jones, Proseding Seminar Nasional Science, Engineering and Technology.",
        "Malang.",
        "8 Santoso, H.",
        "Harjoko, A., 2013.",
        "Haar Cascade Classifier dan Algoritma Adaboost untuk Deteksi Banyak Wajah dalam Ruang Kelas.",
        "Jurnal Teknologi, VI2, pp.108-15 9 Febrianto, A.J., 2012, Pengenalan Wajah Dengan Metode Principle Component Analysis PCA Pada sistem Absensi Real Time, Tesis, Magister Teknik Elektro, Universitas Gadjah Mada, Yogyakarta.",
        "10 Tharanga, J.G.R., Samarakoon, S.M.C.",
        "Karunarathne, IJSER  2021 http//www .ijser.org 500 INTERNATIONAL JOURNAL OF SCIENTIFIC  ENGINEERING RESEARCH, VOLUME 12, ISSUE 1, JANUARY-2021 I SSN 2229-5518 IJSER IJSER  2021 http//www .ijser.org"
      ],
      "word_count": 3060,
      "sections": {}
    },
    "tables": [],
    "metadata": {
      "Author": "Sumaira Hedaoo, Riddhi Shanbhag, Sakshi Sonalkar , Sayam Tukra, Prof. Shailesh Hule",
      "CreationDate": "D:20210120212821+05'30'",
      "Creator": "Microsoft® Word 2019",
      "Keywords": "Objectional Objects, CCTV Surveillance, Gun, knife, alarm, abnormal activities",
      "ModDate": "D:20210125115206+05'30'",
      "Producer": "Microsoft® Word 2019",
      "Subject": "International Journal of Scientific & Engineering Research Volume 12, Issue 1, January-2021\r\n",
      "Title": "CRIMINAL ACTIVITY MONITORING AND PREVENTION USING CCTV SURVEILLANCE"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "applied sciences Review Crowd Monitoring and Localization Using Deep Convolutional Neural Network A Review AkbarKhan 1,JawadAliShah1, ,KushsairyKadir1,WaleedAlbattah2 andFaizullahKhan3 1 ElectronicSection,UniversitiKualaLumpurBritishMalaysianInstitute,Selangor53100, Malaysia akbar.khans.unikl.edu.myA.K.kushsairyunikl.edu.myK.K. 2 DepartmentofInformationTechnology,CollegeofComputer,QassimUniversity, 51921Buraydah,SaudiArabiaw.albattahqu.edu.sa 3 DepartmentofTelecommunicationEngineering,BalochistanUniversityofInformationTechnology, EngineeringandManagementSciences,Quetta87300,Pakistanfaizullah.khanbuitms.edu.pk  Correspondencejawadunikl.edu.my Received18May2020Accepted26June2020Published11July2020 Abstract Crowd management and monitoring is crucial for maintaining public safety and is an important research topic. Developing a robust crowd monitoring system CMS is a challenging task as it involves addressing many key issues such as density variation, irregular distribution of objects, occlusions, pose estimation, etc. Crowd gathering at various places like hospitals, parks, stadiums, airports, cultural and religious points are usually monitored by Close Circuit TelevisionCCTVcameras.ThedrawbacksofCCTVcamerasare limitedareacoverage,installation problems, movability, high power consumption and constant monitoring by the operators. Therefore,manyresearchershaveturnedtowardscomputervisionandmachinelearningthathave overcome these issues by minimizing the need of human involvement. This review is aimed to categorize,analyzeaswellasprovidethelatestdevelopmentandperformanceevolutionincrowd monitoringusingdifferentmachinelearningtechniquesandmethodsthatarepublishedinjournals andconferencesoverthepastfiveyears. Keywords crowdmonitoringcrowdcountingcrowddensityestimationdeepconvolutionalneural networksDCNNcrowdbehavior 1. Introduction Crowdissameordifferentsetofpeoplearrangedinonegroupandmotivatedbycommongoals. Therearetwotypesofcrowdnamelystructuredcrowdandunstructuredcrowd.Intheformer,thedirection ofthemovementistowardsacommonpointandpeoplearenotinscatteredformwhileinthelatertypethe directionofthepeopleisnottowardsacommonpointandtheyareusuallyinscatteredform1. Crowdmonitoringhasawiderangeofapplicationssuchas,safetymonitoring,disastermanagement, trafficmonitoringanddesignofpublicspaces.Thisvarietyofapplicationshaveencouragedresearchers throughout numerous fields to develop models for crowd monitoring and associated tasks such as counting 25, density estimation 68, tracking 9, scene understanding 10, localization 11 and behaviordetection12,13.Amongthese,thecrowdcountinganddensityestimationareimportanttasks and represent fundamental building blocks for several other applications 14. There are three most commonlyusedmethodsforcrowdcountingnamely,objectdetectionbasedcounting1517,clustered basedcounting18andregressionbasedcounting19,20.Inobjectdetectionbasedcountingtheobject detectorsaretrainedtolocalizethepositionofeverypersoninthecrowdforcounting.Clusterbasedcrowd countingconsistsofidentifyingandtrackingvisualfeatures.Featuretrajectoriesthatshowcoherentmotion areclusteredandthenumbersofclusterisregardedasaestimationofmovingobjects21. Regression Appl.Sci.2020,10,4781doi10.3390/app10144781 www.mdpi.com/journal/applsci Appl.Sci.2020,10,4781 2of17 basedcountingestimatesthecrowdcountbycarryingoutregressionbetweentheimagefeaturesandcrowd size.Thoughtheregressionbasedmethodsareworkinggoodinsituationsofhighdensityastheycapture generalizeddensityinformationfromtheimageofcrowd,stillithastwomainlimitationsi.e.,performance degradationduetooverestimatingofcountinlowdensitysituationsandimproperdistributionofcrowdin thescene22.Onemayconsiderthatconventionalcrowdcountingmethodssuchaspatchbasedapproach, objectbasedapproachandrichfeatureapproach8,23,24,whichdependoneitherdetectionorregression, arelimitedwhenhandlingrealscenewithunavoidabledensityvariations.However,thesemethodscan onlybeusedtoestimateandcountthepeopleinlowdensitysituationsinwhichallpartsofthepeople arefullyvisible.Theperformanceofthesemethodsdeteriorateswhenappliedinhighdensitysituations. Anidealcountingmethodshouldhavetheadaptiveabilitytochoosetheappropriatecountingmode accordingtocrowddensity20. Exactcrowdcountingandlocalizationareindispensableforhandling highdensitycrowds. Localizationmeanstogettheaccuratelocationoftheheadsinanimage. Head is the only visible part through which localization can be found in highly dense crowd images or videos25. Althoughnumerousstepshavebeentakeninthedetectionofhumanheads16,17,26, headdetectionisstillachallengingtask. Asaresultofthevariationinthescaleappearanceofheads, itisstillabigproblemtoexactlydiscriminatehumanheadsfromthebackground. Forlocalizationin crowdedscene,densitymaphasbeenusedasaregularizerduringthedetection27. Incomputer vision,crowdbehaviordetectioninvideosurveillanceisoneofthelatestresearchareas1. Crowd behavior detection has many application domains such as automatic detection of riots or chaotic actsincrowdandlocalizationofabnormalregions28. Detectionofcrowdbehaviorisextensively usedinordertomonitorandmaintainthesurveillanceofpublicplaceslikesportsevents,markets, religiousandpoliticalgatherings,etc. Therearetwocategoriesofcrowdbehaviordetectionnamely globalcrowdbehaviordetectionandlocalcrowdbehaviordetection29. Inglobalcrowdbehavior detection a large area is affected, while in the local crowd behavior detection it affects the limited areaofthecrowdandthebehaviorofanindividualisquitedifferentfromitsneighbor. Multiscale textureanalysisisusedforassessingthebehaviorofcrowdinvideosequences30. Theaimofvideo surveillanceisusedtodetectabnormalhumanbehavior31. 1.1. Rational Reviewingtheliteratureisoneofthemostimportantactivitiesinresearch.Thispaperisthefirstpaper inaseriesofresearchpapersinthefieldofcrowdmonitoring.Accordingtoourplanofcurrentworking onasubstantialcrowdmonitoringprojectfundedbyMinistryofEducationinSaudiArabia,itisavery crucialphasetostudytheliteratureandanalyzeitinordertoaddressdifferentaspectsofthesubjectunder investigations.Anycontributioninanysubjectorfieldcannotbeachievedwithaconsiderableknowledge ofthestateoftheart.Webelievethispaperwillprovideusaswellasinterestedresearcherswithoverview ofexistingstudiesinthefieldofcrowdmonitoringandmanagement.Wealsoexpectthisreviewprovides anovelsynthesisofthecurrentresearchworks,whichwehopecanleadtoanewmeansofconsidering crowdmonitoringaswellasfindinganyavailablegaps. 1.2. Datasets Variousdatasetscontainingcrowdvideosandimagesarepubliclyavailableandarebeingusedto validatetheexperimentalresults. Someofthepubliclyavailabledatasetsalongwithitsdescriptionare showninTable1. UCSDdatasetwasthefirstdatasetusedforpeoplecounting32. Thedatahasobtainedthrough a camera installed on a pedestrian pathway. The dataset includes 2000 frames 238  158 of video sequences,alongwithgroundtruthannotationofeachpedestrianineveryfifthframehaving49,885 pedestrianintotal. TheMalldatasethasbeencollectedbymeansofsurveillancecamerasinstalled inashoppingmall33. Ithasatotalof2000frameswithsizeof320240. UCF_CC_50dataset2 isachallengingdatasetcomprisingofawidevarietyofdensitiesandvariousscenes. Thisdataset has been obtained from different places like concerts, political protests, stadiums and marathons. Appl.Sci.2020,10,4781 3of17 Theentirenumbersofannotatedimagesare50containing1279individualsperimage. Thisdataset hasavaryingresolutionandtheindividualsdifferfrom94to4543representingalargevariationinthe image. Thedrawbackofthistypeofdatasetisthat,thereisonlylimitednumberofimagesavailablefor trainingandevaluation. WorldExpo10datasetintroducedin34hasbeenusedforcrossscenecrowd counting. Thedatasetcomprisesof3980framesofsize576720with199,923labeledpedestrians. Themaximumcrowdcountthroughthisdatasetislimitedto220andisinsufficientforevaluating extremelydensecrowdscounting. TheShanghaiTechdataset35hasbeenintroducedforlargescale crowdcountingcontainingof1198imageswith330,165annotatedheads. Intermsofannotatedheads, thisdatasetisoneofthelargest. Thedatasetcontainstwotypes,namelyPartA,PartB.PartAismade of482imagestakenfromtheinternetrandomly.WhereasPartBcomprisesof716imagescollectedfrom themetropolitanstreetinshanghai. ThemostrecentdatasetisUCF-QNRF11having1535images. Withinthisdataset,thenumberofpeoplefluctuatesfrom49to12,865makingamassivevariation indensity. Furthermore,ithasahugeimageresolutionrangingfrom400300to90006000and consists of crowd videos with varying densities and perspective scales. CUHK dataset has been collected from diverse locations namely, street, shopping malls, airports and parks. The dataset comprisesof474videosclipsfrom215scenes36. Table1.Descriptionofdatasets. Overall Datasets Description No.ofImages Resolution Min Ave Max Accessibility Count UCSD Peoplecounting 2000 238158 11 25 46 49,885 Yes MALL Peoplecounting 2000 320240 13 - 53 62,325 Yes UCF_CC_50 Densityestimation 50 Variable 94 1279 4543 63,974 Yes Crossscene WorldExpo10 3980 576720 1 50 253 199,923 Yes crowdcounting Variable, ShanghaiTechA,B Crowdcounting 482 33 501 3139 241,677 Yes 7681024 Crowdcounting 400300to UCF-QNRF 716 9 123 578 88,488 Yes andlocalization 90006000 CUHK Crowdbehavior 1535 Variable 49 815 12,865 - Yes This review paper is mainly focusing on the crowd monitoring crowd counting, crowdlocalizationandbehaviordetection. Therestofthepaperisorganizedasfollows. Section2 showssearchmethodologyandTaxonomyLevel. InSection3,crowdmonitoringapproachestaken fromthepreviousliteraturearesummarizedintabularform. Section4showscrowdrelatedresearch approaches. Section5showstheconvolutionalneuralnetworkanddeepCNNframeworks. Section6 representsthediscussionandSection7elaboratesconclusions. 2. SearchMethodologyandTaxonomyLevel Figure 1 shows the growth of published papers on crowd monitoring Crowd counting, localization and behavior using different machine learning methods and techniques. The graphs showthetwomaindatabasesofscopusandwebofscienceinwhichtheresearchpapershavebeen publishedfromyear2014to2019. Wehavesearchedcrowdmonitoringkeywordinbothdatabases andfounddifferentpaperswithdifferentmethodsandtechniques. Thedetailsofthepaperspublished inbothdatabasesareshowningraphicalviewasshowninFigure1. TaxonomyLevel Theentiretaxonomylevelofcrowdmonitoringhasbeenshownintheformofflowchart.Basically thecrowdrelatedresearchapproacheshavebeencategorizedintotwodomainsbasedontheliterature review namely crowd management and crowd monitoring. Then we have made categories of crowd monitoringi.e.,counting,localizationandbehavior. Focusingoncrowdmonitoring,wejustreviewthe Appl.Sci.2020,10,4781 4of17 crowdmanagementanddidnotcategorizeitfurther. Afterthat,thecountingsectionhasbeendivided intotwopartsnamelydensityestimationandpeoplecounting. Inlocalizationtherearethreemainsub categoriesi.e.,countingandlocalization,estimationandlocalizationandanomalydetectionandlocalization. Finally,thebehaviorcategoryhasbeendividedintothreesubcategoriesi.e.,individualbehaviorestimation, anomalousbehaviordetectionandnormalandabnormalbehaviordetection.Thetaxonomylevelofcrowd monitoringcrowdcounting,localizationandbehaviorhasbeenshowninFigure2. Web of science Scopus No.of papers 30 27 2019 8 25 19 20 2018 7 20 18 16 14 2017 10 15 12 12 13 10 2016 6 10 7 8 2015 5 5 2014 2 0 2014 2015 2016 2017 2018 2019 0 2 4 6 8 10 12 a Web of science and scopus b Machine learning on crowd monitoring Figure1.aThelistofresearchpaperspublishedinwebofscienceandscopusoncrowdmonitoring from20142019whilebshowsmachinelearningoncrowdmonitoring Crowd Related Research Approaches Crowd Crowd Management Monitoring Counting Localization Behavior Counting Individual E D si e t n m s a it t y io n c P o e u o n p t l i e n g loca a li n z d at ion es b t e im ha a v t i i o o r n Estimation Anomalous and behavior localization detection Anomaly Normal and detection abnormal and behavior Localization detection Figure2.Crowdrelatedresearchapproaches. 3. CrowdMonitoringCMApproaches Table2showscompletelyaboutalltheresearchpapersaboutcrowdcounting,localizationand behaviordetection. Differentresearchpaperswithakeywordcrowdmonitoringhavebeensearched whileusingtwomainlyuseddatabasesi.e.,webofscienceandscopusfrom20142019,respectively. Wehavefounddifferentmethodsandtechniquesrelatedtocrowdmonitoringandtriedtoreview itcompletely. Furthertheelaborationofthecrowdcounting, localizationandbehaviorhavebeen deliberatelydiscussedintabularformasshowninTable2. Appl.Sci.2020,10,4781 5of17 Table2.CrowdMonitoringCMapproaches. Ref Process Frameworks/Methods Performance Conclusion/Result Combinationofcrowdsizeestimationand Classificationwith 4 CrowdmonitoringCounting Accuracy90 counting MSE0.0081 Neuralnetworkandregression BPNNcandeal9 37 CrowdmonitoringCounting BPNNprovidesthebestestimation treesusingfisheyecamera framesinsecond ICrowdframeworkwasdesigned onathree-layerapproach,device 38 CrowdmonitoringEstimation Noexperimentalresults Capableoflocationupdates layer,middlewarelayerandthe applicationlayer Airbornecamerasystems, Dependsongoodtraining Gaborfilterplaysaprominent 39 DensityestimationEstimation supportvectormachineandGaborfilter samplesandsimilarimages roleinrealscenesofimages Real-timecrowddensity Crowdmonitoring Informationmanagement Expertsystemmodule 40 measurementsand Controllingcrowdmovement moduleanddecisionsupportsystem performswell communicationsduringhajj CrowdCounting 41 MedianfilterandKalmanfilter Accuracy95.5 Robustsmartsurveillancesystem Normal/abnormalevent Estimationand 11 DeepCNNnetworks Specificity75.8 Decreaseerrorrate localizationDensitymap Detectionandlocalization Globalandlocaldescriptors, Achievedgoodandcompetingmethods 42 Accuracy99.6 Anomalydetection withtwoclassifierswereproposed withlowcomputationalcomplexity DISAMoutperformsforUCSD CountingandLocalization andWorldExpo10datasetswith 43 CNN Reductionofclassificationtime Humanheads thelowestMAEof1.01and8.65, respectively AveragePrecisionandaverage Reductionofclassificationtimeand 25 Countingandlocalization SD-CNNModel recallrate73.58and71.68 improvementindetectionaccuracy 99.1accuracyand 44 CrowdmonitoringBehavior EHCAF HighlyaccurateandlowFNR FNRof2.8, Crowdmonitoring 45 IsometricmappingISOMAP Reducedfeaturespace Reductionofcomputationtime Behaviordetection Appl.Sci.2020,10,4781 6of17 Table2.Cont. Ref Process Frameworks/Methods Performance Conclusion/Result Visualdescriptorshaveextractedand Crowdbehavior 46 Spatio-temporalmodel Accuracy98and88 consideredforbothindividual analysisBehavior andinteractivebehaviors Crowdevacuation Correlationscoreswere 47 LegionEvacsoftware Reducedevacuationtime Evacuationbehavior positive Detectionofanomaly OpticalflowandHorn Computationofdistance Anovelapproachofabnormal 48 Normalandabnormal Schunckalgorithm betweencentroids eventdetectionhasproposed TheSTTmethoddemonstrates comparableresultsof Crowdbehaviordetection Spatio-Temporal Crowdanomalydetection 49 Spatio-temporalCompositions Identifybehavior Texturemodel frameworkwasintroduced STCandInferenceby CompositionIBC Approximatemedianfilter Crowdbehavior Arobustunsupervisedabnormal 50 andforeground Lowerfalserate detectionBehavior crowdbehaviordetectionhasachieved segmentationalgorithm Combiningcompressivesensingand Violentbehavior HybridrandommatrixHRM 51 Accuracy90.17and91.61 deeplearningtoidentifyviolentcrowd detection anddeepneuralnetwork behavior Theperformanceofthis Holisticapproachforabnormal 52 Crowdbehaviordetection Holisticapproach methodsyieldsbetterresults crowdbehaviordetectionhasproposed ThecombinationofSIFTandgenetic Crowdbehavior Scale-invariantfeature 1 Accuracy95 algorithmhasachievedbettersimulation detectionRealtime transformSIFT results Crowdbehaviormonitoring Fixed-widthclustering Accuracyisbetween Theapproachhasasuperior 53 Eventdetection algorithmandYOLO 80-95.7 performanceonsixvideos Abnormalbehavior Opticalflowmethod 54 87.4accuracy Higherdetectionrateforanomaly detectionAbnormality andSVM Appl.Sci.2020,10,4781 7of17 4. CrowdRelatedResearchApproaches After going through an important number of papers, it has been determined that the overall workcanbedividedintotwocategories,namelycrowdmanagingandcrowdmonitoringcounting, localizationandbehavior. Hereisabriefdescription 4.1. CrowdManagement Crowdmanagementhasmadeenormousprogressoverthelastfewyears. Withintheliterature, variousmodelshavebeenproposed. Likein37,theauthorshaveproposedaFiniteStateMachine FSMmodeltosimulatethemovementofcrowdduringTawaftomovearoundtheKaabaseven timesaspartofthehajjinMecca. ThemodelcanbeusedtomonitorandmanagecrowdinMataf place of Tawaf in real time. Similarly in 38, the authors have proposed a framework weighted roundrobintoovercomethecongestionandovercrowdedduringhajjpilgrimage. Theframework wasdesignedtobeproactiveinaccuratelypredictingpotentialproblemsthroughtheuseofsmart monitoringofeachpathofritualslocations. Amodelhasplannedtocountthenumberofpeople byusingnon-participatorynon-intrusivetechniquesupportedbystatisticalapproachbyDesign ofExperimentsDOEforcrowdsafetyandmanagement39. In40,aninformationmanagement module and decision support system was used to monitor and manage the crowd. The proposed framework provides an automated approach for detecting and evaluating the video scene and classifyingcrowdsandtrafficmanagement55. 4.2. CrowdMonitoring Crowd monitoring can further be categorized into crowd counting, crowd localization and crowdbehavior. 4.2.1. CrowdCounting Countingmeansspecificallycountthenumberofpeopleinthecrowd. Thecrowdcountinghas beendiscussedbymanyauthorsintheliterature. Khanetal. 43proposesanovelheadcountingand localizationtechnique,DensityIndependentandScaleAwareModelDISAM,thatperformswellfor highdensitycrowedwherehumanheadistheonlyvisiblepartintheimages. CNNisfirstusedas headdetectorandlaterforcomputingresponsematrixfromthescaleawareheadproposalstoobtain theprobabilitiesofheadintheimages. In56,youonlylookonceYOLOisadetectiontechnique whichisbroadlyusedforthedetectionofobjectsinanimagewithhighlevelofperspectivevalues i.e.,maximumthresholdvalue. Xuetal. 57recommendedCNNandlearntoscalethatgenerate multipolarnormalizeddensitymapsforcrowdcounting. Itextractsapatch-leveldensitymapby aprocessofdensityestimationandclustersthenintomultiplelevelsofdensity. Eachpatchdensity map is normalized via an online learning strategy for the center with multi polar loss. In 58 the crowddensityofsurveillancevideosismeasuredusingCNNandshorttermmemory. Twoclassical deepconvolutionalnetworksnamelyGooglenet59andVGGnet5wereusedforestimatingcrowd density 60. Similarly, 4 first approximate crowd size estimation and secondly count the exact numberofpeopleinthecrowd. Theefficiencyremainsunchangedinthetermsofitsaccuracyof90. 4.2.2. CrowdLocalization Localizationofcrowdsincrowdedimagesreceivedlessattentionfromtheresearchcommunity. Withlocalizationinformation,onecanfigureouthowpeoplearedistributedinthearea,whichisvery importantforcrowdmanagers43. Informationaboutlocalizationcanbeusedtodetectandmonitor anindividualindensecrowds 61. Inordertoidentifythelocationofheadinanimagearegression guideddetectionnetworkRDNethasproposedforRGB-Datasetsthatcansimultaneouslyestimate headcountsandlocalizeheadswithboundingboxes62. Similarlyin27,adensitymaphasbeen usedtolocalizetheheadsindenseimagewithaccurateresults. In63,localizationhasbeenidentified Appl.Sci.2020,10,4781 8of17 whileusingLSC-CNNwiththehelpofametricnamedasMeanLocalizationErrorMLE.Thismodel hasachievedaremarkableperformanceintermsofitsaccuracy. CompressedSensingbasedOutput EncodingCSOEhasbeenproposedwhichcanhelptoimprovetheefficiencyoflocalizationinhighly densecrowdedsituation64. 4.2.3. CrowdBehavior Crowdbehavioranalysisanddetectionhavebecomeaprimaryparteverywhereforpeaceful eventorganization65. Thedifficultiesofbehavioridentificationandabnormalbehaviordetecting areveryimportantissuesinvideoprocessing66. Theresearchershaveproposeddifferentmethods andtechniquesforthecrowdbehaviordetection. Someofthecloserelatedworksareelaboratedhere. In66,67,imageprocessingwithopticalflowandmotionhistoryimagetechniqueswereusedtodetect thebehaviorofcrowd. Similarlyin54,anopticalflowmethodwithSupportVectorMachineSVM wasusedforabnormalbehaviordetection. In68,CascadeDeepAutoEncoderCDAandwiththe combinationofmulti-frameopticalflowinformationhavebeenproposedforthedetectionofcrowd behavior. IsometricMappingISOMAP45,spatio-temporal46andspatio-temporaltexture49 modelswereusedtodetecttheanomalouscrowddetection. In51HybridRandomMatrixHRM anddeepneuralnetworkwereusedforthedetectionofviolentbehaviordetection. OneusesSIFT featureextractiontechnique1andFixed-widthclusteringalgorithmwithYOLOwereusedtodetect crowdbehavior53. 5. CNNandDeepCNNFrameworks Deep CNNs are special types of Artificial Neural Networks ANNs that learn hierarchical representationfromthespatialinformationcontainedindigitalimages. Itwasoriginallydesignto processmultidimensional2Dand3Darraysofhighresolutioninputdatasetssuchasimagesand videos6971. ThefirstdeepCNNarchitecturewasAlexNet69havingsevenhiddenlayerswith millionsofparameters. Deepconvolutionalneuralnetworkshaveachievedgreatsuccessonimage classification70,objectdetection71,crowdcounting72andpeoplelocalization73. Thebrief structureofdeepCNNisshowninFigure3. Figure3.StructureofdeepconvolutionalneuralnetworksCNN74. ThesuccessofconvolutionalneuralnetworksCNNanddeepconvolutionalneuralnetworks DCNNinvariouscomputervisiontaskshasinspiredresearcherstoleveragetheirabilitytolearn Appl.Sci.2020,10,4781 9of17 nonlinearfunctionsfromcrowdimagestotheirrespectivedensitymapsorcounts75. Avarietyof CNNsandDCNNshavebeenproposedintheliteraturewhichareusedforcrowdmonitoring. Recent studiesareincludedinTable3whichrepresentsdifferentmethodsandtechniquesusedforcrowd monitoringi.e.,crowdcounting,densityestimationandlocalization.Theselectionofresearchpapersis from2017-2019respectivelyinwhichdeepconvolutionalneuralnetworks,scaledrivenconvolutional networksandsimpleconvolutionalneuralnetworkshavebeenused. Theexperimentalresultswere evaluatedusingdifferentdatasetsnamelyUCSD32,worldexpo1019,UCF-CC-502,Shanghai TechPartA,B35,UCF-QNRF11andsubway-carriage60datasets. Furtherdetailsarepresentedin Table3. Table3.CNNanddeepCNN Methods/ Ref CrowdMonitoring Datasets Researchfocus Accuracy Techniques UCSD,world Peoplecounting SD-CNN Reducedthe 25 Expo10and Countandlocalize andlocalization model classificationtime UCF-CC-50 Crowdcounting UCSDand Detection,estimation Reducedthe 43 DISAM andLocalization Worldexpo10 andlocalization classificationtime ShanghaiTechA,B, Largevariationin 4.2,14.3,27.1and 57 Crowdcounting SPNL2SM UCF-CC-50 densityforcrowd 20.1ratesofMAE andUCF-QNRF counting ShanghaiTechPartA, Decreasedthe Counting,estimation Estimationand ShanghaiTechB, errorrateof 11 Compositionloss ofdensitymap localization UCF-CC-50and compositional andlocalization. UCF-QNRFdatasets loss. Crowdmanaging 60 DeepCNN Subway-carriagescenes Crowddensityestimation 91.73 andmonitoring 6. Discussion This section describes the pairwise comparison of various methods and test datasets. For comparison we have selected some state of the art models which are widely used for crowd monitoring. Table 4 contains the summary of pairwise comparison using MAE and MSE as benchmarkingparameters. TheCNNbasedcrowdcountingandlocalizationalgorithmspresented in8,22,34,35,76arecomparedwithScaleDrivenConvolutionalNeuralNetworkSD-CNNusing UCSD, UCF-CC-50, WorldExpo10 and ShanghaiTech Part A, B datasets. The MAE and MSE of SD-CNN are lesser than those of other models on UCSD, UCF-CC-50 and WorldExpo10 datasets, respectively. Comparingthesemodels,SD-CNNhastheabilitytocountandlocalizethehumanheads inbothlowandhighleveldensitycrowdimages. Similarly,DensityIndependentandScaleAware ModelDISAMhasthelowestMAEascomparedtoothermodelstestedonUCSDandWorldExpo10 datasets. Unlikepreviousmodelswhichcanonlycountthepeopleindensecrowd,DISAMhasthe abilitytohandlebothcountingandlocalizingpeopleinthedensecrowd. Finally,wehavecompared SD-CNNwithDISAMondifferentdatasetsandconcludedthatSD-CNNhaslowerrateofMSEon UCSDdatasetandMAEonWorldExpo10,respectively. Incrowdmonitoringandcountingproblems,researcherstrytoexplorethedomainandhave applieddifferentmachinelearningtechniquesandmethodologiestocountandlocalizethecrowdas wellastheiranomalousbehavior. In4theauthorshavepresentedtheapproximatesizeestimation andcountingtheaccuratenumberofpeopleinthecrowd. Themodelhasachieved90accuracyand ithasbeenshownthattheefficiencyisnotaffectedbyincreasingthenumberofpeople. TheKalman filteringapproachandKL-divergencetechniquehavebeenused77tomonitorandcountthecrowd insmartcity. Similarlytomonitorandestimatecrowddensity,deepconvolutionalnetworkhasbeen usedin60. Therearethreedifferentclassifiersnamelymultiplelinearregressions,backpropagation neuralnetworkandregressiontreeswhichhavebeenappliedandusedin78tomonitorandcount thenumberofpeopleindensecrowd. In79theproposedmodelhasbeendividedintotwofolds Appl.Sci.2020,10,4781 10of17 firstly,toproposedensityestimationofthecrowdandsecondly,tocountthenumberofpeopleusing K-Gaussian Mixture Model GMM. A new model has been proposed namely identifiable crowd monitoringiCrowdusingthreelayersapproachi.e.,devicelayer,middlewarelayerandapplication layer to identify and monitor the crowd 80. A Feature From Accelerated Segment Test FAST algorithmisintroducedin81todetectandestimatethenumberofpeopleinacrowd. Thedeep learning frameworks like CNN and Long Short Term Memory LSTM have been used in 58 for crowd density estimation. In 38 an expert crowd control and management system for hajj has been used with three strategies i.e., to address congestion and overcrowded situation using First In First Out FIFO, priority queuing and Weighted Round Robin WRR. An automatic multiple humandetectionmethodusinghybridadaptiveGaussianmixturemodelwasintroducedin82for humandetection. Theefficiencyofproposedmethodhasfurtherevaluatedandanalyzedbyusing ReceiverOperating/OutputCharacteristicsROC,MeanAbsoluteErrorMAEandMeanRelative Error MRE. The proposed method has shown better results. The crowd can also be monitored andcountedbyusingmobilephonesandadoptingclusteringmethods. Throughthesemethodsthe modelhasachieved92accuracy83. TheairbornecamerasystemswiththetechniquesofSupport VectorMachineSVMandGaborfiltershavealsobeenusedin84forcrowdmonitoringanddensity estimation. Thequalityofresultsclearlydependsupongoodtrainingsamplesandsimilarimages. In40,the authorshavedevelopedadecisionsupportsystemandinformationmanagementmodule fortherealtimecrowddensitymeasurements. Thismodelhasalsobeenimplementedforthecrowd monitoringduringHajj. In44,theauthorshavepresentedaframeworkforcrowdbehaviorusingan EnhancedContext-AwareFrameworkandachievedexperimentalresultswiththeaccuracyof99.1 and2.8ofFalseNegativeRateFNRindicatingasignificantimprovementoverthe92.0accuracy andFNRof31.3oftheBasicContext-AwareFrameworkBCF.Thedetectionofanomalouscrowd behaviorhasbeenmonitoredin45usingIsometricMappingISOMAP.Duringthemonitoringand detectingofcrowdbehaviortheISOMAPhasreducedthecomputationaltimesignificantly.Toquantify thecrowdbehavioranalysisaspatio-temporalmodelhasbeenproposedin46onCUHKandUMN datasets. Theaccuracyachievedforbothdatasetsare98and88,respectively. Asoftwarenamedas legionEvachasbeenusedin47forthebehaviorofcrowdevacuation,duringsimulatinglegionEvac calculatesvariousmetricsthatreflectaholisticpatternofcrowdevacuation,whichcapturethebehavior ofcrowd. In85,authorshavedevelopedaprobabilisticdetectionofcrowdeventsrunning,walking, splitting,merging,localdispersionandevacuationonOpticalFlowManifoldsOFMusingOptical FlowVectorOFVandOpticalFlowBundlesOFB.Dealingwiththeissueofdifferentbehaviors capturedinsurveillancevideofortheuseofnormalandabnormalbehavioraldetection,clustering basedgroupanalysishasbeenusedin48anddescribedcertaingroupbehavior,suchascollectivity, uniformityandconflict. In49,theauthorshaveproposedaSpatialTemporalTextureSTTmodel whichcanautomateandidentifycrowdbehaviorundercomplexreallifesituation. Theanticipated STTmethoddemonstratessimilarresultsofSpatio-TemporalCompositionSTCandInferenceby CompositionIBCandusedlesstimeandasmalleramountofsystemmemoryresources. In50, theauthorshavepresentedanunsupervisedabnormalcrowdbehaviordetectionusingapproximate medianfilterandforegroundsegmentationalgorithms. In51theauthorshaveproposedamodel thatmaydetectandidentifytheviolentbehaviorofcrowdusinghybridrandommatrixanddeep neuralnetwork. In52,theauthorspresentedanovelmethodfordetectingcrowdbehaviorinvideo sequencesusingprobabilitymodelofspeedanddirection. Thismethodcomprisesoftwomainphases building the motion model speed and direction and comparing the model of different frames to detectanomalies. AScaleInvariantFeatureTransformSIFTtechniqueisusedin1fordetection ofcrowdbehaviorinrealtimevideosequences. Similarly, afixedwidthclusteringalgorithmand YOLOhavebeenusedin53todetectthecrowdbehaviorinvideosurveillance. In54theauthors havesuggestedaneffectiveandconcretemethodfordetectingabnormalitiesonthebasisofoptical flowpathofthejointpointsforeachhumanbody. Themethodhasanexpressivelyhigherdetection rateonthepublicdatasetwith87.4accuracy. In41,theauthorshavepresentedauniquemulti Appl.Sci.2020,10,4781 11of17 persontrackingsystemforcrowdcountingandnormal/abnormalindoorandoutdoormonitoring systemusingmedianandKalmanfilters,andhaveobtained95.5accuracyineventdetection. In42 theauthorsproposedasystemforidentificationandlocalizationofanomaliesincrowdedsensein realtime. Theperformancewascalculatedonthebasisofitsaccuracyi.e.,99.6. Similarly,in43 theauthorshaveproposedanovelmodelnamelyDensityIndependentandScaleAwaremodelfor crowdcountingandlocalizationinhighlydensecrowdandevaluatedthemodelonMeanAbsolute ErrorMAE.In25theScaleDrivenConvolutionalNeuralNetworkmodelhasproposedtocount andlocalizethecrowd. Thisstrategyreducedtheclassificationtimesignificantlyandimprovedthe detectionaccuracy. Therearemanycommonproblemsinresearchrelatedtocrowdmonitoringsuch asscalevariation,complexbackground,localization,etc. whichneedtobesolvedbyusingdifferent techniques. Forscalevariation,SD-CNNhasbeenproposedinliteraturewiththeassumptionthat theheadistheonlyvisiblefeatureinthecrowd. Inadensecrowd,theissueofscalevariationhas beenaddressedbygeneratingascaleawareobjectproposal. Similarly, forlargedensityvariation, learningtoscalemodelhasalsobeenproposed. Localizationofobjectsincomplexbackgroundisstill achallengingtask. DISAMcanbeusedthathastheabilitytopreciselylocalizetheheadsincomplex scenes. Localizationperformanceisprimarilyaffectedbychangingthethresholdvalue,sofindingan optimumstrategyforthisissueisanewdirectionofresearch. Table4.Comparisonofsurveyedmethodsandtestdatasets. Ref UCSD UCF-CC-50 WorldExpo10 ShanghaiTechPartA,B UCF-QNRF MAE MSE MAE MSE MAE MAE MSE MAE MSE 34 1.6 3.31 467 498.5 12.9 - - - - 8 1.61 4.4 235.74 345.6 - - - - - 22 1.03 1.37 302.3 411.6 - 49.25 76.25 - - 35 1.07 1.35 377.6 509.1 11.6 68.3 107.25 - - 76 2.89 9.25 - - 26.87 - - - - 25 1.01 1.28 235.74 345.6 7.42 - - - - 34 1.6 3.31 467 498.5 12.9 - - - - 22 1.03 1.37 302.3 411.6 - - - - - 35 1.07 1.35 377.6 509.1 11.6 68.3 107.25 - - 86 1.17 2.15 406.2 404 14.7 - - - - 87 1.62 2.1 318.1 439.2 9.4 60.65 91.75 - - 88 - - 295.8 320.9 8.86 46.85 68.25 - - 20 1.03 - - - 9.23 20.75 29.42 - - 43 1.01 - - - 8.65 - - - - 35 - - 377.6 509.1 - 68.3 107.25 277 - 87 1.62 2.1 318.1 439.2 - 60.65 91.75 252 514 88 - - 295.8 320.9 8.86 46.85 68.25 - - 89 - - 322.8 397.9 - 46.85 71.05 - - 90 1.04 1.35 291 404.6 7.5 46.45 65.05 - - 91 - - 279.6 388.9 - 43.65 66.7 - - 92 - - 288.4 404.7 9.1 46.1 69.15 - - 93 1.16 1.47 266.1 397.5 8.6 39.4 65.5 - - 94 - - 260.9 365.5 10.3 40.25 66.65 - - 95 1.02 1.29 258.4 334.9 8.2 37.7 59.05 - - 11 - - - - - - - 132 191 57 - - 188.4 315.3 - 35.7 54.75 104 173.6 35 - - - - - - - 315 508 2 - - - - - - - 277 426 87 1.62 2.1 318.1 439.2 9.4 60.65 91.75 270 478 89 - - 322.8 397.9 9.23 46.85 71.05 252 514 96 - - - - - - - 228 445 97 - - - - - - - 190 277 98 - - - - - - - 163 226 7. Conclusions Inconclusion,thisreviewpaperprovidesacomprehensiveliteraturereviewoncrowdmonitoring usingdifferentmachinelearningtechniquesandmethods. Existingapproachesoncrowdmonitoring werethoroughlyreviewed. Fromthisreview,weconcludedthatScaleDrivenConvolutionalNeural Appl.Sci.2020,10,4781 12of17 NetworkSD-CNNandDISAMmodelsaretobeconsideredasnovelmodelsforcrowdcounting andlocalizationindensecrowdimageswithhighestaccuracyondifferentdatasets. These models havetheapplicationstodetectthevisibleheadsinanimagewithrespecttoitsscaleanddensitymap. Extensiveexperimentsondifferentdatasetsdemonstratethatthesemodelshaveachievedasignificant improvement over the previous models as explained in the literature review section. The future development of deep CNN on crowd monitoring and localization has different opportunities andchallenges. AuthorContributionsA.K.andJ.A.S.havecollectedandpreparedthedata.A.K.,K.K.andF.K.havecontributed toreviewandanalysis.W.A.hassupervisedtheprocessofthisreview.ThemanuscriptwaswrittenbyA.K.and J.A.S.Allauthorshavereadandagreedtothepublishedversionofthemanuscript. Funding ThisresearchwasfundedbyMinistryofEducationinSaudiArabiathroughprojectnumberQURDO001. Acknowledgments The authors extend their appreciation to the Deputyship for Research and Innovation, MinistryofEducationinSaudiArabiaforfundingthisresearchworkthroughtheprojectnumberQURDO001. ProjecttitleIntelligentReal-TimeCrowdMonitoringSystemUsingUnmannedAerialVehicleUAVVideoand GlobalPositioningSystemsGPSData. ConflictsofInterest Theauthorsdeclarenoconflictofinterest. References 1. Choudhary,S.Ojha,N.Singh,V.Real-timecrowdbehaviordetectionusingSIFTfeatureextractiontechnique invideosequences.InProceedingsoftheInternationalConferenceonIntelligentComputingandControl SystemsICICCS,Madurai,India,1516June2017pp.936940. 2. Idrees,H.Saleemi,I.Seibert,C.Shah,M.Multi-sourcemulti-scalecountinginextremelydensecrowd images.InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,Portland,OR, USA,2328June2013pp.25472554. 3. Chan,A.B.Vasconcelos,N.Countingpeoplewithlow-levelfeaturesandBayesianregression.IEEETrans. ImageProcess.2011,21,21602177CrossRefPubMed 4. Bharti,Y.Saharan,R.Saxena,A.CountingtheNumberofPeopleinCrowdasaPartofAutomaticCrowd Monitoring ACombinedApproach. InInformationandCommunicationTechnologyforIntelligentSystems SpringerBerlin/Heidelberg,Germany, 2019pp.545552. 5. Boominathan, L. Kruthiventi, S.S. Babu, R.V. Crowdnet A deep convolutional network for dense crowdcounting. InProceedingsofthe24thACMInternationalConferenceonMultimedia,Amsterdam, The Netherlands,1216October2016pp.640644. 6. Wang, Y. Zou, Y. Fast visual object countingvia example-based density estimation. InProceedings of theIEEEInternationalConferenceonImageProcessingICIP,Phoenix,AZ,USA,2528September2016 pp.36533657. 7. Chen,K.Loy,C.C.Gong,S.Xiang,T.Featureminingforlocalisedcrowdcounting.InProceedingsofthe BritishMachineVisionConference2012,Surrey,UK,37September2012p.3. 8. Pham,V.-Q.Kozakaya,T.Yamaguchi,O.Okada,R.CountforestCo-votinguncertainnumberoftargets usingrandomforestforcrowddensityestimation.InProceedingsoftheIEEEInternationalConferenceon ComputerVision,Santiago,Chile,18February2016. 9. Zhu,F.Wang,X.Yu,N.Crowdtrackingwithdynamicevolutionofgroupstructures.InProceedingsofthe EuropeanConferenceonComputerVision,Zurich,Switzerland,612September2014pp.139154. 10. Shao, J. Loy, C.C. Wang, X. Scene-independent group profiling in crowd. In Proceedings of the IEEEConferenceonComputerVisionandPatternRecognition, Columbus, OH,USA,2328June2014 pp.22192226. 11. Idrees,H.Tayyab,M.Athrey,K.Zhang,D.Al-Maadeed,S.Rajpoot,N.Compositionlossforcounting, densitymapestimationandlocalizationindensecrowds.InProceedingsoftheEuropeanConferenceon ComputerVisionECCV,Munich,Germany,814September2018pp.532546. 12. Deep,S.Zheng,X.Karmakar,C.Yu,D.Hamey,L.Jin,J.ASurveyonAnomalousBehaviorDetectionfor ElderlyCareusingDense-sensingNetworks.IEEECommun.Surv.Tutor.2020,22,352370.CrossRef Appl.Sci.2020,10,4781 13of17 13. Ito,R.Tsukada,M.Kondo,M.Matsutani,H.AnAdaptiveAbnormalBehaviorDetectionusingOnline SequentialLearning.InProceedingsofthe2019IEEEInternationalConferenceonComputationalScience andEngineeringCSEandIEEEInternationalConferenceonEmbeddedandUbiquitousComputingEUC, NewYork,NY,USA,13August2019pp.436440. 14. Sindagi,V.A.Patel,V.M.Asurveyofrecentadvancesincnn-basedsingleimagecrowdcountinganddensity estimation.PatternRecognit.Lett.2018,107,316.CrossRef 15. Zeng,L.Xu,X.Cai,B.Qiu,S.Zhang,T.Multi-scaleconvolutionalneuralnetworksforcrowdcounting. InProceedingsoftheIEEEInternationalConferenceonImageProcessingICIP,Beijing, China, 1720 September2017pp.465469. 16. Saqib,M.Khan,S.D.Sharma,N.Blumenstein,M.Personheaddetectioninmultiplescalesusingdeep convolutionalneuralnetworks.InProceedingsoftheInternationalJointConferenceonNeuralNetworks IJCNN,RiodeJaneiro,Brazil,813July2018pp.17. 17. Shami,M.B.Maqbool,S.Sajid,H.Ayaz,Y.Cheung,S.-C.S.Peoplecountingindensecrowdimagesusing sparseheaddetections.IEEETrans.CircuitsSyst.VideoTechnol.2018,29,26272636.CrossRef 18. Saleh,S.A.M.Suandi,S.A.Ibrahim,H.Recentsurveyoncrowddensityestimationandcountingforvisual surveillance.Eng.Appl.Artif.Intell.2015,41,103114.CrossRef 19. Zhang,Y.Zhou,C.Chang,F.Kot,A.C.Multi-resolutionattentionconvolutionalneuralnetworkforcrowd counting.Neurocomputing2019,329,144152.CrossRef 20. Liu,J.Gao,C.Meng,D.Hauptmann,A.G.DecidenetCountingvaryingdensitycrowdsthroughattention guideddetectionanddensityestimation.InProceedingsoftheIEEEConferenceonComputerVisionand PatternRecognition,SaltLakeCity,UT,USA,1823June2018. 21. Luo,J.Wang,J.Xu,H.Lu,H.Real-timepeoplecountingforindoorscenes.SignalProcess.2016,124,2735. CrossRef 22. Zhu,L.Li,C.Yang,Z.Yuan,K.Wang,S.Crowddensityestimationbasedonclassificationactivationmap andpatchdensitylevel.NeuralComput.Appl.2019.CrossRef 23. Lempitsky,V.Zisserman,A.Learningtocountobjectsinimages.InProceedingsoftheAdvancesinNeural InformationProcessingSystems,Vancouver,BC,Canada,69December2010pp.13241332. 24. Xu,B.Qiu,G.Crowddensityestimationbasedonrichfeaturesandrandomprojectionforest.InProceedings oftheIEEEWinterConferenceonApplicationsofComputerVisionWACV,LakePlacid,NY,USA,710 March2016pp.18. 25. Basalamah,S.Khan,S.D.Ullah,H.ScaleDrivenConvolutionalNeuralNetworkModelForPeopleCounting andLocalizationinCrowdScenes.IEEEAccess2019,7,7157671584.CrossRef 26. Li,W.Li,H.Wu,Q.Meng,F.Xu,L.Ngan,K.N.HeadnetAnend-to-endadaptiverelationalnetworkfor headdetection.IEEETrans.CircuitsSyst.VideoTechnol.2020,30,482494.CrossRef 27. Rodriguez, M. Laptev, I. Sivic, J. Audibert, J.-Y. Density-aware person detection and tracking in crowds. In Proceedings of the 2011 International Conference on Computer Vision, Barcelona, Spain, 613November2011pp.24232430. 28. Mehran, R. Oyama, A. Shah, M. Abnormal crowd behavior detection using social force model. InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition, Miami, FL,USA, 2025June2009pp.935942. 29. Yuan,Y.Fang,J.Wang,Q.Onlineanomalydetectionincrowdscenesviastructureanalysis.IEEETrans. Cybern.2014,45,548561.CrossRefPubMed 30. Fagette,A.Courty,N.Racoceanu,D.Dufour,J.-Y.Unsuperviseddensecrowddetectionbymultiscale textureanalysis.PatternRecognit.Lett.2014,44,126133.CrossRef 31. Kumar,N. Vaish,A.DominantFlowbasedAttributeGroupingforIndifferentMovementDetectionin Crowd.Int.J.Comput.Appl.2014,88,16.CrossRef 32. Chan,A.B.Liang,Z.-S.J.Vasconcelos,N.PrivacypreservingcrowdmonitoringCountingpeoplewithout people models or tracking. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,Anchorage,AK,USA,2328June2008pp.17. 33. Chen,K.Gong,S.Xiang,T.Loy,C.C.Cumulativeattributespaceforageandcrowddensityestimation. InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,Portland,OR,USA, 2328June2013pp.24672474. Appl.Sci.2020,10,4781 14of17 34. Zhang,C.Li,H.Wang,X.Yang,X.Cross-scenecrowdcountingviadeepconvolutionalneuralnetworks. InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,Boston,MA,USA, 712June2015. 35. Zhang,Y.Zhou,D.Chen,S.Gao,S.Ma,Y. Single-imagecrowdcountingviamulti-columnconvolutional neural network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas,NV,USA,2730June2016. 36. Shao, J. Kang, K. Loy, C.C. Wang, X. Deeply learned attributes for crowded scene understanding. InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,Boston,MA,USA, 712June2015pp.46574666. 37. Mohamed,S.A.E.Parvez,M.T.CrowdModelingBasedAutoActivatedBarriersforManagementofPilgrims inMataf.InProceedingsoftheInternationalConferenceonInnovativeTrendsinComputerEngineering ITCE,Aswan,Egypt,1921Februry2019pp.260265. 38. Nasser,N.Anan,M.Awad,M.F.C.Bin-Abbas,H.Karim,L.Anexpertcrowdmonitoringandmanagement frameworkforHajj. InProceedingsoftheInternationalConferenceonWirelessNetworksandMobile CommunicationsWINCOM,Rabat,Morocco,14November2017pp.18. 39. Fadhlullah,S.Y.Ismail,W.Pathlossmodelforcrowdcounting.InProceedingsofthe7thIEEEInternational ConferenceonControlSystem,ComputingandEngineeringICCSCE,Penang,Malaysia,2426November 2017pp.4548. 40. Khozium,M.O.Abuarafah,A.G.AbdRabou,E.Aproposedcomputer-basedsystemarchitectureforcrowd managementofpilgrimsusingthermography.LifeSci.J.2012,9,377383. 41. Shehzed,A.Jalal,A.Kim,K.Multi-PersonTrackinginSmartSurveillanceSystemforCrowdCounting andNormal/AbnormalEventsDetection.InProceedingsoftheInternationalConferenceonAppliedand EngineeringMathematicsICAEM,Taxila,Pakistan,2729August2019pp.163168. 42. Sabokrou,M.Fathy,M.Hoseini,M.Klette,R.Real-timeanomalydetectionandlocalizationincrowded scenes. InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognitionworkshops, Boston,MA,USA,712June2015pp.5662. 43. Khan,S.D.Ullah,H.Uzair,M.Ullah,M.Ullah,R.Cheikh,F.A.DisamDensityIndependentandScale AwareModelforCrowdCountingandLocalization.InProceedingsoftheIEEEInternationalConferenceon ImageProcessingICIP,Taipei,Taiwan,2225September2019pp.44744478 44. Sadiq,F.I.Selamat,A.Ibrahim,R.Krejcar,O.EnhancedApproachUsingReducedSBTFDFeaturesand ModifiedIndividualBehaviorEstimationforCrowdConditionPrediction.Entropy2019,21,487.CrossRef 45. Rao, A.S. Gubbi, J. Palaniswami, M. Anomalous Crowd Event Analysis Using Isometric Mapping. InAdvancesinSignalProcessingandIntelligentRecognitionSystemsSpringerBerlin/Heidelberg,Germany, 2016pp.407418. 46. Fradi, H. Luvison, B. Pham, Q.C. Crowd behavior analysis using local mid-level visual descriptors. IEEE Trans.CircuitsSyst.VideoTechnol.2016,27,589602.CrossRef 47. Alginahi,Y.M.Mudassar,M.Kabir,M.N.Tayan,O.AnalyzingtheCrowdEvacuationPatternofaLarge DenselyPopulatedBuilding.Arab.J.Sci.Eng.2019,44,32893304.CrossRef 48. Palanisamy, G. Manikandan, T. Group Behaviour Profiling for Detection of Anomaly in Crowd. In Proceedings of the International Conference on Technical Advancements in Computers and CommunicationsICTACC,Melmaurvathur,India,1011April2017pp.1115. 49. Wang,J. Xu,Z.Crowdanomalydetectionforautomatedvideosurveillance. InProceedingsofthe6th InternationalConferenceonImagingforCrimePreventionandDetectionICDP-15,London,UK,1517 July2015. 50. Xu,F.Rao,Y.Wang,Q.Anunsupervisedabnormalcrowdbehaviordetectionalgorithm.InProceedingsof theInternationalConferenceonSecurity,PatternAnalysis,andCyberneticsSPAC,Shenzhen,China,1517 December2017pp.219223. 51. Gao,M.Jiang,J.Ma,L.Zhou,S.Zou,G.Pan,J.Liu,Z.Violentcrowdbehaviordetectionusingdeep learningandcompressivesensing.InProceedingsoftheChineseControlAndDecisionConferenceCCDC, Nanchang,China,35June2019pp.53295333 52. Chibloun,A.Fkihi,S.E.Mliki,H.Hammami,M.Thami,R.O.H.AbnormalCrowdBehaviorDetection UsingSpeedandDirectionModels.InProceedingsofthe9thInternationalSymposiumonSignal,Image, VideoandCommunicationsISIVC,Rabat,Morocco,2730November2018pp.197202. Appl.Sci.2020,10,4781 15of17 53. Yang, M. Rashidi, L. Rao, A.S. Rajasegarar, S. Ganji, M. Palaniswami, M. Leckie, C. Cluster-based CrowdMovementBehaviorDetection. InProceedingsoftheDigitalImageComputing Techniquesand ApplicationsDICTA,Canberra,Australia,1013December2018pp.18. 54. Yimin,D.Fudong,C.Jinping,L.Wei,C.AbnormalBehaviorDetectionBasedonOpticalFlowTrajectoryof HumanJointPoints.InProceedingsoftheChineseControlAndDecisionConferenceCCDC,Nanchang, China,35June2019pp.653658. 55. Shri,S.J.Jothilakshmi,S.VideoAnalysisforCrowdandTrafficManagement.InProceedingsoftheIEEE InternationalConferenceonSystem,Computation,AutomationandNetworkingICSCA,Pondicherry, India,67July2018pp.16. 56. Xu,M.Ge,Z.Jiang,X.Cui,G.Lv,P.Zhou,B.Xu,C.Depthinformationguidedcrowdcountingfor complexcrowdscenes.PatternRecognit.Lett.2019,125,563569.CrossRef 57. Xu,C.Qiu,K.Fu,J.Bai,S.Xu,Y.Bai,X.LearntoScaleGeneratingMultipolarNormalizedDensityMaps forCrowdCounting.InProceedingsoftheIEEEInternationalConferenceonComputerVision,Seoul,Korea, 27October2November2019pp.83828390. 58. Anees,M.V.Kumar,S.G.DeepLearningFrameworkforDensityEstimationofCrowdVideos.InProceedings ofthe8thInternationalSymposiumonEmbeddedComputingandSystemDesignISED,Cochin,India, 1315December2018pp.1620. 59. Shang,C.Ai,H.Bai,B.End-to-endcrowdcountingviajointlearninglocalandglobalcount.InProceedings oftheIEEEInternationalConferenceonImageProcessingICIP,Phoenix,AZ,USA,2528September2016 pp.12151219. 60. Pu, S. Song, T. Zhang, Y. Xie, D. Estimation of crowd density in surveillance scenes based on deep convolutionalneuralnetwork.ProcediaComput.Sci.2017,111,154159.CrossRef 61. Khan,S.D. Bandini,S. Basalamah,S. Vizzari,G.Analyzingcrowdbehaviorinnaturalisticconditions Identifyingsourcesandsinksandcharacterizingmainflows.Neurocomputing2016,177,543563.CrossRef 62. Lian, D. Li, J. Zheng, J. Luo, W. Gao, S.Densitymapregressionguideddetectionnetworkforrgb-d crowdcountingandlocalization.InProceedingsoftheIEEEConferenceonComputerVisionandPattern Recognition,LongBeach,CA,USA,1520June2019pp.18211830. 63. Sam,D.B.Peri,S.V.Kamath,A.Babu,R.V.Locate,SizeandCountAccuratelyResolvingPeopleinDense CrowdsviaDetection.arXiv2019,arXiv1906.07538. 64. Xue,Y.Liu,S.Li,Y.Qian,X.CrowdSceneAnalysisbyOutputEncoding.arXiv2020,arXiv2001.09556. 65. Tripathi,G.Singh,K.Vishwakarma,D.K.ConvolutionalneuralnetworksforcrowdbehaviouranalysisA survey.Vis.Comput.2019,35,753776.CrossRef 66. Rohit, K. Mistree, K. Lavji, J.Areviewonabnormalcrowdbehaviordetection. InProceedingsofthe InternationalConferenceonInnovationsinInformation,EmbeddedandCommunicationSystemsICIIECS, Coimbatore,India,1718March2017pp.13. 67. Lahiri, S. Jyoti, N. Pyati, S. Dewan, J. Abnormal Crowd Behavior Detection Using Image Processing. In Proceedings of the Fourth International Conference on Computing Communication Control and AutomationICCUBEA,Pune,India,1618August2018pp.15. 68. Wang,T.Qiao,M.Zhu,A.Shan,G.Snoussi,H.Abnormaleventdetectionviatheanalysisofmulti-frame opticalflowinformation.Front.Comput.Sci.2020,14,304313.CrossRef 69. Krizhevsky,A.Sutskever,I.Hinton,G.E.Imagenetclassificationwithdeepconvolutionalneuralnetworks. InProceedingsoftheAdvancesinNeuralInformationProcessingSystems, LakeTahoe, ND,USA,36 December2012. 70. Simonyan,K.Zisserman,A.Verydeepconvolutionalnetworksforlarge-scaleimagerecognition. arXiv 2014,arXiv1409.1556. 71. Szegedy,C.Liu,W.Jia,Y.Sermanet,P.Reed,S.Anguelov,D.Erhan,D.Vanhoucke,V.Rabinovich,A. Goingdeeperwithconvolutions.InProceedingsoftheIEEEConferenceonComputerVisionandPattern Recognition,Boston,MA,USA,712June2015. 72. Saqib,M.Khan,S.D.Sharma,N.Blumenstein,M.Crowdcountinginlow-resolutioncrowdedscenesusing region-baseddeepconvolutionalneuralnetworks.IEEEAccess2019,7,3531735329.CrossRef 73. Shaban, M. Mahmood, A. Al-Maadeed, S. Rajpoot, N. An information fusion framework for person localizationviabodyposeinspectatorcrowds.Inf.Fusion2019, 51,178188.CrossRef Appl.Sci.2020,10,4781 16of17 74. Albelwi, S. Mahmood, A. A framework for designing the architectures of deep convolutional neural networks.Entropy2017,19,242.CrossRef 75. Lamba, S. Nain, N.Atexturebasedmani-foldapproachforcrowddensityestimationusingGaussian MarkovRandomField.Multimed.ToolsAppl.2019,78,56455664.CrossRef 76. Ren,S.He,K.Girshick,R.Sun,J.FasterR-CNNTowardsreal-timeobjectdetectionwithregionproposal networks.InProceedingsoftheAdvancesinNeuralInformationProcessingSystems,Montreal,QC,Canada, 712December2015. 77. Kumar,S.Datta,D.Singh,S.K.Sangaiah,A.K.Anintelligentdecisioncomputingparadigmforcrowd monitoringinthesmartcity.J.ParallelDistrib.Comput.2018,118,344358.CrossRef 78. Hu,X.Zheng,H.Chen,Y.Chen,L.Densecrowdcountingbasedonperspectiveweightmodelusinga fisheyecamera.Optik2015,126,123130.CrossRef 79. Karpagavalli,P.Ramprasad,A.Estimatingthedensityofthepeopleandcountingthenumberofpeoplein acrowdenvironmentforhumansafety.InProceedingsoftheInternationalConferenceonCommunication andSignalProcessing,Melmaruvathur,India,35April2013pp.663667. 80. Saeed,S.N.Abid,A.Waraich,E.U.Atta,S.Naseer,A.Sheikh,A.A.Felemban,E.iCrowdAframework formonitoringofidentifiablecrowd.InProceedingsofthe12thInternationalConferenceonInnovationsin InformationTechnologyIIT,AlAin,UAE,2830November2016pp.17 81. Almagbile,A.EstimationofcrowddensityfromUAVsimagesbasedoncornerdetectionproceduresand clusteringanalysis.Geo-Spat.Inf.Sci.2019,22,2334.CrossRef 82. Karpagavalli,P.Ramprasad,A.Anadaptivehybridgmmformultiplehumandetectionincrowdscenario. Multimed.ToolsAppl.2017,76,1412914149.CrossRef 83. Yuan,Y.Crowdmonitoringusingmobilephones.InProceedingsoftheSixthInternationalConferenceon IntelligentHuman-MachineSystemsandCybernetics,Hangzhou,China,2627August2014pp.261264. 84. Meynberg,O.Kuschk,G.Airbornecrowddensityestimation.ISPRSAnn.Photogramm.RemoteSens.Spat. Inf.Sci.2013,4954.CrossRef 85. Rao,A.S.Gubbi,J.Marusic,S.Palaniswami,M.Crowdeventdetectiononopticalflowmanifolds.IEEE Trans.Cybern.2015,46,15241537.CrossRefPubMed 86. Kang, D. Ma, Z. Chan, A.B. Beyond Counting Comparisons of Density Maps for Crowd Analysis TasksCounting,Detection,andTracking. IEEETrans. CircuitsSyst. VideoTechnol. 2018,29,14081422. CrossRef 87. Sam,D.B.Surya,S.Babu,R.V.Switchingconvolutionalneuralnetworkforcrowdcounting.InProceedings oftheIEEEConferenceonComputerVisionandPatternRecognitionCVPR,Honolulu,HI,USA,2126 July2017. 88. Sindagi, V.A. Patel, V.M.Generatinghigh-qualitycrowddensitymapsusingcontextualpyramidcnns. InProceedingsoftheIEEEInternationalConferenceonComputerVision,Venice,Italy,2229October2017. 89. Sindagi,V.A.Patel,V.M.Cnn-basedcascadedmulti-tasklearningofhigh-levelprioranddensityestimation forcrowdcounting. InProceedingsofthe14thIEEEInternationalConferenceonAdvancedVideoand SignalBasedSurveillanceAVSS,Lecce,Italy,29August1September2017. 90. Shen,Z.Xu,Y.Ni,B.Wang,M.Hu,J.Yang,X.Crowdcountingviaadversarialcross-scaleconsistency pursuit.InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,SaltLakeCity, UT,USA,1823June2018. 91. Liu, X. Weijer, J. Bagdanov, A.D. Leveraging unlabeled data for crowd counting by learning to rank. InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,SaltLakeCity,UT, USA,1823June2018. 92. Shi,Z.Zhang,L.Liu,Y.Cao,X.Ye,Y.Cheng,M.M.Zheng,G.Crowdcountingwithdeepnegative correlationlearning.InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition, SaltLakeCity,UT,USA,1823June2018. 93. Li,Y.Zhang,X.Chen,D.Csrnet Dilatedconvolutionalneuralnetworksforunderstandingthehighly congestedscenes. InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition, Salt LakeCity,UT,USA,1823June2018. 94. Ranjan, V. Le, H. Hoai, M. Iterative crowd counting. In Proceedings of the European Conference on ComputerVisionECCV,Munich,Germany,814September2018. Appl.Sci.2020,10,4781 17of17 95. Cao, X. Wang, Z. Zhao, Y. Su, F. Scale aggregation network for accurate and efficient crowd counting. InProceedingsoftheEuropeanConferenceonComputerVisionECCV,Munich,Germany,814September2018. 96. Badrinarayanan,V.Kendall,A.SegNet,R.C.Adeepconvolutionalencoder-decoderarchitectureforimage segmentation.arXiv 2015,arXiv1511.00561. 97. He,K.Zhang,X.Ren,S.Sun,J.Deepresiduallearningforimagerecognition.InProceedingsoftheIEEE ConferenceonComputerVisionandPatternRecognition,LasVegas,NV,USA,2730June2016. 98. Huang,G.Liu,Z.Maaten,L.v.Weinberger,K.Q.Denselyconnectedconvolutionalnetworks.InProceedings oftheIEEEConferenceonComputerVisionandPatternRecognition,Honolulu,HI,USA,2126July2017. cid13c 2020bytheauthors.LicenseeMDPI,Basel,Switzerland.Thisarticleisanopenaccess articledistributedunderthetermsandconditionsoftheCreativeCommonsAttribution CCBYlicensehttp//creativecommons.org/licenses/by/4.0/.",
    "structured_text": {
      "sentences": [
        "applied sciences Review Crowd Monitoring and Localization Using Deep Convolutional Neural Network A Review AkbarKhan 1,JawadAliShah1, ,KushsairyKadir1,WaleedAlbattah2 andFaizullahKhan3 1 ElectronicSection,UniversitiKualaLumpurBritishMalaysianInstitute,Selangor53100, Malaysia akbar.khans.unikl.edu.myA.K.kushsairyunikl.edu.myK.K.",
        "2 DepartmentofInformationTechnology,CollegeofComputer,QassimUniversity, 51921Buraydah,SaudiArabiaw.albattahqu.edu.sa 3 DepartmentofTelecommunicationEngineering,BalochistanUniversityofInformationTechnology, EngineeringandManagementSciences,Quetta87300,Pakistanfaizullah.khanbuitms.edu.pk  Correspondencejawadunikl.edu.my Received18May2020Accepted26June2020Published11July2020 Abstract Crowd management and monitoring is crucial for maintaining public safety and is an important research topic.",
        "Developing a robust crowd monitoring system CMS is a challenging task as it involves addressing many key issues such as density variation, irregular distribution of objects, occlusions, pose estimation, etc.",
        "Crowd gathering at various places like hospitals, parks, stadiums, airports, cultural and religious points are usually monitored by Close Circuit TelevisionCCTVcameras.ThedrawbacksofCCTVcamerasare limitedareacoverage,installation problems, movability, high power consumption and constant monitoring by the operators.",
        "Therefore,manyresearchershaveturnedtowardscomputervisionandmachinelearningthathave overcome these issues by minimizing the need of human involvement.",
        "This review is aimed to categorize,analyzeaswellasprovidethelatestdevelopmentandperformanceevolutionincrowd monitoringusingdifferentmachinelearningtechniquesandmethodsthatarepublishedinjournals andconferencesoverthepastfiveyears.",
        "Keywords crowdmonitoringcrowdcountingcrowddensityestimationdeepconvolutionalneural networksDCNNcrowdbehavior 1.",
        "Introduction Crowdissameordifferentsetofpeoplearrangedinonegroupandmotivatedbycommongoals.",
        "Therearetwotypesofcrowdnamelystructuredcrowdandunstructuredcrowd.Intheformer,thedirection ofthemovementistowardsacommonpointandpeoplearenotinscatteredformwhileinthelatertypethe directionofthepeopleisnottowardsacommonpointandtheyareusuallyinscatteredform1.",
        "Crowdmonitoringhasawiderangeofapplicationssuchas,safetymonitoring,disastermanagement, trafficmonitoringanddesignofpublicspaces.Thisvarietyofapplicationshaveencouragedresearchers throughout numerous fields to develop models for crowd monitoring and associated tasks such as counting 25, density estimation 68, tracking 9, scene understanding 10, localization 11 and behaviordetection12,13.Amongthese,thecrowdcountinganddensityestimationareimportanttasks and represent fundamental building blocks for several other applications 14.",
        "There are three most commonlyusedmethodsforcrowdcountingnamely,objectdetectionbasedcounting1517,clustered basedcounting18andregressionbasedcounting19,20.Inobjectdetectionbasedcountingtheobject detectorsaretrainedtolocalizethepositionofeverypersoninthecrowdforcounting.Clusterbasedcrowd countingconsistsofidentifyingandtrackingvisualfeatures.Featuretrajectoriesthatshowcoherentmotion areclusteredandthenumbersofclusterisregardedasaestimationofmovingobjects21.",
        "Regression Appl.Sci.2020,10,4781doi10.3390/app10144781 www.mdpi.com/journal/applsci Appl.Sci.2020,10,4781 2of17 basedcountingestimatesthecrowdcountbycarryingoutregressionbetweentheimagefeaturesandcrowd size.Thoughtheregressionbasedmethodsareworkinggoodinsituationsofhighdensityastheycapture generalizeddensityinformationfromtheimageofcrowd,stillithastwomainlimitationsi.e.,performance degradationduetooverestimatingofcountinlowdensitysituationsandimproperdistributionofcrowdin thescene22.Onemayconsiderthatconventionalcrowdcountingmethodssuchaspatchbasedapproach, objectbasedapproachandrichfeatureapproach8,23,24,whichdependoneitherdetectionorregression, arelimitedwhenhandlingrealscenewithunavoidabledensityvariations.However,thesemethodscan onlybeusedtoestimateandcountthepeopleinlowdensitysituationsinwhichallpartsofthepeople arefullyvisible.Theperformanceofthesemethodsdeteriorateswhenappliedinhighdensitysituations.",
        "Anidealcountingmethodshouldhavetheadaptiveabilitytochoosetheappropriatecountingmode accordingtocrowddensity20.",
        "Exactcrowdcountingandlocalizationareindispensableforhandling highdensitycrowds.",
        "Localizationmeanstogettheaccuratelocationoftheheadsinanimage.",
        "Head is the only visible part through which localization can be found in highly dense crowd images or videos25.",
        "Althoughnumerousstepshavebeentakeninthedetectionofhumanheads16,17,26, headdetectionisstillachallengingtask.",
        "Asaresultofthevariationinthescaleappearanceofheads, itisstillabigproblemtoexactlydiscriminatehumanheadsfromthebackground.",
        "Forlocalizationin crowdedscene,densitymaphasbeenusedasaregularizerduringthedetection27.",
        "Incomputer vision,crowdbehaviordetectioninvideosurveillanceisoneofthelatestresearchareas1.",
        "Crowd behavior detection has many application domains such as automatic detection of riots or chaotic actsincrowdandlocalizationofabnormalregions28.",
        "Detectionofcrowdbehaviorisextensively usedinordertomonitorandmaintainthesurveillanceofpublicplaceslikesportsevents,markets, religiousandpoliticalgatherings,etc.",
        "Therearetwocategoriesofcrowdbehaviordetectionnamely globalcrowdbehaviordetectionandlocalcrowdbehaviordetection29.",
        "Inglobalcrowdbehavior detection a large area is affected, while in the local crowd behavior detection it affects the limited areaofthecrowdandthebehaviorofanindividualisquitedifferentfromitsneighbor.",
        "Multiscale textureanalysisisusedforassessingthebehaviorofcrowdinvideosequences30.",
        "Theaimofvideo surveillanceisusedtodetectabnormalhumanbehavior31.",
        "1.1.",
        "Rational Reviewingtheliteratureisoneofthemostimportantactivitiesinresearch.Thispaperisthefirstpaper inaseriesofresearchpapersinthefieldofcrowdmonitoring.Accordingtoourplanofcurrentworking onasubstantialcrowdmonitoringprojectfundedbyMinistryofEducationinSaudiArabia,itisavery crucialphasetostudytheliteratureandanalyzeitinordertoaddressdifferentaspectsofthesubjectunder investigations.Anycontributioninanysubjectorfieldcannotbeachievedwithaconsiderableknowledge ofthestateoftheart.Webelievethispaperwillprovideusaswellasinterestedresearcherswithoverview ofexistingstudiesinthefieldofcrowdmonitoringandmanagement.Wealsoexpectthisreviewprovides anovelsynthesisofthecurrentresearchworks,whichwehopecanleadtoanewmeansofconsidering crowdmonitoringaswellasfindinganyavailablegaps.",
        "1.2.",
        "Datasets Variousdatasetscontainingcrowdvideosandimagesarepubliclyavailableandarebeingusedto validatetheexperimentalresults.",
        "Someofthepubliclyavailabledatasetsalongwithitsdescriptionare showninTable1.",
        "UCSDdatasetwasthefirstdatasetusedforpeoplecounting32.",
        "Thedatahasobtainedthrough a camera installed on a pedestrian pathway.",
        "The dataset includes 2000 frames 238  158 of video sequences,alongwithgroundtruthannotationofeachpedestrianineveryfifthframehaving49,885 pedestrianintotal.",
        "TheMalldatasethasbeencollectedbymeansofsurveillancecamerasinstalled inashoppingmall33.",
        "Ithasatotalof2000frameswithsizeof320240.",
        "UCF_CC_50dataset2 isachallengingdatasetcomprisingofawidevarietyofdensitiesandvariousscenes.",
        "Thisdataset has been obtained from different places like concerts, political protests, stadiums and marathons.",
        "Appl.Sci.2020,10,4781 3of17 Theentirenumbersofannotatedimagesare50containing1279individualsperimage.",
        "Thisdataset hasavaryingresolutionandtheindividualsdifferfrom94to4543representingalargevariationinthe image.",
        "Thedrawbackofthistypeofdatasetisthat,thereisonlylimitednumberofimagesavailablefor trainingandevaluation.",
        "WorldExpo10datasetintroducedin34hasbeenusedforcrossscenecrowd counting.",
        "Thedatasetcomprisesof3980framesofsize576720with199,923labeledpedestrians.",
        "Themaximumcrowdcountthroughthisdatasetislimitedto220andisinsufficientforevaluating extremelydensecrowdscounting.",
        "TheShanghaiTechdataset35hasbeenintroducedforlargescale crowdcountingcontainingof1198imageswith330,165annotatedheads.",
        "Intermsofannotatedheads, thisdatasetisoneofthelargest.",
        "Thedatasetcontainstwotypes,namelyPartA,PartB.PartAismade of482imagestakenfromtheinternetrandomly.WhereasPartBcomprisesof716imagescollectedfrom themetropolitanstreetinshanghai.",
        "ThemostrecentdatasetisUCF-QNRF11having1535images.",
        "Withinthisdataset,thenumberofpeoplefluctuatesfrom49to12,865makingamassivevariation indensity.",
        "Furthermore,ithasahugeimageresolutionrangingfrom400300to90006000and consists of crowd videos with varying densities and perspective scales.",
        "CUHK dataset has been collected from diverse locations namely, street, shopping malls, airports and parks.",
        "The dataset comprisesof474videosclipsfrom215scenes36.",
        "Table1.Descriptionofdatasets.",
        "Overall Datasets Description No.ofImages Resolution Min Ave Max Accessibility Count UCSD Peoplecounting 2000 238158 11 25 46 49,885 Yes MALL Peoplecounting 2000 320240 13 - 53 62,325 Yes UCF_CC_50 Densityestimation 50 Variable 94 1279 4543 63,974 Yes Crossscene WorldExpo10 3980 576720 1 50 253 199,923 Yes crowdcounting Variable, ShanghaiTechA,B Crowdcounting 482 33 501 3139 241,677 Yes 7681024 Crowdcounting 400300to UCF-QNRF 716 9 123 578 88,488 Yes andlocalization 90006000 CUHK Crowdbehavior 1535 Variable 49 815 12,865 - Yes This review paper is mainly focusing on the crowd monitoring crowd counting, crowdlocalizationandbehaviordetection.",
        "Therestofthepaperisorganizedasfollows.",
        "Section2 showssearchmethodologyandTaxonomyLevel.",
        "InSection3,crowdmonitoringapproachestaken fromthepreviousliteraturearesummarizedintabularform.",
        "Section4showscrowdrelatedresearch approaches.",
        "Section5showstheconvolutionalneuralnetworkanddeepCNNframeworks.",
        "Section6 representsthediscussionandSection7elaboratesconclusions.",
        "2.",
        "SearchMethodologyandTaxonomyLevel Figure 1 shows the growth of published papers on crowd monitoring Crowd counting, localization and behavior using different machine learning methods and techniques.",
        "The graphs showthetwomaindatabasesofscopusandwebofscienceinwhichtheresearchpapershavebeen publishedfromyear2014to2019.",
        "Wehavesearchedcrowdmonitoringkeywordinbothdatabases andfounddifferentpaperswithdifferentmethodsandtechniques.",
        "Thedetailsofthepaperspublished inbothdatabasesareshowningraphicalviewasshowninFigure1.",
        "TaxonomyLevel Theentiretaxonomylevelofcrowdmonitoringhasbeenshownintheformofflowchart.Basically thecrowdrelatedresearchapproacheshavebeencategorizedintotwodomainsbasedontheliterature review namely crowd management and crowd monitoring.",
        "Then we have made categories of crowd monitoringi.e.,counting,localizationandbehavior.",
        "Focusingoncrowdmonitoring,wejustreviewthe Appl.Sci.2020,10,4781 4of17 crowdmanagementanddidnotcategorizeitfurther.",
        "Afterthat,thecountingsectionhasbeendivided intotwopartsnamelydensityestimationandpeoplecounting.",
        "Inlocalizationtherearethreemainsub categoriesi.e.,countingandlocalization,estimationandlocalizationandanomalydetectionandlocalization.",
        "Finally,thebehaviorcategoryhasbeendividedintothreesubcategoriesi.e.,individualbehaviorestimation, anomalousbehaviordetectionandnormalandabnormalbehaviordetection.Thetaxonomylevelofcrowd monitoringcrowdcounting,localizationandbehaviorhasbeenshowninFigure2.",
        "Web of science Scopus No.of papers 30 27 2019 8 25 19 20 2018 7 20 18 16 14 2017 10 15 12 12 13 10 2016 6 10 7 8 2015 5 5 2014 2 0 2014 2015 2016 2017 2018 2019 0 2 4 6 8 10 12 a Web of science and scopus b Machine learning on crowd monitoring Figure1.aThelistofresearchpaperspublishedinwebofscienceandscopusoncrowdmonitoring from20142019whilebshowsmachinelearningoncrowdmonitoring Crowd Related Research Approaches Crowd Crowd Management Monitoring Counting Localization Behavior Counting Individual E D si e t n m s a it t y io n c P o e u o n p t l i e n g loca a li n z d at ion es b t e im ha a v t i i o o r n Estimation Anomalous and behavior localization detection Anomaly Normal and detection abnormal and behavior Localization detection Figure2.Crowdrelatedresearchapproaches.",
        "3.",
        "CrowdMonitoringCMApproaches Table2showscompletelyaboutalltheresearchpapersaboutcrowdcounting,localizationand behaviordetection.",
        "Differentresearchpaperswithakeywordcrowdmonitoringhavebeensearched whileusingtwomainlyuseddatabasesi.e.,webofscienceandscopusfrom20142019,respectively.",
        "Wehavefounddifferentmethodsandtechniquesrelatedtocrowdmonitoringandtriedtoreview itcompletely.",
        "Furthertheelaborationofthecrowdcounting, localizationandbehaviorhavebeen deliberatelydiscussedintabularformasshowninTable2.",
        "Appl.Sci.2020,10,4781 5of17 Table2.CrowdMonitoringCMapproaches.",
        "Ref Process Frameworks/Methods Performance Conclusion/Result Combinationofcrowdsizeestimationand Classificationwith 4 CrowdmonitoringCounting Accuracy90 counting MSE0.0081 Neuralnetworkandregression BPNNcandeal9 37 CrowdmonitoringCounting BPNNprovidesthebestestimation treesusingfisheyecamera framesinsecond ICrowdframeworkwasdesigned onathree-layerapproach,device 38 CrowdmonitoringEstimation Noexperimentalresults Capableoflocationupdates layer,middlewarelayerandthe applicationlayer Airbornecamerasystems, Dependsongoodtraining Gaborfilterplaysaprominent 39 DensityestimationEstimation supportvectormachineandGaborfilter samplesandsimilarimages roleinrealscenesofimages Real-timecrowddensity Crowdmonitoring Informationmanagement Expertsystemmodule 40 measurementsand Controllingcrowdmovement moduleanddecisionsupportsystem performswell communicationsduringhajj CrowdCounting 41 MedianfilterandKalmanfilter Accuracy95.5 Robustsmartsurveillancesystem Normal/abnormalevent Estimationand 11 DeepCNNnetworks Specificity75.8 Decreaseerrorrate localizationDensitymap Detectionandlocalization Globalandlocaldescriptors, Achievedgoodandcompetingmethods 42 Accuracy99.6 Anomalydetection withtwoclassifierswereproposed withlowcomputationalcomplexity DISAMoutperformsforUCSD CountingandLocalization andWorldExpo10datasetswith 43 CNN Reductionofclassificationtime Humanheads thelowestMAEof1.01and8.65, respectively AveragePrecisionandaverage Reductionofclassificationtimeand 25 Countingandlocalization SD-CNNModel recallrate73.58and71.68 improvementindetectionaccuracy 99.1accuracyand 44 CrowdmonitoringBehavior EHCAF HighlyaccurateandlowFNR FNRof2.8, Crowdmonitoring 45 IsometricmappingISOMAP Reducedfeaturespace Reductionofcomputationtime Behaviordetection Appl.Sci.2020,10,4781 6of17 Table2.Cont.",
        "Ref Process Frameworks/Methods Performance Conclusion/Result Visualdescriptorshaveextractedand Crowdbehavior 46 Spatio-temporalmodel Accuracy98and88 consideredforbothindividual analysisBehavior andinteractivebehaviors Crowdevacuation Correlationscoreswere 47 LegionEvacsoftware Reducedevacuationtime Evacuationbehavior positive Detectionofanomaly OpticalflowandHorn Computationofdistance Anovelapproachofabnormal 48 Normalandabnormal Schunckalgorithm betweencentroids eventdetectionhasproposed TheSTTmethoddemonstrates comparableresultsof Crowdbehaviordetection Spatio-Temporal Crowdanomalydetection 49 Spatio-temporalCompositions Identifybehavior Texturemodel frameworkwasintroduced STCandInferenceby CompositionIBC Approximatemedianfilter Crowdbehavior Arobustunsupervisedabnormal 50 andforeground Lowerfalserate detectionBehavior crowdbehaviordetectionhasachieved segmentationalgorithm Combiningcompressivesensingand Violentbehavior HybridrandommatrixHRM 51 Accuracy90.17and91.61 deeplearningtoidentifyviolentcrowd detection anddeepneuralnetwork behavior Theperformanceofthis Holisticapproachforabnormal 52 Crowdbehaviordetection Holisticapproach methodsyieldsbetterresults crowdbehaviordetectionhasproposed ThecombinationofSIFTandgenetic Crowdbehavior Scale-invariantfeature 1 Accuracy95 algorithmhasachievedbettersimulation detectionRealtime transformSIFT results Crowdbehaviormonitoring Fixed-widthclustering Accuracyisbetween Theapproachhasasuperior 53 Eventdetection algorithmandYOLO 80-95.7 performanceonsixvideos Abnormalbehavior Opticalflowmethod 54 87.4accuracy Higherdetectionrateforanomaly detectionAbnormality andSVM Appl.Sci.2020,10,4781 7of17 4.",
        "CrowdRelatedResearchApproaches After going through an important number of papers, it has been determined that the overall workcanbedividedintotwocategories,namelycrowdmanagingandcrowdmonitoringcounting, localizationandbehavior.",
        "Hereisabriefdescription 4.1.",
        "CrowdManagement Crowdmanagementhasmadeenormousprogressoverthelastfewyears.",
        "Withintheliterature, variousmodelshavebeenproposed.",
        "Likein37,theauthorshaveproposedaFiniteStateMachine FSMmodeltosimulatethemovementofcrowdduringTawaftomovearoundtheKaabaseven timesaspartofthehajjinMecca.",
        "ThemodelcanbeusedtomonitorandmanagecrowdinMataf place of Tawaf in real time.",
        "Similarly in 38, the authors have proposed a framework weighted roundrobintoovercomethecongestionandovercrowdedduringhajjpilgrimage.",
        "Theframework wasdesignedtobeproactiveinaccuratelypredictingpotentialproblemsthroughtheuseofsmart monitoringofeachpathofritualslocations.",
        "Amodelhasplannedtocountthenumberofpeople byusingnon-participatorynon-intrusivetechniquesupportedbystatisticalapproachbyDesign ofExperimentsDOEforcrowdsafetyandmanagement39.",
        "In40,aninformationmanagement module and decision support system was used to monitor and manage the crowd.",
        "The proposed framework provides an automated approach for detecting and evaluating the video scene and classifyingcrowdsandtrafficmanagement55.",
        "4.2.",
        "CrowdMonitoring Crowd monitoring can further be categorized into crowd counting, crowd localization and crowdbehavior.",
        "4.2.1.",
        "CrowdCounting Countingmeansspecificallycountthenumberofpeopleinthecrowd.",
        "Thecrowdcountinghas beendiscussedbymanyauthorsintheliterature.",
        "Khanetal.",
        "43proposesanovelheadcountingand localizationtechnique,DensityIndependentandScaleAwareModelDISAM,thatperformswellfor highdensitycrowedwherehumanheadistheonlyvisiblepartintheimages.",
        "CNNisfirstusedas headdetectorandlaterforcomputingresponsematrixfromthescaleawareheadproposalstoobtain theprobabilitiesofheadintheimages.",
        "In56,youonlylookonceYOLOisadetectiontechnique whichisbroadlyusedforthedetectionofobjectsinanimagewithhighlevelofperspectivevalues i.e.,maximumthresholdvalue.",
        "Xuetal.",
        "57recommendedCNNandlearntoscalethatgenerate multipolarnormalizeddensitymapsforcrowdcounting.",
        "Itextractsapatch-leveldensitymapby aprocessofdensityestimationandclustersthenintomultiplelevelsofdensity.",
        "Eachpatchdensity map is normalized via an online learning strategy for the center with multi polar loss.",
        "In 58 the crowddensityofsurveillancevideosismeasuredusingCNNandshorttermmemory.",
        "Twoclassical deepconvolutionalnetworksnamelyGooglenet59andVGGnet5wereusedforestimatingcrowd density 60.",
        "Similarly, 4 first approximate crowd size estimation and secondly count the exact numberofpeopleinthecrowd.",
        "Theefficiencyremainsunchangedinthetermsofitsaccuracyof90.",
        "4.2.2.",
        "CrowdLocalization Localizationofcrowdsincrowdedimagesreceivedlessattentionfromtheresearchcommunity.",
        "Withlocalizationinformation,onecanfigureouthowpeoplearedistributedinthearea,whichisvery importantforcrowdmanagers43.",
        "Informationaboutlocalizationcanbeusedtodetectandmonitor anindividualindensecrowds 61.",
        "Inordertoidentifythelocationofheadinanimagearegression guideddetectionnetworkRDNethasproposedforRGB-Datasetsthatcansimultaneouslyestimate headcountsandlocalizeheadswithboundingboxes62.",
        "Similarlyin27,adensitymaphasbeen usedtolocalizetheheadsindenseimagewithaccurateresults.",
        "In63,localizationhasbeenidentified Appl.Sci.2020,10,4781 8of17 whileusingLSC-CNNwiththehelpofametricnamedasMeanLocalizationErrorMLE.Thismodel hasachievedaremarkableperformanceintermsofitsaccuracy.",
        "CompressedSensingbasedOutput EncodingCSOEhasbeenproposedwhichcanhelptoimprovetheefficiencyoflocalizationinhighly densecrowdedsituation64.",
        "4.2.3.",
        "CrowdBehavior Crowdbehavioranalysisanddetectionhavebecomeaprimaryparteverywhereforpeaceful eventorganization65.",
        "Thedifficultiesofbehavioridentificationandabnormalbehaviordetecting areveryimportantissuesinvideoprocessing66.",
        "Theresearchershaveproposeddifferentmethods andtechniquesforthecrowdbehaviordetection.",
        "Someofthecloserelatedworksareelaboratedhere.",
        "In66,67,imageprocessingwithopticalflowandmotionhistoryimagetechniqueswereusedtodetect thebehaviorofcrowd.",
        "Similarlyin54,anopticalflowmethodwithSupportVectorMachineSVM wasusedforabnormalbehaviordetection.",
        "In68,CascadeDeepAutoEncoderCDAandwiththe combinationofmulti-frameopticalflowinformationhavebeenproposedforthedetectionofcrowd behavior.",
        "IsometricMappingISOMAP45,spatio-temporal46andspatio-temporaltexture49 modelswereusedtodetecttheanomalouscrowddetection.",
        "In51HybridRandomMatrixHRM anddeepneuralnetworkwereusedforthedetectionofviolentbehaviordetection.",
        "OneusesSIFT featureextractiontechnique1andFixed-widthclusteringalgorithmwithYOLOwereusedtodetect crowdbehavior53.",
        "5.",
        "CNNandDeepCNNFrameworks Deep CNNs are special types of Artificial Neural Networks ANNs that learn hierarchical representationfromthespatialinformationcontainedindigitalimages.",
        "Itwasoriginallydesignto processmultidimensional2Dand3Darraysofhighresolutioninputdatasetssuchasimagesand videos6971.",
        "ThefirstdeepCNNarchitecturewasAlexNet69havingsevenhiddenlayerswith millionsofparameters.",
        "Deepconvolutionalneuralnetworkshaveachievedgreatsuccessonimage classification70,objectdetection71,crowdcounting72andpeoplelocalization73.",
        "Thebrief structureofdeepCNNisshowninFigure3.",
        "Figure3.StructureofdeepconvolutionalneuralnetworksCNN74.",
        "ThesuccessofconvolutionalneuralnetworksCNNanddeepconvolutionalneuralnetworks DCNNinvariouscomputervisiontaskshasinspiredresearcherstoleveragetheirabilitytolearn Appl.Sci.2020,10,4781 9of17 nonlinearfunctionsfromcrowdimagestotheirrespectivedensitymapsorcounts75.",
        "Avarietyof CNNsandDCNNshavebeenproposedintheliteraturewhichareusedforcrowdmonitoring.",
        "Recent studiesareincludedinTable3whichrepresentsdifferentmethodsandtechniquesusedforcrowd monitoringi.e.,crowdcounting,densityestimationandlocalization.Theselectionofresearchpapersis from2017-2019respectivelyinwhichdeepconvolutionalneuralnetworks,scaledrivenconvolutional networksandsimpleconvolutionalneuralnetworkshavebeenused.",
        "Theexperimentalresultswere evaluatedusingdifferentdatasetsnamelyUCSD32,worldexpo1019,UCF-CC-502,Shanghai TechPartA,B35,UCF-QNRF11andsubway-carriage60datasets.",
        "Furtherdetailsarepresentedin Table3.",
        "Table3.CNNanddeepCNN Methods/ Ref CrowdMonitoring Datasets Researchfocus Accuracy Techniques UCSD,world Peoplecounting SD-CNN Reducedthe 25 Expo10and Countandlocalize andlocalization model classificationtime UCF-CC-50 Crowdcounting UCSDand Detection,estimation Reducedthe 43 DISAM andLocalization Worldexpo10 andlocalization classificationtime ShanghaiTechA,B, Largevariationin 4.2,14.3,27.1and 57 Crowdcounting SPNL2SM UCF-CC-50 densityforcrowd 20.1ratesofMAE andUCF-QNRF counting ShanghaiTechPartA, Decreasedthe Counting,estimation Estimationand ShanghaiTechB, errorrateof 11 Compositionloss ofdensitymap localization UCF-CC-50and compositional andlocalization.",
        "UCF-QNRFdatasets loss.",
        "Crowdmanaging 60 DeepCNN Subway-carriagescenes Crowddensityestimation 91.73 andmonitoring 6.",
        "Discussion This section describes the pairwise comparison of various methods and test datasets.",
        "For comparison we have selected some state of the art models which are widely used for crowd monitoring.",
        "Table 4 contains the summary of pairwise comparison using MAE and MSE as benchmarkingparameters.",
        "TheCNNbasedcrowdcountingandlocalizationalgorithmspresented in8,22,34,35,76arecomparedwithScaleDrivenConvolutionalNeuralNetworkSD-CNNusing UCSD, UCF-CC-50, WorldExpo10 and ShanghaiTech Part A, B datasets.",
        "The MAE and MSE of SD-CNN are lesser than those of other models on UCSD, UCF-CC-50 and WorldExpo10 datasets, respectively.",
        "Comparingthesemodels,SD-CNNhastheabilitytocountandlocalizethehumanheads inbothlowandhighleveldensitycrowdimages.",
        "Similarly,DensityIndependentandScaleAware ModelDISAMhasthelowestMAEascomparedtoothermodelstestedonUCSDandWorldExpo10 datasets.",
        "Unlikepreviousmodelswhichcanonlycountthepeopleindensecrowd,DISAMhasthe abilitytohandlebothcountingandlocalizingpeopleinthedensecrowd.",
        "Finally,wehavecompared SD-CNNwithDISAMondifferentdatasetsandconcludedthatSD-CNNhaslowerrateofMSEon UCSDdatasetandMAEonWorldExpo10,respectively.",
        "Incrowdmonitoringandcountingproblems,researcherstrytoexplorethedomainandhave applieddifferentmachinelearningtechniquesandmethodologiestocountandlocalizethecrowdas wellastheiranomalousbehavior.",
        "In4theauthorshavepresentedtheapproximatesizeestimation andcountingtheaccuratenumberofpeopleinthecrowd.",
        "Themodelhasachieved90accuracyand ithasbeenshownthattheefficiencyisnotaffectedbyincreasingthenumberofpeople.",
        "TheKalman filteringapproachandKL-divergencetechniquehavebeenused77tomonitorandcountthecrowd insmartcity.",
        "Similarlytomonitorandestimatecrowddensity,deepconvolutionalnetworkhasbeen usedin60.",
        "Therearethreedifferentclassifiersnamelymultiplelinearregressions,backpropagation neuralnetworkandregressiontreeswhichhavebeenappliedandusedin78tomonitorandcount thenumberofpeopleindensecrowd.",
        "In79theproposedmodelhasbeendividedintotwofolds Appl.Sci.2020,10,4781 10of17 firstly,toproposedensityestimationofthecrowdandsecondly,tocountthenumberofpeopleusing K-Gaussian Mixture Model GMM.",
        "A new model has been proposed namely identifiable crowd monitoringiCrowdusingthreelayersapproachi.e.,devicelayer,middlewarelayerandapplication layer to identify and monitor the crowd 80.",
        "A Feature From Accelerated Segment Test FAST algorithmisintroducedin81todetectandestimatethenumberofpeopleinacrowd.",
        "Thedeep learning frameworks like CNN and Long Short Term Memory LSTM have been used in 58 for crowd density estimation.",
        "In 38 an expert crowd control and management system for hajj has been used with three strategies i.e., to address congestion and overcrowded situation using First In First Out FIFO, priority queuing and Weighted Round Robin WRR.",
        "An automatic multiple humandetectionmethodusinghybridadaptiveGaussianmixturemodelwasintroducedin82for humandetection.",
        "Theefficiencyofproposedmethodhasfurtherevaluatedandanalyzedbyusing ReceiverOperating/OutputCharacteristicsROC,MeanAbsoluteErrorMAEandMeanRelative Error MRE.",
        "The proposed method has shown better results.",
        "The crowd can also be monitored andcountedbyusingmobilephonesandadoptingclusteringmethods.",
        "Throughthesemethodsthe modelhasachieved92accuracy83.",
        "TheairbornecamerasystemswiththetechniquesofSupport VectorMachineSVMandGaborfiltershavealsobeenusedin84forcrowdmonitoringanddensity estimation.",
        "Thequalityofresultsclearlydependsupongoodtrainingsamplesandsimilarimages.",
        "In40,the authorshavedevelopedadecisionsupportsystemandinformationmanagementmodule fortherealtimecrowddensitymeasurements.",
        "Thismodelhasalsobeenimplementedforthecrowd monitoringduringHajj.",
        "In44,theauthorshavepresentedaframeworkforcrowdbehaviorusingan EnhancedContext-AwareFrameworkandachievedexperimentalresultswiththeaccuracyof99.1 and2.8ofFalseNegativeRateFNRindicatingasignificantimprovementoverthe92.0accuracy andFNRof31.3oftheBasicContext-AwareFrameworkBCF.Thedetectionofanomalouscrowd behaviorhasbeenmonitoredin45usingIsometricMappingISOMAP.Duringthemonitoringand detectingofcrowdbehaviortheISOMAPhasreducedthecomputationaltimesignificantly.Toquantify thecrowdbehavioranalysisaspatio-temporalmodelhasbeenproposedin46onCUHKandUMN datasets.",
        "Theaccuracyachievedforbothdatasetsare98and88,respectively.",
        "Asoftwarenamedas legionEvachasbeenusedin47forthebehaviorofcrowdevacuation,duringsimulatinglegionEvac calculatesvariousmetricsthatreflectaholisticpatternofcrowdevacuation,whichcapturethebehavior ofcrowd.",
        "In85,authorshavedevelopedaprobabilisticdetectionofcrowdeventsrunning,walking, splitting,merging,localdispersionandevacuationonOpticalFlowManifoldsOFMusingOptical FlowVectorOFVandOpticalFlowBundlesOFB.Dealingwiththeissueofdifferentbehaviors capturedinsurveillancevideofortheuseofnormalandabnormalbehavioraldetection,clustering basedgroupanalysishasbeenusedin48anddescribedcertaingroupbehavior,suchascollectivity, uniformityandconflict.",
        "In49,theauthorshaveproposedaSpatialTemporalTextureSTTmodel whichcanautomateandidentifycrowdbehaviorundercomplexreallifesituation.",
        "Theanticipated STTmethoddemonstratessimilarresultsofSpatio-TemporalCompositionSTCandInferenceby CompositionIBCandusedlesstimeandasmalleramountofsystemmemoryresources.",
        "In50, theauthorshavepresentedanunsupervisedabnormalcrowdbehaviordetectionusingapproximate medianfilterandforegroundsegmentationalgorithms.",
        "In51theauthorshaveproposedamodel thatmaydetectandidentifytheviolentbehaviorofcrowdusinghybridrandommatrixanddeep neuralnetwork.",
        "In52,theauthorspresentedanovelmethodfordetectingcrowdbehaviorinvideo sequencesusingprobabilitymodelofspeedanddirection.",
        "Thismethodcomprisesoftwomainphases building the motion model speed and direction and comparing the model of different frames to detectanomalies.",
        "AScaleInvariantFeatureTransformSIFTtechniqueisusedin1fordetection ofcrowdbehaviorinrealtimevideosequences.",
        "Similarly, afixedwidthclusteringalgorithmand YOLOhavebeenusedin53todetectthecrowdbehaviorinvideosurveillance.",
        "In54theauthors havesuggestedaneffectiveandconcretemethodfordetectingabnormalitiesonthebasisofoptical flowpathofthejointpointsforeachhumanbody.",
        "Themethodhasanexpressivelyhigherdetection rateonthepublicdatasetwith87.4accuracy.",
        "In41,theauthorshavepresentedauniquemulti Appl.Sci.2020,10,4781 11of17 persontrackingsystemforcrowdcountingandnormal/abnormalindoorandoutdoormonitoring systemusingmedianandKalmanfilters,andhaveobtained95.5accuracyineventdetection.",
        "In42 theauthorsproposedasystemforidentificationandlocalizationofanomaliesincrowdedsensein realtime.",
        "Theperformancewascalculatedonthebasisofitsaccuracyi.e.,99.6.",
        "Similarly,in43 theauthorshaveproposedanovelmodelnamelyDensityIndependentandScaleAwaremodelfor crowdcountingandlocalizationinhighlydensecrowdandevaluatedthemodelonMeanAbsolute ErrorMAE.In25theScaleDrivenConvolutionalNeuralNetworkmodelhasproposedtocount andlocalizethecrowd.",
        "Thisstrategyreducedtheclassificationtimesignificantlyandimprovedthe detectionaccuracy.",
        "Therearemanycommonproblemsinresearchrelatedtocrowdmonitoringsuch asscalevariation,complexbackground,localization,etc.",
        "whichneedtobesolvedbyusingdifferent techniques.",
        "Forscalevariation,SD-CNNhasbeenproposedinliteraturewiththeassumptionthat theheadistheonlyvisiblefeatureinthecrowd.",
        "Inadensecrowd,theissueofscalevariationhas beenaddressedbygeneratingascaleawareobjectproposal.",
        "Similarly, forlargedensityvariation, learningtoscalemodelhasalsobeenproposed.",
        "Localizationofobjectsincomplexbackgroundisstill achallengingtask.",
        "DISAMcanbeusedthathastheabilitytopreciselylocalizetheheadsincomplex scenes.",
        "Localizationperformanceisprimarilyaffectedbychangingthethresholdvalue,sofindingan optimumstrategyforthisissueisanewdirectionofresearch.",
        "Table4.Comparisonofsurveyedmethodsandtestdatasets.",
        "Ref UCSD UCF-CC-50 WorldExpo10 ShanghaiTechPartA,B UCF-QNRF MAE MSE MAE MSE MAE MAE MSE MAE MSE 34 1.6 3.31 467 498.5 12.9 - - - - 8 1.61 4.4 235.74 345.6 - - - - - 22 1.03 1.37 302.3 411.6 - 49.25 76.25 - - 35 1.07 1.35 377.6 509.1 11.6 68.3 107.25 - - 76 2.89 9.25 - - 26.87 - - - - 25 1.01 1.28 235.74 345.6 7.42 - - - - 34 1.6 3.31 467 498.5 12.9 - - - - 22 1.03 1.37 302.3 411.6 - - - - - 35 1.07 1.35 377.6 509.1 11.6 68.3 107.25 - - 86 1.17 2.15 406.2 404 14.7 - - - - 87 1.62 2.1 318.1 439.2 9.4 60.65 91.75 - - 88 - - 295.8 320.9 8.86 46.85 68.25 - - 20 1.03 - - - 9.23 20.75 29.42 - - 43 1.01 - - - 8.65 - - - - 35 - - 377.6 509.1 - 68.3 107.25 277 - 87 1.62 2.1 318.1 439.2 - 60.65 91.75 252 514 88 - - 295.8 320.9 8.86 46.85 68.25 - - 89 - - 322.8 397.9 - 46.85 71.05 - - 90 1.04 1.35 291 404.6 7.5 46.45 65.05 - - 91 - - 279.6 388.9 - 43.65 66.7 - - 92 - - 288.4 404.7 9.1 46.1 69.15 - - 93 1.16 1.47 266.1 397.5 8.6 39.4 65.5 - - 94 - - 260.9 365.5 10.3 40.25 66.65 - - 95 1.02 1.29 258.4 334.9 8.2 37.7 59.05 - - 11 - - - - - - - 132 191 57 - - 188.4 315.3 - 35.7 54.75 104 173.6 35 - - - - - - - 315 508 2 - - - - - - - 277 426 87 1.62 2.1 318.1 439.2 9.4 60.65 91.75 270 478 89 - - 322.8 397.9 9.23 46.85 71.05 252 514 96 - - - - - - - 228 445 97 - - - - - - - 190 277 98 - - - - - - - 163 226 7.",
        "Conclusions Inconclusion,thisreviewpaperprovidesacomprehensiveliteraturereviewoncrowdmonitoring usingdifferentmachinelearningtechniquesandmethods.",
        "Existingapproachesoncrowdmonitoring werethoroughlyreviewed.",
        "Fromthisreview,weconcludedthatScaleDrivenConvolutionalNeural Appl.Sci.2020,10,4781 12of17 NetworkSD-CNNandDISAMmodelsaretobeconsideredasnovelmodelsforcrowdcounting andlocalizationindensecrowdimageswithhighestaccuracyondifferentdatasets.",
        "These models havetheapplicationstodetectthevisibleheadsinanimagewithrespecttoitsscaleanddensitymap.",
        "Extensiveexperimentsondifferentdatasetsdemonstratethatthesemodelshaveachievedasignificant improvement over the previous models as explained in the literature review section.",
        "The future development of deep CNN on crowd monitoring and localization has different opportunities andchallenges.",
        "AuthorContributionsA.K.andJ.A.S.havecollectedandpreparedthedata.A.K.,K.K.andF.K.havecontributed toreviewandanalysis.W.A.hassupervisedtheprocessofthisreview.ThemanuscriptwaswrittenbyA.K.and J.A.S.Allauthorshavereadandagreedtothepublishedversionofthemanuscript.",
        "Funding ThisresearchwasfundedbyMinistryofEducationinSaudiArabiathroughprojectnumberQURDO001.",
        "Acknowledgments The authors extend their appreciation to the Deputyship for Research and Innovation, MinistryofEducationinSaudiArabiaforfundingthisresearchworkthroughtheprojectnumberQURDO001.",
        "ProjecttitleIntelligentReal-TimeCrowdMonitoringSystemUsingUnmannedAerialVehicleUAVVideoand GlobalPositioningSystemsGPSData.",
        "ConflictsofInterest Theauthorsdeclarenoconflictofinterest.",
        "References 1.",
        "Choudhary,S.Ojha,N.Singh,V.Real-timecrowdbehaviordetectionusingSIFTfeatureextractiontechnique invideosequences.InProceedingsoftheInternationalConferenceonIntelligentComputingandControl SystemsICICCS,Madurai,India,1516June2017pp.936940.",
        "2.",
        "Idrees,H.Saleemi,I.Seibert,C.Shah,M.Multi-sourcemulti-scalecountinginextremelydensecrowd images.InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,Portland,OR, USA,2328June2013pp.25472554.",
        "3.",
        "Chan,A.B.Vasconcelos,N.Countingpeoplewithlow-levelfeaturesandBayesianregression.IEEETrans.",
        "ImageProcess.2011,21,21602177CrossRefPubMed 4.",
        "Bharti,Y.Saharan,R.Saxena,A.CountingtheNumberofPeopleinCrowdasaPartofAutomaticCrowd Monitoring ACombinedApproach.",
        "InInformationandCommunicationTechnologyforIntelligentSystems SpringerBerlin/Heidelberg,Germany, 2019pp.545552.",
        "5.",
        "Boominathan, L.",
        "Kruthiventi, S.S.",
        "Babu, R.V.",
        "Crowdnet A deep convolutional network for dense crowdcounting.",
        "InProceedingsofthe24thACMInternationalConferenceonMultimedia,Amsterdam, The Netherlands,1216October2016pp.640644.",
        "6.",
        "Wang, Y.",
        "Zou, Y.",
        "Fast visual object countingvia example-based density estimation.",
        "InProceedings of theIEEEInternationalConferenceonImageProcessingICIP,Phoenix,AZ,USA,2528September2016 pp.36533657.",
        "7.",
        "Chen,K.Loy,C.C.Gong,S.Xiang,T.Featureminingforlocalisedcrowdcounting.InProceedingsofthe BritishMachineVisionConference2012,Surrey,UK,37September2012p.3.",
        "8.",
        "Pham,V.-Q.Kozakaya,T.Yamaguchi,O.Okada,R.CountforestCo-votinguncertainnumberoftargets usingrandomforestforcrowddensityestimation.InProceedingsoftheIEEEInternationalConferenceon ComputerVision,Santiago,Chile,18February2016.",
        "9.",
        "Zhu,F.Wang,X.Yu,N.Crowdtrackingwithdynamicevolutionofgroupstructures.InProceedingsofthe EuropeanConferenceonComputerVision,Zurich,Switzerland,612September2014pp.139154.",
        "10.",
        "Shao, J.",
        "Loy, C.C.",
        "Wang, X.",
        "Scene-independent group profiling in crowd.",
        "In Proceedings of the IEEEConferenceonComputerVisionandPatternRecognition, Columbus, OH,USA,2328June2014 pp.22192226.",
        "11.",
        "Idrees,H.Tayyab,M.Athrey,K.Zhang,D.Al-Maadeed,S.Rajpoot,N.Compositionlossforcounting, densitymapestimationandlocalizationindensecrowds.InProceedingsoftheEuropeanConferenceon ComputerVisionECCV,Munich,Germany,814September2018pp.532546.",
        "12.",
        "Deep,S.Zheng,X.Karmakar,C.Yu,D.Hamey,L.Jin,J.ASurveyonAnomalousBehaviorDetectionfor ElderlyCareusingDense-sensingNetworks.IEEECommun.Surv.Tutor.2020,22,352370.CrossRef Appl.Sci.2020,10,4781 13of17 13.",
        "Ito,R.Tsukada,M.Kondo,M.Matsutani,H.AnAdaptiveAbnormalBehaviorDetectionusingOnline SequentialLearning.InProceedingsofthe2019IEEEInternationalConferenceonComputationalScience andEngineeringCSEandIEEEInternationalConferenceonEmbeddedandUbiquitousComputingEUC, NewYork,NY,USA,13August2019pp.436440.",
        "14.",
        "Sindagi,V.A.Patel,V.M.Asurveyofrecentadvancesincnn-basedsingleimagecrowdcountinganddensity estimation.PatternRecognit.Lett.2018,107,316.CrossRef 15.",
        "Zeng,L.Xu,X.Cai,B.Qiu,S.Zhang,T.Multi-scaleconvolutionalneuralnetworksforcrowdcounting.",
        "InProceedingsoftheIEEEInternationalConferenceonImageProcessingICIP,Beijing, China, 1720 September2017pp.465469.",
        "16.",
        "Saqib,M.Khan,S.D.Sharma,N.Blumenstein,M.Personheaddetectioninmultiplescalesusingdeep convolutionalneuralnetworks.InProceedingsoftheInternationalJointConferenceonNeuralNetworks IJCNN,RiodeJaneiro,Brazil,813July2018pp.17.",
        "17.",
        "Shami,M.B.Maqbool,S.Sajid,H.Ayaz,Y.Cheung,S.-C.S.Peoplecountingindensecrowdimagesusing sparseheaddetections.IEEETrans.CircuitsSyst.VideoTechnol.2018,29,26272636.CrossRef 18.",
        "Saleh,S.A.M.Suandi,S.A.Ibrahim,H.Recentsurveyoncrowddensityestimationandcountingforvisual surveillance.Eng.Appl.Artif.Intell.2015,41,103114.CrossRef 19.",
        "Zhang,Y.Zhou,C.Chang,F.Kot,A.C.Multi-resolutionattentionconvolutionalneuralnetworkforcrowd counting.Neurocomputing2019,329,144152.CrossRef 20.",
        "Liu,J.Gao,C.Meng,D.Hauptmann,A.G.DecidenetCountingvaryingdensitycrowdsthroughattention guideddetectionanddensityestimation.InProceedingsoftheIEEEConferenceonComputerVisionand PatternRecognition,SaltLakeCity,UT,USA,1823June2018.",
        "21.",
        "Luo,J.Wang,J.Xu,H.Lu,H.Real-timepeoplecountingforindoorscenes.SignalProcess.2016,124,2735.",
        "CrossRef 22.",
        "Zhu,L.Li,C.Yang,Z.Yuan,K.Wang,S.Crowddensityestimationbasedonclassificationactivationmap andpatchdensitylevel.NeuralComput.Appl.2019.CrossRef 23.",
        "Lempitsky,V.Zisserman,A.Learningtocountobjectsinimages.InProceedingsoftheAdvancesinNeural InformationProcessingSystems,Vancouver,BC,Canada,69December2010pp.13241332.",
        "24.",
        "Xu,B.Qiu,G.Crowddensityestimationbasedonrichfeaturesandrandomprojectionforest.InProceedings oftheIEEEWinterConferenceonApplicationsofComputerVisionWACV,LakePlacid,NY,USA,710 March2016pp.18.",
        "25.",
        "Basalamah,S.Khan,S.D.Ullah,H.ScaleDrivenConvolutionalNeuralNetworkModelForPeopleCounting andLocalizationinCrowdScenes.IEEEAccess2019,7,7157671584.CrossRef 26.",
        "Li,W.Li,H.Wu,Q.Meng,F.Xu,L.Ngan,K.N.HeadnetAnend-to-endadaptiverelationalnetworkfor headdetection.IEEETrans.CircuitsSyst.VideoTechnol.2020,30,482494.CrossRef 27.",
        "Rodriguez, M.",
        "Laptev, I.",
        "Sivic, J.",
        "Audibert, J.-Y.",
        "Density-aware person detection and tracking in crowds.",
        "In Proceedings of the 2011 International Conference on Computer Vision, Barcelona, Spain, 613November2011pp.24232430.",
        "28.",
        "Mehran, R.",
        "Oyama, A.",
        "Shah, M.",
        "Abnormal crowd behavior detection using social force model.",
        "InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition, Miami, FL,USA, 2025June2009pp.935942.",
        "29.",
        "Yuan,Y.Fang,J.Wang,Q.Onlineanomalydetectionincrowdscenesviastructureanalysis.IEEETrans.",
        "Cybern.2014,45,548561.CrossRefPubMed 30.",
        "Fagette,A.Courty,N.Racoceanu,D.Dufour,J.-Y.Unsuperviseddensecrowddetectionbymultiscale textureanalysis.PatternRecognit.Lett.2014,44,126133.CrossRef 31.",
        "Kumar,N.",
        "Vaish,A.DominantFlowbasedAttributeGroupingforIndifferentMovementDetectionin Crowd.Int.J.Comput.Appl.2014,88,16.CrossRef 32.",
        "Chan,A.B.Liang,Z.-S.J.Vasconcelos,N.PrivacypreservingcrowdmonitoringCountingpeoplewithout people models or tracking.",
        "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,Anchorage,AK,USA,2328June2008pp.17.",
        "33.",
        "Chen,K.Gong,S.Xiang,T.Loy,C.C.Cumulativeattributespaceforageandcrowddensityestimation.",
        "InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,Portland,OR,USA, 2328June2013pp.24672474.",
        "Appl.Sci.2020,10,4781 14of17 34.",
        "Zhang,C.Li,H.Wang,X.Yang,X.Cross-scenecrowdcountingviadeepconvolutionalneuralnetworks.",
        "InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,Boston,MA,USA, 712June2015.",
        "35.",
        "Zhang,Y.Zhou,D.Chen,S.Gao,S.Ma,Y.",
        "Single-imagecrowdcountingviamulti-columnconvolutional neural network.",
        "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas,NV,USA,2730June2016.",
        "36.",
        "Shao, J.",
        "Kang, K.",
        "Loy, C.C.",
        "Wang, X.",
        "Deeply learned attributes for crowded scene understanding.",
        "InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,Boston,MA,USA, 712June2015pp.46574666.",
        "37.",
        "Mohamed,S.A.E.Parvez,M.T.CrowdModelingBasedAutoActivatedBarriersforManagementofPilgrims inMataf.InProceedingsoftheInternationalConferenceonInnovativeTrendsinComputerEngineering ITCE,Aswan,Egypt,1921Februry2019pp.260265.",
        "38.",
        "Nasser,N.Anan,M.Awad,M.F.C.Bin-Abbas,H.Karim,L.Anexpertcrowdmonitoringandmanagement frameworkforHajj.",
        "InProceedingsoftheInternationalConferenceonWirelessNetworksandMobile CommunicationsWINCOM,Rabat,Morocco,14November2017pp.18.",
        "39.",
        "Fadhlullah,S.Y.Ismail,W.Pathlossmodelforcrowdcounting.InProceedingsofthe7thIEEEInternational ConferenceonControlSystem,ComputingandEngineeringICCSCE,Penang,Malaysia,2426November 2017pp.4548.",
        "40.",
        "Khozium,M.O.Abuarafah,A.G.AbdRabou,E.Aproposedcomputer-basedsystemarchitectureforcrowd managementofpilgrimsusingthermography.LifeSci.J.2012,9,377383.",
        "41.",
        "Shehzed,A.Jalal,A.Kim,K.Multi-PersonTrackinginSmartSurveillanceSystemforCrowdCounting andNormal/AbnormalEventsDetection.InProceedingsoftheInternationalConferenceonAppliedand EngineeringMathematicsICAEM,Taxila,Pakistan,2729August2019pp.163168.",
        "42.",
        "Sabokrou,M.Fathy,M.Hoseini,M.Klette,R.Real-timeanomalydetectionandlocalizationincrowded scenes.",
        "InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognitionworkshops, Boston,MA,USA,712June2015pp.5662.",
        "43.",
        "Khan,S.D.Ullah,H.Uzair,M.Ullah,M.Ullah,R.Cheikh,F.A.DisamDensityIndependentandScale AwareModelforCrowdCountingandLocalization.InProceedingsoftheIEEEInternationalConferenceon ImageProcessingICIP,Taipei,Taiwan,2225September2019pp.44744478 44.",
        "Sadiq,F.I.Selamat,A.Ibrahim,R.Krejcar,O.EnhancedApproachUsingReducedSBTFDFeaturesand ModifiedIndividualBehaviorEstimationforCrowdConditionPrediction.Entropy2019,21,487.CrossRef 45.",
        "Rao, A.S.",
        "Gubbi, J.",
        "Palaniswami, M.",
        "Anomalous Crowd Event Analysis Using Isometric Mapping.",
        "InAdvancesinSignalProcessingandIntelligentRecognitionSystemsSpringerBerlin/Heidelberg,Germany, 2016pp.407418.",
        "46.",
        "Fradi, H.",
        "Luvison, B.",
        "Pham, Q.C.",
        "Crowd behavior analysis using local mid-level visual descriptors.",
        "IEEE Trans.CircuitsSyst.VideoTechnol.2016,27,589602.CrossRef 47.",
        "Alginahi,Y.M.Mudassar,M.Kabir,M.N.Tayan,O.AnalyzingtheCrowdEvacuationPatternofaLarge DenselyPopulatedBuilding.Arab.J.Sci.Eng.2019,44,32893304.CrossRef 48.",
        "Palanisamy, G.",
        "Manikandan, T.",
        "Group Behaviour Profiling for Detection of Anomaly in Crowd.",
        "In Proceedings of the International Conference on Technical Advancements in Computers and CommunicationsICTACC,Melmaurvathur,India,1011April2017pp.1115.",
        "49.",
        "Wang,J.",
        "Xu,Z.Crowdanomalydetectionforautomatedvideosurveillance.",
        "InProceedingsofthe6th InternationalConferenceonImagingforCrimePreventionandDetectionICDP-15,London,UK,1517 July2015.",
        "50.",
        "Xu,F.Rao,Y.Wang,Q.Anunsupervisedabnormalcrowdbehaviordetectionalgorithm.InProceedingsof theInternationalConferenceonSecurity,PatternAnalysis,andCyberneticsSPAC,Shenzhen,China,1517 December2017pp.219223.",
        "51.",
        "Gao,M.Jiang,J.Ma,L.Zhou,S.Zou,G.Pan,J.Liu,Z.Violentcrowdbehaviordetectionusingdeep learningandcompressivesensing.InProceedingsoftheChineseControlAndDecisionConferenceCCDC, Nanchang,China,35June2019pp.53295333 52.",
        "Chibloun,A.Fkihi,S.E.Mliki,H.Hammami,M.Thami,R.O.H.AbnormalCrowdBehaviorDetection UsingSpeedandDirectionModels.InProceedingsofthe9thInternationalSymposiumonSignal,Image, VideoandCommunicationsISIVC,Rabat,Morocco,2730November2018pp.197202.",
        "Appl.Sci.2020,10,4781 15of17 53.",
        "Yang, M.",
        "Rashidi, L.",
        "Rao, A.S.",
        "Rajasegarar, S.",
        "Ganji, M.",
        "Palaniswami, M.",
        "Leckie, C.",
        "Cluster-based CrowdMovementBehaviorDetection.",
        "InProceedingsoftheDigitalImageComputing Techniquesand ApplicationsDICTA,Canberra,Australia,1013December2018pp.18.",
        "54.",
        "Yimin,D.Fudong,C.Jinping,L.Wei,C.AbnormalBehaviorDetectionBasedonOpticalFlowTrajectoryof HumanJointPoints.InProceedingsoftheChineseControlAndDecisionConferenceCCDC,Nanchang, China,35June2019pp.653658.",
        "55.",
        "Shri,S.J.Jothilakshmi,S.VideoAnalysisforCrowdandTrafficManagement.InProceedingsoftheIEEE InternationalConferenceonSystem,Computation,AutomationandNetworkingICSCA,Pondicherry, India,67July2018pp.16.",
        "56.",
        "Xu,M.Ge,Z.Jiang,X.Cui,G.Lv,P.Zhou,B.Xu,C.Depthinformationguidedcrowdcountingfor complexcrowdscenes.PatternRecognit.Lett.2019,125,563569.CrossRef 57.",
        "Xu,C.Qiu,K.Fu,J.Bai,S.Xu,Y.Bai,X.LearntoScaleGeneratingMultipolarNormalizedDensityMaps forCrowdCounting.InProceedingsoftheIEEEInternationalConferenceonComputerVision,Seoul,Korea, 27October2November2019pp.83828390.",
        "58.",
        "Anees,M.V.Kumar,S.G.DeepLearningFrameworkforDensityEstimationofCrowdVideos.InProceedings ofthe8thInternationalSymposiumonEmbeddedComputingandSystemDesignISED,Cochin,India, 1315December2018pp.1620.",
        "59.",
        "Shang,C.Ai,H.Bai,B.End-to-endcrowdcountingviajointlearninglocalandglobalcount.InProceedings oftheIEEEInternationalConferenceonImageProcessingICIP,Phoenix,AZ,USA,2528September2016 pp.12151219.",
        "60.",
        "Pu, S.",
        "Song, T.",
        "Zhang, Y.",
        "Xie, D.",
        "Estimation of crowd density in surveillance scenes based on deep convolutionalneuralnetwork.ProcediaComput.Sci.2017,111,154159.CrossRef 61.",
        "Khan,S.D.",
        "Bandini,S.",
        "Basalamah,S.",
        "Vizzari,G.Analyzingcrowdbehaviorinnaturalisticconditions Identifyingsourcesandsinksandcharacterizingmainflows.Neurocomputing2016,177,543563.CrossRef 62.",
        "Lian, D.",
        "Li, J.",
        "Zheng, J.",
        "Luo, W.",
        "Gao, S.Densitymapregressionguideddetectionnetworkforrgb-d crowdcountingandlocalization.InProceedingsoftheIEEEConferenceonComputerVisionandPattern Recognition,LongBeach,CA,USA,1520June2019pp.18211830.",
        "63.",
        "Sam,D.B.Peri,S.V.Kamath,A.Babu,R.V.Locate,SizeandCountAccuratelyResolvingPeopleinDense CrowdsviaDetection.arXiv2019,arXiv1906.07538.",
        "64.",
        "Xue,Y.Liu,S.Li,Y.Qian,X.CrowdSceneAnalysisbyOutputEncoding.arXiv2020,arXiv2001.09556.",
        "65.",
        "Tripathi,G.Singh,K.Vishwakarma,D.K.ConvolutionalneuralnetworksforcrowdbehaviouranalysisA survey.Vis.Comput.2019,35,753776.CrossRef 66.",
        "Rohit, K.",
        "Mistree, K.",
        "Lavji, J.Areviewonabnormalcrowdbehaviordetection.",
        "InProceedingsofthe InternationalConferenceonInnovationsinInformation,EmbeddedandCommunicationSystemsICIIECS, Coimbatore,India,1718March2017pp.13.",
        "67.",
        "Lahiri, S.",
        "Jyoti, N.",
        "Pyati, S.",
        "Dewan, J.",
        "Abnormal Crowd Behavior Detection Using Image Processing.",
        "In Proceedings of the Fourth International Conference on Computing Communication Control and AutomationICCUBEA,Pune,India,1618August2018pp.15.",
        "68.",
        "Wang,T.Qiao,M.Zhu,A.Shan,G.Snoussi,H.Abnormaleventdetectionviatheanalysisofmulti-frame opticalflowinformation.Front.Comput.Sci.2020,14,304313.CrossRef 69.",
        "Krizhevsky,A.Sutskever,I.Hinton,G.E.Imagenetclassificationwithdeepconvolutionalneuralnetworks.",
        "InProceedingsoftheAdvancesinNeuralInformationProcessingSystems, LakeTahoe, ND,USA,36 December2012.",
        "70.",
        "Simonyan,K.Zisserman,A.Verydeepconvolutionalnetworksforlarge-scaleimagerecognition.",
        "arXiv 2014,arXiv1409.1556.",
        "71.",
        "Szegedy,C.Liu,W.Jia,Y.Sermanet,P.Reed,S.Anguelov,D.Erhan,D.Vanhoucke,V.Rabinovich,A.",
        "Goingdeeperwithconvolutions.InProceedingsoftheIEEEConferenceonComputerVisionandPattern Recognition,Boston,MA,USA,712June2015.",
        "72.",
        "Saqib,M.Khan,S.D.Sharma,N.Blumenstein,M.Crowdcountinginlow-resolutioncrowdedscenesusing region-baseddeepconvolutionalneuralnetworks.IEEEAccess2019,7,3531735329.CrossRef 73.",
        "Shaban, M.",
        "Mahmood, A.",
        "Al-Maadeed, S.",
        "Rajpoot, N.",
        "An information fusion framework for person localizationviabodyposeinspectatorcrowds.Inf.Fusion2019, 51,178188.CrossRef Appl.Sci.2020,10,4781 16of17 74.",
        "Albelwi, S.",
        "Mahmood, A.",
        "A framework for designing the architectures of deep convolutional neural networks.Entropy2017,19,242.CrossRef 75.",
        "Lamba, S.",
        "Nain, N.Atexturebasedmani-foldapproachforcrowddensityestimationusingGaussian MarkovRandomField.Multimed.ToolsAppl.2019,78,56455664.CrossRef 76.",
        "Ren,S.He,K.Girshick,R.Sun,J.FasterR-CNNTowardsreal-timeobjectdetectionwithregionproposal networks.InProceedingsoftheAdvancesinNeuralInformationProcessingSystems,Montreal,QC,Canada, 712December2015.",
        "77.",
        "Kumar,S.Datta,D.Singh,S.K.Sangaiah,A.K.Anintelligentdecisioncomputingparadigmforcrowd monitoringinthesmartcity.J.ParallelDistrib.Comput.2018,118,344358.CrossRef 78.",
        "Hu,X.Zheng,H.Chen,Y.Chen,L.Densecrowdcountingbasedonperspectiveweightmodelusinga fisheyecamera.Optik2015,126,123130.CrossRef 79.",
        "Karpagavalli,P.Ramprasad,A.Estimatingthedensityofthepeopleandcountingthenumberofpeoplein acrowdenvironmentforhumansafety.InProceedingsoftheInternationalConferenceonCommunication andSignalProcessing,Melmaruvathur,India,35April2013pp.663667.",
        "80.",
        "Saeed,S.N.Abid,A.Waraich,E.U.Atta,S.Naseer,A.Sheikh,A.A.Felemban,E.iCrowdAframework formonitoringofidentifiablecrowd.InProceedingsofthe12thInternationalConferenceonInnovationsin InformationTechnologyIIT,AlAin,UAE,2830November2016pp.17 81.",
        "Almagbile,A.EstimationofcrowddensityfromUAVsimagesbasedoncornerdetectionproceduresand clusteringanalysis.Geo-Spat.Inf.Sci.2019,22,2334.CrossRef 82.",
        "Karpagavalli,P.Ramprasad,A.Anadaptivehybridgmmformultiplehumandetectionincrowdscenario.",
        "Multimed.ToolsAppl.2017,76,1412914149.CrossRef 83.",
        "Yuan,Y.Crowdmonitoringusingmobilephones.InProceedingsoftheSixthInternationalConferenceon IntelligentHuman-MachineSystemsandCybernetics,Hangzhou,China,2627August2014pp.261264.",
        "84.",
        "Meynberg,O.Kuschk,G.Airbornecrowddensityestimation.ISPRSAnn.Photogramm.RemoteSens.Spat.",
        "Inf.Sci.2013,4954.CrossRef 85.",
        "Rao,A.S.Gubbi,J.Marusic,S.Palaniswami,M.Crowdeventdetectiononopticalflowmanifolds.IEEE Trans.Cybern.2015,46,15241537.CrossRefPubMed 86.",
        "Kang, D.",
        "Ma, Z.",
        "Chan, A.B.",
        "Beyond Counting Comparisons of Density Maps for Crowd Analysis TasksCounting,Detection,andTracking.",
        "IEEETrans.",
        "CircuitsSyst.",
        "VideoTechnol.",
        "2018,29,14081422.",
        "CrossRef 87.",
        "Sam,D.B.Surya,S.Babu,R.V.Switchingconvolutionalneuralnetworkforcrowdcounting.InProceedings oftheIEEEConferenceonComputerVisionandPatternRecognitionCVPR,Honolulu,HI,USA,2126 July2017.",
        "88.",
        "Sindagi, V.A.",
        "Patel, V.M.Generatinghigh-qualitycrowddensitymapsusingcontextualpyramidcnns.",
        "InProceedingsoftheIEEEInternationalConferenceonComputerVision,Venice,Italy,2229October2017.",
        "89.",
        "Sindagi,V.A.Patel,V.M.Cnn-basedcascadedmulti-tasklearningofhigh-levelprioranddensityestimation forcrowdcounting.",
        "InProceedingsofthe14thIEEEInternationalConferenceonAdvancedVideoand SignalBasedSurveillanceAVSS,Lecce,Italy,29August1September2017.",
        "90.",
        "Shen,Z.Xu,Y.Ni,B.Wang,M.Hu,J.Yang,X.Crowdcountingviaadversarialcross-scaleconsistency pursuit.InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,SaltLakeCity, UT,USA,1823June2018.",
        "91.",
        "Liu, X.",
        "Weijer, J.",
        "Bagdanov, A.D.",
        "Leveraging unlabeled data for crowd counting by learning to rank.",
        "InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,SaltLakeCity,UT, USA,1823June2018.",
        "92.",
        "Shi,Z.Zhang,L.Liu,Y.Cao,X.Ye,Y.Cheng,M.M.Zheng,G.Crowdcountingwithdeepnegative correlationlearning.InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition, SaltLakeCity,UT,USA,1823June2018.",
        "93.",
        "Li,Y.Zhang,X.Chen,D.Csrnet Dilatedconvolutionalneuralnetworksforunderstandingthehighly congestedscenes.",
        "InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition, Salt LakeCity,UT,USA,1823June2018.",
        "94.",
        "Ranjan, V.",
        "Le, H.",
        "Hoai, M.",
        "Iterative crowd counting.",
        "In Proceedings of the European Conference on ComputerVisionECCV,Munich,Germany,814September2018.",
        "Appl.Sci.2020,10,4781 17of17 95.",
        "Cao, X.",
        "Wang, Z.",
        "Zhao, Y.",
        "Su, F.",
        "Scale aggregation network for accurate and efficient crowd counting.",
        "InProceedingsoftheEuropeanConferenceonComputerVisionECCV,Munich,Germany,814September2018.",
        "96.",
        "Badrinarayanan,V.Kendall,A.SegNet,R.C.Adeepconvolutionalencoder-decoderarchitectureforimage segmentation.arXiv 2015,arXiv1511.00561.",
        "97.",
        "He,K.Zhang,X.Ren,S.Sun,J.Deepresiduallearningforimagerecognition.InProceedingsoftheIEEE ConferenceonComputerVisionandPatternRecognition,LasVegas,NV,USA,2730June2016.",
        "98.",
        "Huang,G.Liu,Z.Maaten,L.v.Weinberger,K.Q.Denselyconnectedconvolutionalnetworks.InProceedings oftheIEEEConferenceonComputerVisionandPatternRecognition,Honolulu,HI,USA,2126July2017.",
        "cid13c 2020bytheauthors.LicenseeMDPI,Basel,Switzerland.Thisarticleisanopenaccess articledistributedunderthetermsandconditionsoftheCreativeCommonsAttribution CCBYlicensehttp//creativecommons.org/licenses/by/4.0/."
      ],
      "word_count": 2656,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          ""
        ],
        "data": [
          [
            ""
          ],
          [
            ""
          ]
        ]
      },
      {
        "columns": [
          "web_of_science_scopus\n30_27\n25\n20\n19\n20_18\n16\n14\n15_12_12_13\n10\n10_7_8",
          "no.of_papers\n2019_8\n2018_7\n2017_10\n2016_6"
        ],
        "data": [
          [
            "5\n0\n2014 2015 2016 2017 2018 2019",
            "2015 5\n2014 2\n0 2 4 6 8 10 12"
          ]
        ]
      },
      {
        "columns": [
          "8\n7\n10\n6"
        ],
        "data": [
          [
            "5\n2"
          ]
        ]
      },
      {
        "columns": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        "data": [
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ]
        ]
      }
    ],
    "metadata": {
      "CreationDate": "D:20200712175102+08'00'",
      "ModDate": "D:20200712175102+08'00'",
      "Producer": "iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "Hindawi Mathematical Problems in Engineering Volume 2021, Article ID 9975700, 9 pages https//doi.org/10.1155/2021/9975700 Research Article Weapon Detection Using YOLO V3 for Smart Surveillance System Sanam Narejo ,1 Bishwajeet Pandey ,2 Doris Esenarro vargas ,3 Ciro Rodriguez ,4 and M. Rizwan Anjum 5 1DepartmentofComputerSystemsEngineering,MehranUniversityofEngineeringandTechnologyMUET,Jamshoro,Pakistan 2GranSassoScience Institute,LAquila,Italy 3UniversidadNacional FedericoVillarreal,Lima,Peru 4UniversidadNacional MayordeSanMarcos,Lima,Peru 5Departmentof ElectronicEngineering,TheIslamiaUniversityofBahawalpur,Bahawalpur 63100,Pakistan CorrespondenceshouldbeaddressedtoBishwajeetPandeydr.pandeyieee.org Received 4 March 2021 Revised 15 April 2021 Accepted 3 May 2021 Published 12 May 2021 AcademicEditorZainAnwarAli Copyright2021SanamNarejoetal.ThisisanopenaccessarticledistributedundertheCreativeCommonsAttributionLicense, whichpermitsunrestricteduse,distribution,andreproductioninanymedium,providedtheoriginalworkisproperlycited. Everyyear,alargeamountofpopulationreconcilesgun-relatedviolenceallovertheworld.Inthiswork,wedevelopacomputer- based fully automated system to identify basic armaments, particularly handguns and rifles. Recent work in the field of deep learningandtransferlearninghasdemonstratedsignificantprogressintheareasofobjectdetectionandrecognition.Wehave implementedYOLOV3YouOnlyLookOnceobjectdetectionmodelbytrainingitonourcustomizeddataset.Thetraining results confirm that YOLO V3 outperforms YOLO V2 and traditional convolutional neural network CNN. Additionally, intensiveGPUsorhighcomputationresourceswerenotrequiredinourapproachasweusedtransferlearningfortrainingour model.Applyingthismodelinoursurveillancesystem,wecanattempttosavehumanlifeandaccomplishreductionintherateof manslaughterormasskilling.Additionally,ourproposedsystemcanalsobeimplementedinhigh-endsurveillanceandsecurity robots todetecta weaponorunsafe assets toavoidany kindofassaultorriskto human life. 1.Introduction According to statistics, 4.2 in 100000 people are killed in Pakistaneveryyearinmassshootings.Fromstreetcrimesto Violence committed with guns puts significant impact on an individual institution attack, many precious lives suf- public, health, psychological, and economic cost. Many fered.Thisfurtherindicatesthatmanualsurveillancesystem people die each year from gun-related violence. Psycho- stillneedshumaneyetodetecttheabnormalactivitiesandit logicaltraumaisfrequentamongchildrenwhoareexposed takes a sufficient amount of time reporting to security of- to high levels of violence in their communities or through ficials to tackle the situation. the media. Children exposed to gun-related violence, Although the human visual framework is quick and whether they are victims, perpetrators, or witnesses, can preciseandcanlikewiseperformcomplexundertakingslike experiencenegativepsychologicaleffectsovertheshortand distinguishing different items and recognizing snags with longterms.Numberofstudiesshowthathandheldgunisthe minimalcognizantidea,however,itiscommontruththatif primary weapon used for various crimes like break-in, anindividualwatchessomethingverysimilarforquitealong robbery,shoplifting,andrape.Thesecrimescanbereduced time, there is an opportunity of sluggishness and lack of by identifying the disruptive behavior at early stage and regard. monitoring the suspicious activities carefully so that law Nowadays, with the accessibility of huge datasets, enforcementagenciescanfurthertakeimmediateaction1. quicker GPUs, advanced machine learning algorithms, and Levels of gun-related violence vary greatly among geo- bettercalculations,wecannoweffectivelypreparePCsand graphicallocationsandcountries.Theglobaldeathtollfrom develop automated computer-based system to distinguish use of guns may be as high as 1,000 dead each day 2. and identify numerous items on a site with high accuracy. 2 MathematicalProblemsinEngineering Recent developments indicate that machine learning 36 makinglikeabnormaleventdetectionoranyanomaly.The and advance image processing algorithms have played latestanomalydetectiontechniquescanbedividedintotwo dominant role in smart surveillances and security systems groups,whichareobject-centeredtechniquesandintegrated 7, 8. Apart from this, popularity of smart devices and methods.TheconvolutionalneuralnetworkCNNspatial- networked cameras has also empowered this domain. temporalsystemisonlyappliedtospatial-temporalvolumes However,humanobjectsorweapondetectionandtracking of interest SVOI, reducing the cost of processing. In are still conducted at cloud centers, as real-time, online surveillance videos of complex scenes, researchers in 14 tracking is computationally costly. Significant efforts have proposed a tool for detecting and finding anomalous ac- been made in recent years to monitor robot manipulators tivities. By conducting spatial-temporal convolution layer, thatneedhighcontrolperformanceinreliabilityandspeed thisarchitecturehelpsonetocaptureobjectsfrombothtime 9, 10. The researchers have attempted to improve the domainandfrequencydomain,therebyextractingboththe response characteristics of the robotic system and to at- presenceandmotiondataencodedincontinuousframes.To tenuate the uncertainties in 11. The proposed developed dotraditionalfunctionstolocalnoiseandimprovedetection robustmodel-freecontrollerincorporatestimedelaycontrol precision, spatial-temporal convolution layers are only TDC and adaptive terminal sliding mode control implementedwithinspatial-temporalquantitiesofchanging ATSMC methods. pixels. Researchers proposed anomaly-introduced learning In this research work, we aim to develop a smart sur- method for detecting anomalous activities by developing veillance security system detecting weapons specifically multi-instance learning graph-based model with abnormal guns.Forthispurpose,wehaveappliedfewcomputevision andnormalbimodaldata,highlightingthepositiveinstances methods and deep learning for identification of a weapon by training coarse filter using kernel-SVM classifier and from captured image. Recent work in the field of machine generating improved dictionary learning known as anchor learninganddeeplearningparticularlyconvolutionalneural dictionary learning. Thus, abnormality is measure by networks has shown considerable progress in the areas of selecting the sparse reconstruction cost which yields the object detection and recognition, exclusively in images. As comparison with other techniques including utilizing ab- the first step for any video surveillance application, object normal information and reducing time and cost for SRC. detection and classification are essential for further object Hu et al. 15 have contributed in detecting various tracking tasks. For this purpose, we trained the classifier objects in traffic scenes by presenting a method which de- modelofYOLOv3,i.e.,YouOnlyLookOnce12,13.This tectstheobjectsinthreesteps.Initially,itdetectstheobjects, model is a state-of-the-art real-time object detection clas- recognizes the objects, and finally tracks the objects in sifier.Furthermore,wearenotjustdetectingtheguns,rifles, motionbymainlytargetingthreeclassesofdifferentobjects and fire but also getting the location of the incident and including cars, cyclists, and traffic signs. Therefore, all the storing the data for future use. We have connected three objects are detected using single learning-based detection systemsusingsocketprogramingasademonstrationforthe framework consisting of dense feature extractor and tri- real-life scenario as camera, CCTV operator, and security modal class detection. Additionally, dense features are panels. extractedandsharedwiththerestofdetectorswhichheads Thisworkisanattempttodesignanddevelopasystem to be faster in speed that further needs to be evaluated in whichcandetecttheguns,rifles,andfireinnotimewithless testing phase. Therefore, intraclass variation of objects is computational resources. It is evident from technological proposed for object subcategorization with competitive advancementsthatmostofthehumanassistedapplications performance on several datasets. are now automated and computer-based. Eventually, in Gregaetal.presentedanalgorithmwhichautomatically future these computer-based systems will be replaced by detects knives and firearms in CCTV image and alerts the moresmartmachines,robots,orhumanoidrobots.Inorder security guard or operator 16. Majorly, focusing on lim- to provide visionary sense to robots, object detection plays iting false alarms and providing a real-time application fundamental part for understanding the objects and its wherespecificityofthealgorithmis94.93andsensitivityis interpretation. Thus, our proposed system can also be 81.18 for knife detection. Moreover, specificity for fire implemented in surveillance and security robots to detect alarmsystemis96.69andsensitivityis35.98fordifferent any weapon or unsafe assets. objectsinthevideo.Mousavietal.in17carriedoutvideo classifier also referred to as the Histogram of Directed 2.Literature Review Tracklets which identifies irregular conditions in complex scenes. In comparison to traditional approaches using op- Reducing the life-threatening acts and providing high se- tical flow which only measure edge features from two curityarechallengingateveryplace.Therefore,anumberof subsequent frames, descriptors have been developing over researchers have contributed to monitoring various activi- long-range motion projections called tracklets. Spatiotem- ties and behaviors using object detection. In general, a poralcuboidfootagesequencesarestatisticallygatheredon framework of smart surveillance system is developed on the tracklets that move through them. three levels firstly, to extract low-level information like Ji et al. developed a system for security footage which features engineering and object tracking secondly, to automatically identifies the human behavior using con- identifyunusualhumanactivities,behavior,ordetectionof volutional neural nets CNNs by forming deep learning any weapon and finally, the high level is about decision model which operates directly on the raw inputs 18. MathematicalProblemsinEngineering 3 Therefore, 3D CNN model for classification requires the are transformed into the same width and height 416416 regularization of outputs with high-level characteristics to pixels. increase efficiency and integrating the observations of a Objectdetectionisprimarilyrelatedtocomputervision variety of various models. thatincludesdistinguishingobjectsincomputerizedimages. Pangetal.presentedreal-timeconcealedvariousobject Object detection is a domain that has benefited immensely detection under human dress in 19. Metallic guns on fromtherecentadvancementsintherealmofdeeplearning. human skeleton were used for passive millimeter wave YOLOisbasicallyapretrainedobjectdetector.ItisaCNN imagerywhichreliesonYOLOalgorithmondatasetofsmall model.ACNNisadeeplearningalgorithmwhichcantake scale. Subsequently, comparison is undertaken between inarawinputimageandassignlearnableweightsandbiases Single MultiBox Detector algorithm, YOLOv3-13, SSD- to various aspects/objects in the image. A convolutional VGG16,andYOLOv3-53onPMMWdataset.Moreover,the layer in CNN model is responsible of extracting the high- weapondetectionaccuracycomputed36framespersecond level features such as edges, from the input image. This ofdetectionspeedand95meanaverageprecision.WarsiA worksbyapplyingkxkfilterknownaskernelrepeatedlyover et al. have contributed to automatically detecting the rawimage.Thisfurtherresultsinactivationmapsorfeature handgun invisual surveillance by implementing YOLO V3 maps. These feature maps are the presence of detected algorithm with Faster Region-Based CNN RCNN by features from the given input. Thus, the preprocessing re- differentiating the number of false negatives and false quired is much lower as compared to other classification positives 20, thus, taking real-time images and incorpo- algorithms,whereasinstandardapproach,filtersarehand- rating with ImageNet dataset then training it using YOLO engineeredandinCNNthesearelearnedthroughanumber V3algorithm.TheyhavecomparedFasterRCNNtoYOLO of iterations and training. Figure 3 indicates a basic CNN V3 using four different videos and as a result YOLO V3 architectureasclassificationmodelfor10differentweapons. imparted faster speed in real-time environment. Subsequently,thenextlayerisMax-PoolingorSubsampling layer,whichisresponsibleforreducingthespatialsizeofthe convolved features. This is to decrease the computational 3.Methodology power required toprocess the data throughdimensionality reduction. ReLU is a rectified linear unit activation In this work, we have attempted to develop an integrated expressed in 1, which is related to the feature of non- frameworkforreconnaissancesecuritythatdistinguishesthe saturating activation. It eliminates undesirable values from weapons progressively, if identification is positively true it anactivationmapeffectivelybysettingthemtonil.Finally, will caution/brief the security personals to handle the cir- the last layers are fully connected layers transforming the cumstancebyarrivingattheplaceoftheincidentthroughIP dataintoa1-dimensionalarray.Tocreateaparticularlong cameras.Weproposeamodelthatprovidesavisionarysense feature vector, the flattened output is fed to a feedforward toamachinetoidentifytheunsafeweaponandcanalsoalert neural network and backpropagation is applied to every thehumanadministratorwhenagunorfirearmisobvious iterationoftraining.Theselayersareliabletolearnnonlinear in the edge. Moreover, we have programmed entryways combinationsofthehigh-levelfeaturesasrepresentedbythe locking framework when the shooter seems to carry ap- output of the convolutional layer. palling weapon. On the off chance conceivable, through IP webcams we can likewise share the live photo to approach ReLU fxmax0,x. 1 securitypersonalstomakethemoveinmeantime.Also,we have constructed the information system for recording all As mentioned earlier that YOLO is a pretrained object theexercisestoconveyimpactactivitiesinthemetropolitan detector, a pretrained model simply means that another territories for a future crisis. This further ends up in de- dataset has been trained on it. It is extremely time con- signingthedatabaseforrecordingalltheactivitiesinorder sumingtotrainamodelfromscratchitcantakeweeksora to take prompt actions for future emergency. Figure 1 monthtocompletethetrainingstep.Apretrainedmodelhas presents the overall generalized approach of our research already seen tons of objects and knows how each of them work divided into three parts. must be classified. The weights in the abovementioned Themostimportantandcrucialpartofanyapplicationis pretrained model have been obtained by training the net- to have a desired and suitable dataset in order to train the work on COCO and Imagenet dataset. Thus, it can only machinelearningmodels.Therefore,wemanuallycollected detectobjectsbelongingtotheclassespresentinthedataset huge amount of images from Google. A few of the image used to train the network. It uses Darknet-53 as the back- samples are shown in Figure 2. For each weapon class, we bone network for feature extraction and uses three scale collectedatleast50images.Usinggoogle-images-download predictions. The DarkNet-53 is again convolutional neural is one of the best ways to collect images for constructing network that has 53 layers as elucidated in Figure 4. Dar- onesowndataset.Wefurthersavedthoseimagestoafolder kNet-53 is a fully convolutional neural network. Pooling calledimages.Onemustsaveimagesin.jpgformifthe layerisreplacedwithaconvolutionoperationwithstride2. images are in different extensions, it will be a little trou- Furthermore,residualunitsareappliedtoavoidthegradient blesomeandwillgenerateerrorswhenprovidedfortraining. dispersion. Alternatively, since the images are processed in terms of Initially,CNNarchitectureswerequitelinear.Recently, batches,thereforepriortotraining,thesizesofalltheimages numerous variations are introduced, for example, middle 4 MathematicalProblemsinEngineering Input video Detected guns Detected frame Frame conversion Training data Get location Image preprocessing Classification Alert Object detection Database Object identification Object detection Analysis Action Figure1Theflowof researchmethodology. a b c d e f g h Figure2Sample imagesfrom collecteddataset. blocks, skip connections, and aggregations of data between stacked over it, accumulating to a total of a 106-layer fully layers. These network models have already acquired rich convolutional architecture. Due to its multiscale feature featurerepresentationsbygettingtrainedoverawiderange fusion layers, YOLO V3 uses 3 feature maps of different ofimages.Thus,selectingapretrainednetworkandusingit scales for target detection as shown in Figure 5. as a starting point to learn a new task is a concept behind transferlearning.Inordertorecognizetheweapons,wetook 4.Experimental Results the weights of a pretrained model and trained another YOLO V3 model. Image classification includes, for example, the class of one YOLOV3isdesignedtobeamultiscaleddetectorrather object in a picture. However, object localization is to rec- than image classifier. Therefore, for object detection, clas- ognizetheareaofatleastonearticleinapictureanddrawing sificationheadisreplacedbyappendingadetectionheadto aproliferatingboxaroundtheirdegreeasshowninFigure6. this architecture. Henceforth, the output is vector with the Moreover,Figure7illustratesthedetectionofriflefroman boundingboxcoordinatesandprobabilityclasses.YOLOV3 animated video. The shape of the detection kernel is com- inherits Darknet-53 as its backbone, a framework to train putedby11bbx41nc.Hence,bbisthenumber neural networks with 53 layers as indicated in Figure 4. ofboundingboxes,4isforthe4boundingboxcoordinate Moreover,forobjectdetectiontaskadditional53layersare positionsand1isobjectconfidence,andncisthenumberof MathematicalProblemsinEngineering 5 fc_3 fc_4 Fully connected Fully connected Conv_1 Conv_2 neural network neural network convolution convolution ReLU activation 5  5 kernel Max-pooling 5  5 kernel Max-pooling valid padding 2  2 valid padding 2  2 With dropout 0 1 Flatte ne 2 d 9 Input n1 channels n1 channels n2 channels n2 channels 28  28  1 24  24  n1 12  12  n1 8  8  n2 4  2  n2 Output n3 units Figure3 Feedforwardconvolutionalneural networkCNN. classes. The downsampling of the input image is for three Type Filters Size Output scale predictions and is computed by strides 32, 16, and 8. Convolutional 32 3  3 256  256 The loss function over here is comprisedon three sections, Convolutional 64 3  3/2 128  128 location error L , confidence error L , and classifi- box cls Convolutional 32 1  1 cation error L , as presented in 2. obj 1 Convolutional 64 3  3 LossL L L . 2 Residual 128  128 box cls obj Convolutional 128 3  3/2 64  64 Literature suggests that YOLO v2 often struggled with Convolutional 64 1  1 small object detections. This happened due to loss of fine- 2 Convolutional 128 3  3 grained features as the layers downsampled the input. In Residual 64  64 conclusion, YOLO v2 applies an identity mapping, con- Convolutional 256 3  3/2 32  32 catenating feature maps from a previous layer to capture Convolutional 128 1  1 low-level features. However, YOLO v2s architecture was 8 Convolutional 256 3  3 lacking some of the influential essentials that are encapsu- Residual 32  32 latedinmostofstate-of-the-artalgorithms.Theearlymodels Convolutional 512 3  3/2 16  16 were lacking in the residual blocks, skip connections, and Convolutional 256 1  1 upsampling.Ontheotherhand,YOLOv3incorporatesallof 8 Convolutional 512 3  3 these. The detection of smaller objects can be seen from Residual 16  16 cumulative results demonstrated in Figure 8. We retrained Convolutional 1024 3  3/2 8  8 both YOLO V2 and YOLO V3. Alternatively, we also Convolutional 512 1  1 conducted comparative analysis of the models with tradi- 4 Convolutional 1024 3  3 tional CNN which was trained from the very scratch with Residual 8  8 nullweights.TheobtainedresultsaresummarizedinTable1. Avgpool Global The subsequent part of our research is based on the Connected 1000 recordingoflocationwheretheweaponwasdetectedsothat Softmax thealarmisgenerated.Forthispurpose,atbackendwehave also created a Database. A desktop application is also de- Figure4 Architecturaldetails ofDARKNET-53layers10. veloped in order to provide connectivity with the database system.Therearefourattributesthatarecollectedfromthe map their positions. As it can be seen from the relational sitewhereanobjectlikeweaponwasdetected.Thecollected table provided in Figure 9, the attributes are latitude, lon- information needs to be translated into a geographical gitude, time, and location where weapons were seen or format of longitude and latitude. For this purpose, geo- identified. At backend DAO Data Access Object layer is coding was performed. It is the method of translating ad- alsoavailabletoshowtheuserthedatafromthedatabase.It dresses to geographical details, longitude, and latitude, to is component of Java Foundation Classes JFC, which is a 6 MathematicalProblemsinEngineering Type Filters Size Output Convolutional 32 3  3 256  256 Convolutional 64 3  3/2 128  128 Convolutional 32 1  1 Convolutional 64 3  3 1 Residual 128  128 Convolutional 128 3  3/2 64  64 Convolutional 64 1  1 Convolutional 128 3  3 Residual 64  64 2 Convolutional 256 3  3/2 32  32 Convolutional 128 1  1 Scale 3 Convolutional 256 3  3 Residual 32  32 3 Convolutional 512 3  3/2 16  16 Convolutional 256 1  1 Scale 2 Convolutional 512 3  3 Residual 16  16 4 Convolutional 1024 3  3/2 8  8 Convolutional 512 1  1 Scale 1 Convolutional 1024 3  3 Residual 8  8 Avgpool Global Convs Convs Convs Connected 1000 Softmax YOLO detection layer Figure5 ArchitecturaldescriptionofYOLO V3. Figure6 Boundingboxaround detectedobject weapon categoryGUN. GUI-providing API for Java programs. Swing provides Our proposed system is further compared with the packages that let us render our Java programs a complex existing literature in Table 2. In 21, the proposed system collection of GUI components and it really is platform includes CNN-based VGG-16 architecture as feature ex- independent. Figure 10 presents the class diagram and tractor, followed by state-of-the-art classifiers which are implementation of DAO layer. implemented on a standard gun database. The researchers MathematicalProblemsinEngineering 7 Figure7Real-time weapondetected froma videosurrounded bybounding box.Weaponcategory rifle. Figure8Cumulativeresultofdetectingweapon withprecisionvalue. Table 1Experimental resultsfortrained deep learningmodels. S. no Models Accuracy 1 TraditionalCNN 95 2 YOLOV2 96.76 3 YOLOV3 98.89 Figure9 Imagepresentingthe recordeddatabase. 8 MathematicalProblemsinEngineering Interface DAO getLocation Connectivity Connection con Database connect DAO mp getLocation Implemented by Implemented by GunDetection OfficialPanel setRecord getLoaction Location float lat float lon Used by strib  ng loc Used by getFloat lat setFloat lat float lat  void getFloat lon setFloat lon float lon  void getString loc setString loc String loc  void Figure10Class diagramforDOA layer. Table 2Comparison withthe existingwork. S. no Models Dataset Accuracy 1 Our trained modelYOLOV3 Imagedatasetcollectedforcurrentresearch 98.89 2 AlexnetSVM 22 Gunvideo database24 95 4 FasterRCNN23 Streaming video 95.4 5 CNNVGG-1621 IMDB 93.1 investigated four machine learning models, namely, BoW, surveillance systems with the growing availability of cheap HOGSVM, CNN, and AlexnetSVM, to recognize the computing, video infrastructure, high-end technology, and firearmsandknifesfromadatasetofimages22.Theirwork better video processing. suggeststhatpretrainedAlexnetSVMperformedthebest. As it is evident from the previous studies, researchers have Data Availability widely applied CNN and its variant for weapon or knife identification from CCTV videos 23. It is obvious from The data are available on request. Table2thattheimplementedYOLOv3outperformstherest of the other models. Conflicts of Interest The authors declare that they have no conflicts of interest. 5.Conclusion and Future Work References Inthisstudy,thestate-of-the-artYOLOV3objectdetection model was implemented and trained over our collected 1 S.A.Velastin,B.A.Boghossian,andM.A.Vicencio-Silva,A dataset for weapon detection. We propose a model that motion-based image processing system for detecting poten- providesavisionarysensetoamachineorrobottoidentify tiallydangeroussituationsinundergroundrailwaystations, the unsafe weapon and can also alert the human adminis- Transportation Research Part C Emerging Technologies, trator when a gun or a firearm is obvious in the edge. The vol.14,no.2, pp.96113, 2006. experimental results show that the trained YOLO V3 has 2 UnitedNations,OfficeonDrugsandCrime,ReportonGlobal betterperformancecomparedtotheYOLOV2modelandis StudyofHomicide,https//www.unodc.org/documents/data- lessexpensivecomputationally.Thereisanimmediateneed and-analysis/gsh/Booklet1.pdf. 3 P. M. Kumar, U. Gandhi, R. Varatharajan, G. Manogaran, toupdatethecurrentsurveillancecapabilitieswithimproved R.Jidhesh,and T.Vadivel, Intelligentfacerecognitionand resourcestosupportmonitoringtheeffectivenessofhuman navigationsystemusingneurallearningforsmartsecurityin operators. Smart surveillance systems would fully replace internet of things, Cluster Computing, vol. 22, no. S4, current infrastructure with the growing availability of low- pp. 77337744,2019. cost storage, video infrastructure, and better video pro- 4 V.Babanne,N.S.Mahajan,R.L.Sharma,andP.P.Gargate, cessing technologies. Eventually, the digital monitoring Machine learning based smart surveillance system, in systems in terms of robots would fully replace current Proceedings of the 2019 Third International Conference on MathematicalProblemsinEngineering 9 I-SMAC IoT in Social, Mobile, Analytics and CloudI- 19 L.Pang,H.Liu,Y.Chen,andJ.Miao,Real-timeconcealed SMAC,pp. 8486,IEEE, Palladam,India,December2019. object detection from passive millimeter wave images based 5 A. Joshi, N. Jagdale, R. Gandhi, and S. Chaudhari, Smart on the YOLOv3 algorithm, Sensors, vol. 20, no. 6, p.1678, surveillance system for detection of suspicious behaviour 2020. using machinelearning,in IntelligentComputing, Informa- 20 A.Warsi,M.Abdullah,M.N.Husen,M.Yahya,S.Khan,and tionandControlSystems.ICICCS2019.AdvancesinIntelligent N. Jawaid, Gun detection system using YOLOv3, in Pro- Systems and Computing, A. Pandian, K. Ntalianis, and ceedingsofthe2019IEEEInternationalConferenceonSmart R. Palanisamy, Eds., vol. 1039, Berlin, Germany, Springer, Instrumentation, Measurement and Application ICSIMA, Cham,2020. pp.14,IEEE, KualaLumpur,Malaysia, August2019. 6 K.-E.KoandK.-B.Sim,Deepconvolutionalframeworkfor 21 G.K.VermaandA.Dhillon,Ahandheldgundetectionusing abnormalbehaviordetectioninasmartsurveillancesystem, faster r-cnn deep learning, in Proceedings of the 7th Inter- Engineering Applications of Artificial Intelligence, vol. 67, national Conference on Computer and Communication pp.226234, 2018. Technology, pp. 8488, Kurukshetra, Haryana, November 7 S. Y. Nikouei, Y. Chen, S. Song, R. Xu, B.-Y. Choi, and 2017. T.Faughnan,Smartsurveillanceasanedgenetworkservice 22 S.B.KibriaandM.S.Hasan,Ananalysisoffeatureextraction from harr-cascade, SVM to a lightweight CNN, in Pro- andclassificationalgorithmsfordangerousobjectdetection, ceedings of the 2018 IEEE 4th International Conference on in Proceedings of the 2017 2nd International Conference on Collaboration and Internet Computing CIC, pp. 256265, Electrical  Electronic Engineering ICEEE, pp. 14, IEEE, Philadelphia,PA,USA,April2018. Rajshahi, Bangladesh,December2017. 8 R.Xu,S.Y.Nikouei,Y.Chenetal.,Real-timehumanobjects 23 A. Castillo, S. Tabik, F. Perez, R. Olmos, and F. Herrera, trackingforsmartsurveillanceattheedge,inProceedingsof Brightness guided preprocessing for automatic cold steel the 2018 IEEE International Conference on Communications weapondetectioninsurveillancevideoswithdeeplearning, ICC, pp.16,KansasCity,MO,USA, May2018. Neurocomputing, vol. 330,pp.151161, 2019. 9 S. Ahmed, A. Ahmed, I. Mansoor, F. Junejo, and A. Saeed, 24 V.Gun, Database,http//kt.agh.edu.pl/grega/guns/. Output feedback adaptive fractional-order super-twisting slidingmodecontrolofroboticmanipulator,IranianJournal of Science and Technology, Transactions of Electrical Engi- neering,vol. 45,no.1, pp.335347, 2021. 10 S.Ahmed,H.Wang,andY.Tian,Adaptivefractionalhigh- order terminal sliding mode control for nonlinear robotic manipulator under alternating loads, Asian Journal of Control,2020. 11 S. Ahmed, H. Wang, and Y. Tian, Adaptive high-order terminalslidingmodecontrolbasedontimedelayestimation fortheroboticmanipulatorswithbacklashhysteresis,IEEE Transactions on Systems, Man, and Cybernetics Systems, vol. 51, no.2, pp.11281137, 2021. 12 J.Redmon,S.Divvala,R.Girshick,andA.Farhadi,Youonly lookonceunified,real-timeobjectdetection,inProceedings of the IEEE Conference on Computer Vision and Pattern Recognition,pp. 779788,Las Vegas,NV, USA,June 2016. 13 A. Farhadi and R. Joseph, Yolov3 an incremental im- provement,ComputerVisionandPatternRecognition,2018. 14 C.He,J.Shao,andJ.Sun,Ananomaly-introducedlearning methodforabnormaleventdetection,MultimediaToolsand Applications,vol. 77, no.22,pp. 2957329588,2018. 15 Q.Hu,S.Paisitkriangkrai,C.Shen,A.vandenHengel,and F.Porikli,Fastdetectionofmultipleobjectsintrafficscenes withacommondetectionframework,IEEETransactionson Intelligent Transportation Systems, vol. 17, no. 4, pp. 1002 1014, 2015. 16 M. Grega, A. Matiolanski, P. Guzik, and M. Leszczuk, Au- tomateddetectionoffirearmsandknivesinaCCTVimage, Sensors,vol.16, no.1,p. 47, 2016. 17 H. Mousavi, S. Mohammadi, A. Perina, R. Chellali, and V.Murino,Analyzingtrackletsforthedetectionofabnormal crowd behavior, in Proceedings of the 2015 IEEE Winter ConferenceonApplicationsofComputerVision,pp.148155, IEEE,Waikoloa,HI,USA, January2015. 18 S.Ji,W.Xu,M.Yang,andK.Yu,3Dconvolutionalneural networks for human action recognition, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 35, no.1, pp.221231, 2012.",
    "structured_text": {
      "sentences": [
        "Hindawi Mathematical Problems in Engineering Volume 2021, Article ID 9975700, 9 pages https//doi.org/10.1155/2021/9975700 Research Article Weapon Detection Using YOLO V3 for Smart Surveillance System Sanam Narejo ,1 Bishwajeet Pandey ,2 Doris Esenarro vargas ,3 Ciro Rodriguez ,4 and M.",
        "Rizwan Anjum 5 1DepartmentofComputerSystemsEngineering,MehranUniversityofEngineeringandTechnologyMUET,Jamshoro,Pakistan 2GranSassoScience Institute,LAquila,Italy 3UniversidadNacional FedericoVillarreal,Lima,Peru 4UniversidadNacional MayordeSanMarcos,Lima,Peru 5Departmentof ElectronicEngineering,TheIslamiaUniversityofBahawalpur,Bahawalpur 63100,Pakistan CorrespondenceshouldbeaddressedtoBishwajeetPandeydr.pandeyieee.org Received 4 March 2021 Revised 15 April 2021 Accepted 3 May 2021 Published 12 May 2021 AcademicEditorZainAnwarAli Copyright2021SanamNarejoetal.ThisisanopenaccessarticledistributedundertheCreativeCommonsAttributionLicense, whichpermitsunrestricteduse,distribution,andreproductioninanymedium,providedtheoriginalworkisproperlycited.",
        "Everyyear,alargeamountofpopulationreconcilesgun-relatedviolenceallovertheworld.Inthiswork,wedevelopacomputer- based fully automated system to identify basic armaments, particularly handguns and rifles.",
        "Recent work in the field of deep learningandtransferlearninghasdemonstratedsignificantprogressintheareasofobjectdetectionandrecognition.Wehave implementedYOLOV3YouOnlyLookOnceobjectdetectionmodelbytrainingitonourcustomizeddataset.Thetraining results confirm that YOLO V3 outperforms YOLO V2 and traditional convolutional neural network CNN.",
        "Additionally, intensiveGPUsorhighcomputationresourceswerenotrequiredinourapproachasweusedtransferlearningfortrainingour model.Applyingthismodelinoursurveillancesystem,wecanattempttosavehumanlifeandaccomplishreductionintherateof manslaughterormasskilling.Additionally,ourproposedsystemcanalsobeimplementedinhigh-endsurveillanceandsecurity robots todetecta weaponorunsafe assets toavoidany kindofassaultorriskto human life.",
        "1.Introduction According to statistics, 4.2 in 100000 people are killed in Pakistaneveryyearinmassshootings.Fromstreetcrimesto Violence committed with guns puts significant impact on an individual institution attack, many precious lives suf- public, health, psychological, and economic cost.",
        "Many fered.Thisfurtherindicatesthatmanualsurveillancesystem people die each year from gun-related violence.",
        "Psycho- stillneedshumaneyetodetecttheabnormalactivitiesandit logicaltraumaisfrequentamongchildrenwhoareexposed takes a sufficient amount of time reporting to security of- to high levels of violence in their communities or through ficials to tackle the situation.",
        "the media.",
        "Children exposed to gun-related violence, Although the human visual framework is quick and whether they are victims, perpetrators, or witnesses, can preciseandcanlikewiseperformcomplexundertakingslike experiencenegativepsychologicaleffectsovertheshortand distinguishing different items and recognizing snags with longterms.Numberofstudiesshowthathandheldgunisthe minimalcognizantidea,however,itiscommontruththatif primary weapon used for various crimes like break-in, anindividualwatchessomethingverysimilarforquitealong robbery,shoplifting,andrape.Thesecrimescanbereduced time, there is an opportunity of sluggishness and lack of by identifying the disruptive behavior at early stage and regard.",
        "monitoring the suspicious activities carefully so that law Nowadays, with the accessibility of huge datasets, enforcementagenciescanfurthertakeimmediateaction1.",
        "quicker GPUs, advanced machine learning algorithms, and Levels of gun-related violence vary greatly among geo- bettercalculations,wecannoweffectivelypreparePCsand graphicallocationsandcountries.Theglobaldeathtollfrom develop automated computer-based system to distinguish use of guns may be as high as 1,000 dead each day 2.",
        "and identify numerous items on a site with high accuracy.",
        "2 MathematicalProblemsinEngineering Recent developments indicate that machine learning 36 makinglikeabnormaleventdetectionoranyanomaly.The and advance image processing algorithms have played latestanomalydetectiontechniquescanbedividedintotwo dominant role in smart surveillances and security systems groups,whichareobject-centeredtechniquesandintegrated 7, 8.",
        "Apart from this, popularity of smart devices and methods.TheconvolutionalneuralnetworkCNNspatial- networked cameras has also empowered this domain.",
        "temporalsystemisonlyappliedtospatial-temporalvolumes However,humanobjectsorweapondetectionandtracking of interest SVOI, reducing the cost of processing.",
        "In are still conducted at cloud centers, as real-time, online surveillance videos of complex scenes, researchers in 14 tracking is computationally costly.",
        "Significant efforts have proposed a tool for detecting and finding anomalous ac- been made in recent years to monitor robot manipulators tivities.",
        "By conducting spatial-temporal convolution layer, thatneedhighcontrolperformanceinreliabilityandspeed thisarchitecturehelpsonetocaptureobjectsfrombothtime 9, 10.",
        "The researchers have attempted to improve the domainandfrequencydomain,therebyextractingboththe response characteristics of the robotic system and to at- presenceandmotiondataencodedincontinuousframes.To tenuate the uncertainties in 11.",
        "The proposed developed dotraditionalfunctionstolocalnoiseandimprovedetection robustmodel-freecontrollerincorporatestimedelaycontrol precision, spatial-temporal convolution layers are only TDC and adaptive terminal sliding mode control implementedwithinspatial-temporalquantitiesofchanging ATSMC methods.",
        "pixels.",
        "Researchers proposed anomaly-introduced learning In this research work, we aim to develop a smart sur- method for detecting anomalous activities by developing veillance security system detecting weapons specifically multi-instance learning graph-based model with abnormal guns.Forthispurpose,wehaveappliedfewcomputevision andnormalbimodaldata,highlightingthepositiveinstances methods and deep learning for identification of a weapon by training coarse filter using kernel-SVM classifier and from captured image.",
        "Recent work in the field of machine generating improved dictionary learning known as anchor learninganddeeplearningparticularlyconvolutionalneural dictionary learning.",
        "Thus, abnormality is measure by networks has shown considerable progress in the areas of selecting the sparse reconstruction cost which yields the object detection and recognition, exclusively in images.",
        "As comparison with other techniques including utilizing ab- the first step for any video surveillance application, object normal information and reducing time and cost for SRC.",
        "detection and classification are essential for further object Hu et al.",
        "15 have contributed in detecting various tracking tasks.",
        "For this purpose, we trained the classifier objects in traffic scenes by presenting a method which de- modelofYOLOv3,i.e.,YouOnlyLookOnce12,13.This tectstheobjectsinthreesteps.Initially,itdetectstheobjects, model is a state-of-the-art real-time object detection clas- recognizes the objects, and finally tracks the objects in sifier.Furthermore,wearenotjustdetectingtheguns,rifles, motionbymainlytargetingthreeclassesofdifferentobjects and fire but also getting the location of the incident and including cars, cyclists, and traffic signs.",
        "Therefore, all the storing the data for future use.",
        "We have connected three objects are detected using single learning-based detection systemsusingsocketprogramingasademonstrationforthe framework consisting of dense feature extractor and tri- real-life scenario as camera, CCTV operator, and security modal class detection.",
        "Additionally, dense features are panels.",
        "extractedandsharedwiththerestofdetectorswhichheads Thisworkisanattempttodesignanddevelopasystem to be faster in speed that further needs to be evaluated in whichcandetecttheguns,rifles,andfireinnotimewithless testing phase.",
        "Therefore, intraclass variation of objects is computational resources.",
        "It is evident from technological proposed for object subcategorization with competitive advancementsthatmostofthehumanassistedapplications performance on several datasets.",
        "are now automated and computer-based.",
        "Eventually, in Gregaetal.presentedanalgorithmwhichautomatically future these computer-based systems will be replaced by detects knives and firearms in CCTV image and alerts the moresmartmachines,robots,orhumanoidrobots.Inorder security guard or operator 16.",
        "Majorly, focusing on lim- to provide visionary sense to robots, object detection plays iting false alarms and providing a real-time application fundamental part for understanding the objects and its wherespecificityofthealgorithmis94.93andsensitivityis interpretation.",
        "Thus, our proposed system can also be 81.18 for knife detection.",
        "Moreover, specificity for fire implemented in surveillance and security robots to detect alarmsystemis96.69andsensitivityis35.98fordifferent any weapon or unsafe assets.",
        "objectsinthevideo.Mousavietal.in17carriedoutvideo classifier also referred to as the Histogram of Directed 2.Literature Review Tracklets which identifies irregular conditions in complex scenes.",
        "In comparison to traditional approaches using op- Reducing the life-threatening acts and providing high se- tical flow which only measure edge features from two curityarechallengingateveryplace.Therefore,anumberof subsequent frames, descriptors have been developing over researchers have contributed to monitoring various activi- long-range motion projections called tracklets.",
        "Spatiotem- ties and behaviors using object detection.",
        "In general, a poralcuboidfootagesequencesarestatisticallygatheredon framework of smart surveillance system is developed on the tracklets that move through them.",
        "three levels firstly, to extract low-level information like Ji et al.",
        "developed a system for security footage which features engineering and object tracking secondly, to automatically identifies the human behavior using con- identifyunusualhumanactivities,behavior,ordetectionof volutional neural nets CNNs by forming deep learning any weapon and finally, the high level is about decision model which operates directly on the raw inputs 18.",
        "MathematicalProblemsinEngineering 3 Therefore, 3D CNN model for classification requires the are transformed into the same width and height 416416 regularization of outputs with high-level characteristics to pixels.",
        "increase efficiency and integrating the observations of a Objectdetectionisprimarilyrelatedtocomputervision variety of various models.",
        "thatincludesdistinguishingobjectsincomputerizedimages.",
        "Pangetal.presentedreal-timeconcealedvariousobject Object detection is a domain that has benefited immensely detection under human dress in 19.",
        "Metallic guns on fromtherecentadvancementsintherealmofdeeplearning.",
        "human skeleton were used for passive millimeter wave YOLOisbasicallyapretrainedobjectdetector.ItisaCNN imagerywhichreliesonYOLOalgorithmondatasetofsmall model.ACNNisadeeplearningalgorithmwhichcantake scale.",
        "Subsequently, comparison is undertaken between inarawinputimageandassignlearnableweightsandbiases Single MultiBox Detector algorithm, YOLOv3-13, SSD- to various aspects/objects in the image.",
        "A convolutional VGG16,andYOLOv3-53onPMMWdataset.Moreover,the layer in CNN model is responsible of extracting the high- weapondetectionaccuracycomputed36framespersecond level features such as edges, from the input image.",
        "This ofdetectionspeedand95meanaverageprecision.WarsiA worksbyapplyingkxkfilterknownaskernelrepeatedlyover et al.",
        "have contributed to automatically detecting the rawimage.Thisfurtherresultsinactivationmapsorfeature handgun invisual surveillance by implementing YOLO V3 maps.",
        "These feature maps are the presence of detected algorithm with Faster Region-Based CNN RCNN by features from the given input.",
        "Thus, the preprocessing re- differentiating the number of false negatives and false quired is much lower as compared to other classification positives 20, thus, taking real-time images and incorpo- algorithms,whereasinstandardapproach,filtersarehand- rating with ImageNet dataset then training it using YOLO engineeredandinCNNthesearelearnedthroughanumber V3algorithm.TheyhavecomparedFasterRCNNtoYOLO of iterations and training.",
        "Figure 3 indicates a basic CNN V3 using four different videos and as a result YOLO V3 architectureasclassificationmodelfor10differentweapons.",
        "imparted faster speed in real-time environment.",
        "Subsequently,thenextlayerisMax-PoolingorSubsampling layer,whichisresponsibleforreducingthespatialsizeofthe convolved features.",
        "This is to decrease the computational 3.Methodology power required toprocess the data throughdimensionality reduction.",
        "ReLU is a rectified linear unit activation In this work, we have attempted to develop an integrated expressed in 1, which is related to the feature of non- frameworkforreconnaissancesecuritythatdistinguishesthe saturating activation.",
        "It eliminates undesirable values from weapons progressively, if identification is positively true it anactivationmapeffectivelybysettingthemtonil.Finally, will caution/brief the security personals to handle the cir- the last layers are fully connected layers transforming the cumstancebyarrivingattheplaceoftheincidentthroughIP dataintoa1-dimensionalarray.Tocreateaparticularlong cameras.Weproposeamodelthatprovidesavisionarysense feature vector, the flattened output is fed to a feedforward toamachinetoidentifytheunsafeweaponandcanalsoalert neural network and backpropagation is applied to every thehumanadministratorwhenagunorfirearmisobvious iterationoftraining.Theselayersareliabletolearnnonlinear in the edge.",
        "Moreover, we have programmed entryways combinationsofthehigh-levelfeaturesasrepresentedbythe locking framework when the shooter seems to carry ap- output of the convolutional layer.",
        "palling weapon.",
        "On the off chance conceivable, through IP webcams we can likewise share the live photo to approach ReLU fxmax0,x.",
        "1 securitypersonalstomakethemoveinmeantime.Also,we have constructed the information system for recording all As mentioned earlier that YOLO is a pretrained object theexercisestoconveyimpactactivitiesinthemetropolitan detector, a pretrained model simply means that another territories for a future crisis.",
        "This further ends up in de- dataset has been trained on it.",
        "It is extremely time con- signingthedatabaseforrecordingalltheactivitiesinorder sumingtotrainamodelfromscratchitcantakeweeksora to take prompt actions for future emergency.",
        "Figure 1 monthtocompletethetrainingstep.Apretrainedmodelhas presents the overall generalized approach of our research already seen tons of objects and knows how each of them work divided into three parts.",
        "must be classified.",
        "The weights in the abovementioned Themostimportantandcrucialpartofanyapplicationis pretrained model have been obtained by training the net- to have a desired and suitable dataset in order to train the work on COCO and Imagenet dataset.",
        "Thus, it can only machinelearningmodels.Therefore,wemanuallycollected detectobjectsbelongingtotheclassespresentinthedataset huge amount of images from Google.",
        "A few of the image used to train the network.",
        "It uses Darknet-53 as the back- samples are shown in Figure 2.",
        "For each weapon class, we bone network for feature extraction and uses three scale collectedatleast50images.Usinggoogle-images-download predictions.",
        "The DarkNet-53 is again convolutional neural is one of the best ways to collect images for constructing network that has 53 layers as elucidated in Figure 4.",
        "Dar- onesowndataset.Wefurthersavedthoseimagestoafolder kNet-53 is a fully convolutional neural network.",
        "Pooling calledimages.Onemustsaveimagesin.jpgformifthe layerisreplacedwithaconvolutionoperationwithstride2.",
        "images are in different extensions, it will be a little trou- Furthermore,residualunitsareappliedtoavoidthegradient blesomeandwillgenerateerrorswhenprovidedfortraining.",
        "dispersion.",
        "Alternatively, since the images are processed in terms of Initially,CNNarchitectureswerequitelinear.Recently, batches,thereforepriortotraining,thesizesofalltheimages numerous variations are introduced, for example, middle 4 MathematicalProblemsinEngineering Input video Detected guns Detected frame Frame conversion Training data Get location Image preprocessing Classification Alert Object detection Database Object identification Object detection Analysis Action Figure1Theflowof researchmethodology.",
        "a b c d e f g h Figure2Sample imagesfrom collecteddataset.",
        "blocks, skip connections, and aggregations of data between stacked over it, accumulating to a total of a 106-layer fully layers.",
        "These network models have already acquired rich convolutional architecture.",
        "Due to its multiscale feature featurerepresentationsbygettingtrainedoverawiderange fusion layers, YOLO V3 uses 3 feature maps of different ofimages.Thus,selectingapretrainednetworkandusingit scales for target detection as shown in Figure 5.",
        "as a starting point to learn a new task is a concept behind transferlearning.Inordertorecognizetheweapons,wetook 4.Experimental Results the weights of a pretrained model and trained another YOLO V3 model.",
        "Image classification includes, for example, the class of one YOLOV3isdesignedtobeamultiscaleddetectorrather object in a picture.",
        "However, object localization is to rec- than image classifier.",
        "Therefore, for object detection, clas- ognizetheareaofatleastonearticleinapictureanddrawing sificationheadisreplacedbyappendingadetectionheadto aproliferatingboxaroundtheirdegreeasshowninFigure6.",
        "this architecture.",
        "Henceforth, the output is vector with the Moreover,Figure7illustratesthedetectionofriflefroman boundingboxcoordinatesandprobabilityclasses.YOLOV3 animated video.",
        "The shape of the detection kernel is com- inherits Darknet-53 as its backbone, a framework to train putedby11bbx41nc.Hence,bbisthenumber neural networks with 53 layers as indicated in Figure 4.",
        "ofboundingboxes,4isforthe4boundingboxcoordinate Moreover,forobjectdetectiontaskadditional53layersare positionsand1isobjectconfidence,andncisthenumberof MathematicalProblemsinEngineering 5 fc_3 fc_4 Fully connected Fully connected Conv_1 Conv_2 neural network neural network convolution convolution ReLU activation 5  5 kernel Max-pooling 5  5 kernel Max-pooling valid padding 2  2 valid padding 2  2 With dropout 0 1 Flatte ne 2 d 9 Input n1 channels n1 channels n2 channels n2 channels 28  28  1 24  24  n1 12  12  n1 8  8  n2 4  2  n2 Output n3 units Figure3 Feedforwardconvolutionalneural networkCNN.",
        "classes.",
        "The downsampling of the input image is for three Type Filters Size Output scale predictions and is computed by strides 32, 16, and 8.",
        "Convolutional 32 3  3 256  256 The loss function over here is comprisedon three sections, Convolutional 64 3  3/2 128  128 location error L , confidence error L , and classifi- box cls Convolutional 32 1  1 cation error L , as presented in 2.",
        "obj 1 Convolutional 64 3  3 LossL L L .",
        "2 Residual 128  128 box cls obj Convolutional 128 3  3/2 64  64 Literature suggests that YOLO v2 often struggled with Convolutional 64 1  1 small object detections.",
        "This happened due to loss of fine- 2 Convolutional 128 3  3 grained features as the layers downsampled the input.",
        "In Residual 64  64 conclusion, YOLO v2 applies an identity mapping, con- Convolutional 256 3  3/2 32  32 catenating feature maps from a previous layer to capture Convolutional 128 1  1 low-level features.",
        "However, YOLO v2s architecture was 8 Convolutional 256 3  3 lacking some of the influential essentials that are encapsu- Residual 32  32 latedinmostofstate-of-the-artalgorithms.Theearlymodels Convolutional 512 3  3/2 16  16 were lacking in the residual blocks, skip connections, and Convolutional 256 1  1 upsampling.Ontheotherhand,YOLOv3incorporatesallof 8 Convolutional 512 3  3 these.",
        "The detection of smaller objects can be seen from Residual 16  16 cumulative results demonstrated in Figure 8.",
        "We retrained Convolutional 1024 3  3/2 8  8 both YOLO V2 and YOLO V3.",
        "Alternatively, we also Convolutional 512 1  1 conducted comparative analysis of the models with tradi- 4 Convolutional 1024 3  3 tional CNN which was trained from the very scratch with Residual 8  8 nullweights.TheobtainedresultsaresummarizedinTable1.",
        "Avgpool Global The subsequent part of our research is based on the Connected 1000 recordingoflocationwheretheweaponwasdetectedsothat Softmax thealarmisgenerated.Forthispurpose,atbackendwehave also created a Database.",
        "A desktop application is also de- Figure4 Architecturaldetails ofDARKNET-53layers10.",
        "veloped in order to provide connectivity with the database system.Therearefourattributesthatarecollectedfromthe map their positions.",
        "As it can be seen from the relational sitewhereanobjectlikeweaponwasdetected.Thecollected table provided in Figure 9, the attributes are latitude, lon- information needs to be translated into a geographical gitude, time, and location where weapons were seen or format of longitude and latitude.",
        "For this purpose, geo- identified.",
        "At backend DAO Data Access Object layer is coding was performed.",
        "It is the method of translating ad- alsoavailabletoshowtheuserthedatafromthedatabase.It dresses to geographical details, longitude, and latitude, to is component of Java Foundation Classes JFC, which is a 6 MathematicalProblemsinEngineering Type Filters Size Output Convolutional 32 3  3 256  256 Convolutional 64 3  3/2 128  128 Convolutional 32 1  1 Convolutional 64 3  3 1 Residual 128  128 Convolutional 128 3  3/2 64  64 Convolutional 64 1  1 Convolutional 128 3  3 Residual 64  64 2 Convolutional 256 3  3/2 32  32 Convolutional 128 1  1 Scale 3 Convolutional 256 3  3 Residual 32  32 3 Convolutional 512 3  3/2 16  16 Convolutional 256 1  1 Scale 2 Convolutional 512 3  3 Residual 16  16 4 Convolutional 1024 3  3/2 8  8 Convolutional 512 1  1 Scale 1 Convolutional 1024 3  3 Residual 8  8 Avgpool Global Convs Convs Convs Connected 1000 Softmax YOLO detection layer Figure5 ArchitecturaldescriptionofYOLO V3.",
        "Figure6 Boundingboxaround detectedobject weapon categoryGUN.",
        "GUI-providing API for Java programs.",
        "Swing provides Our proposed system is further compared with the packages that let us render our Java programs a complex existing literature in Table 2.",
        "In 21, the proposed system collection of GUI components and it really is platform includes CNN-based VGG-16 architecture as feature ex- independent.",
        "Figure 10 presents the class diagram and tractor, followed by state-of-the-art classifiers which are implementation of DAO layer.",
        "implemented on a standard gun database.",
        "The researchers MathematicalProblemsinEngineering 7 Figure7Real-time weapondetected froma videosurrounded bybounding box.Weaponcategory rifle.",
        "Figure8Cumulativeresultofdetectingweapon withprecisionvalue.",
        "Table 1Experimental resultsfortrained deep learningmodels.",
        "S.",
        "no Models Accuracy 1 TraditionalCNN 95 2 YOLOV2 96.76 3 YOLOV3 98.89 Figure9 Imagepresentingthe recordeddatabase.",
        "8 MathematicalProblemsinEngineering Interface DAO getLocation Connectivity Connection con Database connect DAO mp getLocation Implemented by Implemented by GunDetection OfficialPanel setRecord getLoaction Location float lat float lon Used by strib  ng loc Used by getFloat lat setFloat lat float lat  void getFloat lon setFloat lon float lon  void getString loc setString loc String loc  void Figure10Class diagramforDOA layer.",
        "Table 2Comparison withthe existingwork.",
        "S.",
        "no Models Dataset Accuracy 1 Our trained modelYOLOV3 Imagedatasetcollectedforcurrentresearch 98.89 2 AlexnetSVM 22 Gunvideo database24 95 4 FasterRCNN23 Streaming video 95.4 5 CNNVGG-1621 IMDB 93.1 investigated four machine learning models, namely, BoW, surveillance systems with the growing availability of cheap HOGSVM, CNN, and AlexnetSVM, to recognize the computing, video infrastructure, high-end technology, and firearmsandknifesfromadatasetofimages22.Theirwork better video processing.",
        "suggeststhatpretrainedAlexnetSVMperformedthebest.",
        "As it is evident from the previous studies, researchers have Data Availability widely applied CNN and its variant for weapon or knife identification from CCTV videos 23.",
        "It is obvious from The data are available on request.",
        "Table2thattheimplementedYOLOv3outperformstherest of the other models.",
        "Conflicts of Interest The authors declare that they have no conflicts of interest.",
        "5.Conclusion and Future Work References Inthisstudy,thestate-of-the-artYOLOV3objectdetection model was implemented and trained over our collected 1 S.A.Velastin,B.A.Boghossian,andM.A.Vicencio-Silva,A dataset for weapon detection.",
        "We propose a model that motion-based image processing system for detecting poten- providesavisionarysensetoamachineorrobottoidentify tiallydangeroussituationsinundergroundrailwaystations, the unsafe weapon and can also alert the human adminis- Transportation Research Part C Emerging Technologies, trator when a gun or a firearm is obvious in the edge.",
        "The vol.14,no.2, pp.96113, 2006.",
        "experimental results show that the trained YOLO V3 has 2 UnitedNations,OfficeonDrugsandCrime,ReportonGlobal betterperformancecomparedtotheYOLOV2modelandis StudyofHomicide,https//www.unodc.org/documents/data- lessexpensivecomputationally.Thereisanimmediateneed and-analysis/gsh/Booklet1.pdf.",
        "3 P.",
        "M.",
        "Kumar, U.",
        "Gandhi, R.",
        "Varatharajan, G.",
        "Manogaran, toupdatethecurrentsurveillancecapabilitieswithimproved R.Jidhesh,and T.Vadivel, Intelligentfacerecognitionand resourcestosupportmonitoringtheeffectivenessofhuman navigationsystemusingneurallearningforsmartsecurityin operators.",
        "Smart surveillance systems would fully replace internet of things, Cluster Computing, vol.",
        "22, no.",
        "S4, current infrastructure with the growing availability of low- pp.",
        "77337744,2019.",
        "cost storage, video infrastructure, and better video pro- 4 V.Babanne,N.S.Mahajan,R.L.Sharma,andP.P.Gargate, cessing technologies.",
        "Eventually, the digital monitoring Machine learning based smart surveillance system, in systems in terms of robots would fully replace current Proceedings of the 2019 Third International Conference on MathematicalProblemsinEngineering 9 I-SMAC IoT in Social, Mobile, Analytics and CloudI- 19 L.Pang,H.Liu,Y.Chen,andJ.Miao,Real-timeconcealed SMAC,pp.",
        "8486,IEEE, Palladam,India,December2019.",
        "object detection from passive millimeter wave images based 5 A.",
        "Joshi, N.",
        "Jagdale, R.",
        "Gandhi, and S.",
        "Chaudhari, Smart on the YOLOv3 algorithm, Sensors, vol.",
        "20, no.",
        "6, p.1678, surveillance system for detection of suspicious behaviour 2020.",
        "using machinelearning,in IntelligentComputing, Informa- 20 A.Warsi,M.Abdullah,M.N.Husen,M.Yahya,S.Khan,and tionandControlSystems.ICICCS2019.AdvancesinIntelligent N.",
        "Jawaid, Gun detection system using YOLOv3, in Pro- Systems and Computing, A.",
        "Pandian, K.",
        "Ntalianis, and ceedingsofthe2019IEEEInternationalConferenceonSmart R.",
        "Palanisamy, Eds., vol.",
        "1039, Berlin, Germany, Springer, Instrumentation, Measurement and Application ICSIMA, Cham,2020.",
        "pp.14,IEEE, KualaLumpur,Malaysia, August2019.",
        "6 K.-E.KoandK.-B.Sim,Deepconvolutionalframeworkfor 21 G.K.VermaandA.Dhillon,Ahandheldgundetectionusing abnormalbehaviordetectioninasmartsurveillancesystem, faster r-cnn deep learning, in Proceedings of the 7th Inter- Engineering Applications of Artificial Intelligence, vol.",
        "67, national Conference on Computer and Communication pp.226234, 2018.",
        "Technology, pp.",
        "8488, Kurukshetra, Haryana, November 7 S.",
        "Y.",
        "Nikouei, Y.",
        "Chen, S.",
        "Song, R.",
        "Xu, B.-Y.",
        "Choi, and 2017.",
        "T.Faughnan,Smartsurveillanceasanedgenetworkservice 22 S.B.KibriaandM.S.Hasan,Ananalysisoffeatureextraction from harr-cascade, SVM to a lightweight CNN, in Pro- andclassificationalgorithmsfordangerousobjectdetection, ceedings of the 2018 IEEE 4th International Conference on in Proceedings of the 2017 2nd International Conference on Collaboration and Internet Computing CIC, pp.",
        "256265, Electrical  Electronic Engineering ICEEE, pp.",
        "14, IEEE, Philadelphia,PA,USA,April2018.",
        "Rajshahi, Bangladesh,December2017.",
        "8 R.Xu,S.Y.Nikouei,Y.Chenetal.,Real-timehumanobjects 23 A.",
        "Castillo, S.",
        "Tabik, F.",
        "Perez, R.",
        "Olmos, and F.",
        "Herrera, trackingforsmartsurveillanceattheedge,inProceedingsof Brightness guided preprocessing for automatic cold steel the 2018 IEEE International Conference on Communications weapondetectioninsurveillancevideoswithdeeplearning, ICC, pp.16,KansasCity,MO,USA, May2018.",
        "Neurocomputing, vol.",
        "330,pp.151161, 2019.",
        "9 S.",
        "Ahmed, A.",
        "Ahmed, I.",
        "Mansoor, F.",
        "Junejo, and A.",
        "Saeed, 24 V.Gun, Database,http//kt.agh.edu.pl/grega/guns/.",
        "Output feedback adaptive fractional-order super-twisting slidingmodecontrolofroboticmanipulator,IranianJournal of Science and Technology, Transactions of Electrical Engi- neering,vol.",
        "45,no.1, pp.335347, 2021.",
        "10 S.Ahmed,H.Wang,andY.Tian,Adaptivefractionalhigh- order terminal sliding mode control for nonlinear robotic manipulator under alternating loads, Asian Journal of Control,2020.",
        "11 S.",
        "Ahmed, H.",
        "Wang, and Y.",
        "Tian, Adaptive high-order terminalslidingmodecontrolbasedontimedelayestimation fortheroboticmanipulatorswithbacklashhysteresis,IEEE Transactions on Systems, Man, and Cybernetics Systems, vol.",
        "51, no.2, pp.11281137, 2021.",
        "12 J.Redmon,S.Divvala,R.Girshick,andA.Farhadi,Youonly lookonceunified,real-timeobjectdetection,inProceedings of the IEEE Conference on Computer Vision and Pattern Recognition,pp.",
        "779788,Las Vegas,NV, USA,June 2016.",
        "13 A.",
        "Farhadi and R.",
        "Joseph, Yolov3 an incremental im- provement,ComputerVisionandPatternRecognition,2018.",
        "14 C.He,J.Shao,andJ.Sun,Ananomaly-introducedlearning methodforabnormaleventdetection,MultimediaToolsand Applications,vol.",
        "77, no.22,pp.",
        "2957329588,2018.",
        "15 Q.Hu,S.Paisitkriangkrai,C.Shen,A.vandenHengel,and F.Porikli,Fastdetectionofmultipleobjectsintrafficscenes withacommondetectionframework,IEEETransactionson Intelligent Transportation Systems, vol.",
        "17, no.",
        "4, pp.",
        "1002 1014, 2015.",
        "16 M.",
        "Grega, A.",
        "Matiolanski, P.",
        "Guzik, and M.",
        "Leszczuk, Au- tomateddetectionoffirearmsandknivesinaCCTVimage, Sensors,vol.16, no.1,p.",
        "47, 2016.",
        "17 H.",
        "Mousavi, S.",
        "Mohammadi, A.",
        "Perina, R.",
        "Chellali, and V.Murino,Analyzingtrackletsforthedetectionofabnormal crowd behavior, in Proceedings of the 2015 IEEE Winter ConferenceonApplicationsofComputerVision,pp.148155, IEEE,Waikoloa,HI,USA, January2015.",
        "18 S.Ji,W.Xu,M.Yang,andK.Yu,3Dconvolutionalneural networks for human action recognition, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.",
        "35, no.1, pp.221231, 2012."
      ],
      "word_count": 3274,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "<<interface>>\ndao"
        ],
        "data": [
          [
            "+getLocation()"
          ]
        ]
      },
      {
        "columns": [
          "connectivity"
        ],
        "data": [
          [
            "–Connection con"
          ],
          [
            "+connect()"
          ]
        ]
      },
      {
        "columns": [
          "dao_[mp]"
        ],
        "data": [
          [
            "+getLocation()"
          ]
        ]
      },
      {
        "columns": [
          "gundetection"
        ],
        "data": [
          [
            "+setRecord()"
          ]
        ]
      },
      {
        "columns": [
          "officialpanel"
        ],
        "data": [
          [
            "+getLoaction()"
          ]
        ]
      },
      {
        "columns": [
          "location"
        ],
        "data": [
          [
            "–float lat\n–float lon\n–strib = ng loc"
          ],
          [
            "+getFloat lat()\n+setFloat lat (float lat) : void\n+getFloat lon()\n+setFloat lon (float lon) : void\n+getString loc()\n+setString loc (String loc) : void"
          ]
        ]
      }
    ],
    "metadata": {
      "CreationDate": "D:20210511143909+05'30'",
      "Creator": "Aspose Ltd.",
      "ModDate": "D:20210512074854+00'00'",
      "Producer": "PDFsharp 1.32.2608-g (www.pdfsharp.net) (Original: Aspose.Pdf for .NET 10.1.0; modified using iTextSharp™ 5.4.0 ©2000-2012 1T3XT BVBA (AGPL-version))"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320- 2882 CROWD DETECTION AND MANAGEMENT IN SURVEILLANCE SYSTEM 1Nidhi Shetty,2Pooja Sankpal,3Priyanka Shripad,4Sandip Zade 1,2,3Student, 4Assistant Professor 1Electronics Department, 1Atharva College of Engineering, Mumbai, India Abstract The steady increase in population and overcrowding has become an unavoidable factor in any public gathering or on the street during any festive occasions. The development in technology has made monitoring smart and methods of tracking humans has advanced. In order to provide an aid to this problem, our project is proposing to provide technical support to manage the crowd by detecting humans and keeping in track the count of the people in the scene. In our study, we develop a system using Raspberry Pi 3 board that consists of ARMv8 CPU that detects the human heads and provide a count of humans in the region using OpenCV-Python. A Haar cascade classifier is trained for human head detection. Human tracking is achieved by indicating the direction of movement of the person. The results of the analysis will be helpful in managing the crowd in any area with high density of crowds. Index Terms  Haar Cascade Classifier, Adaboost Algorithm, Head Detection I. INTRODUCTION Indias high rate of increase in population, several times makes it difficult to manage it. In several occasions managing the crowd becomes a daunting task such as in temples during special occasions, in railway stations during peak hours, and so on. In this paper, we propose a method to manage the crowd by keeping in track the count of the people in the scene.The crowd can be navigated to disperse from the crowded region by tracking the people which provides the direction of movement of people. The crowded region will be defined by the maximum permissible count of humans in a particular area. Up until now different projects were using the tracking methods based on features like motion blobs, texture and color and head detection based on background modelling, head-shoulder detection using omega model and so on. This project focusses on training a cascade classifier for human head detection by taking positive samples images containing human heads and negative samples images containing plain background. II. CONCEPT In this project, we develop a system using Raspberry Pi 3 board that consists of ARMv8 CPU that detects the human heads and provide a count of humans in the region using OpenCV-Python. A Haar cascade classifier is trained for human head detection. The trained cascade is then used to process the video frames in which the human heads are detected and the count of the humans in the scene is provided. The detected human heads are then tracked using optical flow algorithm. This tracking provides the direction of motion of the persons in the scene. III. LITERATURE SURVEY Detection of objects by using a cascade of simple features was mainly introduced by researchers for face detection. 1 The role of Haar features extracted from an integral image in object detection is elaborated in their work. Another method of human detection was done by using human detector that was part-based. Parts may not be clearly visible as they depend on factors inter object occlusion, illumination, etc.234 Some other studies used foreground segmentation to detect presence of human. The background is subtracted from the frame and some types of filtering, for example Gaussian filtering, is done to extract human motion blobs out of the frame. This process is usually done in a grayscale image.56 Density based head detection has been demonstrated by some researchers. The density of the crowd is initially estimated from which the heads of the individual persons are detected.In certain researches energy coefficients are used in detection crowd.7 Head detection for tracking passengers in railway stations has also been a major field of study for many researchers. Many work has been done to look into the direction in which the passengers move through space coordinate information. IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 84 www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320- 2882 IV. BLOCK DIAGRAM Collect training samples using camera Positive Negative samples human samples other heads than human heads Train Haar Cascade Classifier Trained Cascade Classifier Real Time Video feed Interface of Raspberry Pi Detection and training of human heads Fig no. 1Working of project V. WORKING PRINCIPLE The working principle of this based on three basic concepts 5.1.Haar Cascade Classifier Object Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, Rapid Object Detection using a Boosted Cascade of Simple Features in 2001. It is a machine learning based approach where a cascade function is trained from a lotof positive and negative images. It is then used to detect objects in other images.1 5.2.Adaboost Algorithm Ada-boost or Adaptive Boosting is one of ensemble boosting classifier proposed in 1996.Adaboost uses an iterative procedure where different classifiers, that when used independently perform poorly, are combined to form a single strong classifier in order to increase the efficiency. Adaboost should meet two conditions, namely, athe classifier should be trained interactively on various weighed training examples, bIn each iteration, it tries to provide an excellent fit for these examples by minimizing training error.6 The procedure in which the adaboost works can be listed as follows1Initially, Adaboost selects a training subset randomly, 2It iteratively trains the AdaBoost machine learning model by selecting the training set based on the accurate prediction of the last training, 3It assigns the higher weight to wrong classified observations so that in the next iteration these observations will get the high probability for classification, 4Also, It assigns the weight to the trained classifier in each iteration according to the accuracy of the classifier. The more accurate classifier will get high weight, 5This process iterate until the complete training data fits without any error or until reached to the specified maximum number of estimators, 6To classify, perform a vote across all of the learning algorithms you built. IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 85 www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320- 2882 5.3.Optical Flow Algorithm Optical flow algorithm is based on how images in two consecutive frames form a pattern of motion due to the motion of either object or the camera. Each pattern acts as a 2D displacement vector field hence the head and tail of the arrow vector shows the direction of movement of the object from one from to another. Optical flow algorithm works on several assumptions aThe intensities of pixel of a point object does not differ between consecutive frames, bThe pixel being tracked should have motion similar to its neighbouring pixel.8 The optical flow diagram not only gives the direction in which the observer is moving and the objects in the background, but also the environment and structure of objects. VI. IMPLEMENTATION 6.1.Training In this project we firs train a haar cascade classifier to detect human heads in a crowd cascade classifier training involves collection of positive samples and negative samples.The positive samples are the images which contain human heads and the negative samples background images are the images that do not contain human heads. Separate videos are taken in an area with and without humans. The videos are then processed and the frames are segmented.5 Some of the samples we used for our training purpose. The frames with the humans are then subjected to an annotation tool which allows us to mark the human heads. The process of marking human heads consumes time but larger the number of images with marked human heads given as input better is the accuracy of head detection. Annotation tool is an Open CV application which, when executed, opens the images one after the other. A sample of our image with human heads marked using annotation tool .The tool outputs a text file containing in each line the path of each image followed by the pixel locations of the heads marked, each separated by a space. Positive samples are then created using the annotation tool output containing the pixel locations of marked human heads in the frame and the background images. The cascade classifier is then trained and it built the small stages of classifier. A cascade classifier consists of a cascade of small stages of classifier each classifying the sub-window on the basis of certain features. The stages in the trained cascade are sorted using Adaboost algorithm. The classifier uses the Haar features extracted from the positive samples. Some researches suggest that nstages should be ideally 20 and splits should be 2.npos indicates the number of positive samples and -nneg the number of negative samples. This step is extremely CPU intensive and can take several hours/days to complete. Fig no.2- Positive Samples IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 86 www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320- 2882 Fig no.3-Negative Sample Fig no. 4-Marking human heads using annotation tool 6.2.Detection We capture two real time videos in our institution using a 12 mega pixel camera one consisting of humans and the other with no persons in the scene. Surveillance cameras in crowd are specifically positioned in a particular angle and hence video is recorded in a specified angle and then trained using that video. We then segment each video into frames and save each in separate directories as positive and negative.34 The video is read each frame and each frame is made to pass through all the stages of cascade classifier. A sequence of increasingly complex classifiers is called a cascade. The positive images are then marked for human heads using annotation tool. In the training of our cascade classifier using real time video frames, we use 1000 positive samples and 4400 negative samples. The training of 20 stages cascade classifier takes about 5 days. The trained classifier is then used for head detection. Video frames taken in the same scenario are tested against the trained cascade classifier. In the frames, after passing through the twenty stages of the classifier, the head regions are detected and results are obtained. Each frame is compare with several sub windows. The compared window is either passed to the next stage or refused by that stage. A window must pass through all the stages. Any stage in the classifier may reject it. After a window passes through all the stages, it is detected as the human head. IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 87 www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320-2882 6.3.Tracking The detected human heads are then tracked for their position in successive frames to compute the direction of motion of any person. The tracking is done by optical flow concept. Using optical flow concept, the corners of the bounding box indicating the human heads in a frame are fetched and the corresponding pixels in the successive frames are then found.3 The movement of a person is determined by comparing the pixel values in each frame. Each person is tracked individually.4 VII. APPLICATION Crowd detection can be used in local trains, buses and other daily vehicle services. One would be able to organize the frequency of trains as well as the timings of the trains based on live feed of head counts. It will be beneficial for the commuters since they wont have to face the exhaustion of travelling daily alongwith large crowds. Tracking of human heads can be applied for surveillance purposes. It will be useful in tracking suspicious individuals or to scan a particular area for thieves. Another application of human crowd detection and analysis is in cases of emergency evacuations. They can be planned using by studying about how crowd interacts with each other and how it reacts to certain situations. These are based on biological models and patterns, thus the movements predicted are seemingly accurate.The above mentioned model is apparently utilized within film industries to produce realistic and lifelike simulations and scenes which comes under cgi. Other applications can be listed as follows1. Improving a human detector using superpixels. a An algorithm to improve a generic human detector using an unsupervised learning framework. b Representation of humans in terms of superpixel-based Bag-of-Words representation. 2. Part-based multiple-human tracking with occlusion handling a An algorithm to track multiple humans using online-learned person- specific classifiers. b Representation of humans in terms of part-based model to capture the appearance variations. c An occlusion handling approach to improve human detection performance in crowded scenes. d An approach to overcome partial occlusions for human tracking. 3. Multiple-human segmentation leveraging human detector a An algorithm to automatically segment multiple humans in videos based on human detections. b Representation of humans in terms of the part-based detection potentials to capture the spatial distribution c A new approach to using tracklet-based CRF optimization to smooth the segmentation boundaries. 4. NONA An efficient tracking system a A computer vision system for real-time human tracking in high- resolution videos. b A multi-threaded architecture to process video ingestion, tracking and video output simultaneously. c A novel approach to using local frame differencing to handle long-term occlusion. VIII. FUTURE SCOPE Tracking a target across different cameras would be a very useful application for wide area surveillance. The challenge is to Crowd behavior analysis is going to be the future talk which is sometimes also reffered as crowd artificial intelligence or swarm intelligence. However, there are some difficulties in analyzing behavior in a crowd scene. In order to achieve the goal, the analyzing procedure must be done comprehensively through video surveillance. Human instincts are put to test and are applied to biological and artificial models that form a complex system of multiple agents and their interactions. This section explores some of the possible directions our work may be taken in the future. Motion-based human detection Our proposed human detection method used only static features such as superpixels or HOG, while in videos the motion features, e.g. Histogram of 124 Optical Flow HOF, can also provide very discriminative information. Since the local motion patterns of humans are different from the background or other objects, these correctly associate a person appearing in different cameras, each with differing viewpoints and lighting, whilst considering the spatial and temporal constraints. Human pose estimation based on segmentation. One interesting area to explore is estimating human poses in videos. IX. CONCLUSION Crowd management using head detection is realized using computer vision in our study, implementing our study using video taken from our institution. We use Haar features and Adaboost algorithm to detect the persons head region. We track the human using optical flow concept. Using increased number of samples, the results are found to be efficient. The human detection and tracking can generally be used in surveillance tasks. IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 88 www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320-2882 X. REFERENCE LIST 1 Paul Viola and Michael Jones, Rapid Object Detection using a Boosted Cascade of Simple Features, Mitsubishi Electric Research Labs, Cambridge, 2001, IEEE. 2 P.Papageorgiou, Micheal Oren and Tornaso Poggio, A General Framework for Object Detection, Center for Biological and Computational Learning Artificial Intelligence Laboratory, Cambridge. 3 Ashfin Dehghan, Haroon Idrees, Amir Roshan Zamir and Mubrarak Shah, Automatic Detection and Tracking of Pedestrians in Videos with Various Crowd Densities, Computer Vision Lab, University of Central Florida, Orlando,USA, 2014, Springer International Publishing Switzerland. 4 Energetic, Electronic and Communication Engineering Vol2, No10, 2008. 5 Songyan Ma and Tiancang Du. Improved Adoboost face detection, International Conference on Measuring Technology and Mechatronics Automation, Changsha, 2010. 6 Mikel Rodriguez, Ivan Laptev, Josef Sivic and Jean- Y ves Audibert, Density-aware person detection and tracking in crowds, Imagine, LIGM, Universite Paris-Est. IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 89",
    "structured_text": {
      "sentences": [
        "www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320- 2882 CROWD DETECTION AND MANAGEMENT IN SURVEILLANCE SYSTEM 1Nidhi Shetty,2Pooja Sankpal,3Priyanka Shripad,4Sandip Zade 1,2,3Student, 4Assistant Professor 1Electronics Department, 1Atharva College of Engineering, Mumbai, India Abstract The steady increase in population and overcrowding has become an unavoidable factor in any public gathering or on the street during any festive occasions.",
        "The development in technology has made monitoring smart and methods of tracking humans has advanced.",
        "In order to provide an aid to this problem, our project is proposing to provide technical support to manage the crowd by detecting humans and keeping in track the count of the people in the scene.",
        "In our study, we develop a system using Raspberry Pi 3 board that consists of ARMv8 CPU that detects the human heads and provide a count of humans in the region using OpenCV-Python.",
        "A Haar cascade classifier is trained for human head detection.",
        "Human tracking is achieved by indicating the direction of movement of the person.",
        "The results of the analysis will be helpful in managing the crowd in any area with high density of crowds.",
        "Index Terms  Haar Cascade Classifier, Adaboost Algorithm, Head Detection I.",
        "INTRODUCTION Indias high rate of increase in population, several times makes it difficult to manage it.",
        "In several occasions managing the crowd becomes a daunting task such as in temples during special occasions, in railway stations during peak hours, and so on.",
        "In this paper, we propose a method to manage the crowd by keeping in track the count of the people in the scene.The crowd can be navigated to disperse from the crowded region by tracking the people which provides the direction of movement of people.",
        "The crowded region will be defined by the maximum permissible count of humans in a particular area.",
        "Up until now different projects were using the tracking methods based on features like motion blobs, texture and color and head detection based on background modelling, head-shoulder detection using omega model and so on.",
        "This project focusses on training a cascade classifier for human head detection by taking positive samples images containing human heads and negative samples images containing plain background.",
        "II.",
        "CONCEPT In this project, we develop a system using Raspberry Pi 3 board that consists of ARMv8 CPU that detects the human heads and provide a count of humans in the region using OpenCV-Python.",
        "A Haar cascade classifier is trained for human head detection.",
        "The trained cascade is then used to process the video frames in which the human heads are detected and the count of the humans in the scene is provided.",
        "The detected human heads are then tracked using optical flow algorithm.",
        "This tracking provides the direction of motion of the persons in the scene.",
        "III.",
        "LITERATURE SURVEY Detection of objects by using a cascade of simple features was mainly introduced by researchers for face detection.",
        "1 The role of Haar features extracted from an integral image in object detection is elaborated in their work.",
        "Another method of human detection was done by using human detector that was part-based.",
        "Parts may not be clearly visible as they depend on factors inter object occlusion, illumination, etc.234 Some other studies used foreground segmentation to detect presence of human.",
        "The background is subtracted from the frame and some types of filtering, for example Gaussian filtering, is done to extract human motion blobs out of the frame.",
        "This process is usually done in a grayscale image.56 Density based head detection has been demonstrated by some researchers.",
        "The density of the crowd is initially estimated from which the heads of the individual persons are detected.In certain researches energy coefficients are used in detection crowd.7 Head detection for tracking passengers in railway stations has also been a major field of study for many researchers.",
        "Many work has been done to look into the direction in which the passengers move through space coordinate information.",
        "IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 84 www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320- 2882 IV.",
        "BLOCK DIAGRAM Collect training samples using camera Positive Negative samples human samples other heads than human heads Train Haar Cascade Classifier Trained Cascade Classifier Real Time Video feed Interface of Raspberry Pi Detection and training of human heads Fig no.",
        "1Working of project V.",
        "WORKING PRINCIPLE The working principle of this based on three basic concepts 5.1.Haar Cascade Classifier Object Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, Rapid Object Detection using a Boosted Cascade of Simple Features in 2001.",
        "It is a machine learning based approach where a cascade function is trained from a lotof positive and negative images.",
        "It is then used to detect objects in other images.1 5.2.Adaboost Algorithm Ada-boost or Adaptive Boosting is one of ensemble boosting classifier proposed in 1996.Adaboost uses an iterative procedure where different classifiers, that when used independently perform poorly, are combined to form a single strong classifier in order to increase the efficiency.",
        "Adaboost should meet two conditions, namely, athe classifier should be trained interactively on various weighed training examples, bIn each iteration, it tries to provide an excellent fit for these examples by minimizing training error.6 The procedure in which the adaboost works can be listed as follows1Initially, Adaboost selects a training subset randomly, 2It iteratively trains the AdaBoost machine learning model by selecting the training set based on the accurate prediction of the last training, 3It assigns the higher weight to wrong classified observations so that in the next iteration these observations will get the high probability for classification, 4Also, It assigns the weight to the trained classifier in each iteration according to the accuracy of the classifier.",
        "The more accurate classifier will get high weight, 5This process iterate until the complete training data fits without any error or until reached to the specified maximum number of estimators, 6To classify, perform a vote across all of the learning algorithms you built.",
        "IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 85 www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320- 2882 5.3.Optical Flow Algorithm Optical flow algorithm is based on how images in two consecutive frames form a pattern of motion due to the motion of either object or the camera.",
        "Each pattern acts as a 2D displacement vector field hence the head and tail of the arrow vector shows the direction of movement of the object from one from to another.",
        "Optical flow algorithm works on several assumptions aThe intensities of pixel of a point object does not differ between consecutive frames, bThe pixel being tracked should have motion similar to its neighbouring pixel.8 The optical flow diagram not only gives the direction in which the observer is moving and the objects in the background, but also the environment and structure of objects.",
        "VI.",
        "IMPLEMENTATION 6.1.Training In this project we firs train a haar cascade classifier to detect human heads in a crowd cascade classifier training involves collection of positive samples and negative samples.The positive samples are the images which contain human heads and the negative samples background images are the images that do not contain human heads.",
        "Separate videos are taken in an area with and without humans.",
        "The videos are then processed and the frames are segmented.5 Some of the samples we used for our training purpose.",
        "The frames with the humans are then subjected to an annotation tool which allows us to mark the human heads.",
        "The process of marking human heads consumes time but larger the number of images with marked human heads given as input better is the accuracy of head detection.",
        "Annotation tool is an Open CV application which, when executed, opens the images one after the other.",
        "A sample of our image with human heads marked using annotation tool .The tool outputs a text file containing in each line the path of each image followed by the pixel locations of the heads marked, each separated by a space.",
        "Positive samples are then created using the annotation tool output containing the pixel locations of marked human heads in the frame and the background images.",
        "The cascade classifier is then trained and it built the small stages of classifier.",
        "A cascade classifier consists of a cascade of small stages of classifier each classifying the sub-window on the basis of certain features.",
        "The stages in the trained cascade are sorted using Adaboost algorithm.",
        "The classifier uses the Haar features extracted from the positive samples.",
        "Some researches suggest that nstages should be ideally 20 and splits should be 2.npos indicates the number of positive samples and -nneg the number of negative samples.",
        "This step is extremely CPU intensive and can take several hours/days to complete.",
        "Fig no.2- Positive Samples IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 86 www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320- 2882 Fig no.3-Negative Sample Fig no.",
        "4-Marking human heads using annotation tool 6.2.Detection We capture two real time videos in our institution using a 12 mega pixel camera one consisting of humans and the other with no persons in the scene.",
        "Surveillance cameras in crowd are specifically positioned in a particular angle and hence video is recorded in a specified angle and then trained using that video.",
        "We then segment each video into frames and save each in separate directories as positive and negative.34 The video is read each frame and each frame is made to pass through all the stages of cascade classifier.",
        "A sequence of increasingly complex classifiers is called a cascade.",
        "The positive images are then marked for human heads using annotation tool.",
        "In the training of our cascade classifier using real time video frames, we use 1000 positive samples and 4400 negative samples.",
        "The training of 20 stages cascade classifier takes about 5 days.",
        "The trained classifier is then used for head detection.",
        "Video frames taken in the same scenario are tested against the trained cascade classifier.",
        "In the frames, after passing through the twenty stages of the classifier, the head regions are detected and results are obtained.",
        "Each frame is compare with several sub windows.",
        "The compared window is either passed to the next stage or refused by that stage.",
        "A window must pass through all the stages.",
        "Any stage in the classifier may reject it.",
        "After a window passes through all the stages, it is detected as the human head.",
        "IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 87 www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320-2882 6.3.Tracking The detected human heads are then tracked for their position in successive frames to compute the direction of motion of any person.",
        "The tracking is done by optical flow concept.",
        "Using optical flow concept, the corners of the bounding box indicating the human heads in a frame are fetched and the corresponding pixels in the successive frames are then found.3 The movement of a person is determined by comparing the pixel values in each frame.",
        "Each person is tracked individually.4 VII.",
        "APPLICATION Crowd detection can be used in local trains, buses and other daily vehicle services.",
        "One would be able to organize the frequency of trains as well as the timings of the trains based on live feed of head counts.",
        "It will be beneficial for the commuters since they wont have to face the exhaustion of travelling daily alongwith large crowds.",
        "Tracking of human heads can be applied for surveillance purposes.",
        "It will be useful in tracking suspicious individuals or to scan a particular area for thieves.",
        "Another application of human crowd detection and analysis is in cases of emergency evacuations.",
        "They can be planned using by studying about how crowd interacts with each other and how it reacts to certain situations.",
        "These are based on biological models and patterns, thus the movements predicted are seemingly accurate.The above mentioned model is apparently utilized within film industries to produce realistic and lifelike simulations and scenes which comes under cgi.",
        "Other applications can be listed as follows1.",
        "Improving a human detector using superpixels.",
        "a An algorithm to improve a generic human detector using an unsupervised learning framework.",
        "b Representation of humans in terms of superpixel-based Bag-of-Words representation.",
        "2.",
        "Part-based multiple-human tracking with occlusion handling a An algorithm to track multiple humans using online-learned person- specific classifiers.",
        "b Representation of humans in terms of part-based model to capture the appearance variations.",
        "c An occlusion handling approach to improve human detection performance in crowded scenes.",
        "d An approach to overcome partial occlusions for human tracking.",
        "3.",
        "Multiple-human segmentation leveraging human detector a An algorithm to automatically segment multiple humans in videos based on human detections.",
        "b Representation of humans in terms of the part-based detection potentials to capture the spatial distribution c A new approach to using tracklet-based CRF optimization to smooth the segmentation boundaries.",
        "4.",
        "NONA An efficient tracking system a A computer vision system for real-time human tracking in high- resolution videos.",
        "b A multi-threaded architecture to process video ingestion, tracking and video output simultaneously.",
        "c A novel approach to using local frame differencing to handle long-term occlusion.",
        "VIII.",
        "FUTURE SCOPE Tracking a target across different cameras would be a very useful application for wide area surveillance.",
        "The challenge is to Crowd behavior analysis is going to be the future talk which is sometimes also reffered as crowd artificial intelligence or swarm intelligence.",
        "However, there are some difficulties in analyzing behavior in a crowd scene.",
        "In order to achieve the goal, the analyzing procedure must be done comprehensively through video surveillance.",
        "Human instincts are put to test and are applied to biological and artificial models that form a complex system of multiple agents and their interactions.",
        "This section explores some of the possible directions our work may be taken in the future.",
        "Motion-based human detection Our proposed human detection method used only static features such as superpixels or HOG, while in videos the motion features, e.g.",
        "Histogram of 124 Optical Flow HOF, can also provide very discriminative information.",
        "Since the local motion patterns of humans are different from the background or other objects, these correctly associate a person appearing in different cameras, each with differing viewpoints and lighting, whilst considering the spatial and temporal constraints.",
        "Human pose estimation based on segmentation.",
        "One interesting area to explore is estimating human poses in videos.",
        "IX.",
        "CONCLUSION Crowd management using head detection is realized using computer vision in our study, implementing our study using video taken from our institution.",
        "We use Haar features and Adaboost algorithm to detect the persons head region.",
        "We track the human using optical flow concept.",
        "Using increased number of samples, the results are found to be efficient.",
        "The human detection and tracking can generally be used in surveillance tasks.",
        "IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 88 www.ijcrt.org  2020 IJCRT  Volume 8, Issue 3 March 2020  ISSN 2320-2882 X.",
        "REFERENCE LIST 1 Paul Viola and Michael Jones, Rapid Object Detection using a Boosted Cascade of Simple Features, Mitsubishi Electric Research Labs, Cambridge, 2001, IEEE.",
        "2 P.Papageorgiou, Micheal Oren and Tornaso Poggio, A General Framework for Object Detection, Center for Biological and Computational Learning Artificial Intelligence Laboratory, Cambridge.",
        "3 Ashfin Dehghan, Haroon Idrees, Amir Roshan Zamir and Mubrarak Shah, Automatic Detection and Tracking of Pedestrians in Videos with Various Crowd Densities, Computer Vision Lab, University of Central Florida, Orlando,USA, 2014, Springer International Publishing Switzerland.",
        "4 Energetic, Electronic and Communication Engineering Vol2, No10, 2008.",
        "5 Songyan Ma and Tiancang Du.",
        "Improved Adoboost face detection, International Conference on Measuring Technology and Mechatronics Automation, Changsha, 2010.",
        "6 Mikel Rodriguez, Ivan Laptev, Josef Sivic and Jean- Y ves Audibert, Density-aware person detection and tracking in crowds, Imagine, LIGM, Universite Paris-Est.",
        "IJCRT2003013 International Journal of Creative Research Thoughts IJCRT www.ijcrt.org 89"
      ],
      "word_count": 2632,
      "sections": {}
    },
    "tables": [],
    "metadata": {
      "Title": "IJRTI",
      "Author": "Hitesh",
      "Creator": "Microsoft® Word 2016",
      "CreationDate": "D:20200304170148+05'30'",
      "ModDate": "D:20200304170148+05'30'",
      "Producer": "Microsoft® Word 2016"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "ReceivedJanuary13,2021,acceptedFebruary1,2021,dateofpublicationFebruary12,2021,dateofcurrentversionMarch4,2021. DigitalObjectIdentifier10.1109/ACCESS.2021.3059170 Weapon Detection in Real-Time CCTV Videos Using Deep Learning MUHAMMADTAHIRBHATTI 1,MUHAMMADGUFRANKHAN 1,SeniorMember,IEEE, MASOODASLAM 2,ANDMUHAMMADJUNAIDFIAZ1 1DepartmentofElectricalEngineering,NationalUniversityofComputerandEmergingSciences,Faisalabad35400,Pakistan 2DepartmentofElectricalEngineering,ComsatsUniversityIslamabad,Islamabad45550,Pakistan CorrespondingauthorMuhammadTahirBhattitahir.bhatti320gmail.com ThisworkwassupportedbytheHigherEducationCommissionHECofPakistanthroughtheTechnologyDevelopmentFundTDF underGrantTDF-02-161. ABSTRACT Securityandsafetyisabigconcernfortodaysmodernworld.Foracountrytobeeconomically strong, it must ensure a safe and secure environment for investors and tourists. Having said that, Closed CircuitTelevisionCCTVcamerasarebeingusedforsurveillanceandtomonitoractivitiesi.e.robberies butthesecamerasstillrequirehumansupervisionandintervention.Weneedasystemthatcanautomatically detect these illegal activities. Despite state-of-the-art deep learning algorithms, fast processing hardware, and advanced CCTV cameras, weapon detection in real-time is still a serious challenge. Observing angle differences,occlusionsbythecarrierofthefirearmandpersonsarounditfurtherenhancesthedifficultyofthe challenge.ThisworkfocusesonprovidingasecureplaceusingCCTVfootageasasourcetodetectharmful weapons by applying the state of the art open-source deep learning algorithms. We have implemented binary classification assuming pistol class as the reference class and relevant confusion objects inclusion concept is introduced to reduce false positives and false negatives. No standard dataset was available for real-timescenariosowemadeourowndatasetbymakingweaponphotosfromourowncamera,manually collected images from internet, extracted data from YouTube CCTV videos, through GitHub repositories, databyuniversityofGranadaandInternetMoviesFirearmsDatabaseIMFDBimfdb.org.Twoapproaches are used i.e. sliding window/classification and region proposal/object detection. Some of the algorithms usedareVGG16,Inception-V3,Inception-ResnetV2,SSDMobileNetV1,Faster-RCNNInception-ResnetV2 FRIRv2, YOLOv3, and YOLOv4. Precision and recall count the most rather than accuracy when object detection is performed so these entire algorithms were tested in terms of them. Yolov4 stands out best amongstallotheralgorithmsandgaveaF1-scoreof91alongwithameanaverageprecisionof91.73 higherthanpreviouslyachieved. INDEXTERMS Gundetection,deeplearning,objectdetection,artificialintelligence,computervision. I. INTRODUCTION what we speak or write has an impact on the people. Even Thecrimerateacrosstheglobehasincreasedmainlybecause if the news they heard is crafted having no truth but as it ofthefrequentuseofhandheldweaponsduringviolentactiv- getsviralinafewhoursbecauseofthemediaandespecially ity. For a country to progress, the law-and-order situation socialmedia,thedamagewillbedone.Peoplenowhavemore mustbeincontrol.Whetherwewanttoattractinvestorsfor depression and have less control over their anger, and hate investmentortogeneraterevenuewiththetourismindustry, speeches can get those people to lose their minds. People alltheseneedsisapeacefulandsafeenvironment.Thecrime canbebrainwashedandpsychologicalstudiesshowthatifa ratio because of guns is very critical in numerous parts of personhasaweaponinthissituation,hemaylosehissenses the world. It includes mainly those countries in which it is andcommitaviolentactivity. legaltokeepafirearm.Theworldisaglobalvillagenowand High incidents were recorded in past few years with the use of harmful weapons in public areas. Starting with the The associate editor coordinating the review of this manuscript and pastyearsattacksonacoupleofMosquesinNewZealand, approvingitforpublicationwasShadiAlawneh . on March 15, 2019 at 140 pm, the attacker attacks the ThisworkislicensedunderaCreativeCommonsAttribution-NonCommercial-NoDerivatives4.0License. 34366 Formoreinformation,seehttps//creativecommons.org/licenses/by-nc-nd/4.0/ VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning ChristchurchAL-NoorMosqueduringaFridayprayerkilling of selecting features manually, CNN automatically learns almost 44 innocent and unarmed worshippers. On the same featuresfromgivendata. day just after 15 minutes at 155 PM, another attack hap- This article presents an automatic detection and classifi- pened killing seven more civilians 1. Active shooter inci- cationmethodofweaponsforreal-timescenariousingstate dents had also occurred in USA and then in Europe. The of the art deep learning models. For real-time implemen- mostsignificantcaseswerethoseatColumbineHighSchool tation relating the problem question of this work detect- USA, 37 victims, Andreas Broeiviks assault on Uotya ingweaponsinreal-timeforpotentialrobbers/terroristusing IslandNorway,179victimsortheCharlieHebdonewspaper deep learning, detection and classification was done for attackkilling23.AccordingtostatsprovidedbytheUNODC, pistol, revolver and other shot handheld weapons as in sin- among0.1Millionpeopleofacountry,thecrimesinvolving gle class called pistol and related confusion objects such as gunsareveryhighi-e.1.6inBelgium,UnitedStateshaving cell phone, metal detector, wallet, selfie stick in not pistol 4.7andMexicowithanumberof21.52. class. A major reason behind this was our research done on CCTV cameras play an important role to overcome this weapons used in robbery cases and it further motivated us problemandareconsideredtobeoneofthemostimportant to choose pistol and revolver as our target object. We go requirementsforthesecurityaspect.3.CCTVsareinstalled throughseveralCCTVcapturedrobberyvideosonYouTube ineverypublicplacetodayandaremainlyusedforproviding and found that almost 95 of cases have pistol or revolver safety, crime investigation, and other security measures for astheweaponused.Withtheimplementationofthissystem, detection. CCTV footage is the most important evidence in manyrobberycrimes,andotherincidentslikewhathappened courts.Afteracrimeiscommitted,lawenforcementagencies last year in New Zealands Christchurch mosque could be arriveatthesceneandtaketherecordingoffootagewiththem controlledusingearlyalarmsystembyalertingtheoperator 4.Ifwelookatthesurveillancesystemofdifferentcountries andconcernedauthoritiessoactioncanbetakenimmediately. aroundtheworld,UKhasabout4.5millioncameras,which Gun detection in real-time is a very challenging task. are used for surveillance. Sweden has about 50000 cameras As our desired object has a small size so, detecting it in an installed around 2010. The government of Poland was able image is also very challenging in presence of other objects, to reduce drug cases by 60 and street fights by 40 by especially those objects that can be confused with it. Deep installing just 450 cameras in the city of Poznan 5. China learning models faced several below mentioned challenges hastheworldsbiggestsurveillancesystemand170million fordetectionandclassificationtask camerasaroundthenation,andtheseareexpectedtoexpand  The first and main problem is the data through which threetimes,throughanadditional400milliontobeconnected CNNlearnitsfeaturestobeusedlaterforclassification by 2020. It took only seven minutes for Chinese officials anddetection. to find and apprehend BBC reporter John Sudworth using  Nostandarddatasetwasavailableforweapons. their strong CCTV cameras network and facial recognition  For real-time scenarios, making a novel dataset manu- technologyandputthecriminalbehindthebar6. allywasaverylongandtime-consumingprocess. In previous years, though having surveillance cameras  Labelingthedesireddatabaseisnotaneasytask,asall installed, to use them for security purposes was not an easy dataneedstobelabeledmanually. and dependable method. A human has to be there all the  Different detection algorithms were used, so a labeled timetomonitorscreens.CCTVoperatorhastomonitor20- datasetforonealgorithmcannotbeutilizedfortheother 25screensfor10hours.Hehastolook,observe,identify,and one. controlthesituationthatcanbeharmfultotheindividualsand  Every algorithm requires different labeling and pre- theproperty.Asthenumberofscreensincreases,theconcen- processingoperationsforthesame-labeleddatabase. trationofthepersondecreasesconsiderablytomonitoreach  As for real-time implementation, detection systems screen with time. It is impossible for the person monitoring require the exact location of the weapon so gun block- thescreenstokeepthesamelevelofattentionallthetime7. ingorocclusionisalsoaproblemthatarisesfrequently The solution to aforementioned problem is to install anditcouldoccurbecauseofself,inter-object,orback- surveillancecameraswiththeabilitytoautomaticallydetect groundblocking. weaponsandraisealarmtoalerttheoperatorsorsecurityper- sonals.However,thereisnotmuchworkdoneonalgorithms Different approaches are used in this work for weapon for weapon detection in surveillance cameras, and related classificationanddetectionpurposebutallhavedeeplearning studies are often considering concealed weapon detection and CNN architecture behind them because oftheir state of CWD, mostly using X-rays or millimeter waves images the art performance. Training from scratch took very much employingtraditionalmachinelearningtechniques812. time so the Transfer learning approach was used and Ima- In the past few years, deep learning in particular convo- geNet and COCO common objects in context pre-trained lutional neural network CNN has given groundbreaking models are used. Different datasets were made for classifi- results in object categorizing and detection. It has achieved cation and detection. For real-time purposes, we made our finest results thus far in classical problems of image pro- datasetbytakingweaponphotosfromthecamera,datawas cessingsuchasgrouping,detectionandlocalization.Instead extractedmanuallyfromrobberyCCTVvideos,downloaded VOLUME9,2021 34367 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning fromimfdbinternetmoviefirearmdatabase,databyuniver- detect hidden weapons in a situation where the image of sityofGranadaandotheronlinerepositories.Alltheworkhas the scene was present over and under exposed area. Their beendonetoachieveresultsinreal-time. methodologywastoapplyahomomorphicfiltercapturedat Themaincontributionsofthisworkarepresentationofa distinct exposure conditions to visual and IR pictures 16. first detailed and comprehensive work on weapon detection Current techniques attain high precision by using various that can achieve detection in videos from real-time CCTV combinations of extractors and detectors, either by using andworkswelleveninlowresolutionandbrightnessbecause easy intensity descriptors, boundary detection, and pattern most of the work done earlier is on high definition training matching9orbyusingmorecomplicatedtechniquessuch images but realtime scenario needs realtime training data ascascadeclassifierswithboosting. as well for better results, finding of the most suitable and CWD though had worked for some sort of cases but it appropriateCNNbasedobjectdetectorfortheapplicationof had many limitations. These systems were based on metal weapondetectioninreal-timeCCTVvideostreams,making detection non-metallic guns cannot be detected. They were ofanewdatasetbecausereal-timedetectionalsoneedsreal- costly to use in many locations because they need to be timetrainingdatasowemadeanewdatabaseof8327images coupledwithX-rayscannersandconveyorbeltsandresponds andpreprocesseditusingdifferentOpenCVfiltersi.e.Equal- to all metallic objects, so were not accurate. Economic cost ized, Grayscale and clahe that helped in detecting images andhealthriskslimitedthepracticalimplementationofsuch inlowbrightnessandresolution,introducingtheconceptof methods. Furthermore, video-based firearm detection was a relatedconfusionclassestoreducefalsepositivesandnega- preventivemeasureforacousticdetectionofgunshotandcan tives,trainingandtestingofournoveldatabaseonthelatest becombinedwithitforimplementation17,18. state of the deep learning based classification and detection Theideaofautomatedimageprocessingforpublicsecurity modelsamongthemYolov4performedbestintermsofboth purposesinmanyfieldshasbeenwellrecognizedandstudied. speed and accuracy and our selected trained model predict CCTVwastheultimateneedforthiskindofworktoprogress. imagesatalmosteveryorientation,angle,andview,achieving CCTV was first used back in 1946 in Germany and at that the highest mean average precision of 91.73 along with a time, these cameras were installed to observe the launch of F1-scoreof91onYolov4. a rocket named V2 19. Although it had been used earlier, Therestofthepaperisorganizedasfollowsrelatedwork majorimprovementshappenedinthelasttwodecades.With isdiscussedinSectionII.Theimplementationmethodology the advancement in CCTV technology, visual object recog- basedondeeplearningalgorithmsisexplainedinSectionIII. nition and detection for surveillance, control, and security Thedatasetconstruction,annotation,andpreprocessingusing were performed. In 1973, Charge-Coupled Device CCD different filters have been discussed in section IV, which was developed, which made the deployment of surveillance follows the experiments and results in Section V. Finally, cameras possible by 1980 20. If we go a bit forward in theconclusionandfutureworkisdiscussedinSectionVI. time,acompanynamedAxisCommunicationdevelopedthe first-evernetworkcamera,whichenabledthetransformation II. RELATEDWORK of surveillance cameras from analog to digital 20. This Theproblemofdetectionandclassificationofobjectsinreal- transformation of analog to digital video made it possible time started after major developments in the CCTV field, for everyone to apply image processing, machine learning, processing hardware, and deep learning models. Very little and computer vision techniques on videos recorded from work has been done in this field before and most of the surveillancecameras.In2003,RoyalPalmMiddleSchoolin previous effort was related to concealed weapon detection Phoenixusedfacialrecognitionforthefirsttimefortracking CWD. missingchildren. StartingwithconcealedweapondetectionCWD,before Several object detection algorithms were proposed in the its use in weapon detection, it was used for luggage control fieldofcomputervisiontomakesurveillancesystembetter. and other security purposes at airports and was based on Objectdetectionalgorithmswereusedinseveralsectorslike imagingtechniqueslikemillimeter-waveandinfraredimag- anomaly detection, deterrence, human detection, and traffic ing8.Sheenetal.suggestedCWDmethodbasedonathree- monitoring 21. R. Chellapa et.al. discussed briefly object dimensional millimeter mm wave imaging method, for tracking and detection in surveillance cameras 22. The detectinghiddenweaponsatairportsandothersafelocations authors had explained the tracking of an object using mul- in the body 13. Z. Xue et al. suggested a CWD technique tiple surveillance cameras. Another author addressed tech- basedonafusion-basedtechniqueofmulti-scaledecomposi- niques for detecting objects that come into contact with tion,whichcombinescolorvisualpicturewithinfraredIR another object and are occluded. They also wrote regarding picture integration 14. R. Blum et al. suggested a CWD the segmentation of mean fluctuations. They outlined how methodbasedontheinclusionofvisualpictureandIRormm mean segmentation of shifts can help detect objects. They wave picture using a multi-resolution mosaic technique to used a Bayesian Kalman filter with a simplified Gaussian highlightthehiddenweaponofthetargetpicture15. blend BKF-SGM algorithm to track the detected object E.M.Upadhyayet.al.suggestedaCWDtechniqueusing 23.J.SMarquesproposeddistincttechniquesforevaluating image fusion. They used IR image and visual fusion to the efficiency of distinct algorithms for object recognition 34368 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning 24. B. Triggs et.al. described histogram oriented gradient learnedthedeeprepresentationofthedataandreducedalot HOG.HOGbecameanovelarchitectureforfeatureextrac- ofmanualwork,andsavedtimeandenergy. tion. It was used mostly in applications involved in human RohithVajhalaetal.proposedthetechniqueofknifeand detection 25. In 2005, the sliding window technique was gun detection in surveillance systems. They had used HOG proposedfortherecognitionofnumberplates26.Theyhad asafeatureextractoralongwithbackpropagationofartificial usedaslidingwindowforthepurposeofsegmentationanda neural networks for classification purposes. The detection neuralnetworkforcharacterrecognitiononthenumberplate. was performed using different scenarios, first weapon only Asdescribedabove,objectiondetectionforthecomputer and then using HOG and background subtraction methods visiontaskswasusedforsomeapplicationswithbigobjects for human before the desired object and claimed to have to identity like a person, transport or traffic monitoring, an accuracy of 83 34. The aforementioned work uses etc. Literature review on weapon detection left me with the the CNN along with non-linearity of ReLu, convolutional opinionthatregardlessofmanyobjectdetectionalgorithms, neurallayer,fullyconnectedlayer,anddropoutlayerofCNN the algorithms proposed for weapon detection are very few. to reach a result for detection with multiple classes and At last, the idea of firearm detection using the images and implemented their work using the Tensor flow open-source videoswasproposedandfalsealarmswerereducedbyclas- platform. Their system achieved a test accuracy of 90.2  sifying neural networks with region-based descriptors and for their dataset 35. MichałGrega et al. proposed knives determiningregionofinterestROIusingtheslidingwindow and firearm detection in CCTV images. They had applied techniqueandthentrainedtheneuralnetworkclassifierwith MPEG-7 and principle component analysis along with the imagepixels27. slidingwindowapproach,whichmadetheirworkslowerfor With the development in CCTVs, object detection for real-time scenarios, although they claimed to achieve good different computer vision problems for real-time were per- accuracyontheirtestdataset.5. formedandtheideatodetectfirearmswereintroducedfirst Verma et al. had also used the deep learning technique by L. Ward et al. in 2007 28 and a surveillance system to detect weapons and used the Faster RCNN model. The was also implemented by them a year later in 2008 29. work was performed on imfdb, which in my opinion is not Intheaforementionedwork,writerscreatedanaccuratepistol suitable to train a model for real-time case. They claimed detection model for RGB pictures. However, in the same to have an accuracy of 93.1 on that dataset but in the scene,theirmethoddidnotdetectvariouspistols11,10, case of weapon detection, only achieving higher accuracy 29. The approach used comprises of first removing non- is not enough, and precision and recall must the considered related items from the segmented picture using the K-mean 36. Siham Tabik et al. work was very much related to clustering algorithm and then applying the SURF Speed the real-time scenario. They used Faster RCNN to detect up Robust Features method to detect points of interest. weapons in real-time using sliding window and region pro- Darker gave the concept of SIFT based weapon detection posalmethods.Bestresultswereobtainedbyusingtheregion algorithmandforROIestimation,usedthemotionsegmen- proposaltechnique.Theslidingwindowwasalsoverytime- tationmethod30.SIFTalgorithmispronetofalsealarms, consumingandtook14s/image,ontheotherhand,theregion so for estimating ROI, authors used motion segmentation proposal method processed the image in 140ms with 7 fps rather than using SIFT on complete image. When ROI was 37. They trained the network on Faster RCNN using only determined,thenSIFTwasappliedtodetectfirearmsintheir oneclassfocusingonreducingthefalsepositive.Recentpast case. objectiondetectionworkwiththeapplicationtofirearmswas Differentapproachesthenusedforweapondetectionusing proposedin2019,whereagroupofresearchers,JavedIqbal sliding window and region proposal algorithms. HOG His- etal.proposedorientationawaredetectionoftheobject.This togram of oriented Gradient models were used to predict system is more suitable for long and thin objects like rifles the objects in the frame. HOG significant work used low- etc. The predicted bounding box in their case was aligned levelfeatures,discriminativelearning,andpictorialstructure with the object and had the less unnecessary area to deal alongwithSVM25,31,32.Thesealgorithmswereslow with. Images of very high quality were used for training for real-time scenarios with 14s per image. Although these and testing purposes, which may make it less suitable for classifiersgavegoodaccuracies,theslownessofthesliding real-time scenarios 38. Jose Luis Salazar Gonzalez et al. window method was a big problem, especially for the real- work was very much related to achieve real-time results. timeimplementationpurpose. They did immense experimentation using different datasets Thisworkfocusesonthestateoftheartdeeplearningnet- and trained FasterRCNN using Feature Pyramid Network work rather SIFT and HOG features which use handcrafted withResnet50andimprovesthepreviousstateoftheartby rules for feature extraction, selection, and detection in real- 3.9139. time visual scenario using CCTV cameras. X. Zhang et al. concluded an important finding that helped my work. They III. METHODOLOGY concluded that the automatic feature representation gave Deeplearningisabranchofmachinelearninginspiredbythe improved results rather than manual features 33. Not only functionalityandstructureofthehumanbrainalsocalledan thelearnedfeatureswerebetterinperformance,theyalsohad artificial neural network. The methodology adopted in this VOLUME9,2021 34369 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning work features the state of art deep learning, especially the convolutional neural networks due to their exceptional per- formanceinthisfield.40.Theaforementionedtechniques are used for both the classification as well as localizing the specific object in a frame so both the object classification and detection algorithms were used and because our object is small with other object in background so after experi- mentationwefoundthebestalgorithmforourcase.Sliding window/classification and region proposal/object detection algorithmswereused,andthesetechniqueswillbediscussed FIGURE1. ObjectRecognitiontodetectionHierarchy. laterinthissection. We had started by doing the classification using different the feature extracted, it then predicts the label based on the deeplearningmodelsandachievedgoodprecisionbutforthe probability. real-timescenarios,thelowframepersecondsofclassifica- tion models were the real issue in implementation. Oxford VGG 41, 42, Google Inceptionv3 43 and Inception- 2 OBJECTLOCALIZATION Resnetv2 44, 45 were trained using the aforementioned This method outputs the actual location of an object in an approach. imagebygivingtheassociatedheightandwidthalongwith To achieve high precision, increase number of frame itscoordinates. per seconds and improve localization, we moved to the object detection and region proposal methods. The differ- 3 OBJECTDETECTION ent state of the art deep learning models for object detec- This task uses the properties of the aforementioned algo- tion were used and the results were compared in terms of rithms. The detection algorithm tells us the bounding box precision, speed, and standard metric of F1 score. State havingxandycoordinateswithassociatedwidthandheight of the art deep learning based SSDMobileNetv1 4648, along with the class label. Non-max suppression is used to YOLOv3 49, FasterRCNN-InceptionResnetv2 5052, outputtheboxwithourdesiredthreshold54.Thisprocess andYOLOv453weretrainedandtested. givesthefollowingresultsaltogether Differentdatasetsweremadekeepinginmindtheclassifi- cationanddetectionproblemasbothhaveaseparaterequire-  BoundingBox mentforperformingthetaskstoachievehighaccuracy,mean  Probability average precision as well as frame per second for the real- In past object detection was very limited because of less timeimplementation.Tounderstandobjectclassificationand data and low processing power of computers but with the detection let us first briefly understand object recognition passageoftimethecomputingpowerofcomputersincreased as both the aforementioned types come under the umbrella and world moved from CPUs to Graphic Processing Units of this and combined classification and localization make GPU. GPUs were firstly made for increasing the graphic detection possible for any kind of detection problem giving quality of the systems and for gaming but later GPUs were classnameaswellastheregionwhereourdesiredobjectis used extensively for deep learning. In ImageNet, competi- intheframe. tionsstartedandcontainedabout1000classes55.Thiswas the evolution of machine learning and deep learning. In the A. OBJECTRECOGNITION beginning,themodelswerenotverydeep,meanstherewere Asthenamesuggests,itistheprocessofpredictingthereal not many layers as they are now in an algorithm. Because classorcategoryofanimagetowhichitbelongsbymaking oftheaforementioneddevelopments,in2012A.Krizhevsky probability high only for that particular class. CNNs are presentedamodelcalledAlexNettrainedonImageNetand used to efficiently perform this process. Many state of the gotthefirstpositioninthatcompetition.Thiswasthebegin- art Classification and Detection algorithms uses CNN as a ning of object detection in deep learning. It gave a way to backendtoperformtheirtasks. researchers and then every year the algorithms and models Fig. 1 depicts that classification and localization come keeponcoming.Allthesealgorithmscontainlayersthatwork underthecategoryofrecognitionandcombinedclassification ontheprincipleoftheconvolutionalneuralnetworkCNN. and localization is performed to do object detection. Let us haveabriefoverviewoftheobjectclassification,localization, B. CLASSIFICATIONANDDETECTIONAPPROACH anddetection. There are many ways to generate region proposals, but the simplestwayofgeneratingthemisbyusingtheslidingwin- 1 IMAGECLASSIFICATION dow approach. The sliding window method is slow because The classification model takes an image and slide the ker- filterslidesovertheentireframeandhaslimitations,which nel/filteroverthewholeimagetogetthefeaturemaps.From were tackled by the region proposal approach, so we have 34370 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning the following two approaches used in our work for both classificationanddetectionmodelsare  Slidingwindow/ClassificationModels  Regionproposal/ObjectDetectionModels 1 SLIDINGWINDOW/CLASSIFICATIONMODELS In the method to the sliding window, a box or window is moved over a picture to select an area and use the object recognition model to identify each frame patch covered by thewindow.Itisanexhaustivesearchoverthewholepicture forobjects.Notonlydoweneedtosearchinthepictureforall feasibleplaces,wealsoneedtosearchondistinctscales.This is because models are usually trained on a particular range. Theoutcomesareintensofthousands104ofpicturespots being classified 56. The sliding window method is com- putationally very costly because of the search with various aspectratiosandespeciallyforeachpixelofanimageifthe strideorstepvalueisless. 2 REGIONPROPOSAL/OBJECTDETECTIONMODELS Thistechniquetakesanimageastheboundingboxesofinput and output proposals related to all areas in a picture most probable to be the object. These regional proposals may be FIGURE2. TrainingandOptimizationFlowDiagram. noisy coinciding not containing the object flawlessly, but there is a proposal among these region proposals related to partialderivativeofcostfunctionJOwithamultiplierofthe theoriginaltargetobject.Asthismethodtakesapictureasthe learningratealphaα fromtheoldorpreviousweightvalue. boundingboxesofinputandoutputrelatedtoallpatchesina Gradientdescentisthemainweightoptimizationalgorithm. picturemostprobabletobeacategory,soitproposesaregion It is used as a base in all optimizers used for the modeling withthemaximumscoreasthelocationofanobject.Instead andithelpsinconvergingthemodelandreachingtheminima of considering all possible regions of the input frame as wherewegetthebestanddesiredweightsvalues. possibilities,thismethodusesdetectionproposaltechniques toselectregions57.Region-basedCNNsR-CNNwasthe D. CONFUSIONOBJECTINCLUSION firstdetectionmodeltointroduceCNNsunderthisapproach We have formulated the problem to reduce the number 58.Theselectivesearchmethodofthisapproachproduces of false positives and negatives by adding relevant confu- 2000boxeshavingmaximumlikelihood. sion object. The weapon category includes all the handheld Selective search is a widely used proposal generation weapons such as, pistol, revolver, shotgun and other than method because it is very fast having a good recall value. weaponincludestheobjectsthatcanmostbeconfusedwith Itisdependentonthehierarchicalcalculationofdesiredareas pistolclassese.g.mobile,metaldetector,selfiestick,purse, established on the compatibility of color, texture, size, and etc. shape59. By understanding the differences between classification Yolo series is among the state of the art object detection and detection algorithms, sliding window, and region pro- models. Unlike the other region proposal-based methods it posalmethods,letsnowlookatthealgorithmsusedforboth divides the input image into an SxS grid and then simulta- approaches. neously predicts the probability and bounding boxes for an objectwithacenterfallingintoagridcell49,53. E. CLASSIFIERSANDOBJECTDETECTORS Theclassifiersusedundertheslidingwindowapproach C. TRAININGMECHANISM  VGG16 Fig.2describesthegeneralmethodologyusedintrainingand  InceptionV3 optimization. It starts with defining a problem, finding the  InceptionResnetV2 requireddataset,applyingpre-processingmethods,andthen finally training and evaluating the dataset. If the evaluation Theobjectdetectorsusedforreal-timedetectionare is correct then we save those weights as a classifier but  SSDMobilNetV1 if its incorrect then comes the process of backpropagation  YoloV3 algorithm along with the gradient descent algorithm 60.  FasterRCNN-InceptionResNetV2 Inbackpropagation,weightsareoptimizedbysubtractingthe  YoloV4 VOLUME9,2021 34371 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning Three databases named database1, database2, and database3werecreatedonebyoneafterexperimentationon different algorithms with diverse images, first for classifi- cation and then for object detection. Although the results obtained from the classification algorithms were not bad but the frames per second were very slow for real-time implementation. Detail for each database will be discussed inthenextsection. IV. DATASETCONSTRUCTION,ANNOTATIONAND PRE-PROCESSINGD-CAP Dataplaysakeyroleinthedevelopmentofanydeeplearning model as the model learns and extract feature from it. For a real-time model to detect weapons with minimized pro- cessing time and high precision, the importance of accurate andrelevantdataincreasesfurtherasallotherprocessesare dependentonit. When we study the stats and goes through almost FIGURE3. DatasetsamplesforpistolClass-Toplefttobottomrighta-d 50-60 videos of robbery on available online resources, aCCTVimagebMediumResolutionImagecImagewithDark backgroundandLowResolution,dFilteredImage. we come to know that 95 percent of the videos have revolver or pistol as a weapon, so we focused on binary classificationwithpistolandrevolvertobeinasingleclass 3 REASONOFCHOOSINGDATACATEGORIESOFPISTOL calledpistol.Besides,tomakethesystemmorepreciseandto CLASS reducethefalsepositiveandfalsenegativevaluesweadded Thereasonwechoosepistolandrevolverinthepistolclass objectsthatcanbeconfusedwithaweaponsuchasawallet, is because of our study and analysis after watching many cellphone,metaldetectoretcandputtheminaseparateclass robberiesandshootingincidentCCTVvideos.Weconcluded nameditasnotpistol. thatalmost95oftheweaponusedinthosecaseswereeither Lets now discuss the datasets used in our case because, pistolorrevolver.Fig.3showssomesampleimagesforreal- in a supervised learning case, the network learns the repre- timefromthecollecteddatasetofthepistolclass. sentation of the input data with given true answers, so the datamustbeclean,preprocessed,andproperlyannotatedto makethenetworklearnandpredictbetter. 4 WEAPONDATASETCATEGORIESFORNOT-PISTOLCLASS Datasets for this class include objects that can most likely be confused with pistol class objects. Following are some A. DATASETCONSTRUCTIONANDSELECTION samplescategoriesforthenotpistolclass The task of dataset construction and collection was very importantandtoughaswellbecausetherewasnobenchmark  Wallet datasetavailableforthis.Datasetforreal-timedetectionwas  MetalDetector collected and constructed in different phases and data was  Cellphone collected from the internet, extracted from YouTube CCTV  Selfiestick videos,throughGitHubrepositories,databytheUniversityof Granadaresearchgroup,andinternetmoviefirearmdatabase imfdb.org. 5 REASONOFCHOOSINGDATACATEGORIESOF NOT-PISTOLCLASS Weintroducedthisrelevantconfusionobjectconceptbecause 1 WEAPONDATASETCLASSES these are the objects that can mostly be confused with our Theweapondatasetforreal-timeweapondetectionisdivided desired weapon object, so predicting them correctly results intothefollowingtwoclasses inreducingthenumberoffalsepositivesandfalsenegatives,  Pistol henceincreasingoverallaccuracyandprecision.  Not-Pistol Some previously done work though had objects other than weapons used for the background or class other than a 2 WEAPONDATASETCATEGORIESFORPISTOLCLASS weapon but they had samples like cars, airplanes, cats, etc Datasetforthisclassincludesweaponsamplesofthefollow- andthereareveryfewerchancesforthemtobeconfusedwith ingcategories ourdesiredweapon,whichisverysmallascomparedtothem.  Pistol Asourdesiredobjectsofpistolclassaresmallsotherearelot  Revolver ofchancesforthemtobeconfusedwithsomeotherobjects  Othershothandheldweapons having some features like that. Fig. 4 shows some sample 34372 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning TABLE1. DataDistribution. ing the shortcomings and problems of the previous dataset. Theneedforthisdatasetarisesbecausethoughwegotarea- sonable accuracy from classification models but the frames per second were very few. To detect images from CCTV videos,similarkindsoftrainingdatamustbeincludedsowe madeourowndatasettotacklethisissue. This dataset contains 8327 images divided into the pis- tol and not pistol class. In this case, a related confusion FIGURE4. Datasetsamplesfornot-pistolClass-Toplefttobottomright data concept was introduced to reduce false positives and a-daCellPhonebMetalDetectorcSelfieStickdWallet. false negatives in real-time detection. Dataset images were extracted from several online sources, from CCTV videos imagesfromthecollecteddatasetofthenotpistolclasswhich for the particular robbery scenario, made our own dataset helpsinreducingfalsepositivesandnegatives. with a weapon in hand for the diverse scenario, did data augmentation,andfinally,itwasseparatedfortestandtrain B. DATASETSFORREAL-TIMEDETECTION case. Thisworkdealswiththebinaryclassificationforareal-time scenario so two classes were made and pistol and revolver C. DATADISTRIBUTION images were included in pistol class and not pistol class Each of the aforementioned datasets are divided into the includeconfusionclasseslikemobilephone,metaldetector, following categories mentioned in Table 1 with split size selfie stick, wallet, purse, etc. For the pistol and not pistol defining the separation percentage of the total data into test classes, we have made three datasets, which are explained andtrain. below. D. DATAPRE-PROCESSINGANDANNOTATION 1 DATASET1 Many things affect the performance of a Machine Learning This was the initial dataset used while starting this work. MLmodelforaspecifiedjob.First,therepresentationand Inthisdataset,wehad1732imagesintotal,with750images qualityofthedataareessential.Iftherearemanyirrelevant inpistolclassand950innotpistolclass.Datasetwasdivided and redundant data existing or noisy and unreliable data, by the separation criteria described in Table 1 of train and then it is harder to discover representation during the train- test. Images were collected from online sources and imfdb ing stage. Data preparation and filtering steps take signifi- database and sliding window classification algorithms were cant processing time in ML issues 61. The pre-processing trainedandtestedonit. process involves data cleaning, standardization, processing, extraction and choice of features, etc. The final training 2 DATASET2 datasetistheresultofpre-processingprocessesappliedtothe Thiswastheseconddatasetmadeforthereal-timescenario. collecteddataset. Thisdatasetcontains5254imagesandclassification,aswell Pre-processingisnecessaryforbettertrainingofamodel, asobjectdetectionalgorithms,weretrainedonthisdatasetto sothefirststepistomakethesamesizeorresolutionofthe meet the task. Images were extracted for real-time scenario dataset.Thenextstepistoapplythemeannormalization.The with the desired object in hand from online, sources, imfdb thirdstepismakingboundingboxesontheseimages,which database,andImageNetwebsite.Datasetwasdividedbythe is also called annotation, localization, or labeling. In data, separationcriteriaoftestandtrainexplainedinTable1. labeling a bounding box is made on each image. The value x,ycoordinates,andwidth,heightofthelabeledobjectwas 3 DATASET3 storedinxml,csvortxtformat.Followingarethefourmain This was the third dataset constructed for the real-time sce- stepsofdatapreprocessing narioand objectdetectionalgorithmswere performedonit.  Imagescaling Thisdatabasewasmadebyenhancingdataset2byovercom-  Data-augmentation VOLUME9,2021 34373 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning FIGURE5. ImageAugmentationandScaling. FIGURE6. ImageAnnotationandLabelling.  Imagelabeling  ImageFilteringusingOpenCV  RGBtoGrayscale  Equalized  Clahe Fig. 5, 6 and 7 shows the results after applying the afore- mentionedpre-processingtechniques. V. EXPERIMENTS,RESULTSANDANALYSIS Wehavedetectedweaponsinreal-timeCCTVstreamsinlow resolution,darklightwithreal-timeframepersecond.Most oftheworkdonebeforewasondetectingimagesandvideos of high quality and because those models were trained on high-qualitydatasets,itisnotpossibletothendetectanobject oflowresolutioninreal-time.Theresultsareanalyzedafter trainingandtestingmodelsondatasetsmentionedinTable1. As described in the methodology section the results for FIGURE7. ImageFiltrationusingOpenCVFilters-aOriginalImage bEqualizedFilterResultcGrayScaleFilterResultdClaheFilter differentapproachesareevaluated.Ourmainproblemstate- Result. mentisofreal-timedetectionbecause97ofweaponused inrobberycaseswerepistolorrevolver,sodifferentdataset results have been evaluated here for sliding window and TruePositives regionproposalapproach. Recall 2 The performance of these models was analyzed by com- TruePositivesFalseNegatives paringthemintermsofthestandardmetricsofF1-scoreand 2PrecisionRecall F1-score 3 framepersecondsalongwithmeanaverageprecisionmAP PrecisionRecall forthebestperformedmodelandthesetermsarecalculated byusingthebelowequation1,2and3.F1scoreisratioofthe A. DATASET-1EXPERIMENTATIONANDRESULTS precisionandrecallfunctions. Dataset 1 contains 1732 images distributed between two TruePositives classes of pistol and not-pistol with 750 and 982 images Precision  1 TruePositivesFalsePositives ineachclassrespectively.Experimentationondataset-1has 34374 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning TABLE2. SlidingWindowResultsComparisonDataset-1. FIGURE8. BestslidingwindowmodelaccuracygraphInceptionResNetv2. beenperformedusingtheslidingwindow/classificationmod- elsofVGG16,Inceptionv3andInceptionResNetv2. After experimentation, we have analyzed that the results obtained are not good because most of the images of this datasethavewhiteorthesamekindofbackgroundwhichlead toapointwherethemodelalsostartslearningthebackground as its region of interest ROI and in real-time background variessoanewdatasetwasrequiredtotrainandtestthemodel onimageswithdiversecasesandbackground.Table2shows the results for the aforementioned models using this dataset givingprecision,recall,andF1-score. FIGURE9. BestslidingwindowmodelLossgraphInceptionResNetv2. B. DATASET-2EXPERIMENTATIONANDRESULTS This dataset contains two classes of pistol and not- pistol with 3000 and 2254 images in each class respec- tively. Table 3 shows results based on it. Experimenta- tion on dataset-2 has been performed using the sliding window/classification models of VGG16, Inceptionv3, and InceptionResNetv2. Experimentationresultsshowthatthoughwegetareason- able accuracy from classification models using this dataset but the frames per second were very few and which was a bigprobleminmakingareal-timeweapondetector.Among these classification models, InceptionResnetV2 performed best and achieves the best results. Table 3 shows the results under the sliding window methods using dataset 2 and Fig. 8, 9, and 10 shows the accuracy, loss, and confusion matrix FIGURE10. BestslidingwindowmodelConfusionMatrix respectivelyforthebestclassificationmodelunderthesliding InceptionResNetv2. windowapproach. C. DATASET-3EXPERIMENTATIONANDRESULTS  FasterRCNN-InceptionResNetV2 After experimentation on the previous two datasets and not  YoloV4 findingsatisfactoryresultsforthereal-timecaseanewdataset Each model had its pros and cons. SSD-MobileNet is was made. Images were collected from robbery videos, our goodintermsofprocessingframespersecond.FasterRCNN- own dataset images holding a weapon in different scenar- InceptionResNetv2 has good precision and recall but not ios, images with a dark background and low resolution, processingspeed.Yolofamilyhasaseriesofmodels.Ithasa and images extracted from applying different OpenCV fil- differentapproachforthedetectionpurpose.Unliketheother ters are added to make real-time detection possible. A total regionproposalbasedmethods,itdividestheinputimageinto of8327imagesareusedinthiscase.Followingobjectdetec- anSxSgridandthensimultaneouslypredictstheprobability tionmodelsweretrainedandevaluatedusingthisdataset andboundingboxesforanobjectwiththecenterfallingintoa  SSDMobilNetV1 gridcell.WehavetrainedthelateststateoftheartYolov3and  YoloV3 Yolov4onourownweapondataset3forreal-timedetection VOLUME9,2021 34375 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning TABLE3. SlidingWindowResultsComparisonDataset-2. TABLE4. RegionProposal/ObjectDetectionModels-Dataset-3. FIGURE11. BestObjectDetectionModel-Yolov4lossvsmAP. TABLE5. BestPerformedModelYolov4mAPCalculation. andbestresultswereobtainedthroughYOLOv4intermsof both processing speed and precision. Table 4 below shows the results for the aforementioned detection models for this datasetatastandardthresholdscoreof50. Yolov4 performs best among all the models of both the sliding window and region proposal approach. Performance graphforyolov4intermsoflossandmeanaverageprecision mAPonavalidationdatasetisshowninFig.11.Wecansee that how smooth is the model loss curve and how precisely it converges to the best level giving a very good loss score of1.062andameanaverageprecisionof91.73.Themean averageprecisionisthemeanoftheaverageprecisionvalues foralltherelevantclasses.Theassociatedvaluesofaverage standard metrics of precision, recall, and F1-score for precisionAPforpistolandnot-pistolclassforthecalcula- evaluation. tionofmeanaverageprecisionvalueisgiveninTable5.  Some classification models showed good results but The mean average precision value is calculated for the they were not suitable for a real-time scenario, were yolov4modelasitperformsbestinallscenarioandaccurately slow, not much accurate, and fast as compared to the detected the desired object even when the object has a very objectdetectionmodelsastheyperformsverywelland small presense in the frame and there were lots of other achievedhighprecisionandrecall. objectsinthebackgroundaswell.  Thereasonwhysomeclassificationmodelshaveagood F1-scoreisthetrainingandevaluationoninitialdatasets D. ANALYSISANDDISCUSSION wemadewhenstartingthiswork,butafterexperimenta-  Table2,3,and4aboveshowsthecomparisonbetween tion,wecometoknowthatthesemodelsarenotsuitable the classification and object detection models using forreal-timescenarioshavingthebackgroundobjects. 34376 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning FIGURE13. BestperformedmodelscomparisonAccuracyvsF1-score. FIGURE12. ObjectDetectionmodelsPerformance/ComparisonGraph. TABLE6. Yolov4HyperParameters.  Object detection models performed well for the real- time scenario and performance comparison in terms of speedandF1-scorebetweenthedetectionmodelscanbe seen from Fig. 12. Inference results are obtained using theNVIDIARTX2080tiforeachmodel.  ThestandardmetricsofmeanaverageprecisionmAP, recallandF1-scorearecalculateandallthemodelshave beencomparedatabenchmarkIoUthresholdof0.50or 50.  Yolov4 performs best amongst all models with a mean average precision and F1-score of 91.73 and 91 respectively with detection confidence of 99 in the majorityofcases.  Comparison in terms of test accuracy vs F1-score TABLE7. Comparisonwithsomeexistingstudies. for the best-performed models of both classifica- tion and detection approaches is shown in the Fig.13. Accuracy and F1-score for VGG, Inceptionv3, InceptionResNetv2, SSDMobileNet, FasterRCNN- InceptionResNetv2, Yolov3 and yolov4 are 78.20, 85.20, 92.20, 79, 96, 94, 99 and 81.69, 84.36,85.74,59,87,86and91respectively.  Fig.14-19showstheinferenceordetectionresultsofour modelforpistolandnotpistolclassonimages,videos, andreal-timeCCTVstreams.  Hyperparameters used in training the best-performed detectorYolov4canbeobservedfromTable6. Itisveryhardtodoacomparisonwithstudiesconducted previously on this subject because each study has its own dataset, models and metrics used to evaluate performance. in terms of mAP and precisoin at a standard iou threshold Itshouldalsobenoticedachieverealtimedetection,wealso of50,whicheverwasavailable. needtohavearealtimedatasetfortraningbecausewithhigh qualitytrainingimageswecannotachieveresultsinrealtime. E. DETECTIONRESULTS-PISTOLCLASSWITHOUT Each study also has different testing conditions, either just BACKGROUND on images, videos or on images with high quality but our SeeFigure14. approachfromstartwastoachieverealtimeresults.Insome studies,theperformanecemetricusedisaccuray,othershave F. DETECTIONRESULTS-PISTOLCLASSWITH precisoinormeanaverageprecisionmAPbutmostlymAP BACKGROUND is used as standard so we have given comparison results SeeFigure15. VOLUME9,2021 34377 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning FIGURE14. DetectionResults-Onlyweaponinthewholeframewithoutanybackgroundatdifferentangles,brightness,sharpness,andquality. FIGURE15. DetectionResults-Toplefttobottomrighta-iaImagewithfrontandsideview,bImageverticalviewcImagewithDarkbackground andLowResolutionfullytiltedsideview,dLowbrightnessimagesideviewslightlytiltedeImagewiththebackviewfFullfrontviewgSmallCCTV objecthVerysmallobjectwithsideviewiImagewithfullsideview. G. DETECTIONRESULTS-PISTOLCLASSINVIDEOS I. DETECTIONRESULTSNOTPISTOLCLASS SeeFigure16. SeeFigure18. H. DETECTIONRESULTS-PISTOLCLASSINREALTIME CCTVSTREAMS J. MISDETECTIONS SeeFigure17. SeeFigure19. 34378 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning FIGURE16. DetectionResults-Toplefttobottomrighta-f-video1inferencea-c,video2inferenced-faSmallobject-sideviewtilted,bSmall objectwithsideviewcSmallobjectfrontviewdsidevieweTopviewdoubleobjectfSmallobjectwithfrontandsideview. FIGURE17. DetectionResults-Toplefttobottomrighta-i-cctvstream1a-c,cctvstream2d-f,cctvstream3g-iaSmallobjectinLowresolutionb TiltedObjectcLowResolutionverticalobject,dDaylightsideviewwithslightlytiltedeDaylightsideviewfDaylightsideviewflippedgSmall objectmediumresolutionhverticalviewisideview. VI. CONCLUSIONANDFUTUREWORK and tourists, as security and safety are their primary needs. For both monitoring and control purposes, this work has We have focused on detecting the weapon in live CCTV presentedanovelautomaticweapondetectionsysteminreal- streams and at the same time reduced the false negatives time. This work will indeed help in improving the secu- and positives. To achieve high precision and recall we con- rity, law and order situation for the betterment and safety structed a new training database for the real-time scenario, of humanity, especially for the countries who had suffered then trained, and evaluated it on the latest state-of-the-art a lot with these kind of violent activities. This will bring deep learning models using two approaches, i.e. sliding a positive impact on the economy by attracting investors window/classification and region proposal/object detection. VOLUME9,2021 34379 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning FIGURE18. DetectionResults-Toplefttobottomrighta-daCellphonebMetaldetectorcWalletd Selfiestick. FIGURE19. MisdetectionsFalsepositivesandNegatives. Differentalgorithmswereinvestigatedtogetgoodprecision ACKNOWLEDGMENT andrecall. TheauthorswishtoextendgratitudetoMr.RehanMushtaq Throughaseriesofexperiments,weconcludedthatobject of Ingenious Zone who provided assistance as an industrial detection algorithms with ROI Region of Interest perform partnerinmakingthisworkpossible. better than algorithms without ROI. We have tested many REFERENCES models but among all of them, the state-of-the-art Yolov4, 1 2019. Christchurch Mosque Shootzings. Accessed Jul. 10, 2019. trainedonournewdatabase,gaveveryfewfalsepositiveand Online.Availablehttps//en.wikipedia.org/wiki/Christchurch_mosque_ negative values, hence achieved the most successful results. shootings Itgave91.73meanaverageprecisionmAPandaF1-score 2 2019. Global Study on Homicide. Accessed Jul. 10, 2019. Online. Available https//www.unodc.org/unodc/en/data-and-analysis/global- of 91 with almost 99 confidence score on all types of study-on-homicide.html imagesandvideos.Wecansaythatitsatisfactorilyqualifies 3 W.Deisman,CCTVLiteraturereviewandbibliography,inResearch as an automatic real-time weapon detector. Looking at the and Evaluation Branch, Community, Contract and Aboriginal Policing Services Directorate. Ottawa, ON, Canada Royal Canadian Mounted, results,wegotthehighestmeanaverageprecisionmAPF1- 2003. score as compared to the research done before for real-time 4 J. Ratcliffe, Video surveillance of public places, US Dept. Justice, scenarios. Office Community Oriented Policing Services, Washington, DC, USA, Tech.Rep.4,2006. Thefutureworkincludesreducingthefalsepositivesand 5 M.Grega,A.Matiolałski,P.Guzik,andM.Leszczuk,Automateddetec- negativesevenmoreasthereisstillaneedforimprovement. tionoffirearmsandknivesinaCCTVimage,Sensors,vol.16,no.1, Wemightalsotrytoincreasethenumberofclassesorobjects p.47,Jan.2016. 6 TechCrunch. 2019. Chinas CCTV Surveillance Network Took Just 7 in the future but the priority is to further improve precision Minutes to Capture BBC Reporter. Accessed Jul. 15, 2019. Online. andrecall. Availablehttps//techcrunch.com/2017-12-13/china-cctv-bbc-reporter/ 34380 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning 7 N. Cohen, J. Gattuso, and K. MacLennan-Brown. CCTV Operational 29 I.T.Darker,A.G.Gale,andA.Blechko,CCTVasanautomatedsensor Requirements Manual 2009. St Albans, U.K. Home Office Scientific for firearms detection Human-derived performance as a precursor to DevelopmentBranch,2009. automaticrecognition,Proc.SPIE,vol.7112,Oct.2008,Art.no.71120V. 8 G.Flitton,T.P.Breckon,andN.Megherbi,Acomparisonof3Dinterest 30 I. T. Darker, P. Kuo, M. Y. Yang, A. Blechko, C. Grecos, D. Makris, pointdescriptorswithapplicationtoairportbaggageobjectdetectionin J.-C.Nebel,andA.Gale,AutomationoftheCCTV-mediateddetectionof complexCTimagery,PatternRecognit.,vol.46,no.9,pp.24202436, individualsillegallycarryingfirearmsCombiningpsychologicalandtech- Sep.2013. nologicalapproaches,Proc.SPIE,vol.7341,Apr.2009,Art.no.73410P. 9 R.Gesick,C.Saritac,andC.-C.Hung,Automaticimageanalysisprocess 31 R.Al-Rfouetal.,TheanoAPythonframeworkforfastcomputationof forthedetectionofconcealedweapons,inProc.5thAnnu.Workshop mathematicalexpressions,2016,arXiv1605.02688.Online.Available CyberSecur.Inf.Intell.Res.CyberSecur.Inf.Intell.ChallengesStrategies http//arxiv.org/abs/1605.02688 CSIIRW,2009,p.20. 32 F.Chollet.2019.Fchollet.AccessedApr.10,2019.Online.Available 10 R. K. Tiwari and G. K. Verma, A computer vision based framework https//github.com/fchollet forvisualgundetectionusingHarrisinterestpointdetector,Procedia 33 K.He,X.Zhang,S.Ren,andJ.Sun,Deepresiduallearningforimage Comput.Sci.,vol.54,pp.703712,Aug.2015. recognition,inProc.IEEEConf.Comput.Vis.PatternRecognit.CVPR, 11 R.K.TiwariandG.K.Verma,Acomputervisionbasedframeworkfor Jun.2016,pp.770778. visualgundetectionusingSURF,inProc.Int.Conf.Electr.,Electron., 34 2016. Weapon Detection in Surveillance Cameras Images. Signals,Commun.Optim.EESCO,Jan.2015,pp.15. Accessed Feb. 13, 2021. Online. Available http//www.diva- 12 Z. Xiao, X. Lu, J. Yan, L. Wu, and L. Ren, Automatic detection of portal.org/smash/record.jsf?piddiva23A1054902dswid-1974 concealedpistolsusingpassivemillimeterwaveimaging,inProc.IEEE 35 M.Nakib,R.T.Khan,M.S.Hasan,andJ.Uddin,Crimesceneprediction Int.Conf.Imag.Syst.Techn.IST,Sep.2015,pp.14. by detecting threatening objects using convolutional neural network, 13 D. M. Sheen, D. L. Mcmakin, and T. E. Hall, Three-dimensional in Proc. Int. Conf. Comput., Commun., Chem., Mater. Electron. Eng. millimeter-waveimagingforconcealedweapondetection,IEEETrans. IC4ME2,Feb.2018,pp.14. Microw.TheoryTechn.,vol.49,no.9,pp.15811592,Sep.2001. 36 G.K.VermaandA.Dhillon,AhandheldgundetectionusingfasterR- 14 Z. Xue, R. S. Blum, and Y. Li, Fusion of visual and IR images for CNNdeeplearning,inProc.7thInt.Conf.Comput.Commun.Technol. concealedweapondetection,inProc.5thInt.Conf.Inf.Fusion,vol.2, ICCCT,2017,pp.8488. Jul.2002,pp.11981205. 37 R.Olmos,S.Tabik,andF.Herrera,Automatichandgundetectionalarm 15 R. Blum, Z. Xue, Z. Liu, and D. S. Forsyth, Multisensor concealed in videos using deep learning, Neurocomputing, vol. 275, pp.6672, weapon detection by using a multiresolution mosaic approach, in Jan.2018. Proc. IEEE 60th Veh. Technol. Conf. VTC-Fall, vol. 7, Sep. 2004, 38 J. Iqbal, M. A. Munir, A. Mahmood, A. Rafaqat Ali, and M. Ali, pp.45974601. Orientationawareobjectdetectionwithapplicationtofirearms,2019, 16 E.M.UpadhyayandN.K.Rana,Exposurefusionforconcealedweapon arXiv1904.10032.Online.Availablehttps//arxiv.org/abs/1904.10032 detection, in Proc. 2nd Int. Conf. Devices, Circuits Syst. ICDCS, 39 J.L.S.González,C.Zaccaro,J.A.Álvarez-García,L.M.S.Morillo,and Mar.2014,pp.16. F.S.Caparrini,Real-timegundetectioninCCTVAnopenproblem, 17 R.Maher,Modelingandsignalprocessingofacousticgunshotrecord- NeuralNetw.,vol.132,pp.297308,Dec.2020. ings,inProc.IEEE12thDigit.SignalProcess.Workshop4thIEEESignal 40 2017. Convolutional Neural Networks. Accessed Aug. 15, 2018. Process.Educ.Workshop,Sep.2006,pp.257261. Online.Availablehttp//cs231n.github.io/convolutional-networks/ 18 A.Chacon-Rodriguez,P.Julian,L.Castro,P.Alvarado,andN.Hernandez, 41 K.SimonyanandA.Zisserman,Verydeepconvolutionalnetworksfor Evaluationofgunshotdetectionalgorithms,IEEETrans.CircuitsSyst.I, large-scaleimagerecognition,2014,arXiv1409.1556.Online.Avail- Reg.Papers,vol.58,no.2,pp.363373,Feb.2011. ablehttp//arxiv.org/abs/1409.1556 19 2019. From Edison to Internet A History of Video Surveillance. 42 2019. VGG16Convolutional Network for Classification and Detec- Accessed Jun. 13, 2019. Online. Available https//www. tion. Accessed Dec. 19, 2018. Online. Available https//neurohive. business2community.com/tech-gadgets/from-edison-to-internet-a- io/en/popular-networks/vgg16/ history-of-video-surveillance-0578308 20 2019. Infographic History of Video SurveillanceIFSEC Global  43 C.Szegedy,V.Vanhoucke,S.Ioffe,J.Shlens,andZ.Wojna,Rethinking SecurityandFireNewsandResources.AccessedSep.15,2019.Online. the inception architecture for computer vision, in Proc. IEEE Conf. Comput.Vis.PatternRecognit.CVPR,Jun.2016,pp.28182826. Available https//www.ifsecglobal.com/video-surveillance/infographic- history-of-video-surveillance/ 44 C. Szegedy, S. Ioffe, V. Vanhoucke, and A. A. Alemi, Inception-v4, 21 W.Hu,T.Tan,L.Wang,andS.Maybank,Asurveyonvisualsurveillance inception-resnetandtheimpactofresidualconnectionsonlearning,in ofobjectmotionandbehaviors,IEEETrans.Syst.,Man,Cybern.C,Appl. Proc.31stAAAIConf.Artif.Intell.,2017,pp.17. Rev.,vol.34,no.3,pp.334352,Aug.2004. 45 Medium. 2019. A Simple Guide to the Versions of the 22 A.C.Sankaranarayanan,A.Veeraraghavan,andR.Chellappa,Object Inception Network. Accessed Jul. 27, 2019. Online. Available detection, tracking and recognition for multiple smart cameras, Proc. https//towardsdatascience.com/a-simple-guide-to-the-versions-of-the- IEEE,vol.96,no.10,pp.16061624,Oct.2008. inception-network-7fc52b863202 23 S. Zhang, C. Wang, S.-C. Chan, X. Wei, and C.-H. Ho, New object 46 D.Anguelov,D.Erhan,C.Szegedy,S.Reed,C.-Y.Fu,andA.C.Berg, detection, tracking, and recognition approaches for video surveillance SSDSingleshotmultiboxdetector,inProc.Eur.Conf.Comput.Vis. overcameranetwork,IEEESensorsJ.,vol.15,no.5,pp.26792691, Cham,SwitzerlandSpringer,2016,pp.2137. May2015. 47 Medium. 2019. Understanding SSD MultiBoxReal-Time Object 24 J.C.NascimentoandJ.S.Marques,Performanceevaluationofobject Detection in Deep Learning. Accessed Aug. 19, 2019. Online. detection algorithms for video surveillance, IEEE Trans. Multimedia, Available https//towardsdatascience.com/understanding-ssd-multibox- vol.8,no.4,pp.761774,Aug.2006. real-time-object-detection-in-deep-learning-495ef744fab 25 N. Dalal and B. Triggs, Histograms of oriented gradients for human 48 A.G.Howard,M.Zhu,B.Chen,D.Kalenichenko,W.Wang,T.Weyand, detection,Tech.Rep.,2005. M.Andreetto,andH.Adam,MobileNetsEfficientconvolutionalneu- 26 C. Anagnostopoulos, I. Anagnostopoulos, G. Tsekouras, G. Kouzas, ral networks for mobile vision applications, 2017, arXiv1704.04861. V.Loumos,andE.Kayafas,Usingslidingconcentricwindowsforlicense Online.Availablehttp//arxiv.org/abs/1704.04861 platesegmentationandprocessing,inProc.IEEEWorkshopSignalPro- 49 J. Redmon and A. Farhadi, YOLOv3 An incremental improve- cess.Syst.DesignImplement.,Nov.2005,pp.337342. ment,2018,arXiv1804.02767.Online.Availablehttp//arxiv.org/abs/ 27 M.Grega,S.Lach,andR.Sieradzki,Automatedrecognitionoffirearms 1804.02767 insurveillancevideo,inProc.IEEEInt.Multi-DisciplinaryConf.Cog- 50 S.Ren,K.He,R.Girshick,andJ.Sun,FasterR-CNNTowardsreal-time nit.MethodsSituationAwarenessDecis.SupportCogSIMA,Feb.2013, objectdetectionwithregionproposalnetworks,inProc.Adv.NeuralInf. pp.4550. Process.Syst.,2015.pp.9199. 28 I.Darker,A.Gale,L.Ward,andA.Blechko,CanCCTVreliablydetect 51 2019. Faster R-CNN Explained. Accessed guncrime?inProc.41stAnnu.IEEEInt.CarnahanConf.Secur.Technol., Aug. 25, 2019. Online. Available https//medium. Oct.2007,pp.264271. com/smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f VOLUME9,2021 34381 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning 52 Medium.2019.FasterRCNNObjectdetection.AccessedAug.27,2019. MUHAMMAD GUFRAN KHAN SeniorMem- Online. Available https//towardsdatascience.com/faster-rcnn-object- ber,IEEEreceivedtheB.Sc.degreeinelectrical detection-f865e5ed7fc4 engineering from the University of Engineering 53 A. Bochkovskiy, C.-Y. Wang, and H.-Y. Mark Liao, YOLOv4 Opti- and Technology, Lahore, Pakistan, in 2003, and mal speed and accuracy of object detection, 2020, arXiv2004.10934. theM.Sc.degreeinelectricalengineeringspecial- Online.Availablehttp//arxiv.org/abs/2004.10934 izationinsignalprocessingandthePh.D.degree 54 GeeksforGeeks. 2020. Object Detection Vs Object Recognition Vs in electrical engineering specialization in wire- Image Segmentation. Accessed Dec. 28, 2020. Online. Available lesscommunicationfromtheBlekingeInstituteof https//www.geeksforgeeks.org/object-detection-vs-object-recognition- Technology, Sweden, in 2005 and 2011, respec- vs-image-segmentation/ tively. 55 2019. ImageNet. Accessed Jun. 5, 2019. Online. Available http// HeiscurrentlyanAssociateProfessorandtheHeadoftheDepartmentof www.image-net.org/ 56 J. O. Laguna, A. G. Olaya, and D. Borrajo, A dynamic sliding win- ElectricalEngineering,FASTNUCESChiniot-FaisalabadCampus.Before dow approach for activity recognition, in Proc. Int. Conf. User Mod- joiningFAST,hehasworkedasanAnalysisEngineerwithVolvoCarCorpo- eling, Adaptation, Personalization. Berlin, Germany Springer, 2011, ration,Sweden.Hehasconductedresearchintheareasofsignalprocessing, pp.219230. computer vision, and machine learning. He has also worked on different 57 J. Hosang, R. Benenson, P. Dollar, and B. Schiele, What makes for fundedresearchprojectsintheareaofembeddedsystemsandrobotics.He effectivedetectionproposals?IEEETrans.PatternAnal.Mach.Intell., isactivelyinvolvedintheapplicationsoftheAIandIoTtechnologytosolve vol.38,no.4,pp.814830,Apr.2016. real-world problems. He is also the Chairperson of the IEEE Faisalabad 58 R.Girshick,J.Donahue,T.Darrell,andJ.Malik,Richfeaturehierarchies Subsection. foraccurateobjectdetectionandsemanticsegmentation,inProc.IEEE Conf.Comput.Vis.PatternRecognit.,Jun.2014,pp.580587. 59 A. Consulting. 2019. Selective Search for Object Detection C / Python  Learn OpenCV. Accessed May 25, 2019. Online. Avail- able https//www.learnopencv.com/selective-search-for-object-detection- MASOOD ASLAM received the B.S. degree in cpp-python/ electrical engineering from The University of 60 Y.Lecun,L.Bottou,Y.Bengio,andP.Haffner,Gradient-basedlearn- Faisalabad,Faisalabad,Pakistan,in2013,andthe ing applied to document recognition, Proc. IEEE, vol. 86, no. 11, pp.22782324,Nov.1998. M.S.degreeinelectricalengineeringfromFAST- 61 S.B.Kotsiantis,D.Kanellopoulos,andP.E.Pintelas,Datapreprocessing NUCES,Islamabad,Pakistan,in2018. forsupervisedleaning,Int.J.Comput.Sci.,vol.1,no.2,pp.111117, HeiscurrentlyworkingasaResearchAssociate 2006. withtheVisualComputingTechnologyVC-Tech Laboratory, Islamabad. Before joining VC-Tech, he worked as a Research Assistant with FAST- NUCES.Hisresearchinterestsincludecomputer MUHAMMAD TAHIR BHATTI received the visionandimageprocessing. B.Sc. degree in electrical and electronics engi- neeringfromAirUniversity,Islamabad,Pakistan, in2013,andtheM.S.degreeinelectricalengineer- ingwithspecializationandresearchinthefieldof artificialIntelligenceandmachinelearningfrom MUHAMMADJUNAID FIAZreceivedtheB.S. theNationalUniversityofComputerandEmerg- degreeincomputersciencefromGovernmentCol- ingSciences,Faisalabad,Pakistan,in2019. legeUniversityFaisalabad,Pakistan,in2019. HehasworkedasanElectricalandElectronics He has worked as an Android Developer. He EngineerwithNationalSilkandRayanPvtLtd. is currently working as a Research Assistant in He is currently working as a Research Assistant in the field of artificial thefieldofartificialintelligencewiththeNational intelligencewiththeNationalUniversityofComputerandEmergingSci- UniversityofComputerandEmergingSciences, ences.HewasaCertifiedArtificialIntelligenceEngineerfromSaylaniMass Faisalabad,Pakistan. TrainingProgram,Faisalabad,in2018.Hereceivedthebronzemedalfrom theNationalUniversityofComputerandEmergingSciences. 34382 VOLUME9,2021",
    "structured_text": {
      "sentences": [
        "ReceivedJanuary13,2021,acceptedFebruary1,2021,dateofpublicationFebruary12,2021,dateofcurrentversionMarch4,2021.",
        "DigitalObjectIdentifier10.1109/ACCESS.2021.3059170 Weapon Detection in Real-Time CCTV Videos Using Deep Learning MUHAMMADTAHIRBHATTI 1,MUHAMMADGUFRANKHAN 1,SeniorMember,IEEE, MASOODASLAM 2,ANDMUHAMMADJUNAIDFIAZ1 1DepartmentofElectricalEngineering,NationalUniversityofComputerandEmergingSciences,Faisalabad35400,Pakistan 2DepartmentofElectricalEngineering,ComsatsUniversityIslamabad,Islamabad45550,Pakistan CorrespondingauthorMuhammadTahirBhattitahir.bhatti320gmail.com ThisworkwassupportedbytheHigherEducationCommissionHECofPakistanthroughtheTechnologyDevelopmentFundTDF underGrantTDF-02-161.",
        "ABSTRACT Securityandsafetyisabigconcernfortodaysmodernworld.Foracountrytobeeconomically strong, it must ensure a safe and secure environment for investors and tourists.",
        "Having said that, Closed CircuitTelevisionCCTVcamerasarebeingusedforsurveillanceandtomonitoractivitiesi.e.robberies butthesecamerasstillrequirehumansupervisionandintervention.Weneedasystemthatcanautomatically detect these illegal activities.",
        "Despite state-of-the-art deep learning algorithms, fast processing hardware, and advanced CCTV cameras, weapon detection in real-time is still a serious challenge.",
        "Observing angle differences,occlusionsbythecarrierofthefirearmandpersonsarounditfurtherenhancesthedifficultyofthe challenge.ThisworkfocusesonprovidingasecureplaceusingCCTVfootageasasourcetodetectharmful weapons by applying the state of the art open-source deep learning algorithms.",
        "We have implemented binary classification assuming pistol class as the reference class and relevant confusion objects inclusion concept is introduced to reduce false positives and false negatives.",
        "No standard dataset was available for real-timescenariosowemadeourowndatasetbymakingweaponphotosfromourowncamera,manually collected images from internet, extracted data from YouTube CCTV videos, through GitHub repositories, databyuniversityofGranadaandInternetMoviesFirearmsDatabaseIMFDBimfdb.org.Twoapproaches are used i.e.",
        "sliding window/classification and region proposal/object detection.",
        "Some of the algorithms usedareVGG16,Inception-V3,Inception-ResnetV2,SSDMobileNetV1,Faster-RCNNInception-ResnetV2 FRIRv2, YOLOv3, and YOLOv4.",
        "Precision and recall count the most rather than accuracy when object detection is performed so these entire algorithms were tested in terms of them.",
        "Yolov4 stands out best amongstallotheralgorithmsandgaveaF1-scoreof91alongwithameanaverageprecisionof91.73 higherthanpreviouslyachieved.",
        "INDEXTERMS Gundetection,deeplearning,objectdetection,artificialintelligence,computervision.",
        "I.",
        "INTRODUCTION what we speak or write has an impact on the people.",
        "Even Thecrimerateacrosstheglobehasincreasedmainlybecause if the news they heard is crafted having no truth but as it ofthefrequentuseofhandheldweaponsduringviolentactiv- getsviralinafewhoursbecauseofthemediaandespecially ity.",
        "For a country to progress, the law-and-order situation socialmedia,thedamagewillbedone.Peoplenowhavemore mustbeincontrol.Whetherwewanttoattractinvestorsfor depression and have less control over their anger, and hate investmentortogeneraterevenuewiththetourismindustry, speeches can get those people to lose their minds.",
        "People alltheseneedsisapeacefulandsafeenvironment.Thecrime canbebrainwashedandpsychologicalstudiesshowthatifa ratio because of guns is very critical in numerous parts of personhasaweaponinthissituation,hemaylosehissenses the world.",
        "It includes mainly those countries in which it is andcommitaviolentactivity.",
        "legaltokeepafirearm.Theworldisaglobalvillagenowand High incidents were recorded in past few years with the use of harmful weapons in public areas.",
        "Starting with the The associate editor coordinating the review of this manuscript and pastyearsattacksonacoupleofMosquesinNewZealand, approvingitforpublicationwasShadiAlawneh .",
        "on March 15, 2019 at 140 pm, the attacker attacks the ThisworkislicensedunderaCreativeCommonsAttribution-NonCommercial-NoDerivatives4.0License.",
        "34366 Formoreinformation,seehttps//creativecommons.org/licenses/by-nc-nd/4.0/ VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning ChristchurchAL-NoorMosqueduringaFridayprayerkilling of selecting features manually, CNN automatically learns almost 44 innocent and unarmed worshippers.",
        "On the same featuresfromgivendata.",
        "day just after 15 minutes at 155 PM, another attack hap- This article presents an automatic detection and classifi- pened killing seven more civilians 1.",
        "Active shooter inci- cationmethodofweaponsforreal-timescenariousingstate dents had also occurred in USA and then in Europe.",
        "The of the art deep learning models.",
        "For real-time implemen- mostsignificantcaseswerethoseatColumbineHighSchool tation relating the problem question of this work detect- USA, 37 victims, Andreas Broeiviks assault on Uotya ingweaponsinreal-timeforpotentialrobbers/terroristusing IslandNorway,179victimsortheCharlieHebdonewspaper deep learning, detection and classification was done for attackkilling23.AccordingtostatsprovidedbytheUNODC, pistol, revolver and other shot handheld weapons as in sin- among0.1Millionpeopleofacountry,thecrimesinvolving gle class called pistol and related confusion objects such as gunsareveryhighi-e.1.6inBelgium,UnitedStateshaving cell phone, metal detector, wallet, selfie stick in not pistol 4.7andMexicowithanumberof21.52.",
        "class.",
        "A major reason behind this was our research done on CCTV cameras play an important role to overcome this weapons used in robbery cases and it further motivated us problemandareconsideredtobeoneofthemostimportant to choose pistol and revolver as our target object.",
        "We go requirementsforthesecurityaspect.3.CCTVsareinstalled throughseveralCCTVcapturedrobberyvideosonYouTube ineverypublicplacetodayandaremainlyusedforproviding and found that almost 95 of cases have pistol or revolver safety, crime investigation, and other security measures for astheweaponused.Withtheimplementationofthissystem, detection.",
        "CCTV footage is the most important evidence in manyrobberycrimes,andotherincidentslikewhathappened courts.Afteracrimeiscommitted,lawenforcementagencies last year in New Zealands Christchurch mosque could be arriveatthesceneandtaketherecordingoffootagewiththem controlledusingearlyalarmsystembyalertingtheoperator 4.Ifwelookatthesurveillancesystemofdifferentcountries andconcernedauthoritiessoactioncanbetakenimmediately.",
        "aroundtheworld,UKhasabout4.5millioncameras,which Gun detection in real-time is a very challenging task.",
        "are used for surveillance.",
        "Sweden has about 50000 cameras As our desired object has a small size so, detecting it in an installed around 2010.",
        "The government of Poland was able image is also very challenging in presence of other objects, to reduce drug cases by 60 and street fights by 40 by especially those objects that can be confused with it.",
        "Deep installing just 450 cameras in the city of Poznan 5.",
        "China learning models faced several below mentioned challenges hastheworldsbiggestsurveillancesystemand170million fordetectionandclassificationtask camerasaroundthenation,andtheseareexpectedtoexpand  The first and main problem is the data through which threetimes,throughanadditional400milliontobeconnected CNNlearnitsfeaturestobeusedlaterforclassification by 2020.",
        "It took only seven minutes for Chinese officials anddetection.",
        "to find and apprehend BBC reporter John Sudworth using  Nostandarddatasetwasavailableforweapons.",
        "their strong CCTV cameras network and facial recognition  For real-time scenarios, making a novel dataset manu- technologyandputthecriminalbehindthebar6.",
        "allywasaverylongandtime-consumingprocess.",
        "In previous years, though having surveillance cameras  Labelingthedesireddatabaseisnotaneasytask,asall installed, to use them for security purposes was not an easy dataneedstobelabeledmanually.",
        "and dependable method.",
        "A human has to be there all the  Different detection algorithms were used, so a labeled timetomonitorscreens.CCTVoperatorhastomonitor20- datasetforonealgorithmcannotbeutilizedfortheother 25screensfor10hours.Hehastolook,observe,identify,and one.",
        "controlthesituationthatcanbeharmfultotheindividualsand  Every algorithm requires different labeling and pre- theproperty.Asthenumberofscreensincreases,theconcen- processingoperationsforthesame-labeleddatabase.",
        "trationofthepersondecreasesconsiderablytomonitoreach  As for real-time implementation, detection systems screen with time.",
        "It is impossible for the person monitoring require the exact location of the weapon so gun block- thescreenstokeepthesamelevelofattentionallthetime7.",
        "ingorocclusionisalsoaproblemthatarisesfrequently The solution to aforementioned problem is to install anditcouldoccurbecauseofself,inter-object,orback- surveillancecameraswiththeabilitytoautomaticallydetect groundblocking.",
        "weaponsandraisealarmtoalerttheoperatorsorsecurityper- sonals.However,thereisnotmuchworkdoneonalgorithms Different approaches are used in this work for weapon for weapon detection in surveillance cameras, and related classificationanddetectionpurposebutallhavedeeplearning studies are often considering concealed weapon detection and CNN architecture behind them because oftheir state of CWD, mostly using X-rays or millimeter waves images the art performance.",
        "Training from scratch took very much employingtraditionalmachinelearningtechniques812.",
        "time so the Transfer learning approach was used and Ima- In the past few years, deep learning in particular convo- geNet and COCO common objects in context pre-trained lutional neural network CNN has given groundbreaking models are used.",
        "Different datasets were made for classifi- results in object categorizing and detection.",
        "It has achieved cation and detection.",
        "For real-time purposes, we made our finest results thus far in classical problems of image pro- datasetbytakingweaponphotosfromthecamera,datawas cessingsuchasgrouping,detectionandlocalization.Instead extractedmanuallyfromrobberyCCTVvideos,downloaded VOLUME9,2021 34367 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning fromimfdbinternetmoviefirearmdatabase,databyuniver- detect hidden weapons in a situation where the image of sityofGranadaandotheronlinerepositories.Alltheworkhas the scene was present over and under exposed area.",
        "Their beendonetoachieveresultsinreal-time.",
        "methodologywastoapplyahomomorphicfiltercapturedat Themaincontributionsofthisworkarepresentationofa distinct exposure conditions to visual and IR pictures 16.",
        "first detailed and comprehensive work on weapon detection Current techniques attain high precision by using various that can achieve detection in videos from real-time CCTV combinations of extractors and detectors, either by using andworkswelleveninlowresolutionandbrightnessbecause easy intensity descriptors, boundary detection, and pattern most of the work done earlier is on high definition training matching9orbyusingmorecomplicatedtechniquessuch images but realtime scenario needs realtime training data ascascadeclassifierswithboosting.",
        "as well for better results, finding of the most suitable and CWD though had worked for some sort of cases but it appropriateCNNbasedobjectdetectorfortheapplicationof had many limitations.",
        "These systems were based on metal weapondetectioninreal-timeCCTVvideostreams,making detection non-metallic guns cannot be detected.",
        "They were ofanewdatasetbecausereal-timedetectionalsoneedsreal- costly to use in many locations because they need to be timetrainingdatasowemadeanewdatabaseof8327images coupledwithX-rayscannersandconveyorbeltsandresponds andpreprocesseditusingdifferentOpenCVfiltersi.e.Equal- to all metallic objects, so were not accurate.",
        "Economic cost ized, Grayscale and clahe that helped in detecting images andhealthriskslimitedthepracticalimplementationofsuch inlowbrightnessandresolution,introducingtheconceptof methods.",
        "Furthermore, video-based firearm detection was a relatedconfusionclassestoreducefalsepositivesandnega- preventivemeasureforacousticdetectionofgunshotandcan tives,trainingandtestingofournoveldatabaseonthelatest becombinedwithitforimplementation17,18.",
        "state of the deep learning based classification and detection Theideaofautomatedimageprocessingforpublicsecurity modelsamongthemYolov4performedbestintermsofboth purposesinmanyfieldshasbeenwellrecognizedandstudied.",
        "speed and accuracy and our selected trained model predict CCTVwastheultimateneedforthiskindofworktoprogress.",
        "imagesatalmosteveryorientation,angle,andview,achieving CCTV was first used back in 1946 in Germany and at that the highest mean average precision of 91.73 along with a time, these cameras were installed to observe the launch of F1-scoreof91onYolov4.",
        "a rocket named V2 19.",
        "Although it had been used earlier, Therestofthepaperisorganizedasfollowsrelatedwork majorimprovementshappenedinthelasttwodecades.With isdiscussedinSectionII.Theimplementationmethodology the advancement in CCTV technology, visual object recog- basedondeeplearningalgorithmsisexplainedinSectionIII.",
        "nition and detection for surveillance, control, and security Thedatasetconstruction,annotation,andpreprocessingusing were performed.",
        "In 1973, Charge-Coupled Device CCD different filters have been discussed in section IV, which was developed, which made the deployment of surveillance follows the experiments and results in Section V.",
        "Finally, cameras possible by 1980 20.",
        "If we go a bit forward in theconclusionandfutureworkisdiscussedinSectionVI.",
        "time,acompanynamedAxisCommunicationdevelopedthe first-evernetworkcamera,whichenabledthetransformation II.",
        "RELATEDWORK of surveillance cameras from analog to digital 20.",
        "This Theproblemofdetectionandclassificationofobjectsinreal- transformation of analog to digital video made it possible time started after major developments in the CCTV field, for everyone to apply image processing, machine learning, processing hardware, and deep learning models.",
        "Very little and computer vision techniques on videos recorded from work has been done in this field before and most of the surveillancecameras.In2003,RoyalPalmMiddleSchoolin previous effort was related to concealed weapon detection Phoenixusedfacialrecognitionforthefirsttimefortracking CWD.",
        "missingchildren.",
        "StartingwithconcealedweapondetectionCWD,before Several object detection algorithms were proposed in the its use in weapon detection, it was used for luggage control fieldofcomputervisiontomakesurveillancesystembetter.",
        "and other security purposes at airports and was based on Objectdetectionalgorithmswereusedinseveralsectorslike imagingtechniqueslikemillimeter-waveandinfraredimag- anomaly detection, deterrence, human detection, and traffic ing8.Sheenetal.suggestedCWDmethodbasedonathree- monitoring 21.",
        "R.",
        "Chellapa et.al.",
        "discussed briefly object dimensional millimeter mm wave imaging method, for tracking and detection in surveillance cameras 22.",
        "The detectinghiddenweaponsatairportsandothersafelocations authors had explained the tracking of an object using mul- in the body 13.",
        "Z.",
        "Xue et al.",
        "suggested a CWD technique tiple surveillance cameras.",
        "Another author addressed tech- basedonafusion-basedtechniqueofmulti-scaledecomposi- niques for detecting objects that come into contact with tion,whichcombinescolorvisualpicturewithinfraredIR another object and are occluded.",
        "They also wrote regarding picture integration 14.",
        "R.",
        "Blum et al.",
        "suggested a CWD the segmentation of mean fluctuations.",
        "They outlined how methodbasedontheinclusionofvisualpictureandIRormm mean segmentation of shifts can help detect objects.",
        "They wave picture using a multi-resolution mosaic technique to used a Bayesian Kalman filter with a simplified Gaussian highlightthehiddenweaponofthetargetpicture15.",
        "blend BKF-SGM algorithm to track the detected object E.M.Upadhyayet.al.suggestedaCWDtechniqueusing 23.J.SMarquesproposeddistincttechniquesforevaluating image fusion.",
        "They used IR image and visual fusion to the efficiency of distinct algorithms for object recognition 34368 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning 24.",
        "B.",
        "Triggs et.al.",
        "described histogram oriented gradient learnedthedeeprepresentationofthedataandreducedalot HOG.HOGbecameanovelarchitectureforfeatureextrac- ofmanualwork,andsavedtimeandenergy.",
        "tion.",
        "It was used mostly in applications involved in human RohithVajhalaetal.proposedthetechniqueofknifeand detection 25.",
        "In 2005, the sliding window technique was gun detection in surveillance systems.",
        "They had used HOG proposedfortherecognitionofnumberplates26.Theyhad asafeatureextractoralongwithbackpropagationofartificial usedaslidingwindowforthepurposeofsegmentationanda neural networks for classification purposes.",
        "The detection neuralnetworkforcharacterrecognitiononthenumberplate.",
        "was performed using different scenarios, first weapon only Asdescribedabove,objectiondetectionforthecomputer and then using HOG and background subtraction methods visiontaskswasusedforsomeapplicationswithbigobjects for human before the desired object and claimed to have to identity like a person, transport or traffic monitoring, an accuracy of 83 34.",
        "The aforementioned work uses etc.",
        "Literature review on weapon detection left me with the the CNN along with non-linearity of ReLu, convolutional opinionthatregardlessofmanyobjectdetectionalgorithms, neurallayer,fullyconnectedlayer,anddropoutlayerofCNN the algorithms proposed for weapon detection are very few.",
        "to reach a result for detection with multiple classes and At last, the idea of firearm detection using the images and implemented their work using the Tensor flow open-source videoswasproposedandfalsealarmswerereducedbyclas- platform.",
        "Their system achieved a test accuracy of 90.2  sifying neural networks with region-based descriptors and for their dataset 35.",
        "MichałGrega et al.",
        "proposed knives determiningregionofinterestROIusingtheslidingwindow and firearm detection in CCTV images.",
        "They had applied techniqueandthentrainedtheneuralnetworkclassifierwith MPEG-7 and principle component analysis along with the imagepixels27.",
        "slidingwindowapproach,whichmadetheirworkslowerfor With the development in CCTVs, object detection for real-time scenarios, although they claimed to achieve good different computer vision problems for real-time were per- accuracyontheirtestdataset.5.",
        "formedandtheideatodetectfirearmswereintroducedfirst Verma et al.",
        "had also used the deep learning technique by L.",
        "Ward et al.",
        "in 2007 28 and a surveillance system to detect weapons and used the Faster RCNN model.",
        "The was also implemented by them a year later in 2008 29.",
        "work was performed on imfdb, which in my opinion is not Intheaforementionedwork,writerscreatedanaccuratepistol suitable to train a model for real-time case.",
        "They claimed detection model for RGB pictures.",
        "However, in the same to have an accuracy of 93.1 on that dataset but in the scene,theirmethoddidnotdetectvariouspistols11,10, case of weapon detection, only achieving higher accuracy 29.",
        "The approach used comprises of first removing non- is not enough, and precision and recall must the considered related items from the segmented picture using the K-mean 36.",
        "Siham Tabik et al.",
        "work was very much related to clustering algorithm and then applying the SURF Speed the real-time scenario.",
        "They used Faster RCNN to detect up Robust Features method to detect points of interest.",
        "weapons in real-time using sliding window and region pro- Darker gave the concept of SIFT based weapon detection posalmethods.Bestresultswereobtainedbyusingtheregion algorithmandforROIestimation,usedthemotionsegmen- proposaltechnique.Theslidingwindowwasalsoverytime- tationmethod30.SIFTalgorithmispronetofalsealarms, consumingandtook14s/image,ontheotherhand,theregion so for estimating ROI, authors used motion segmentation proposal method processed the image in 140ms with 7 fps rather than using SIFT on complete image.",
        "When ROI was 37.",
        "They trained the network on Faster RCNN using only determined,thenSIFTwasappliedtodetectfirearmsintheir oneclassfocusingonreducingthefalsepositive.Recentpast case.",
        "objectiondetectionworkwiththeapplicationtofirearmswas Differentapproachesthenusedforweapondetectionusing proposedin2019,whereagroupofresearchers,JavedIqbal sliding window and region proposal algorithms.",
        "HOG His- etal.proposedorientationawaredetectionoftheobject.This togram of oriented Gradient models were used to predict system is more suitable for long and thin objects like rifles the objects in the frame.",
        "HOG significant work used low- etc.",
        "The predicted bounding box in their case was aligned levelfeatures,discriminativelearning,andpictorialstructure with the object and had the less unnecessary area to deal alongwithSVM25,31,32.Thesealgorithmswereslow with.",
        "Images of very high quality were used for training for real-time scenarios with 14s per image.",
        "Although these and testing purposes, which may make it less suitable for classifiersgavegoodaccuracies,theslownessofthesliding real-time scenarios 38.",
        "Jose Luis Salazar Gonzalez et al.",
        "window method was a big problem, especially for the real- work was very much related to achieve real-time results.",
        "timeimplementationpurpose.",
        "They did immense experimentation using different datasets Thisworkfocusesonthestateoftheartdeeplearningnet- and trained FasterRCNN using Feature Pyramid Network work rather SIFT and HOG features which use handcrafted withResnet50andimprovesthepreviousstateoftheartby rules for feature extraction, selection, and detection in real- 3.9139.",
        "time visual scenario using CCTV cameras.",
        "X.",
        "Zhang et al.",
        "concluded an important finding that helped my work.",
        "They III.",
        "METHODOLOGY concluded that the automatic feature representation gave Deeplearningisabranchofmachinelearninginspiredbythe improved results rather than manual features 33.",
        "Not only functionalityandstructureofthehumanbrainalsocalledan thelearnedfeatureswerebetterinperformance,theyalsohad artificial neural network.",
        "The methodology adopted in this VOLUME9,2021 34369 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning work features the state of art deep learning, especially the convolutional neural networks due to their exceptional per- formanceinthisfield.40.Theaforementionedtechniques are used for both the classification as well as localizing the specific object in a frame so both the object classification and detection algorithms were used and because our object is small with other object in background so after experi- mentationwefoundthebestalgorithmforourcase.Sliding window/classification and region proposal/object detection algorithmswereused,andthesetechniqueswillbediscussed FIGURE1.",
        "ObjectRecognitiontodetectionHierarchy.",
        "laterinthissection.",
        "We had started by doing the classification using different the feature extracted, it then predicts the label based on the deeplearningmodelsandachievedgoodprecisionbutforthe probability.",
        "real-timescenarios,thelowframepersecondsofclassifica- tion models were the real issue in implementation.",
        "Oxford VGG 41, 42, Google Inceptionv3 43 and Inception- 2 OBJECTLOCALIZATION Resnetv2 44, 45 were trained using the aforementioned This method outputs the actual location of an object in an approach.",
        "imagebygivingtheassociatedheightandwidthalongwith To achieve high precision, increase number of frame itscoordinates.",
        "per seconds and improve localization, we moved to the object detection and region proposal methods.",
        "The differ- 3 OBJECTDETECTION ent state of the art deep learning models for object detec- This task uses the properties of the aforementioned algo- tion were used and the results were compared in terms of rithms.",
        "The detection algorithm tells us the bounding box precision, speed, and standard metric of F1 score.",
        "State havingxandycoordinateswithassociatedwidthandheight of the art deep learning based SSDMobileNetv1 4648, along with the class label.",
        "Non-max suppression is used to YOLOv3 49, FasterRCNN-InceptionResnetv2 5052, outputtheboxwithourdesiredthreshold54.Thisprocess andYOLOv453weretrainedandtested.",
        "givesthefollowingresultsaltogether Differentdatasetsweremadekeepinginmindtheclassifi- cationanddetectionproblemasbothhaveaseparaterequire-  BoundingBox mentforperformingthetaskstoachievehighaccuracy,mean  Probability average precision as well as frame per second for the real- In past object detection was very limited because of less timeimplementation.Tounderstandobjectclassificationand data and low processing power of computers but with the detection let us first briefly understand object recognition passageoftimethecomputingpowerofcomputersincreased as both the aforementioned types come under the umbrella and world moved from CPUs to Graphic Processing Units of this and combined classification and localization make GPU.",
        "GPUs were firstly made for increasing the graphic detection possible for any kind of detection problem giving quality of the systems and for gaming but later GPUs were classnameaswellastheregionwhereourdesiredobjectis used extensively for deep learning.",
        "In ImageNet, competi- intheframe.",
        "tionsstartedandcontainedabout1000classes55.Thiswas the evolution of machine learning and deep learning.",
        "In the A.",
        "OBJECTRECOGNITION beginning,themodelswerenotverydeep,meanstherewere Asthenamesuggests,itistheprocessofpredictingthereal not many layers as they are now in an algorithm.",
        "Because classorcategoryofanimagetowhichitbelongsbymaking oftheaforementioneddevelopments,in2012A.Krizhevsky probability high only for that particular class.",
        "CNNs are presentedamodelcalledAlexNettrainedonImageNetand used to efficiently perform this process.",
        "Many state of the gotthefirstpositioninthatcompetition.Thiswasthebegin- art Classification and Detection algorithms uses CNN as a ning of object detection in deep learning.",
        "It gave a way to backendtoperformtheirtasks.",
        "researchers and then every year the algorithms and models Fig.",
        "1 depicts that classification and localization come keeponcoming.Allthesealgorithmscontainlayersthatwork underthecategoryofrecognitionandcombinedclassification ontheprincipleoftheconvolutionalneuralnetworkCNN.",
        "and localization is performed to do object detection.",
        "Let us haveabriefoverviewoftheobjectclassification,localization, B.",
        "CLASSIFICATIONANDDETECTIONAPPROACH anddetection.",
        "There are many ways to generate region proposals, but the simplestwayofgeneratingthemisbyusingtheslidingwin- 1 IMAGECLASSIFICATION dow approach.",
        "The sliding window method is slow because The classification model takes an image and slide the ker- filterslidesovertheentireframeandhaslimitations,which nel/filteroverthewholeimagetogetthefeaturemaps.From were tackled by the region proposal approach, so we have 34370 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning the following two approaches used in our work for both classificationanddetectionmodelsare  Slidingwindow/ClassificationModels  Regionproposal/ObjectDetectionModels 1 SLIDINGWINDOW/CLASSIFICATIONMODELS In the method to the sliding window, a box or window is moved over a picture to select an area and use the object recognition model to identify each frame patch covered by thewindow.Itisanexhaustivesearchoverthewholepicture forobjects.Notonlydoweneedtosearchinthepictureforall feasibleplaces,wealsoneedtosearchondistinctscales.This is because models are usually trained on a particular range.",
        "Theoutcomesareintensofthousands104ofpicturespots being classified 56.",
        "The sliding window method is com- putationally very costly because of the search with various aspectratiosandespeciallyforeachpixelofanimageifthe strideorstepvalueisless.",
        "2 REGIONPROPOSAL/OBJECTDETECTIONMODELS Thistechniquetakesanimageastheboundingboxesofinput and output proposals related to all areas in a picture most probable to be the object.",
        "These regional proposals may be FIGURE2.",
        "TrainingandOptimizationFlowDiagram.",
        "noisy coinciding not containing the object flawlessly, but there is a proposal among these region proposals related to partialderivativeofcostfunctionJOwithamultiplierofthe theoriginaltargetobject.Asthismethodtakesapictureasthe learningratealphaα fromtheoldorpreviousweightvalue.",
        "boundingboxesofinputandoutputrelatedtoallpatchesina Gradientdescentisthemainweightoptimizationalgorithm.",
        "picturemostprobabletobeacategory,soitproposesaregion It is used as a base in all optimizers used for the modeling withthemaximumscoreasthelocationofanobject.Instead andithelpsinconvergingthemodelandreachingtheminima of considering all possible regions of the input frame as wherewegetthebestanddesiredweightsvalues.",
        "possibilities,thismethodusesdetectionproposaltechniques toselectregions57.Region-basedCNNsR-CNNwasthe D.",
        "CONFUSIONOBJECTINCLUSION firstdetectionmodeltointroduceCNNsunderthisapproach We have formulated the problem to reduce the number 58.Theselectivesearchmethodofthisapproachproduces of false positives and negatives by adding relevant confu- 2000boxeshavingmaximumlikelihood.",
        "sion object.",
        "The weapon category includes all the handheld Selective search is a widely used proposal generation weapons such as, pistol, revolver, shotgun and other than method because it is very fast having a good recall value.",
        "weaponincludestheobjectsthatcanmostbeconfusedwith Itisdependentonthehierarchicalcalculationofdesiredareas pistolclassese.g.mobile,metaldetector,selfiestick,purse, established on the compatibility of color, texture, size, and etc.",
        "shape59.",
        "By understanding the differences between classification Yolo series is among the state of the art object detection and detection algorithms, sliding window, and region pro- models.",
        "Unlike the other region proposal-based methods it posalmethods,letsnowlookatthealgorithmsusedforboth divides the input image into an SxS grid and then simulta- approaches.",
        "neously predicts the probability and bounding boxes for an objectwithacenterfallingintoagridcell49,53.",
        "E.",
        "CLASSIFIERSANDOBJECTDETECTORS Theclassifiersusedundertheslidingwindowapproach C.",
        "TRAININGMECHANISM  VGG16 Fig.2describesthegeneralmethodologyusedintrainingand  InceptionV3 optimization.",
        "It starts with defining a problem, finding the  InceptionResnetV2 requireddataset,applyingpre-processingmethods,andthen finally training and evaluating the dataset.",
        "If the evaluation Theobjectdetectorsusedforreal-timedetectionare is correct then we save those weights as a classifier but  SSDMobilNetV1 if its incorrect then comes the process of backpropagation  YoloV3 algorithm along with the gradient descent algorithm 60.",
        "FasterRCNN-InceptionResNetV2 Inbackpropagation,weightsareoptimizedbysubtractingthe  YoloV4 VOLUME9,2021 34371 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning Three databases named database1, database2, and database3werecreatedonebyoneafterexperimentationon different algorithms with diverse images, first for classifi- cation and then for object detection.",
        "Although the results obtained from the classification algorithms were not bad but the frames per second were very slow for real-time implementation.",
        "Detail for each database will be discussed inthenextsection.",
        "IV.",
        "DATASETCONSTRUCTION,ANNOTATIONAND PRE-PROCESSINGD-CAP Dataplaysakeyroleinthedevelopmentofanydeeplearning model as the model learns and extract feature from it.",
        "For a real-time model to detect weapons with minimized pro- cessing time and high precision, the importance of accurate andrelevantdataincreasesfurtherasallotherprocessesare dependentonit.",
        "When we study the stats and goes through almost FIGURE3.",
        "DatasetsamplesforpistolClass-Toplefttobottomrighta-d 50-60 videos of robbery on available online resources, aCCTVimagebMediumResolutionImagecImagewithDark backgroundandLowResolution,dFilteredImage.",
        "we come to know that 95 percent of the videos have revolver or pistol as a weapon, so we focused on binary classificationwithpistolandrevolvertobeinasingleclass 3 REASONOFCHOOSINGDATACATEGORIESOFPISTOL calledpistol.Besides,tomakethesystemmorepreciseandto CLASS reducethefalsepositiveandfalsenegativevaluesweadded Thereasonwechoosepistolandrevolverinthepistolclass objectsthatcanbeconfusedwithaweaponsuchasawallet, is because of our study and analysis after watching many cellphone,metaldetectoretcandputtheminaseparateclass robberiesandshootingincidentCCTVvideos.Weconcluded nameditasnotpistol.",
        "thatalmost95oftheweaponusedinthosecaseswereeither Lets now discuss the datasets used in our case because, pistolorrevolver.Fig.3showssomesampleimagesforreal- in a supervised learning case, the network learns the repre- timefromthecollecteddatasetofthepistolclass.",
        "sentation of the input data with given true answers, so the datamustbeclean,preprocessed,andproperlyannotatedto makethenetworklearnandpredictbetter.",
        "4 WEAPONDATASETCATEGORIESFORNOT-PISTOLCLASS Datasets for this class include objects that can most likely be confused with pistol class objects.",
        "Following are some A.",
        "DATASETCONSTRUCTIONANDSELECTION samplescategoriesforthenotpistolclass The task of dataset construction and collection was very importantandtoughaswellbecausetherewasnobenchmark  Wallet datasetavailableforthis.Datasetforreal-timedetectionwas  MetalDetector collected and constructed in different phases and data was  Cellphone collected from the internet, extracted from YouTube CCTV  Selfiestick videos,throughGitHubrepositories,databytheUniversityof Granadaresearchgroup,andinternetmoviefirearmdatabase imfdb.org.",
        "5 REASONOFCHOOSINGDATACATEGORIESOF NOT-PISTOLCLASS Weintroducedthisrelevantconfusionobjectconceptbecause 1 WEAPONDATASETCLASSES these are the objects that can mostly be confused with our Theweapondatasetforreal-timeweapondetectionisdivided desired weapon object, so predicting them correctly results intothefollowingtwoclasses inreducingthenumberoffalsepositivesandfalsenegatives,  Pistol henceincreasingoverallaccuracyandprecision.",
        "Not-Pistol Some previously done work though had objects other than weapons used for the background or class other than a 2 WEAPONDATASETCATEGORIESFORPISTOLCLASS weapon but they had samples like cars, airplanes, cats, etc Datasetforthisclassincludesweaponsamplesofthefollow- andthereareveryfewerchancesforthemtobeconfusedwith ingcategories ourdesiredweapon,whichisverysmallascomparedtothem.",
        "Pistol Asourdesiredobjectsofpistolclassaresmallsotherearelot  Revolver ofchancesforthemtobeconfusedwithsomeotherobjects  Othershothandheldweapons having some features like that.",
        "Fig.",
        "4 shows some sample 34372 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning TABLE1.",
        "DataDistribution.",
        "ing the shortcomings and problems of the previous dataset.",
        "Theneedforthisdatasetarisesbecausethoughwegotarea- sonable accuracy from classification models but the frames per second were very few.",
        "To detect images from CCTV videos,similarkindsoftrainingdatamustbeincludedsowe madeourowndatasettotacklethisissue.",
        "This dataset contains 8327 images divided into the pis- tol and not pistol class.",
        "In this case, a related confusion FIGURE4.",
        "Datasetsamplesfornot-pistolClass-Toplefttobottomright data concept was introduced to reduce false positives and a-daCellPhonebMetalDetectorcSelfieStickdWallet.",
        "false negatives in real-time detection.",
        "Dataset images were extracted from several online sources, from CCTV videos imagesfromthecollecteddatasetofthenotpistolclasswhich for the particular robbery scenario, made our own dataset helpsinreducingfalsepositivesandnegatives.",
        "with a weapon in hand for the diverse scenario, did data augmentation,andfinally,itwasseparatedfortestandtrain B.",
        "DATASETSFORREAL-TIMEDETECTION case.",
        "Thisworkdealswiththebinaryclassificationforareal-time scenario so two classes were made and pistol and revolver C.",
        "DATADISTRIBUTION images were included in pistol class and not pistol class Each of the aforementioned datasets are divided into the includeconfusionclasseslikemobilephone,metaldetector, following categories mentioned in Table 1 with split size selfie stick, wallet, purse, etc.",
        "For the pistol and not pistol defining the separation percentage of the total data into test classes, we have made three datasets, which are explained andtrain.",
        "below.",
        "D.",
        "DATAPRE-PROCESSINGANDANNOTATION 1 DATASET1 Many things affect the performance of a Machine Learning This was the initial dataset used while starting this work.",
        "MLmodelforaspecifiedjob.First,therepresentationand Inthisdataset,wehad1732imagesintotal,with750images qualityofthedataareessential.Iftherearemanyirrelevant inpistolclassand950innotpistolclass.Datasetwasdivided and redundant data existing or noisy and unreliable data, by the separation criteria described in Table 1 of train and then it is harder to discover representation during the train- test.",
        "Images were collected from online sources and imfdb ing stage.",
        "Data preparation and filtering steps take signifi- database and sliding window classification algorithms were cant processing time in ML issues 61.",
        "The pre-processing trainedandtestedonit.",
        "process involves data cleaning, standardization, processing, extraction and choice of features, etc.",
        "The final training 2 DATASET2 datasetistheresultofpre-processingprocessesappliedtothe Thiswastheseconddatasetmadeforthereal-timescenario.",
        "collecteddataset.",
        "Thisdatasetcontains5254imagesandclassification,aswell Pre-processingisnecessaryforbettertrainingofamodel, asobjectdetectionalgorithms,weretrainedonthisdatasetto sothefirststepistomakethesamesizeorresolutionofthe meet the task.",
        "Images were extracted for real-time scenario dataset.Thenextstepistoapplythemeannormalization.The with the desired object in hand from online, sources, imfdb thirdstepismakingboundingboxesontheseimages,which database,andImageNetwebsite.Datasetwasdividedbythe is also called annotation, localization, or labeling.",
        "In data, separationcriteriaoftestandtrainexplainedinTable1.",
        "labeling a bounding box is made on each image.",
        "The value x,ycoordinates,andwidth,heightofthelabeledobjectwas 3 DATASET3 storedinxml,csvortxtformat.Followingarethefourmain This was the third dataset constructed for the real-time sce- stepsofdatapreprocessing narioand objectdetectionalgorithmswere performedonit.",
        "Imagescaling Thisdatabasewasmadebyenhancingdataset2byovercom-  Data-augmentation VOLUME9,2021 34373 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning FIGURE5.",
        "ImageAugmentationandScaling.",
        "FIGURE6.",
        "ImageAnnotationandLabelling.",
        "Imagelabeling  ImageFilteringusingOpenCV  RGBtoGrayscale  Equalized  Clahe Fig.",
        "5, 6 and 7 shows the results after applying the afore- mentionedpre-processingtechniques.",
        "V.",
        "EXPERIMENTS,RESULTSANDANALYSIS Wehavedetectedweaponsinreal-timeCCTVstreamsinlow resolution,darklightwithreal-timeframepersecond.Most oftheworkdonebeforewasondetectingimagesandvideos of high quality and because those models were trained on high-qualitydatasets,itisnotpossibletothendetectanobject oflowresolutioninreal-time.Theresultsareanalyzedafter trainingandtestingmodelsondatasetsmentionedinTable1.",
        "As described in the methodology section the results for FIGURE7.",
        "ImageFiltrationusingOpenCVFilters-aOriginalImage bEqualizedFilterResultcGrayScaleFilterResultdClaheFilter differentapproachesareevaluated.Ourmainproblemstate- Result.",
        "mentisofreal-timedetectionbecause97ofweaponused inrobberycaseswerepistolorrevolver,sodifferentdataset results have been evaluated here for sliding window and TruePositives regionproposalapproach.",
        "Recall 2 The performance of these models was analyzed by com- TruePositivesFalseNegatives paringthemintermsofthestandardmetricsofF1-scoreand 2PrecisionRecall F1-score 3 framepersecondsalongwithmeanaverageprecisionmAP PrecisionRecall forthebestperformedmodelandthesetermsarecalculated byusingthebelowequation1,2and3.F1scoreisratioofthe A.",
        "DATASET-1EXPERIMENTATIONANDRESULTS precisionandrecallfunctions.",
        "Dataset 1 contains 1732 images distributed between two TruePositives classes of pistol and not-pistol with 750 and 982 images Precision  1 TruePositivesFalsePositives ineachclassrespectively.Experimentationondataset-1has 34374 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning TABLE2.",
        "SlidingWindowResultsComparisonDataset-1.",
        "FIGURE8.",
        "BestslidingwindowmodelaccuracygraphInceptionResNetv2.",
        "beenperformedusingtheslidingwindow/classificationmod- elsofVGG16,Inceptionv3andInceptionResNetv2.",
        "After experimentation, we have analyzed that the results obtained are not good because most of the images of this datasethavewhiteorthesamekindofbackgroundwhichlead toapointwherethemodelalsostartslearningthebackground as its region of interest ROI and in real-time background variessoanewdatasetwasrequiredtotrainandtestthemodel onimageswithdiversecasesandbackground.Table2shows the results for the aforementioned models using this dataset givingprecision,recall,andF1-score.",
        "FIGURE9.",
        "BestslidingwindowmodelLossgraphInceptionResNetv2.",
        "B.",
        "DATASET-2EXPERIMENTATIONANDRESULTS This dataset contains two classes of pistol and not- pistol with 3000 and 2254 images in each class respec- tively.",
        "Table 3 shows results based on it.",
        "Experimenta- tion on dataset-2 has been performed using the sliding window/classification models of VGG16, Inceptionv3, and InceptionResNetv2.",
        "Experimentationresultsshowthatthoughwegetareason- able accuracy from classification models using this dataset but the frames per second were very few and which was a bigprobleminmakingareal-timeweapondetector.Among these classification models, InceptionResnetV2 performed best and achieves the best results.",
        "Table 3 shows the results under the sliding window methods using dataset 2 and Fig.",
        "8, 9, and 10 shows the accuracy, loss, and confusion matrix FIGURE10.",
        "BestslidingwindowmodelConfusionMatrix respectivelyforthebestclassificationmodelunderthesliding InceptionResNetv2.",
        "windowapproach.",
        "C.",
        "DATASET-3EXPERIMENTATIONANDRESULTS  FasterRCNN-InceptionResNetV2 After experimentation on the previous two datasets and not  YoloV4 findingsatisfactoryresultsforthereal-timecaseanewdataset Each model had its pros and cons.",
        "SSD-MobileNet is was made.",
        "Images were collected from robbery videos, our goodintermsofprocessingframespersecond.FasterRCNN- own dataset images holding a weapon in different scenar- InceptionResNetv2 has good precision and recall but not ios, images with a dark background and low resolution, processingspeed.Yolofamilyhasaseriesofmodels.Ithasa and images extracted from applying different OpenCV fil- differentapproachforthedetectionpurpose.Unliketheother ters are added to make real-time detection possible.",
        "A total regionproposalbasedmethods,itdividestheinputimageinto of8327imagesareusedinthiscase.Followingobjectdetec- anSxSgridandthensimultaneouslypredictstheprobability tionmodelsweretrainedandevaluatedusingthisdataset andboundingboxesforanobjectwiththecenterfallingintoa  SSDMobilNetV1 gridcell.WehavetrainedthelateststateoftheartYolov3and  YoloV3 Yolov4onourownweapondataset3forreal-timedetection VOLUME9,2021 34375 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning TABLE3.",
        "SlidingWindowResultsComparisonDataset-2.",
        "TABLE4.",
        "RegionProposal/ObjectDetectionModels-Dataset-3.",
        "FIGURE11.",
        "BestObjectDetectionModel-Yolov4lossvsmAP.",
        "TABLE5.",
        "BestPerformedModelYolov4mAPCalculation.",
        "andbestresultswereobtainedthroughYOLOv4intermsof both processing speed and precision.",
        "Table 4 below shows the results for the aforementioned detection models for this datasetatastandardthresholdscoreof50.",
        "Yolov4 performs best among all the models of both the sliding window and region proposal approach.",
        "Performance graphforyolov4intermsoflossandmeanaverageprecision mAPonavalidationdatasetisshowninFig.11.Wecansee that how smooth is the model loss curve and how precisely it converges to the best level giving a very good loss score of1.062andameanaverageprecisionof91.73.Themean averageprecisionisthemeanoftheaverageprecisionvalues foralltherelevantclasses.Theassociatedvaluesofaverage standard metrics of precision, recall, and F1-score for precisionAPforpistolandnot-pistolclassforthecalcula- evaluation.",
        "tionofmeanaverageprecisionvalueisgiveninTable5.",
        "Some classification models showed good results but The mean average precision value is calculated for the they were not suitable for a real-time scenario, were yolov4modelasitperformsbestinallscenarioandaccurately slow, not much accurate, and fast as compared to the detected the desired object even when the object has a very objectdetectionmodelsastheyperformsverywelland small presense in the frame and there were lots of other achievedhighprecisionandrecall.",
        "objectsinthebackgroundaswell.",
        "Thereasonwhysomeclassificationmodelshaveagood F1-scoreisthetrainingandevaluationoninitialdatasets D.",
        "ANALYSISANDDISCUSSION wemadewhenstartingthiswork,butafterexperimenta-  Table2,3,and4aboveshowsthecomparisonbetween tion,wecometoknowthatthesemodelsarenotsuitable the classification and object detection models using forreal-timescenarioshavingthebackgroundobjects.",
        "34376 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning FIGURE13.",
        "BestperformedmodelscomparisonAccuracyvsF1-score.",
        "FIGURE12.",
        "ObjectDetectionmodelsPerformance/ComparisonGraph.",
        "TABLE6.",
        "Yolov4HyperParameters.",
        "Object detection models performed well for the real- time scenario and performance comparison in terms of speedandF1-scorebetweenthedetectionmodelscanbe seen from Fig.",
        "12.",
        "Inference results are obtained using theNVIDIARTX2080tiforeachmodel.",
        "ThestandardmetricsofmeanaverageprecisionmAP, recallandF1-scorearecalculateandallthemodelshave beencomparedatabenchmarkIoUthresholdof0.50or 50.",
        "Yolov4 performs best amongst all models with a mean average precision and F1-score of 91.73 and 91 respectively with detection confidence of 99 in the majorityofcases.",
        "Comparison in terms of test accuracy vs F1-score TABLE7.",
        "Comparisonwithsomeexistingstudies.",
        "for the best-performed models of both classifica- tion and detection approaches is shown in the Fig.13.",
        "Accuracy and F1-score for VGG, Inceptionv3, InceptionResNetv2, SSDMobileNet, FasterRCNN- InceptionResNetv2, Yolov3 and yolov4 are 78.20, 85.20, 92.20, 79, 96, 94, 99 and 81.69, 84.36,85.74,59,87,86and91respectively.",
        "Fig.14-19showstheinferenceordetectionresultsofour modelforpistolandnotpistolclassonimages,videos, andreal-timeCCTVstreams.",
        "Hyperparameters used in training the best-performed detectorYolov4canbeobservedfromTable6.",
        "Itisveryhardtodoacomparisonwithstudiesconducted previously on this subject because each study has its own dataset, models and metrics used to evaluate performance.",
        "in terms of mAP and precisoin at a standard iou threshold Itshouldalsobenoticedachieverealtimedetection,wealso of50,whicheverwasavailable.",
        "needtohavearealtimedatasetfortraningbecausewithhigh qualitytrainingimageswecannotachieveresultsinrealtime.",
        "E.",
        "DETECTIONRESULTS-PISTOLCLASSWITHOUT Each study also has different testing conditions, either just BACKGROUND on images, videos or on images with high quality but our SeeFigure14.",
        "approachfromstartwastoachieverealtimeresults.Insome studies,theperformanecemetricusedisaccuray,othershave F.",
        "DETECTIONRESULTS-PISTOLCLASSWITH precisoinormeanaverageprecisionmAPbutmostlymAP BACKGROUND is used as standard so we have given comparison results SeeFigure15.",
        "VOLUME9,2021 34377 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning FIGURE14.",
        "DetectionResults-Onlyweaponinthewholeframewithoutanybackgroundatdifferentangles,brightness,sharpness,andquality.",
        "FIGURE15.",
        "DetectionResults-Toplefttobottomrighta-iaImagewithfrontandsideview,bImageverticalviewcImagewithDarkbackground andLowResolutionfullytiltedsideview,dLowbrightnessimagesideviewslightlytiltedeImagewiththebackviewfFullfrontviewgSmallCCTV objecthVerysmallobjectwithsideviewiImagewithfullsideview.",
        "G.",
        "DETECTIONRESULTS-PISTOLCLASSINVIDEOS I.",
        "DETECTIONRESULTSNOTPISTOLCLASS SeeFigure16.",
        "SeeFigure18.",
        "H.",
        "DETECTIONRESULTS-PISTOLCLASSINREALTIME CCTVSTREAMS J.",
        "MISDETECTIONS SeeFigure17.",
        "SeeFigure19.",
        "34378 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning FIGURE16.",
        "DetectionResults-Toplefttobottomrighta-f-video1inferencea-c,video2inferenced-faSmallobject-sideviewtilted,bSmall objectwithsideviewcSmallobjectfrontviewdsidevieweTopviewdoubleobjectfSmallobjectwithfrontandsideview.",
        "FIGURE17.",
        "DetectionResults-Toplefttobottomrighta-i-cctvstream1a-c,cctvstream2d-f,cctvstream3g-iaSmallobjectinLowresolutionb TiltedObjectcLowResolutionverticalobject,dDaylightsideviewwithslightlytiltedeDaylightsideviewfDaylightsideviewflippedgSmall objectmediumresolutionhverticalviewisideview.",
        "VI.",
        "CONCLUSIONANDFUTUREWORK and tourists, as security and safety are their primary needs.",
        "For both monitoring and control purposes, this work has We have focused on detecting the weapon in live CCTV presentedanovelautomaticweapondetectionsysteminreal- streams and at the same time reduced the false negatives time.",
        "This work will indeed help in improving the secu- and positives.",
        "To achieve high precision and recall we con- rity, law and order situation for the betterment and safety structed a new training database for the real-time scenario, of humanity, especially for the countries who had suffered then trained, and evaluated it on the latest state-of-the-art a lot with these kind of violent activities.",
        "This will bring deep learning models using two approaches, i.e.",
        "sliding a positive impact on the economy by attracting investors window/classification and region proposal/object detection.",
        "VOLUME9,2021 34379 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning FIGURE18.",
        "DetectionResults-Toplefttobottomrighta-daCellphonebMetaldetectorcWalletd Selfiestick.",
        "FIGURE19.",
        "MisdetectionsFalsepositivesandNegatives.",
        "Differentalgorithmswereinvestigatedtogetgoodprecision ACKNOWLEDGMENT andrecall.",
        "TheauthorswishtoextendgratitudetoMr.RehanMushtaq Throughaseriesofexperiments,weconcludedthatobject of Ingenious Zone who provided assistance as an industrial detection algorithms with ROI Region of Interest perform partnerinmakingthisworkpossible.",
        "better than algorithms without ROI.",
        "We have tested many REFERENCES models but among all of them, the state-of-the-art Yolov4, 1 2019.",
        "Christchurch Mosque Shootzings.",
        "Accessed Jul.",
        "10, 2019.",
        "trainedonournewdatabase,gaveveryfewfalsepositiveand Online.Availablehttps//en.wikipedia.org/wiki/Christchurch_mosque_ negative values, hence achieved the most successful results.",
        "shootings Itgave91.73meanaverageprecisionmAPandaF1-score 2 2019.",
        "Global Study on Homicide.",
        "Accessed Jul.",
        "10, 2019.",
        "Online.",
        "Available https//www.unodc.org/unodc/en/data-and-analysis/global- of 91 with almost 99 confidence score on all types of study-on-homicide.html imagesandvideos.Wecansaythatitsatisfactorilyqualifies 3 W.Deisman,CCTVLiteraturereviewandbibliography,inResearch as an automatic real-time weapon detector.",
        "Looking at the and Evaluation Branch, Community, Contract and Aboriginal Policing Services Directorate.",
        "Ottawa, ON, Canada Royal Canadian Mounted, results,wegotthehighestmeanaverageprecisionmAPF1- 2003.",
        "score as compared to the research done before for real-time 4 J.",
        "Ratcliffe, Video surveillance of public places, US Dept.",
        "Justice, scenarios.",
        "Office Community Oriented Policing Services, Washington, DC, USA, Tech.Rep.4,2006.",
        "Thefutureworkincludesreducingthefalsepositivesand 5 M.Grega,A.Matiolałski,P.Guzik,andM.Leszczuk,Automateddetec- negativesevenmoreasthereisstillaneedforimprovement.",
        "tionoffirearmsandknivesinaCCTVimage,Sensors,vol.16,no.1, Wemightalsotrytoincreasethenumberofclassesorobjects p.47,Jan.2016.",
        "6 TechCrunch.",
        "2019.",
        "Chinas CCTV Surveillance Network Took Just 7 in the future but the priority is to further improve precision Minutes to Capture BBC Reporter.",
        "Accessed Jul.",
        "15, 2019.",
        "Online.",
        "andrecall.",
        "Availablehttps//techcrunch.com/2017-12-13/china-cctv-bbc-reporter/ 34380 VOLUME9,2021 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning 7 N.",
        "Cohen, J.",
        "Gattuso, and K.",
        "MacLennan-Brown.",
        "CCTV Operational 29 I.T.Darker,A.G.Gale,andA.Blechko,CCTVasanautomatedsensor Requirements Manual 2009.",
        "St Albans, U.K.",
        "Home Office Scientific for firearms detection Human-derived performance as a precursor to DevelopmentBranch,2009.",
        "automaticrecognition,Proc.SPIE,vol.7112,Oct.2008,Art.no.71120V.",
        "8 G.Flitton,T.P.Breckon,andN.Megherbi,Acomparisonof3Dinterest 30 I.",
        "T.",
        "Darker, P.",
        "Kuo, M.",
        "Y.",
        "Yang, A.",
        "Blechko, C.",
        "Grecos, D.",
        "Makris, pointdescriptorswithapplicationtoairportbaggageobjectdetectionin J.-C.Nebel,andA.Gale,AutomationoftheCCTV-mediateddetectionof complexCTimagery,PatternRecognit.,vol.46,no.9,pp.24202436, individualsillegallycarryingfirearmsCombiningpsychologicalandtech- Sep.2013.",
        "nologicalapproaches,Proc.SPIE,vol.7341,Apr.2009,Art.no.73410P.",
        "9 R.Gesick,C.Saritac,andC.-C.Hung,Automaticimageanalysisprocess 31 R.Al-Rfouetal.,TheanoAPythonframeworkforfastcomputationof forthedetectionofconcealedweapons,inProc.5thAnnu.Workshop mathematicalexpressions,2016,arXiv1605.02688.Online.Available CyberSecur.Inf.Intell.Res.CyberSecur.Inf.Intell.ChallengesStrategies http//arxiv.org/abs/1605.02688 CSIIRW,2009,p.20.",
        "32 F.Chollet.2019.Fchollet.AccessedApr.10,2019.Online.Available 10 R.",
        "K.",
        "Tiwari and G.",
        "K.",
        "Verma, A computer vision based framework https//github.com/fchollet forvisualgundetectionusingHarrisinterestpointdetector,Procedia 33 K.He,X.Zhang,S.Ren,andJ.Sun,Deepresiduallearningforimage Comput.Sci.,vol.54,pp.703712,Aug.2015.",
        "recognition,inProc.IEEEConf.Comput.Vis.PatternRecognit.CVPR, 11 R.K.TiwariandG.K.Verma,Acomputervisionbasedframeworkfor Jun.2016,pp.770778.",
        "visualgundetectionusingSURF,inProc.Int.Conf.Electr.,Electron., 34 2016.",
        "Weapon Detection in Surveillance Cameras Images.",
        "Signals,Commun.Optim.EESCO,Jan.2015,pp.15.",
        "Accessed Feb.",
        "13, 2021.",
        "Online.",
        "Available http//www.diva- 12 Z.",
        "Xiao, X.",
        "Lu, J.",
        "Yan, L.",
        "Wu, and L.",
        "Ren, Automatic detection of portal.org/smash/record.jsf?piddiva23A1054902dswid-1974 concealedpistolsusingpassivemillimeterwaveimaging,inProc.IEEE 35 M.Nakib,R.T.Khan,M.S.Hasan,andJ.Uddin,Crimesceneprediction Int.Conf.Imag.Syst.Techn.IST,Sep.2015,pp.14.",
        "by detecting threatening objects using convolutional neural network, 13 D.",
        "M.",
        "Sheen, D.",
        "L.",
        "Mcmakin, and T.",
        "E.",
        "Hall, Three-dimensional in Proc.",
        "Int.",
        "Conf.",
        "Comput., Commun., Chem., Mater.",
        "Electron.",
        "Eng.",
        "millimeter-waveimagingforconcealedweapondetection,IEEETrans.",
        "IC4ME2,Feb.2018,pp.14.",
        "Microw.TheoryTechn.,vol.49,no.9,pp.15811592,Sep.2001.",
        "36 G.K.VermaandA.Dhillon,AhandheldgundetectionusingfasterR- 14 Z.",
        "Xue, R.",
        "S.",
        "Blum, and Y.",
        "Li, Fusion of visual and IR images for CNNdeeplearning,inProc.7thInt.Conf.Comput.Commun.Technol.",
        "concealedweapondetection,inProc.5thInt.Conf.Inf.Fusion,vol.2, ICCCT,2017,pp.8488.",
        "Jul.2002,pp.11981205.",
        "37 R.Olmos,S.Tabik,andF.Herrera,Automatichandgundetectionalarm 15 R.",
        "Blum, Z.",
        "Xue, Z.",
        "Liu, and D.",
        "S.",
        "Forsyth, Multisensor concealed in videos using deep learning, Neurocomputing, vol.",
        "275, pp.6672, weapon detection by using a multiresolution mosaic approach, in Jan.2018.",
        "Proc.",
        "IEEE 60th Veh.",
        "Technol.",
        "Conf.",
        "VTC-Fall, vol.",
        "7, Sep.",
        "2004, 38 J.",
        "Iqbal, M.",
        "A.",
        "Munir, A.",
        "Mahmood, A.",
        "Rafaqat Ali, and M.",
        "Ali, pp.45974601.",
        "Orientationawareobjectdetectionwithapplicationtofirearms,2019, 16 E.M.UpadhyayandN.K.Rana,Exposurefusionforconcealedweapon arXiv1904.10032.Online.Availablehttps//arxiv.org/abs/1904.10032 detection, in Proc.",
        "2nd Int.",
        "Conf.",
        "Devices, Circuits Syst.",
        "ICDCS, 39 J.L.S.González,C.Zaccaro,J.A.Álvarez-García,L.M.S.Morillo,and Mar.2014,pp.16.",
        "F.S.Caparrini,Real-timegundetectioninCCTVAnopenproblem, 17 R.Maher,Modelingandsignalprocessingofacousticgunshotrecord- NeuralNetw.,vol.132,pp.297308,Dec.2020.",
        "ings,inProc.IEEE12thDigit.SignalProcess.Workshop4thIEEESignal 40 2017.",
        "Convolutional Neural Networks.",
        "Accessed Aug.",
        "15, 2018.",
        "Process.Educ.Workshop,Sep.2006,pp.257261.",
        "Online.Availablehttp//cs231n.github.io/convolutional-networks/ 18 A.Chacon-Rodriguez,P.Julian,L.Castro,P.Alvarado,andN.Hernandez, 41 K.SimonyanandA.Zisserman,Verydeepconvolutionalnetworksfor Evaluationofgunshotdetectionalgorithms,IEEETrans.CircuitsSyst.I, large-scaleimagerecognition,2014,arXiv1409.1556.Online.Avail- Reg.Papers,vol.58,no.2,pp.363373,Feb.2011.",
        "ablehttp//arxiv.org/abs/1409.1556 19 2019.",
        "From Edison to Internet A History of Video Surveillance.",
        "42 2019.",
        "VGG16Convolutional Network for Classification and Detec- Accessed Jun.",
        "13, 2019.",
        "Online.",
        "Available https//www.",
        "tion.",
        "Accessed Dec.",
        "19, 2018.",
        "Online.",
        "Available https//neurohive.",
        "business2community.com/tech-gadgets/from-edison-to-internet-a- io/en/popular-networks/vgg16/ history-of-video-surveillance-0578308 20 2019.",
        "Infographic History of Video SurveillanceIFSEC Global  43 C.Szegedy,V.Vanhoucke,S.Ioffe,J.Shlens,andZ.Wojna,Rethinking SecurityandFireNewsandResources.AccessedSep.15,2019.Online.",
        "the inception architecture for computer vision, in Proc.",
        "IEEE Conf.",
        "Comput.Vis.PatternRecognit.CVPR,Jun.2016,pp.28182826.",
        "Available https//www.ifsecglobal.com/video-surveillance/infographic- history-of-video-surveillance/ 44 C.",
        "Szegedy, S.",
        "Ioffe, V.",
        "Vanhoucke, and A.",
        "A.",
        "Alemi, Inception-v4, 21 W.Hu,T.Tan,L.Wang,andS.Maybank,Asurveyonvisualsurveillance inception-resnetandtheimpactofresidualconnectionsonlearning,in ofobjectmotionandbehaviors,IEEETrans.Syst.,Man,Cybern.C,Appl.",
        "Proc.31stAAAIConf.Artif.Intell.,2017,pp.17.",
        "Rev.,vol.34,no.3,pp.334352,Aug.2004.",
        "45 Medium.",
        "2019.",
        "A Simple Guide to the Versions of the 22 A.C.Sankaranarayanan,A.Veeraraghavan,andR.Chellappa,Object Inception Network.",
        "Accessed Jul.",
        "27, 2019.",
        "Online.",
        "Available detection, tracking and recognition for multiple smart cameras, Proc.",
        "https//towardsdatascience.com/a-simple-guide-to-the-versions-of-the- IEEE,vol.96,no.10,pp.16061624,Oct.2008.",
        "inception-network-7fc52b863202 23 S.",
        "Zhang, C.",
        "Wang, S.-C.",
        "Chan, X.",
        "Wei, and C.-H.",
        "Ho, New object 46 D.Anguelov,D.Erhan,C.Szegedy,S.Reed,C.-Y.Fu,andA.C.Berg, detection, tracking, and recognition approaches for video surveillance SSDSingleshotmultiboxdetector,inProc.Eur.Conf.Comput.Vis.",
        "overcameranetwork,IEEESensorsJ.,vol.15,no.5,pp.26792691, Cham,SwitzerlandSpringer,2016,pp.2137.",
        "May2015.",
        "47 Medium.",
        "2019.",
        "Understanding SSD MultiBoxReal-Time Object 24 J.C.NascimentoandJ.S.Marques,Performanceevaluationofobject Detection in Deep Learning.",
        "Accessed Aug.",
        "19, 2019.",
        "Online.",
        "detection algorithms for video surveillance, IEEE Trans.",
        "Multimedia, Available https//towardsdatascience.com/understanding-ssd-multibox- vol.8,no.4,pp.761774,Aug.2006.",
        "real-time-object-detection-in-deep-learning-495ef744fab 25 N.",
        "Dalal and B.",
        "Triggs, Histograms of oriented gradients for human 48 A.G.Howard,M.Zhu,B.Chen,D.Kalenichenko,W.Wang,T.Weyand, detection,Tech.Rep.,2005.",
        "M.Andreetto,andH.Adam,MobileNetsEfficientconvolutionalneu- 26 C.",
        "Anagnostopoulos, I.",
        "Anagnostopoulos, G.",
        "Tsekouras, G.",
        "Kouzas, ral networks for mobile vision applications, 2017, arXiv1704.04861.",
        "V.Loumos,andE.Kayafas,Usingslidingconcentricwindowsforlicense Online.Availablehttp//arxiv.org/abs/1704.04861 platesegmentationandprocessing,inProc.IEEEWorkshopSignalPro- 49 J.",
        "Redmon and A.",
        "Farhadi, YOLOv3 An incremental improve- cess.Syst.DesignImplement.,Nov.2005,pp.337342.",
        "ment,2018,arXiv1804.02767.Online.Availablehttp//arxiv.org/abs/ 27 M.Grega,S.Lach,andR.Sieradzki,Automatedrecognitionoffirearms 1804.02767 insurveillancevideo,inProc.IEEEInt.Multi-DisciplinaryConf.Cog- 50 S.Ren,K.He,R.Girshick,andJ.Sun,FasterR-CNNTowardsreal-time nit.MethodsSituationAwarenessDecis.SupportCogSIMA,Feb.2013, objectdetectionwithregionproposalnetworks,inProc.Adv.NeuralInf.",
        "pp.4550.",
        "Process.Syst.,2015.pp.9199.",
        "28 I.Darker,A.Gale,L.Ward,andA.Blechko,CanCCTVreliablydetect 51 2019.",
        "Faster R-CNN Explained.",
        "Accessed guncrime?inProc.41stAnnu.IEEEInt.CarnahanConf.Secur.Technol., Aug.",
        "25, 2019.",
        "Online.",
        "Available https//medium.",
        "Oct.2007,pp.264271.",
        "com/smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f VOLUME9,2021 34381 M.T.Bhattietal.WeaponDetectioninReal-TimeCCTVVideosUsingDeepLearning 52 Medium.2019.FasterRCNNObjectdetection.AccessedAug.27,2019.",
        "MUHAMMAD GUFRAN KHAN SeniorMem- Online.",
        "Available https//towardsdatascience.com/faster-rcnn-object- ber,IEEEreceivedtheB.Sc.degreeinelectrical detection-f865e5ed7fc4 engineering from the University of Engineering 53 A.",
        "Bochkovskiy, C.-Y.",
        "Wang, and H.-Y.",
        "Mark Liao, YOLOv4 Opti- and Technology, Lahore, Pakistan, in 2003, and mal speed and accuracy of object detection, 2020, arXiv2004.10934.",
        "theM.Sc.degreeinelectricalengineeringspecial- Online.Availablehttp//arxiv.org/abs/2004.10934 izationinsignalprocessingandthePh.D.degree 54 GeeksforGeeks.",
        "2020.",
        "Object Detection Vs Object Recognition Vs in electrical engineering specialization in wire- Image Segmentation.",
        "Accessed Dec.",
        "28, 2020.",
        "Online.",
        "Available lesscommunicationfromtheBlekingeInstituteof https//www.geeksforgeeks.org/object-detection-vs-object-recognition- Technology, Sweden, in 2005 and 2011, respec- vs-image-segmentation/ tively.",
        "55 2019.",
        "ImageNet.",
        "Accessed Jun.",
        "5, 2019.",
        "Online.",
        "Available http// HeiscurrentlyanAssociateProfessorandtheHeadoftheDepartmentof www.image-net.org/ 56 J.",
        "O.",
        "Laguna, A.",
        "G.",
        "Olaya, and D.",
        "Borrajo, A dynamic sliding win- ElectricalEngineering,FASTNUCESChiniot-FaisalabadCampus.Before dow approach for activity recognition, in Proc.",
        "Int.",
        "Conf.",
        "User Mod- joiningFAST,hehasworkedasanAnalysisEngineerwithVolvoCarCorpo- eling, Adaptation, Personalization.",
        "Berlin, Germany Springer, 2011, ration,Sweden.Hehasconductedresearchintheareasofsignalprocessing, pp.219230.",
        "computer vision, and machine learning.",
        "He has also worked on different 57 J.",
        "Hosang, R.",
        "Benenson, P.",
        "Dollar, and B.",
        "Schiele, What makes for fundedresearchprojectsintheareaofembeddedsystemsandrobotics.He effectivedetectionproposals?IEEETrans.PatternAnal.Mach.Intell., isactivelyinvolvedintheapplicationsoftheAIandIoTtechnologytosolve vol.38,no.4,pp.814830,Apr.2016.",
        "real-world problems.",
        "He is also the Chairperson of the IEEE Faisalabad 58 R.Girshick,J.Donahue,T.Darrell,andJ.Malik,Richfeaturehierarchies Subsection.",
        "foraccurateobjectdetectionandsemanticsegmentation,inProc.IEEE Conf.Comput.Vis.PatternRecognit.,Jun.2014,pp.580587.",
        "59 A.",
        "Consulting.",
        "2019.",
        "Selective Search for Object Detection C / Python  Learn OpenCV.",
        "Accessed May 25, 2019.",
        "Online.",
        "Avail- able https//www.learnopencv.com/selective-search-for-object-detection- MASOOD ASLAM received the B.S.",
        "degree in cpp-python/ electrical engineering from The University of 60 Y.Lecun,L.Bottou,Y.Bengio,andP.Haffner,Gradient-basedlearn- Faisalabad,Faisalabad,Pakistan,in2013,andthe ing applied to document recognition, Proc.",
        "IEEE, vol.",
        "86, no.",
        "11, pp.22782324,Nov.1998.",
        "M.S.degreeinelectricalengineeringfromFAST- 61 S.B.Kotsiantis,D.Kanellopoulos,andP.E.Pintelas,Datapreprocessing NUCES,Islamabad,Pakistan,in2018.",
        "forsupervisedleaning,Int.J.Comput.Sci.,vol.1,no.2,pp.111117, HeiscurrentlyworkingasaResearchAssociate 2006.",
        "withtheVisualComputingTechnologyVC-Tech Laboratory, Islamabad.",
        "Before joining VC-Tech, he worked as a Research Assistant with FAST- NUCES.Hisresearchinterestsincludecomputer MUHAMMAD TAHIR BHATTI received the visionandimageprocessing.",
        "B.Sc.",
        "degree in electrical and electronics engi- neeringfromAirUniversity,Islamabad,Pakistan, in2013,andtheM.S.degreeinelectricalengineer- ingwithspecializationandresearchinthefieldof artificialIntelligenceandmachinelearningfrom MUHAMMADJUNAID FIAZreceivedtheB.S.",
        "theNationalUniversityofComputerandEmerg- degreeincomputersciencefromGovernmentCol- ingSciences,Faisalabad,Pakistan,in2019.",
        "legeUniversityFaisalabad,Pakistan,in2019.",
        "HehasworkedasanElectricalandElectronics He has worked as an Android Developer.",
        "He EngineerwithNationalSilkandRayanPvtLtd.",
        "is currently working as a Research Assistant in He is currently working as a Research Assistant in the field of artificial thefieldofartificialintelligencewiththeNational intelligencewiththeNationalUniversityofComputerandEmergingSci- UniversityofComputerandEmergingSciences, ences.HewasaCertifiedArtificialIntelligenceEngineerfromSaylaniMass Faisalabad,Pakistan.",
        "TrainingProgram,Faisalabad,in2018.Hereceivedthebronzemedalfrom theNationalUniversityofComputerandEmergingSciences.",
        "34382 VOLUME9,2021"
      ],
      "word_count": 5636,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        "data": [
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ]
        ]
      },
      {
        "columns": [
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        "data": [
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ]
        ]
      },
      {
        "columns": [
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        "data": [
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            ""
          ]
        ]
      },
      {
        "columns": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        "data": [
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ]
        ]
      },
      {
        "columns": [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        "data": [
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
          ]
        ]
      },
      {
        "columns": [
          ""
        ],
        "data": [
          [
            ""
          ],
          [
            ""
          ]
        ]
      },
      {
        "columns": [
          "",
          "",
          "",
          ""
        ],
        "data": [
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ]
        ]
      },
      {
        "columns": [
          "",
          "",
          "",
          ""
        ],
        "data": [
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ],
          [
            "",
            "",
            "",
            ""
          ]
        ]
      }
    ],
    "metadata": {
      "CreationDate": "D:20240225183655",
      "Creator": "PDFium",
      "Producer": "PDFium"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com REAL - TIME CROWD MONITORING SYSTEM Hrishikesh Gaikwad1, Sumit Jadhav2, Nirbhaya Gunjal3, Sushant Survase4, Prof. Kaustubh Shinde5 1,2,3,4Students, Dept Of Computer Engineering, SITS, Maharashtra, India. 5Professor, Dept Of Computer Engineering, SITS, Maharashtra, India. DOI  https//www.doi.org/10.56726/IRJMETS38950 ABSTRACT The use of video-based monitoring systems for crowd analysis is becoming increasingly important due to population growth and the high cost of human monitoring. This paper proposes a framework for detecting, tracking, and counting crowds using video-based monitoring systems. Compared to sensor-based and human- based solutions, video-based systems offer more flexible functionalities, better performance, and lower costs. Crowd management is a crucial research area that requires attention to prevent potential losses, disasters, and accidents. The integration of different crowd detection and monitoring techniques can enhance performance and control compared to limited stand-alone techniques. Crowd management involves accessing and interpreting information sources, predicting crowd behavior, and deciding on the use of interventions based on context. The paper concludes that more investigative work is needed to further advance the field of crowd management. Keywords Crowd Detection, Tracking, Image Processing. I. INTRODUCTION Crowd management has become an increasingly important research area due to the potential losses, disasters, and accidents that could occur if it were neglected. The rise in video-based monitoring systems has led to a growing interest in the field of computer vision. The collection of information of people passing by surveillance cameras has opened up new avenues for studying crowd control, detection, and tracking, based on the acquired dataset. This dataset can be used for various purposes, such as counting, surveying, and monitoring the population in a specific area or controlling traffic in the same area. With the aid of different methods and algorithms developed for image and video processing, video sequences obtained through observation cameras can be analyzed to extract the required information. Automated tools based on computers and recent technologies like laser, RFID, Wi-Fi, Bluetooth, and AI have been developed to detect and recognize crowds. The second phase of managing crowds is to monitor, track, and analyze the detected crowd to obtain reliable insights. Many researchers have investigated this topic using theoretical, statistical, data mining, machine learning, and prediction techniques. The detection, tracking, counting, etc. tools are tallied by advanced programmed software, making crowd management an active and flourishing research area that needs attention. In recent years, the need for effective crowd monitoring has increased due to the growing concerns of security, safety, and efficiency in various public places, such as airports, railway stations, and sports arenas. The use of video-based monitoring systems for crowd analysis has gained popularity as they offer more flexible functionalities, enhanced performance, and lower costs compared to sensor-based and human-based monitoring systems. II. PROBLEM The problem statement highlights the need for an automated system that can count and monitor people in various public places such as universities, shopping malls, railway stations, and airports. Traditional methods of manual counting and monitoring are time-consuming and impractical, especially in areas with a high volume of foot traffic. This is where an automated system that uses video surveillance can provide valuable insights. Such a system can be developed using deep learning techniques that enable the detection and tracking of individuals in real-time. By analyzing the video footage, the system can count the number of people present in a specific area and monitor their movements. www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2807 e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com This information can be used for various purposes such as improving crowd control, optimizing resource allocation, and enhancing security measures. For instance, in a university setting, the system can monitor the number of students present in a lecture hall or a library. This information can be used to optimize the use of space and resources and prevent overcrowding. Similarly, in a shopping mall or an airport, the system can help to monitor the movement of people and prevent the formation of queues or overcrowding in certain areas. Overall, an automated crowd detection and monitoring system using video surveillance and deep learning techniques can provide valuable insights into the behavior and movement of people in public places. This can lead to more efficient resource allocation, better crowd control, and enhanced security measures. III. SOLUTION The proposed methodology for crowd detection and tracking involves a framework that can be used to analyze and count human beings in a crowd. The first step in this process is to subtract the background and remove unwanted pixels from the image. This method helps to identify and count people in the crowd. The database used to test the performance of the proposed system is also described in detail, which helps to identify the limitations of the model. By using this methodology, it will be possible to develop an automated system that can provide meaningful information from recorded videos, thereby reducing the need for manual monitoring and counting of people in various places such as universities, shopping malls, railway stations, airports, and other crowded areas. The proposed system will be able to detect and track crowds in real-time using Frame by Frame analysis, advanced algorithms and image processing techniques. IV. PROPOSED SYSTEM Generate Train set and Test set In this this phase we first create training and testing dataset for proposed system. The basic objective of this module to generate the ground truth values for both training and testing dataset. Three different features have been extracted from each image like height, width and channel. It extracts the actual pixel values of each image during data creation. The outcome this process the .csv files both training and testing respectively. The crowd monitoring system will detect the number of people count them and it will show to count as frame count. Python Python is a popular high-level programming language that is widely used in machine learning and computer vision applications, including crowd monitoring detection systems. Pythons popularity in these domains is mainly due to its simplicity, readability, and ease of use, as well as the availability of many open- source libraries and tools that can be used for developing such systems. In the context of crowd monitoring detection systems, Python can be used to perform a range of tasks, including image processing, data analysis, and machine learning. For example, Python libraries such as OpenCV, NumPy, and SciPy can be used for image processing tasks such as image segmentation, feature extraction, and classification. Similarly, machine learning www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2808 e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com libraries such as TensorFlow, Keras, and PyTorch can be used for training and deploying machine learning models, for crowd detection and analysis. CNN Training and Testing Convolutional Neural Networks CNNs are a type of deep learning algorithm that is particularly well-suited for image processing tasks, such as crowd detection. CNNs are designed to learn features from images in a hierarchical manner, where lower layers learn simple features, such as edges and corners, and higher layers learn more complex features, such as shapes and objects. In the context of crowd detection, CNNs can be trained on a large dataset of images and videos, such as aerial photographs or security camera footage, to learn how to identify patterns and features that are indicative of a crowd. The CNN algorithm works by processing the input image through a series of convolutional layers, pooling layers, and fully connected layers. The convolutional layers use a set of filters to scan the input image and extract features that are relevant to the task of crowd detection. These filters learn to identify patterns and edges in the image, such as the shapes of individuals or groups of individuals in the crowd. The pooling layers down sample the output of the convolutional layers by selecting the most relevant features and reducing the resolution of the image. This helps to reduce the computational complexity of the algorithm and prevent overfitting to the training data. The fully connected layers take the output of the convolutional and pooling layers and use it to classify the input image as containing a crowd or not. This is done by mapping the extracted features to a set of output classes, such as crowd or no crowd, using a set of learned weights. To train the CNN algorithm for crowd detection, a large dataset of labeled images is required. The images in the dataset are first preprocessed to normalize the pixel values and apply data augmentation techniques to increase the size of the dataset. The CNN is then trained using a loss function, such as binary cross-entropy, which measures the difference between the predicted output and the true label. Once the CNN is trained, it can be used to detect crowds in new images by applying the same convolutional filters and fully connected layers to the input image. The output of the CNN is a probability score indicating the likelihood that the input image contains a crowd. Overall, CNNs are a powerful tool for crowd detection systems, as they can learn to extract useful features from images and classify them with high accuracy. By training CNNs on large datasets of labeled images, developers can create robust and effective crowd detection systems that can be used for various applications, such as crowd control, security, and event planning. TensorFlow Library Module In the first module we implement the access interfaces and should be customized for every deep learning tool called TensorFlow. With the help of this APIs often need to be compatible with applications source code. Deep Learning Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn representations of data. It has been shown to be highly effective in computer vision tasks, such as image classification, object detection, and segmentation, making it a useful tool for crowd detection systems. Deep learning algorithm, such as Convolutional Neural Networks CNNs, can be trained on large datasets of crowd images to learn how to identify patterns and features that are indicative of a crowd. These algorithms can extract useful information from images, such as crowd size, density, and movement patterns, which can be used for various applications, such as crowd control, security, and event planning. In the context of crowd detection, deep learning algorithms can be used to perform a range of tasks, including crowd counting, crowd segmentation, and crowd behavior analysis. For example, a CNN can be trained to detect the presence of crowds in images by learning to identify patterns of individuals and their distribution across the image. Similarly, Deep learning algorithms can be trained using a supervised or unsupervised learning approach. In supervised learning, the algorithm is trained on a labeled dataset of crowd images, where each image is labeled with the number of individuals in the image or whether it contains a crowd or not. In unsupervised learning, the algorithm is trained on an unlabeled dataset of crowd images and is tasked with learning to identify patterns and features in the data without any explicit guidance. www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2809 e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com V. CROWD DETECTION A crowd detection system is a system designed to detect and monitor the presence and movement of crowds in real-time using computer vision and machine learning techniques. These systems are used in a variety of applications, including public safety, event management, and transportation. The main purpose of a crowd detection system is to provide real-time insights into crowd behavior and movement that can help prevent and respond to potential crowd-related incidents such as overcrowding, stampedes, and unauthorized gatherings. These systems use various techniques such as object detection, segmentation, and tracking to identify individuals and groups within the crowd and estimate crowd density. A typical crowd detection system consists of multiple cameras and sensors placed strategically in public spaces to capture visual and environmental data. The data is then processed using algorithms and techniques such as convolutional neural networks CNNs to extract features from images and classify them with high accuracy. Image Processing Public detection using image processing frame by frame and using gray scale conversion is a commonly used technique in crowd detection. The basic idea is to convert the video frames to grayscale, which helps in reducing the amount of information that needs to be processed. Grayscale images only contain luminance information, which makes them easier to work with than full-color images. Once the video frames are converted to grayscale, image processing techniques can be used to detect and track people in the scene. One approach is to use a technique called background subtraction, which involves subtracting the current frame from a background model to detect moving objects in the scene. The basic idea behind image processing frame by frame is to analyze each frame of the video separately, and extract features that can be used to identify and track people in the scene. These features can include properties such as color, texture, and shape, which can be used to distinguish people from the background and other objects in the scene. One common technique used in frame-by-frame image processing for crowd detection is background subtraction. This involves creating a model of the scenes background, and then subtracting the current frame from this model to detect moving objects in the scene. By comparing each frame to the background model, it is possible to detect and track people as they move through the scene. Another technique used in frame-by-frame image processing for crowd detection is blob detection. This involves identifying regions of pixels in the image that have similar properties, such as color or intensity, and grouping them together into blobs. By analyzing the properties of these blobs, it is possible to identify and track individual people in the scene. www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2810 e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com Feature Extraction Feature extraction is a fundamental step in computer vision and machine learning, and it involves identifying and extracting important information or features from raw images that can be used for further analysis, such as classification, detection, or segmentation. These features can be statistical or structural, and can capture information such as texture, shape, or color. The process of feature extraction can be broken down into several elements, including Preprocessing The first step in feature extraction is often preprocessing, which involves preparing the image for analysis. This can include steps such as resizing, cropping, or color normalization, which help to improve the quality and consistency of the image. Feature Selection Once the image is preprocessed, the next step is to select the most relevant features that can help to distinguish between different objects or classes. This can be done manually, by identifying important visual cues or properties that are specific to the problem at hand, or automatically, using machine learning techniques such as principal component analysis PCA or linear discriminant analysis LDA. Feature Representation After the relevant features have been selected, the next step is to represent them in a suitable format that can be used for analysis. This can involve transforming the raw image data into a more compact or meaningful representation, such as a histogram of color values, a texture descriptor, or a shape model. Feature Extraction Once the features have been selected and represented, the final step is to extract them from the image. This can involve applying a set of operations or filters to the image data, such as convolution or wavelet transforms, to identify and extract the relevant features. Feature Normalization In some cases, it may also be necessary to normalize the extracted features to improve their consistency and robustness. This can involve techniques such as z-score normalization or min- max normalization, which help to ensure that the features are scaled and centered appropriately. Image Segmentation Image segmentation is a process of dividing an image into multiple segments or regions, each of which corresponds to a different object or part of the image. Image segmentation plays a critical role in computer vision applications, such as object detection, tracking, and recognition. The goal of image segmentation is to partition an image into meaningful regions that can be analyzed and processed independently. This is typically achieved by applying a set of image processing techniques to identify regions that share similar visual characteristics, such as color, texture, or intensity. There are several techniques for image segmentation, including Thresholding This technique involves selecting a threshold value and partitioning the image into regions based on the intensity values of each pixel. Pixels with intensity values above the threshold are assigned to one region, while pixels with intensity values below the threshold are assigned to another region. Edge Detection This technique involves detecting the edges or boundaries between different regions in an image. This can be done using techniques such as the Canny edge detector or the Sobel edge detector. Region Growing This technique involves starting with a seed pixel and iteratively adding neighboring pixels to the region based on some similarity criterion. This process continues until all pixels in the region have been added. Clustering This technique involves grouping pixels into clusters based on their visual similarity. This can be done using algorithms such as k-means clustering or hierarchical clustering. Classification In a crowd detection system, classification of images typically involves identifying and categorizing different objects or groups within the crowd. This process can be performed using various techniques, including traditional computer vision methods and deep learning-based approaches. In traditional computer vision methods, feature extraction algorithms are used to identify and extract relevant features from the images, such as edges, corners, and texture patterns. These features are then used to train a classifier, such as a support vector machine SVM or k-nearest neighbor KNN, to recognize different objects or groups within the crowd, such as individuals or clusters. In deep learning-based approaches, Convolutional Neural Networks CNNs are commonly used for image classification tasks. CNNs are a type of neural network that are www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2811 e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com specifically designed for image processing tasks, as they can automatically learn and extract relevant features from images by using multiple layers of convolutional filters. The process of image classification in a crowd detection system using CNNs typically involves the following steps Data Preparation Collecting and preparing a large dataset of labeled images for training the model. Training the Model Using the prepared dataset to train the CNN model to recognize different objects or groups within the crowd. Validation Testing the trained model on a separate dataset of images to evaluate its accuracy and performance. Deployment Using the trained model to classify new images in real-time. During the training process, the CNN model learns to recognize patterns and features in the crowd images by adjusting the weights of the neural network connections based on the errors between the predicted and actual class labels. Once the model is trained and validated, it can be used to classify new crowd images by feeding them into the model and predicting the corresponding class labels based on the learned features and patterns. VI. CONCLUSION In conclusion, the proposed CNN-based method provides a promising approach for crowd detection and counting in still images from various scenes. The use of features derived from a CNN model trained for other computer vision tasks enables accurate representation of crowd density. The neighboring local counts are also strongly correlated, and feature extraction techniques contribute to good detection accuracy. The system uses the RESNET deep convolutional network, which provides up to 152 hidden layers, and can be extended with multiple convolutional layers with an ensemble deep learning model for even higher accuracy. Experimental findings demonstrate that the proposed method outperforms other recent related methods and can be extended to work on image and video datasets. Overall, this system offers better accuracy for crowd detection from heterogeneous images, making it a valuable tool for various applications. VII. REFERENCES 1 Crowd Detection And Tracking In Surveillance Video Sequences Sohail Salim Othman O Khalifa Farah Abdul Rahman Adidah Lajis 2019 IEEE International Conference on Smart Instrumentation, Measurement and Application ICSIMA 2 Multi-UAV Based Crowd Monitoring System Rodrigo Saar de Moraes Edison Pignaton de Freitas IEEE Transactions on Aerospace and Electronic Systems 3 In-Depth Survey to Detect, Monitor and Manage Crowd Ali M. Al-Shaery Shroug S. Alshehri Norah S. Farooqi Mohamed O. Khozium IEEE Access 4 Analysis and Design of Public Places Crowd Stampede Early-Warning Simulating System Shangnan Liu Zhenjiang Zhu Qiang Cheng Hao Zhang 2016 International Conference on Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration ICIICII 5 Crowd Monitoring Using Mobile Phones Yaoxuan Yuan 2014 Sixth International Conference on Intelligent Human-Machine Systems and Cybernetics 6 A Real-Time Crowd Detection and Monitoring System using Machine Learning Pooja Shrivastav Vakula Rani J 2023 International Conference on Intelligent Data Communication Technologies and Internet of Things IDCIoT 7 Crowd detection and management using cascade classifier on ARMv8 and OpenCV Python S. Syed Ameer Abbas P. Oliver Jayaprakash M. Anitha X. Vinitha Jaini 2017 International Conference on Innovations iasdfghjkln Information, Embedded and Communication Systems ICIIECS 8 Multi-Person Tracking in Smart Surveillance System for Crowd Counting and Normal/Abnormal Events Detection Ahsan Shehzed Ahmad Jalal Kibum Kim 2019 International Conference on Applied and Engineering Mathematics ICAEM. www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2812",
    "structured_text": {
      "sentences": [
        "e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com REAL - TIME CROWD MONITORING SYSTEM Hrishikesh Gaikwad1, Sumit Jadhav2, Nirbhaya Gunjal3, Sushant Survase4, Prof.",
        "Kaustubh Shinde5 1,2,3,4Students, Dept Of Computer Engineering, SITS, Maharashtra, India.",
        "5Professor, Dept Of Computer Engineering, SITS, Maharashtra, India.",
        "DOI  https//www.doi.org/10.56726/IRJMETS38950 ABSTRACT The use of video-based monitoring systems for crowd analysis is becoming increasingly important due to population growth and the high cost of human monitoring.",
        "This paper proposes a framework for detecting, tracking, and counting crowds using video-based monitoring systems.",
        "Compared to sensor-based and human- based solutions, video-based systems offer more flexible functionalities, better performance, and lower costs.",
        "Crowd management is a crucial research area that requires attention to prevent potential losses, disasters, and accidents.",
        "The integration of different crowd detection and monitoring techniques can enhance performance and control compared to limited stand-alone techniques.",
        "Crowd management involves accessing and interpreting information sources, predicting crowd behavior, and deciding on the use of interventions based on context.",
        "The paper concludes that more investigative work is needed to further advance the field of crowd management.",
        "Keywords Crowd Detection, Tracking, Image Processing.",
        "I.",
        "INTRODUCTION Crowd management has become an increasingly important research area due to the potential losses, disasters, and accidents that could occur if it were neglected.",
        "The rise in video-based monitoring systems has led to a growing interest in the field of computer vision.",
        "The collection of information of people passing by surveillance cameras has opened up new avenues for studying crowd control, detection, and tracking, based on the acquired dataset.",
        "This dataset can be used for various purposes, such as counting, surveying, and monitoring the population in a specific area or controlling traffic in the same area.",
        "With the aid of different methods and algorithms developed for image and video processing, video sequences obtained through observation cameras can be analyzed to extract the required information.",
        "Automated tools based on computers and recent technologies like laser, RFID, Wi-Fi, Bluetooth, and AI have been developed to detect and recognize crowds.",
        "The second phase of managing crowds is to monitor, track, and analyze the detected crowd to obtain reliable insights.",
        "Many researchers have investigated this topic using theoretical, statistical, data mining, machine learning, and prediction techniques.",
        "The detection, tracking, counting, etc.",
        "tools are tallied by advanced programmed software, making crowd management an active and flourishing research area that needs attention.",
        "In recent years, the need for effective crowd monitoring has increased due to the growing concerns of security, safety, and efficiency in various public places, such as airports, railway stations, and sports arenas.",
        "The use of video-based monitoring systems for crowd analysis has gained popularity as they offer more flexible functionalities, enhanced performance, and lower costs compared to sensor-based and human-based monitoring systems.",
        "II.",
        "PROBLEM The problem statement highlights the need for an automated system that can count and monitor people in various public places such as universities, shopping malls, railway stations, and airports.",
        "Traditional methods of manual counting and monitoring are time-consuming and impractical, especially in areas with a high volume of foot traffic.",
        "This is where an automated system that uses video surveillance can provide valuable insights.",
        "Such a system can be developed using deep learning techniques that enable the detection and tracking of individuals in real-time.",
        "By analyzing the video footage, the system can count the number of people present in a specific area and monitor their movements.",
        "www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2807 e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com This information can be used for various purposes such as improving crowd control, optimizing resource allocation, and enhancing security measures.",
        "For instance, in a university setting, the system can monitor the number of students present in a lecture hall or a library.",
        "This information can be used to optimize the use of space and resources and prevent overcrowding.",
        "Similarly, in a shopping mall or an airport, the system can help to monitor the movement of people and prevent the formation of queues or overcrowding in certain areas.",
        "Overall, an automated crowd detection and monitoring system using video surveillance and deep learning techniques can provide valuable insights into the behavior and movement of people in public places.",
        "This can lead to more efficient resource allocation, better crowd control, and enhanced security measures.",
        "III.",
        "SOLUTION The proposed methodology for crowd detection and tracking involves a framework that can be used to analyze and count human beings in a crowd.",
        "The first step in this process is to subtract the background and remove unwanted pixels from the image.",
        "This method helps to identify and count people in the crowd.",
        "The database used to test the performance of the proposed system is also described in detail, which helps to identify the limitations of the model.",
        "By using this methodology, it will be possible to develop an automated system that can provide meaningful information from recorded videos, thereby reducing the need for manual monitoring and counting of people in various places such as universities, shopping malls, railway stations, airports, and other crowded areas.",
        "The proposed system will be able to detect and track crowds in real-time using Frame by Frame analysis, advanced algorithms and image processing techniques.",
        "IV.",
        "PROPOSED SYSTEM Generate Train set and Test set In this this phase we first create training and testing dataset for proposed system.",
        "The basic objective of this module to generate the ground truth values for both training and testing dataset.",
        "Three different features have been extracted from each image like height, width and channel.",
        "It extracts the actual pixel values of each image during data creation.",
        "The outcome this process the .csv files both training and testing respectively.",
        "The crowd monitoring system will detect the number of people count them and it will show to count as frame count.",
        "Python Python is a popular high-level programming language that is widely used in machine learning and computer vision applications, including crowd monitoring detection systems.",
        "Pythons popularity in these domains is mainly due to its simplicity, readability, and ease of use, as well as the availability of many open- source libraries and tools that can be used for developing such systems.",
        "In the context of crowd monitoring detection systems, Python can be used to perform a range of tasks, including image processing, data analysis, and machine learning.",
        "For example, Python libraries such as OpenCV, NumPy, and SciPy can be used for image processing tasks such as image segmentation, feature extraction, and classification.",
        "Similarly, machine learning www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2808 e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com libraries such as TensorFlow, Keras, and PyTorch can be used for training and deploying machine learning models, for crowd detection and analysis.",
        "CNN Training and Testing Convolutional Neural Networks CNNs are a type of deep learning algorithm that is particularly well-suited for image processing tasks, such as crowd detection.",
        "CNNs are designed to learn features from images in a hierarchical manner, where lower layers learn simple features, such as edges and corners, and higher layers learn more complex features, such as shapes and objects.",
        "In the context of crowd detection, CNNs can be trained on a large dataset of images and videos, such as aerial photographs or security camera footage, to learn how to identify patterns and features that are indicative of a crowd.",
        "The CNN algorithm works by processing the input image through a series of convolutional layers, pooling layers, and fully connected layers.",
        "The convolutional layers use a set of filters to scan the input image and extract features that are relevant to the task of crowd detection.",
        "These filters learn to identify patterns and edges in the image, such as the shapes of individuals or groups of individuals in the crowd.",
        "The pooling layers down sample the output of the convolutional layers by selecting the most relevant features and reducing the resolution of the image.",
        "This helps to reduce the computational complexity of the algorithm and prevent overfitting to the training data.",
        "The fully connected layers take the output of the convolutional and pooling layers and use it to classify the input image as containing a crowd or not.",
        "This is done by mapping the extracted features to a set of output classes, such as crowd or no crowd, using a set of learned weights.",
        "To train the CNN algorithm for crowd detection, a large dataset of labeled images is required.",
        "The images in the dataset are first preprocessed to normalize the pixel values and apply data augmentation techniques to increase the size of the dataset.",
        "The CNN is then trained using a loss function, such as binary cross-entropy, which measures the difference between the predicted output and the true label.",
        "Once the CNN is trained, it can be used to detect crowds in new images by applying the same convolutional filters and fully connected layers to the input image.",
        "The output of the CNN is a probability score indicating the likelihood that the input image contains a crowd.",
        "Overall, CNNs are a powerful tool for crowd detection systems, as they can learn to extract useful features from images and classify them with high accuracy.",
        "By training CNNs on large datasets of labeled images, developers can create robust and effective crowd detection systems that can be used for various applications, such as crowd control, security, and event planning.",
        "TensorFlow Library Module In the first module we implement the access interfaces and should be customized for every deep learning tool called TensorFlow.",
        "With the help of this APIs often need to be compatible with applications source code.",
        "Deep Learning Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn representations of data.",
        "It has been shown to be highly effective in computer vision tasks, such as image classification, object detection, and segmentation, making it a useful tool for crowd detection systems.",
        "Deep learning algorithm, such as Convolutional Neural Networks CNNs, can be trained on large datasets of crowd images to learn how to identify patterns and features that are indicative of a crowd.",
        "These algorithms can extract useful information from images, such as crowd size, density, and movement patterns, which can be used for various applications, such as crowd control, security, and event planning.",
        "In the context of crowd detection, deep learning algorithms can be used to perform a range of tasks, including crowd counting, crowd segmentation, and crowd behavior analysis.",
        "For example, a CNN can be trained to detect the presence of crowds in images by learning to identify patterns of individuals and their distribution across the image.",
        "Similarly, Deep learning algorithms can be trained using a supervised or unsupervised learning approach.",
        "In supervised learning, the algorithm is trained on a labeled dataset of crowd images, where each image is labeled with the number of individuals in the image or whether it contains a crowd or not.",
        "In unsupervised learning, the algorithm is trained on an unlabeled dataset of crowd images and is tasked with learning to identify patterns and features in the data without any explicit guidance.",
        "www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2809 e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com V.",
        "CROWD DETECTION A crowd detection system is a system designed to detect and monitor the presence and movement of crowds in real-time using computer vision and machine learning techniques.",
        "These systems are used in a variety of applications, including public safety, event management, and transportation.",
        "The main purpose of a crowd detection system is to provide real-time insights into crowd behavior and movement that can help prevent and respond to potential crowd-related incidents such as overcrowding, stampedes, and unauthorized gatherings.",
        "These systems use various techniques such as object detection, segmentation, and tracking to identify individuals and groups within the crowd and estimate crowd density.",
        "A typical crowd detection system consists of multiple cameras and sensors placed strategically in public spaces to capture visual and environmental data.",
        "The data is then processed using algorithms and techniques such as convolutional neural networks CNNs to extract features from images and classify them with high accuracy.",
        "Image Processing Public detection using image processing frame by frame and using gray scale conversion is a commonly used technique in crowd detection.",
        "The basic idea is to convert the video frames to grayscale, which helps in reducing the amount of information that needs to be processed.",
        "Grayscale images only contain luminance information, which makes them easier to work with than full-color images.",
        "Once the video frames are converted to grayscale, image processing techniques can be used to detect and track people in the scene.",
        "One approach is to use a technique called background subtraction, which involves subtracting the current frame from a background model to detect moving objects in the scene.",
        "The basic idea behind image processing frame by frame is to analyze each frame of the video separately, and extract features that can be used to identify and track people in the scene.",
        "These features can include properties such as color, texture, and shape, which can be used to distinguish people from the background and other objects in the scene.",
        "One common technique used in frame-by-frame image processing for crowd detection is background subtraction.",
        "This involves creating a model of the scenes background, and then subtracting the current frame from this model to detect moving objects in the scene.",
        "By comparing each frame to the background model, it is possible to detect and track people as they move through the scene.",
        "Another technique used in frame-by-frame image processing for crowd detection is blob detection.",
        "This involves identifying regions of pixels in the image that have similar properties, such as color or intensity, and grouping them together into blobs.",
        "By analyzing the properties of these blobs, it is possible to identify and track individual people in the scene.",
        "www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2810 e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com Feature Extraction Feature extraction is a fundamental step in computer vision and machine learning, and it involves identifying and extracting important information or features from raw images that can be used for further analysis, such as classification, detection, or segmentation.",
        "These features can be statistical or structural, and can capture information such as texture, shape, or color.",
        "The process of feature extraction can be broken down into several elements, including Preprocessing The first step in feature extraction is often preprocessing, which involves preparing the image for analysis.",
        "This can include steps such as resizing, cropping, or color normalization, which help to improve the quality and consistency of the image.",
        "Feature Selection Once the image is preprocessed, the next step is to select the most relevant features that can help to distinguish between different objects or classes.",
        "This can be done manually, by identifying important visual cues or properties that are specific to the problem at hand, or automatically, using machine learning techniques such as principal component analysis PCA or linear discriminant analysis LDA.",
        "Feature Representation After the relevant features have been selected, the next step is to represent them in a suitable format that can be used for analysis.",
        "This can involve transforming the raw image data into a more compact or meaningful representation, such as a histogram of color values, a texture descriptor, or a shape model.",
        "Feature Extraction Once the features have been selected and represented, the final step is to extract them from the image.",
        "This can involve applying a set of operations or filters to the image data, such as convolution or wavelet transforms, to identify and extract the relevant features.",
        "Feature Normalization In some cases, it may also be necessary to normalize the extracted features to improve their consistency and robustness.",
        "This can involve techniques such as z-score normalization or min- max normalization, which help to ensure that the features are scaled and centered appropriately.",
        "Image Segmentation Image segmentation is a process of dividing an image into multiple segments or regions, each of which corresponds to a different object or part of the image.",
        "Image segmentation plays a critical role in computer vision applications, such as object detection, tracking, and recognition.",
        "The goal of image segmentation is to partition an image into meaningful regions that can be analyzed and processed independently.",
        "This is typically achieved by applying a set of image processing techniques to identify regions that share similar visual characteristics, such as color, texture, or intensity.",
        "There are several techniques for image segmentation, including Thresholding This technique involves selecting a threshold value and partitioning the image into regions based on the intensity values of each pixel.",
        "Pixels with intensity values above the threshold are assigned to one region, while pixels with intensity values below the threshold are assigned to another region.",
        "Edge Detection This technique involves detecting the edges or boundaries between different regions in an image.",
        "This can be done using techniques such as the Canny edge detector or the Sobel edge detector.",
        "Region Growing This technique involves starting with a seed pixel and iteratively adding neighboring pixels to the region based on some similarity criterion.",
        "This process continues until all pixels in the region have been added.",
        "Clustering This technique involves grouping pixels into clusters based on their visual similarity.",
        "This can be done using algorithms such as k-means clustering or hierarchical clustering.",
        "Classification In a crowd detection system, classification of images typically involves identifying and categorizing different objects or groups within the crowd.",
        "This process can be performed using various techniques, including traditional computer vision methods and deep learning-based approaches.",
        "In traditional computer vision methods, feature extraction algorithms are used to identify and extract relevant features from the images, such as edges, corners, and texture patterns.",
        "These features are then used to train a classifier, such as a support vector machine SVM or k-nearest neighbor KNN, to recognize different objects or groups within the crowd, such as individuals or clusters.",
        "In deep learning-based approaches, Convolutional Neural Networks CNNs are commonly used for image classification tasks.",
        "CNNs are a type of neural network that are www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2811 e-ISSN 2582-5208 International Research Journal of Modernization in Engineering Technology and Science  Peer-Reviewed, Open Access, Fully Refereed International Journal  Volume05/Issue05/May-2023 Impact Factor- 7.868 www.irjmets.com specifically designed for image processing tasks, as they can automatically learn and extract relevant features from images by using multiple layers of convolutional filters.",
        "The process of image classification in a crowd detection system using CNNs typically involves the following steps Data Preparation Collecting and preparing a large dataset of labeled images for training the model.",
        "Training the Model Using the prepared dataset to train the CNN model to recognize different objects or groups within the crowd.",
        "Validation Testing the trained model on a separate dataset of images to evaluate its accuracy and performance.",
        "Deployment Using the trained model to classify new images in real-time.",
        "During the training process, the CNN model learns to recognize patterns and features in the crowd images by adjusting the weights of the neural network connections based on the errors between the predicted and actual class labels.",
        "Once the model is trained and validated, it can be used to classify new crowd images by feeding them into the model and predicting the corresponding class labels based on the learned features and patterns.",
        "VI.",
        "CONCLUSION In conclusion, the proposed CNN-based method provides a promising approach for crowd detection and counting in still images from various scenes.",
        "The use of features derived from a CNN model trained for other computer vision tasks enables accurate representation of crowd density.",
        "The neighboring local counts are also strongly correlated, and feature extraction techniques contribute to good detection accuracy.",
        "The system uses the RESNET deep convolutional network, which provides up to 152 hidden layers, and can be extended with multiple convolutional layers with an ensemble deep learning model for even higher accuracy.",
        "Experimental findings demonstrate that the proposed method outperforms other recent related methods and can be extended to work on image and video datasets.",
        "Overall, this system offers better accuracy for crowd detection from heterogeneous images, making it a valuable tool for various applications.",
        "VII.",
        "REFERENCES 1 Crowd Detection And Tracking In Surveillance Video Sequences Sohail Salim Othman O Khalifa Farah Abdul Rahman Adidah Lajis 2019 IEEE International Conference on Smart Instrumentation, Measurement and Application ICSIMA 2 Multi-UAV Based Crowd Monitoring System Rodrigo Saar de Moraes Edison Pignaton de Freitas IEEE Transactions on Aerospace and Electronic Systems 3 In-Depth Survey to Detect, Monitor and Manage Crowd Ali M.",
        "Al-Shaery Shroug S.",
        "Alshehri Norah S.",
        "Farooqi Mohamed O.",
        "Khozium IEEE Access 4 Analysis and Design of Public Places Crowd Stampede Early-Warning Simulating System Shangnan Liu Zhenjiang Zhu Qiang Cheng Hao Zhang 2016 International Conference on Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration ICIICII 5 Crowd Monitoring Using Mobile Phones Yaoxuan Yuan 2014 Sixth International Conference on Intelligent Human-Machine Systems and Cybernetics 6 A Real-Time Crowd Detection and Monitoring System using Machine Learning Pooja Shrivastav Vakula Rani J 2023 International Conference on Intelligent Data Communication Technologies and Internet of Things IDCIoT 7 Crowd detection and management using cascade classifier on ARMv8 and OpenCV Python S.",
        "Syed Ameer Abbas P.",
        "Oliver Jayaprakash M.",
        "Anitha X.",
        "Vinitha Jaini 2017 International Conference on Innovations iasdfghjkln Information, Embedded and Communication Systems ICIIECS 8 Multi-Person Tracking in Smart Surveillance System for Crowd Counting and Normal/Abnormal Events Detection Ahsan Shehzed Ahmad Jalal Kibum Kim 2019 International Conference on Applied and Engineering Mathematics ICAEM.",
        "www.irjmets.com International Research Journal of Modernization in Engineering, Technology and Science 2812"
      ],
      "word_count": 3675,
      "sections": {}
    },
    "tables": [],
    "metadata": {
      "Author": "xyz",
      "Creator": "Microsoft® Word 2010",
      "CreationDate": "D:20230514103146+05'30'",
      "ModDate": "D:20230514103146+05'30'",
      "Producer": "Microsoft® Word 2010"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Bagh Electrical Radar System Magnetron 11111 ABC Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-01-01 05/01/24 Not Applicable Defect Analysis Brief Description of the Defect Defect Analysis The defect was localised to Defective Magnetron and it was rectified by System not transmitting replacement of the defective magnetron with new magnetron Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, The defect was reported to Local headquarters through proper channel. The repair agency Magnetron OPDEF 01/24, STOREDEM 01/24 undertook the Defect identification and after careful scrutiny, isolated the problem to defective Magnetron. The demand of Magnetron was placed on Material organisation at Mumbai. This item thereafter was delivered by Material Organisation to INS Bagh and repair of System 1 was undertaken successfully Key Personnel involved in Defect Analysis and Resolution Sl. No. Name Rank/Designation Unit 01. Tika Ram Senior Foreman Repair Unit 1 02. Ram Vilas HSK 1 Repair Unit 1 03. S Desai HSK 2 Repair Unit 1",
    "structured_text": {
      "sentences": [
        "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Bagh Electrical Radar System Magnetron 11111 ABC Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-01-01 05/01/24 Not Applicable Defect Analysis Brief Description of the Defect Defect Analysis The defect was localised to Defective Magnetron and it was rectified by System not transmitting replacement of the defective magnetron with new magnetron Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, The defect was reported to Local headquarters through proper channel.",
        "The repair agency Magnetron OPDEF 01/24, STOREDEM 01/24 undertook the Defect identification and after careful scrutiny, isolated the problem to defective Magnetron.",
        "The demand of Magnetron was placed on Material organisation at Mumbai.",
        "This item thereafter was delivered by Material Organisation to INS Bagh and repair of System 1 was undertaken successfully Key Personnel involved in Defect Analysis and Resolution Sl.",
        "No.",
        "Name Rank/Designation Unit 01.",
        "Tika Ram Senior Foreman Repair Unit 1 02.",
        "Ram Vilas HSK 1 Repair Unit 1 03.",
        "S Desai HSK 2 Repair Unit 1"
      ],
      "word_count": 198,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "name_of_the\nship/establishment",
          "department",
          "system",
          "sub-system",
          "unique_identification\ncode",
          "oem"
        ],
        "data": [
          [
            "INS Bagh",
            "Electrical",
            "Radar System",
            "Magnetron",
            "11111",
            "ABC"
          ]
        ]
      },
      {
        "columns": [
          "date_defect\noccurred",
          "date_defect\nresolved",
          "if_defect_still_outstanding,_reasons_thereof"
        ],
        "data": [
          [
            "01/01/2024",
            "05/01/24",
            "Not Applicable"
          ]
        ]
      },
      {
        "columns": [
          "brief_description_of_the_defect",
          "defect_analysis"
        ],
        "data": [
          [
            "System not transmitting",
            "The defect was localised to Defective Magnetron and it was rectified by\nreplacement of the defective magnetron with new magnetron"
          ]
        ]
      },
      {
        "columns": [
          "steps_taken_to_resolve_the_defect",
          "spare_parts_used_to_resolve_the\ndefect",
          "important_correspondence_related_to\ndefect_analysis_and_resolution\n(opdef,_storedem,_etc,)"
        ],
        "data": [
          [
            "The defect was reported to Local\nheadquarters through proper\nchannel. The repair agency\nundertook the Defect identification\nand after careful scrutiny, isolated\nthe problem to defective",
            "Magnetron",
            "OPDEF 01/24, STOREDEM 01/24"
          ]
        ]
      },
      {
        "columns": [
          "sl._no.",
          "name",
          "rank/designation",
          "unit"
        ],
        "data": [
          [
            "01.",
            "Tika Ram",
            "Senior Foreman",
            "Repair Unit 1"
          ],
          [
            "02.",
            "Ram Vilas",
            "HSK 1",
            "Repair Unit 1"
          ],
          [
            "03.",
            "S Desai",
            "HSK 2",
            "Repair Unit 1"
          ]
        ]
      }
    ],
    "metadata": {
      "Author": "Skand Pujari",
      "Creator": "Microsoft® Word 2021",
      "CreationDate": "D:20241105210133+05'30'",
      "ModDate": "D:20241105210133+05'30'",
      "Producer": "Microsoft® Word 2021"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Bagh Electrical Radar System Power Supply Unit 22222 ABC Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-02-01 05/02/24 Applicable Defect Analysis Brief Description of the Defect Defect Analysis The magnetron showed signs of overheating, which was resolved by Weak or intermittent signal output replacing it with a new unit. Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, The radar system was powered down and disconnected from its power source. All high-voltage capacitors Power Supply Unit REPAIRREQ 02/24, MATREQ 03/24 were discharged to ensure safety. The faulty Power Supply Unit was identified according to the systems maintenance manual and subsequently replaced. Once the new unit was installed, the input/output voltage, current, and overall performance were tested to confirm compliance with the operational standards outlined in the manual. Key Personnel involved in Defect Analysis and Resolution Sl. No. Name Rank/Designation Unit 01. Sanatan Gridharan Foreman Repair Unit 4 02. Vishwanath Shrirang HSK 3 Repair Unit 4 03. S Desai HSK 2 Repair Unit 4",
    "structured_text": {
      "sentences": [
        "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Bagh Electrical Radar System Power Supply Unit 22222 ABC Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-02-01 05/02/24 Applicable Defect Analysis Brief Description of the Defect Defect Analysis The magnetron showed signs of overheating, which was resolved by Weak or intermittent signal output replacing it with a new unit.",
        "Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, The radar system was powered down and disconnected from its power source.",
        "All high-voltage capacitors Power Supply Unit REPAIRREQ 02/24, MATREQ 03/24 were discharged to ensure safety.",
        "The faulty Power Supply Unit was identified according to the systems maintenance manual and subsequently replaced.",
        "Once the new unit was installed, the input/output voltage, current, and overall performance were tested to confirm compliance with the operational standards outlined in the manual.",
        "Key Personnel involved in Defect Analysis and Resolution Sl.",
        "No.",
        "Name Rank/Designation Unit 01.",
        "Sanatan Gridharan Foreman Repair Unit 4 02.",
        "Vishwanath Shrirang HSK 3 Repair Unit 4 03.",
        "S Desai HSK 2 Repair Unit 4"
      ],
      "word_count": 203,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "name_of_the\nship/establishment",
          "department",
          "system",
          "sub-system",
          "unique_identification\ncode",
          "oem"
        ],
        "data": [
          [
            "INS Bagh",
            "Electrical",
            "Radar System",
            "Power Supply Unit",
            "22222",
            "ABC"
          ]
        ]
      },
      {
        "columns": [
          "date_defect\noccurred",
          "date_defect\nresolved",
          "if_defect_still_outstanding,_reasons_thereof"
        ],
        "data": [
          [
            "01/02/2024",
            "05/02/24",
            "Applicable"
          ]
        ]
      },
      {
        "columns": [
          "brief_description_of_the_defect",
          "defect_analysis"
        ],
        "data": [
          [
            "Weak or intermittent signal output",
            "The magnetron showed signs of overheating, which was resolved by\nreplacing it with a new unit."
          ]
        ]
      },
      {
        "columns": [
          "steps_taken_to_resolve_the_defect",
          "spare_parts_used_to_resolve_the\ndefect",
          "important_correspondence_related_to\ndefect_analysis_and_resolution\n(opdef,_storedem,_etc,)"
        ],
        "data": [
          [
            "The radar system was powered down\nand disconnected from its power\nsource. All high-voltage capacitors\nwere discharged to ensure safety.\nThe faulty Power Supply Unit was\nidentified according to the system's",
            "Power Supply Unit",
            "REPAIRREQ 02/24, MATREQ 03/24"
          ]
        ]
      },
      {
        "columns": [
          "sl._no.",
          "name",
          "rank/designation",
          "unit"
        ],
        "data": [
          [
            "01.",
            "Sanatan Gridharan",
            "Foreman",
            "Repair Unit 4"
          ],
          [
            "02.",
            "Vishwanath Shrirang",
            "HSK 3",
            "Repair Unit 4"
          ],
          [
            "03.",
            "S Desai",
            "HSK 2",
            "Repair Unit 4"
          ]
        ]
      }
    ],
    "metadata": {
      "Author": "Skand Pujari",
      "Creator": "Microsoft® Word 2021",
      "CreationDate": "D:20241105210141+05'30'",
      "ModDate": "D:20241105210141+05'30'",
      "Producer": "Microsoft® Word 2021"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Bagh Electrical Radar System Cooling Fan 33333 ABC Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-03-01 2024-03-05 Not Applicable Defect Analysis Brief Description of the Defect Defect Analysis The magnetron failed to generate the required frequency, necessitating a Unusual noise during operation replacement. Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, After powering down the radar system and isolating it from its power supply, the cooling fan was Cooling Fan MAINTREQ 04/24, SUPPLYORD 05/24 inspected. Following the systems diagnostics, the defective Cooling Fan was replaced. Post-installation, airflow, fan speed, and temperature regulation were tested to ensure that the new cooling system met the performance parameters specified in the maintenance documentation. Key Personnel involved in Defect Analysis and Resolution Sl. No. Name Rank/Designation Unit 01. Arnav Soumen Foreman Repair Unit 6 02. Ram Vilas HSK 1 Repair Unit 1 03. S Desai HSK 2 Repair Unit 1",
    "structured_text": {
      "sentences": [
        "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Bagh Electrical Radar System Cooling Fan 33333 ABC Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-03-01 2024-03-05 Not Applicable Defect Analysis Brief Description of the Defect Defect Analysis The magnetron failed to generate the required frequency, necessitating a Unusual noise during operation replacement.",
        "Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, After powering down the radar system and isolating it from its power supply, the cooling fan was Cooling Fan MAINTREQ 04/24, SUPPLYORD 05/24 inspected.",
        "Following the systems diagnostics, the defective Cooling Fan was replaced.",
        "Post-installation, airflow, fan speed, and temperature regulation were tested to ensure that the new cooling system met the performance parameters specified in the maintenance documentation.",
        "Key Personnel involved in Defect Analysis and Resolution Sl.",
        "No.",
        "Name Rank/Designation Unit 01.",
        "Arnav Soumen Foreman Repair Unit 6 02.",
        "Ram Vilas HSK 1 Repair Unit 1 03.",
        "S Desai HSK 2 Repair Unit 1"
      ],
      "word_count": 187,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "name_of_the\nship/establishment",
          "department",
          "system",
          "sub-system",
          "unique_identification\ncode",
          "oem"
        ],
        "data": [
          [
            "INS Bagh",
            "Electrical",
            "Radar System",
            "Cooling Fan",
            "33333",
            "ABC"
          ]
        ]
      },
      {
        "columns": [
          "date_defect\noccurred",
          "date_defect\nresolved",
          "if_defect_still_outstanding,_reasons_thereof"
        ],
        "data": [
          [
            "01/03/2024",
            "05/3/2024",
            "Not Applicable"
          ]
        ]
      },
      {
        "columns": [
          "brief_description_of_the_defect",
          "defect_analysis"
        ],
        "data": [
          [
            "Unusual noise during operation",
            "The magnetron failed to generate the required frequency, necessitating a\nreplacement."
          ]
        ]
      },
      {
        "columns": [
          "steps_taken_to_resolve_the_defect",
          "spare_parts_used_to_resolve_the\ndefect",
          "important_correspondence_related_to\ndefect_analysis_and_resolution\n(opdef,_storedem,_etc,)"
        ],
        "data": [
          [
            "After powering down the radar\nsystem and isolating it from its power\nsupply, the cooling fan was\ninspected. Following the system's\ndiagnostics, the defective Cooling\nFan was replaced. Post-installation,",
            "Cooling Fan",
            "MAINTREQ 04/24, SUPPLYORD 05/24"
          ]
        ]
      },
      {
        "columns": [
          "sl._no.",
          "name",
          "rank/designation",
          "unit"
        ],
        "data": [
          [
            "01.",
            "Arnav Soumen",
            "Foreman",
            "Repair Unit 6"
          ],
          [
            "02.",
            "Ram Vilas",
            "HSK 1",
            "Repair Unit 1"
          ],
          [
            "03.",
            "S Desai",
            "HSK 2",
            "Repair Unit 1"
          ]
        ]
      }
    ],
    "metadata": {
      "Author": "Skand Pujari",
      "Creator": "Microsoft® Word 2021",
      "CreationDate": "D:20241105210148+05'30'",
      "ModDate": "D:20241105210148+05'30'",
      "Producer": "Microsoft® Word 2021"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code Waveguide INS Bagh Electrical Radar System 44444 ABC Assembly Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-04-01 2024-04-05 Applicable Defect Analysis Brief Description of the Defect Defect Analysis The magnetron was experiencing power fluctuations, which were fixed by Inconsistent power levels detected installing a new magnetron. Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, The radar system was powered off, and all high-voltage components were discharged. The damaged Waveguide Assembly DEFECTREP 06/24, PARTDEL 07/24 Waveguide Assembly was removed as per the systems manual. After the replacement part was fitted, the systems transmission path, signal integrity, and standing wave ratio VSWR were evaluated. The results were within the permissible limits, confirming the waveguides correct installation and functionality. Key Personnel involved in Defect Analysis and Resolution Sl. No. Name Rank/Designation Unit 01. Asija Sahni Senior Foreman Repair Unit 7 02. Vishwanath Shrirang HSK 3 Repair Unit 7 03. Ram Vilas HSK 1 Repair Unit 7",
    "structured_text": {
      "sentences": [
        "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code Waveguide INS Bagh Electrical Radar System 44444 ABC Assembly Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-04-01 2024-04-05 Applicable Defect Analysis Brief Description of the Defect Defect Analysis The magnetron was experiencing power fluctuations, which were fixed by Inconsistent power levels detected installing a new magnetron.",
        "Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, The radar system was powered off, and all high-voltage components were discharged.",
        "The damaged Waveguide Assembly DEFECTREP 06/24, PARTDEL 07/24 Waveguide Assembly was removed as per the systems manual.",
        "After the replacement part was fitted, the systems transmission path, signal integrity, and standing wave ratio VSWR were evaluated.",
        "The results were within the permissible limits, confirming the waveguides correct installation and functionality.",
        "Key Personnel involved in Defect Analysis and Resolution Sl.",
        "No.",
        "Name Rank/Designation Unit 01.",
        "Asija Sahni Senior Foreman Repair Unit 7 02.",
        "Vishwanath Shrirang HSK 3 Repair Unit 7 03.",
        "Ram Vilas HSK 1 Repair Unit 7"
      ],
      "word_count": 193,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "name_of_the\nship/establishment",
          "department",
          "system",
          "sub-system",
          "unique_identification\ncode",
          "oem"
        ],
        "data": [
          [
            "INS Bagh",
            "Electrical",
            "Radar System",
            "Waveguide\nAssembly",
            "44444",
            "ABC"
          ]
        ]
      },
      {
        "columns": [
          "date_defect\noccurred",
          "date_defect\nresolved",
          "if_defect_still_outstanding,_reasons_thereof"
        ],
        "data": [
          [
            "01/04/2024",
            "05/4/2024",
            "Applicable"
          ]
        ]
      },
      {
        "columns": [
          "brief_description_of_the_defect",
          "defect_analysis"
        ],
        "data": [
          [
            "Inconsistent power levels detected",
            "The magnetron was experiencing power fluctuations, which were fixed by\ninstalling a new magnetron."
          ]
        ]
      },
      {
        "columns": [
          "steps_taken_to_resolve_the_defect",
          "spare_parts_used_to_resolve_the\ndefect",
          "important_correspondence_related_to\ndefect_analysis_and_resolution\n(opdef,_storedem,_etc,)"
        ],
        "data": [
          [
            "The radar system was powered off,\nand all high-voltage components\nwere discharged. The damaged\nWaveguide Assembly was removed\nas per the system's manual. After the",
            "Waveguide Assembly",
            "DEFECTREP 06/24, PARTDEL 07/24"
          ]
        ]
      },
      {
        "columns": [
          "sl._no.",
          "name",
          "rank/designation",
          "unit"
        ],
        "data": [
          [
            "01.",
            "Asija Sahni",
            "Senior Foreman",
            "Repair Unit 7"
          ],
          [
            "02.",
            "Vishwanath Shrirang",
            "HSK 3",
            "Repair Unit 7"
          ],
          [
            "03.",
            "Ram Vilas",
            "HSK 1",
            "Repair Unit 7"
          ]
        ]
      }
    ],
    "metadata": {
      "Author": "Skand Pujari",
      "Creator": "Microsoft® Word 2021",
      "CreationDate": "D:20241105210155+05'30'",
      "ModDate": "D:20241105210155+05'30'",
      "Producer": "Microsoft® Word 2021"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Bagh Electrical Radar System Control Board 55555 ABC Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-05-01 2024-05-05 Not Applicable Defect Analysis Brief Description of the Defect Defect Analysis The magnetron had a short circuit issue that was resolved through the System shutdown unexpectedly replacement of the faulty component. Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, Following the safe power-down of the radar system and the discharge of all capacitors, the defective Control Control Board SYSTEMCHK 08/24, ORDERCONF 09/24 Board was carefully removed. A new control board was installed based on the systems technical specifications. Functional checks, including signal processing, system control commands, and diagnostic feedback, were conducted. The systems performance was confirmed to be stable and within the required operational limits. Key Personnel involved in Defect Analysis and Resolution Sl. No. Name Rank/Designation Unit 01. Tika Ram Senior Foreman Repair Unit 1 02. S Desai HSK 2 Repair Unit 1 03. Vishwanath Shrirang HSK 3 Repair Unit 1",
    "structured_text": {
      "sentences": [
        "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Bagh Electrical Radar System Control Board 55555 ABC Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-05-01 2024-05-05 Not Applicable Defect Analysis Brief Description of the Defect Defect Analysis The magnetron had a short circuit issue that was resolved through the System shutdown unexpectedly replacement of the faulty component.",
        "Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, Following the safe power-down of the radar system and the discharge of all capacitors, the defective Control Control Board SYSTEMCHK 08/24, ORDERCONF 09/24 Board was carefully removed.",
        "A new control board was installed based on the systems technical specifications.",
        "Functional checks, including signal processing, system control commands, and diagnostic feedback, were conducted.",
        "The systems performance was confirmed to be stable and within the required operational limits.",
        "Key Personnel involved in Defect Analysis and Resolution Sl.",
        "No.",
        "Name Rank/Designation Unit 01.",
        "Tika Ram Senior Foreman Repair Unit 1 02.",
        "S Desai HSK 2 Repair Unit 1 03.",
        "Vishwanath Shrirang HSK 3 Repair Unit 1"
      ],
      "word_count": 200,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "name_of_the\nship/establishment",
          "department",
          "system",
          "sub-system",
          "unique_identification\ncode",
          "oem"
        ],
        "data": [
          [
            "INS Bagh",
            "Electrical",
            "Radar System",
            "Control Board",
            "55555",
            "ABC"
          ]
        ]
      },
      {
        "columns": [
          "date_defect\noccurred",
          "date_defect\nresolved",
          "if_defect_still_outstanding,_reasons_thereof"
        ],
        "data": [
          [
            "01/05/2024",
            "05/5/2024",
            "Not Applicable"
          ]
        ]
      },
      {
        "columns": [
          "brief_description_of_the_defect",
          "defect_analysis"
        ],
        "data": [
          [
            "System shutdown unexpectedly",
            "The magnetron had a short circuit issue that was resolved through the\nreplacement of the faulty component."
          ]
        ]
      },
      {
        "columns": [
          "steps_taken_to_resolve_the_defect",
          "spare_parts_used_to_resolve_the\ndefect",
          "important_correspondence_related_to\ndefect_analysis_and_resolution\n(opdef,_storedem,_etc,)"
        ],
        "data": [
          [
            "Following the safe power-down of the\nradar system and the discharge of all\ncapacitors, the defective Control\nBoard was carefully removed. A new\ncontrol board was installed based on\nthe system's technical specifications.",
            "Control Board",
            "SYSTEMCHK 08/24, ORDERCONF 09/24"
          ]
        ]
      },
      {
        "columns": [
          "sl._no.",
          "name",
          "rank/designation",
          "unit"
        ],
        "data": [
          [
            "01.",
            "Tika Ram",
            "Senior Foreman",
            "Repair Unit 1"
          ],
          [
            "02.",
            "S Desai",
            "HSK 2",
            "Repair Unit 1"
          ],
          [
            "03.",
            "Vishwanath Shrirang",
            "HSK 3",
            "Repair Unit 1"
          ]
        ]
      }
    ],
    "metadata": {
      "Author": "Skand Pujari",
      "Creator": "Microsoft® Word 2021",
      "CreationDate": "D:20241105210201+05'30'",
      "ModDate": "D:20241105210201+05'30'",
      "Producer": "Microsoft® Word 2021"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Cheetah Electrical Radar System Magnetron 66666 DEF Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-06-01 2024-06-05 Not Applicable Defect Analysis Brief Description of the Defect Defect Analysis Magnetron showed signs of overheating, resolved by replacing with a new Weak or intermittent signal output unit. Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, Input/output voltage, current, and performance were tested to confirm Magnetron OPDEF 01/24, STOREDEM 01/24 the replacement met system requirements. Key Personnel involved in Defect Analysis and Resolution Sl. No. Name Rank/Designation Unit 01. Tika Ram Senior Foreman Repair Unit 1 02. S Desai HSK 2 Repair Unit 1 03. Vishwanath Shrirang HSK 3 Repair Unit 1",
    "structured_text": {
      "sentences": [
        "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Cheetah Electrical Radar System Magnetron 66666 DEF Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-06-01 2024-06-05 Not Applicable Defect Analysis Brief Description of the Defect Defect Analysis Magnetron showed signs of overheating, resolved by replacing with a new Weak or intermittent signal output unit.",
        "Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, Input/output voltage, current, and performance were tested to confirm Magnetron OPDEF 01/24, STOREDEM 01/24 the replacement met system requirements.",
        "Key Personnel involved in Defect Analysis and Resolution Sl.",
        "No.",
        "Name Rank/Designation Unit 01.",
        "Tika Ram Senior Foreman Repair Unit 1 02.",
        "S Desai HSK 2 Repair Unit 1 03.",
        "Vishwanath Shrirang HSK 3 Repair Unit 1"
      ],
      "word_count": 149,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "name_of_the\nship/establishment",
          "department",
          "system",
          "sub-system",
          "unique_identification\ncode",
          "oem"
        ],
        "data": [
          [
            "INS Cheetah",
            "Electrical",
            "Radar System",
            "Magnetron",
            "66666",
            "DEF"
          ]
        ]
      },
      {
        "columns": [
          "date_defect\noccurred",
          "date_defect\nresolved",
          "if_defect_still_outstanding,_reasons_thereof"
        ],
        "data": [
          [
            "01/06/2024",
            "05/6/2024",
            "Not Applicable"
          ]
        ]
      },
      {
        "columns": [
          "brief_description_of_the_defect",
          "defect_analysis"
        ],
        "data": [
          [
            "Weak or intermittent signal output",
            "Magnetron showed signs of overheating, resolved by replacing with a new\nunit."
          ]
        ]
      },
      {
        "columns": [
          "steps_taken_to_resolve_the_defect",
          "spare_parts_used_to_resolve_the\ndefect",
          "important_correspondence_related_to\ndefect_analysis_and_resolution\n(opdef,_storedem,_etc,)"
        ],
        "data": [
          [
            "Input/output voltage, current, and\nperformance were tested to confirm\nthe replacement met system\nrequirements.",
            "Magnetron",
            "OPDEF 01/24, STOREDEM 01/24"
          ]
        ]
      },
      {
        "columns": [
          "sl._no.",
          "name",
          "rank/designation",
          "unit"
        ],
        "data": [
          [
            "01.",
            "Tika Ram",
            "Senior Foreman",
            "Repair Unit 1"
          ],
          [
            "02.",
            "S Desai",
            "HSK 2",
            "Repair Unit 1"
          ],
          [
            "03.",
            "Vishwanath Shrirang",
            "HSK 3",
            "Repair Unit 1"
          ]
        ]
      }
    ],
    "metadata": {
      "Author": "Skand Pujari",
      "Creator": "Microsoft® Word 2021",
      "CreationDate": "D:20241105210212+05'30'",
      "ModDate": "D:20241105210212+05'30'",
      "Producer": "Microsoft® Word 2021"
    },
    "error_message": null
  },
  {
    "original_file": ".",
    "cleaned_text": "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Cheetah Electrical Radar System Power Supply Unit 77777 DEF Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-03-01 05/03/24 Applicable Defect Analysis Brief Description of the Defect Defect Analysis Weak signal output Overheating issue in power supply unit resolved by replacement. Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, Input/output voltage, current, and overall performance were tested to Power Supply Unit REPAIRREQ 02/24, MATREQ 03/24 ensure compliance with operational standards. Key Personnel involved in Defect Analysis and Resolution Sl. No. Name Rank/Designation Unit 01. Sanatan Gridharan Foreman Repair Unit 4 02. Vishwanath Shrirang HSK 3 Repair Unit 4 03. S Desai HSK 2 Repair Unit 4",
    "structured_text": {
      "sentences": [
        "Critical Defects Analysis Reports Basic Information Name of the Unique Identification Department System Sub-System OEM Ship/Establishment Code INS Cheetah Electrical Radar System Power Supply Unit 77777 DEF Date Defect Date Defect If defect still outstanding, reasons thereof Occurred Resolved 2024-03-01 05/03/24 Applicable Defect Analysis Brief Description of the Defect Defect Analysis Weak signal output Overheating issue in power supply unit resolved by replacement.",
        "Defect Resolution Important correspondence related to Spare parts used to resolve the Steps taken to resolve the defect defect analysis and resolution defect OPDEF, STOREDEM, etc, Input/output voltage, current, and overall performance were tested to Power Supply Unit REPAIRREQ 02/24, MATREQ 03/24 ensure compliance with operational standards.",
        "Key Personnel involved in Defect Analysis and Resolution Sl.",
        "No.",
        "Name Rank/Designation Unit 01.",
        "Sanatan Gridharan Foreman Repair Unit 4 02.",
        "Vishwanath Shrirang HSK 3 Repair Unit 4 03.",
        "S Desai HSK 2 Repair Unit 4"
      ],
      "word_count": 146,
      "sections": {}
    },
    "tables": [
      {
        "columns": [
          "name_of_the\nship/establishment",
          "department",
          "system",
          "sub-system",
          "unique_identification\ncode",
          "oem"
        ],
        "data": [
          [
            "INS Cheetah",
            "Electrical",
            "Radar System",
            "Power Supply Unit",
            "77777",
            "DEF"
          ]
        ]
      },
      {
        "columns": [
          "date_defect\noccurred",
          "date_defect\nresolved",
          "if_defect_still_outstanding,_reasons_thereof"
        ],
        "data": [
          [
            "01/03/2024",
            "05/03/24",
            "Applicable"
          ]
        ]
      },
      {
        "columns": [
          "brief_description_of_the_defect",
          "defect_analysis"
        ],
        "data": [
          [
            "Weak signal output",
            "Overheating issue in power supply unit; resolved by replacement."
          ]
        ]
      },
      {
        "columns": [
          "steps_taken_to_resolve_the_defect",
          "spare_parts_used_to_resolve_the\ndefect",
          "important_correspondence_related_to\ndefect_analysis_and_resolution\n(opdef,_storedem,_etc,)"
        ],
        "data": [
          [
            "Input/output voltage, current, and\noverall performance were tested to\nensure compliance with operational\nstandards.",
            "Power Supply Unit",
            "REPAIRREQ 02/24, MATREQ 03/24"
          ]
        ]
      },
      {
        "columns": [
          "sl._no.",
          "name",
          "rank/designation",
          "unit"
        ],
        "data": [
          [
            "01.",
            "Sanatan Gridharan",
            "Foreman",
            "Repair Unit 4"
          ],
          [
            "02.",
            "Vishwanath Shrirang",
            "HSK 3",
            "Repair Unit 4"
          ],
          [
            "03.",
            "S Desai",
            "HSK 2",
            "Repair Unit 4"
          ]
        ]
      }
    ],
    "metadata": {
      "Author": "Skand Pujari",
      "Creator": "Microsoft® Word 2021",
      "CreationDate": "D:20241105210219+05'30'",
      "ModDate": "D:20241105210219+05'30'",
      "Producer": "Microsoft® Word 2021"
    },
    "error_message": null
  }
]